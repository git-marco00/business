{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "openai.api_key = \"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\"\n",
    "old_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_documentation(code):\n",
    "    prompt = f\"Please generate documentation for the following code:\\n\\n{code}\\n\\nDocumentation:\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-002\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=500,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    return response.choices[0].text.strip()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_metric(doc):\n",
    "    prompt = f\"Please give me a measure of how much semantically correct this documentation is from 0 to 10:\\n\\n{doc}\\n\\n\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-002\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=500,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    return response.choices[0].text.strip()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import word_tokenize\n",
    "def similarity_score(code_snippet, generated_doc):\n",
    "    # Tokenize the code snippet and generated documentation\n",
    "    code_tokens = word_tokenize(code_snippet)\n",
    "    doc_tokens = word_tokenize(generated_doc)\n",
    "\n",
    "    # Convert the code snippet and generated documentation to strings\n",
    "    code_str = ' '.join(code_tokens)\n",
    "    doc_str = ' '.join(doc_tokens)\n",
    "\n",
    "    # Create a TfidfVectorizer object\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Fit the vectorizer on the code snippet and generated documentation\n",
    "    vectorizer.fit_transform([code_str, doc_str])\n",
    "\n",
    "    # Compute the cosine similarity between the code snippet and generated documentation vectors\n",
    "    similarity = cosine_similarity(vectorizer.transform([code_str]), vectorizer.transform([doc_str]))\n",
    "\n",
    "    return similarity[0][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Set the LanguageTool API URL\n",
    "url = 'https://api.languagetool.org/v2/check'\n",
    "\n",
    "# Set the language of the text\n",
    "language = 'en-US'\n",
    "def check_grammar(text):\n",
    "    # Set the API parameters\n",
    "    params = {\n",
    "        'text': text,\n",
    "        'language': language,\n",
    "    }\n",
    "    # Send a GET request to the API and get the response\n",
    "    response = requests.get(url, params=params)\n",
    "    # Parse the response and get the number of grammar errors\n",
    "    errors = response.json()['matches']\n",
    "    num_errors = len(errors)\n",
    "    print(num_errors)\n",
    "    return num_errors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Ñode_blocks_21.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"results.csv\")\n",
    "code = \"\"\n",
    "code_id = dataset.iloc[0]['kaggle_id']\n",
    "count =0\n",
    "for index, row in dataset.iterrows():\n",
    "    if row['code_block_id']>6:\n",
    "        continue\n",
    "    if row['kaggle_id']==code_id:\n",
    "        code += row['code_block']\n",
    "    else:\n",
    "        documentation = generate_documentation(code)\n",
    "        semantic_ev = generate_metric(documentation)\n",
    "        grammar_ev = check_grammar(documentation)\n",
    "        similarity = similarity_score(code, documentation)\n",
    "        new_row = {\"code_block\":code, \"documentation\":documentation, \"evaluation\":semantic_ev, \"grammar_errors\": grammar_ev, \"similarity measure\": similarity}\n",
    "        df=df.append(new_row, ignore_index=True)\n",
    "        df.to_csv(\"results.csv\")\n",
    "        count +=1\n",
    "        code_id=row['kaggle_id']\n",
    "        code = row['code_block']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# RESULTS ANALYSIS\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(\"results_grammar_errors.csv\")\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_null = df['code_block'].isnull().sum()\n",
    "num_null"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['evaluation'] = df['evaluation'].apply(lambda x: int(x) if len(x) == 1 else x)\n",
    "num_strings = df['evaluation'].apply(lambda x: isinstance(x, str)).sum()\n",
    "num_strings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num = [len(df), num_null, num_strings]\n",
    "labels = [\"Total number of rows\", \"Number of null rows\", \"Number of wrong evaluations\"]\n",
    "data = pd.DataFrame({\"Rows\": num, \"Labels\":labels})\n",
    "sns.barplot(x='Labels', y='Rows', data=data)\n",
    "plt.title('Bar plot using seaborn')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df = df.drop(df[df['evaluation'].apply(lambda x: type(x) == str)].index)\n",
    "num_null = df['code_block'].isnull().sum()\n",
    "print(num_null)\n",
    "num_strings = df['evaluation'].apply(lambda x: isinstance(x, str)).sum()\n",
    "print(num_strings)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped_df = df.groupby('evaluation')['code_block'].count().reset_index()\n",
    "print(grouped_df)\n",
    "sns.barplot(x='evaluation', y='code_block', data=grouped_df)\n",
    "plt.title('Number of code snippets per evaluation number')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# grammar analysis\n",
    "# group by a specific column\n",
    "grouped = df.groupby('evaluation')\n",
    "\n",
    "# calculate the mean, median, and max of another specific column for each group\n",
    "aggregated = grouped['num_grammar_errors'].agg(['min', 'mean', 'max'])\n",
    "print(aggregated)\n",
    "\n",
    "# reset the index to make the group column a regular column\n",
    "aggregated = aggregated.reset_index()\n",
    "\n",
    "# reshape the data into long form using the melt method\n",
    "melted = pd.melt(aggregated, id_vars='evaluation', var_name='statistic', value_name='number of grammar errors')\n",
    "\n",
    "# plot the mean, median, and max of the aggregation column for each group in the same graph\n",
    "sns.set(style='whitegrid')\n",
    "sns.catplot(x='evaluation', y='number of grammar errors', hue='statistic', kind='bar', data=melted)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"CODE BLOCK:\\n\")\n",
    "print(df.loc[df['evaluation'] == 7].iloc[2]['code_block'])\n",
    "print(\"\\n\\nDOCUMENTATION:\\n\")\n",
    "print(df.loc[df['evaluation'] == 7].iloc[2]['documentation'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"CODE BLOCK:\\n\")\n",
    "print(df.loc[df['evaluation'] == 8].iloc[2]['code_block'])\n",
    "print(\"\\n\\nDOCUMENTATION:\\n\")\n",
    "print(df.loc[df['evaluation'] == 8].iloc[2]['documentation'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"CODE BLOCK:\\n\")\n",
    "print(df.loc[df['evaluation'] == 9].iloc[1]['code_block'])\n",
    "print(\"\\n\\nDOCUMENTATION:\\n\")\n",
    "print(df.loc[df['evaluation'] == 9].iloc[1]['documentation'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate the maximum, minimum and average number of words per value\n",
    "max_words = df['code_block'].apply(lambda x: len(re.split(r'[ /.]', x))).max()\n",
    "min_words = df['code_block'].apply(lambda x: len(re.split(r'[ /.]', x))).min()\n",
    "avg_words = df['code_block'].apply(lambda x: len(re.split(r'[ /.]', x))).mean()\n",
    "\n",
    "num = [max_words, avg_words, min_words]\n",
    "labels = [\"Max\", \"Average\", \"Min\"]\n",
    "data = pd.DataFrame({\"Number of words\": num, \"Distribution\":labels})\n",
    "print(data)\n",
    "sns.barplot(x='Distribution', y='Number of words', data=data)\n",
    "plt.title('Number of words per code_block')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate the maximum, minimum and average number of words per value\n",
    "max_words = df['documentation'].apply(lambda x: len(re.split(r'[ /.]', x))).max()\n",
    "min_words = df['documentation'].apply(lambda x: len(re.split(r'[ /.]', x))).min()\n",
    "avg_words = df['documentation'].apply(lambda x: len(re.split(r'[ /.]', x))).mean()\n",
    "\n",
    "num = [max_words, avg_words, min_words]\n",
    "labels = [\"Max\", \"Average\", \"Min\"]\n",
    "data = pd.DataFrame({\"Number of words\": num, \"Distribution\":labels})\n",
    "print(data)\n",
    "sns.barplot(x='Distribution', y='Number of words', data=data)\n",
    "plt.title('Number of words per documentation')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# why similarity measure is not so good\n",
    "\n",
    "plt.boxplot(df['similarity measure'])\n",
    "\n",
    "# set the title and axis labels\n",
    "plt.title('Box plot of the similarity measure')\n",
    "plt.ylabel('similarity')\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
