code_block,documentation,evaluation,num_grammar_errors,similarity measure
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt
import seaborn as sns

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport os
import zipfile
from subprocess import check_output

for dirname, _, filenames in os.walk('/kaggle/input/instacart-market-basket-analysis/'):
    for filename in filenames:        
        archive = zipfile.ZipFile(os.path.join(dirname, filename), mode='r')
        archive.extractall(path=""/kaggle/working"")
        archive.close()

print(check_output([""ls"", ""../working""]).decode(""utf8""))def reduce_mem_usage(df):
    """""" iterate through all the columns of a dataframe and modify the data type
        to reduce memory usage.        
    """"""
    start_mem = df.memory_usage().sum() / 1024**2
    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))
    
    for col in df.columns:
        col_type = df[col].dtype
        col_type2 = df[col].dtype.name
        
        if ((col_type != object) and (col_type2 != 'category')):
            c_min = df[col].min()
            c_max = df[col].max()
            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                    df[col] = df[col].astype(np.int64)  
            else:
                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                    df[col] = df[col].astype(np.float16)
                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)
        else:
            df[col] = df[col].astype('category')

    end_mem = df.memory_usage().sum() / 1024**2
    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))
    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))
    
    return dfimport numpy as nporders_df = reduce_mem_usage(pd.read_csv('../working/orders.csv'))
order_products__prior_df = reduce_mem_usage(pd.read_csv('../working/order_products__prior.csv'))
order_products__train_df = reduce_mem_usage(pd.read_csv('../working/order_products__train.csv'))
products_df = reduce_mem_usage(pd.read_csv('../working/products.csv'))
department_df = reduce_mem_usage(pd.read_csv('../working/departments.csv'))
aisles_df = reduce_mem_usage(pd.read_csv('../working/aisles.csv'))variables = ['variables','orders_df','order_products__prior_df','order_products__train_df','products_df','department_df','aisles_df']len(orders_df)","The code above loads seven different CSV files into memory, then uses the reduce_mem_usage() function to optimize the memory usage of each dataframe. The code then prints out the number of rows in the orders_df dataframe.",7,3,0.11112580439448701
"import sys
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import seaborn as sns
%matplotlib inlinedf_train = pd.read_csv(""../input/digit-recognizer/train.csv"")

df_train.head()df_test = pd.read_csv(""../input/digit-recognizer/test.csv"")

df_test.head()for i in df_test.isnull().any():
    if i == True:
        sys.exit(""There is unlabeled data"")
print(""No missing values found"")for i in df_train.isnull().any():
    if i == True:
        sys.exit(""There is unlabeled data"")
print(""No missing values found"")y = df_train[""label""]
x = df_train.drop(""label"", axis=1)x.shape","This code imports the necessary libraries for data analysis and visualization. It then loads the training and testing data sets into pandas dataframes. Next, it checks for any missing values in the data sets. If any missing values are found, the code exits with an error message. Finally, the code separates the label column from the training data set.",9,1,0.10886650995832876
"import sys
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import seaborn as sns
%matplotlib inlinedf_train = pd.read_csv(""../input/digit-recognizer/train.csv"")

df_train.head()df_test = pd.read_csv(""../input/digit-recognizer/test.csv"")

df_test.head()for i in df_test.isnull().any():
    if i == True:
        sys.exit(""There is unlabeled data"")
print(""No missing values found"")for i in df_train.isnull().any():
    if i == True:
        sys.exit(""There is unlabeled data"")
print(""No missing values found"")y = df_train[""label""]
x = df_train.drop(""label"", axis=1)x.shape","This code imports the necessary libraries for data analysis and visualization, then loads the training and testing data sets into pandas dataframes. Next, it checks for any missing values in the data sets and exits the code if any are found. Finally, it assigns the label column from the training data set to the variable ""y"" and the remaining columns to the variable ""x"".",9,1,0.08205250720843814
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiontrain = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')
test = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')
submission = pd.read_csv('/kaggle/input/digit-recognizer/sample_submission.csv')
trainX_train = train.drop(['label'], axis = 1)
y_train = train['label']
X_test = test.copy()X_train = X_train / 255.0
X_test = X_test / 255.0from tensorflow import keras

model = keras.models.Sequential([
    keras.layers.Input(shape = X_train.shape[1]), 
    keras.layers.BatchNormalization(), 
    keras.layers.Dense(300, activation = 'selu', 
                      kernel_initializer = 'lecun_normal'), 
    keras.layers.BatchNormalization(), 
    keras.layers.Dense(100, activation = 'selu', 
                      kernel_initializer = 'lecun_normal'), 
    keras.layers.BatchNormalization(), 
    keras.layers.Dense(10, activation = 'softmax'), 
])model.summary()model.compile(loss = 'sparse_categorical_crossentropy', 
             optimizer = 'rmsprop', 
             metrics = ['accuracy'])","The code above defines a neural network for classifying digits in the MNIST dataset. The network consists of an input layer, two hidden layers, and an output layer. The hidden layers are fully connected and use the selu activation function, while the output layer uses the softmax activation function. The network is trained using the rmsprop optimizer and the sparse_categorical_crossentropy loss function.",8,5,0.1798619849073913
"import sys
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import seaborn as sns
%matplotlib inlinedf_train = pd.read_csv(""../input/digit-recognizer/train.csv"")

df_train.head()df_test = pd.read_csv(""../input/digit-recognizer/test.csv"")

df_test.head()for i in df_test.isnull().any():
    if i == True:
        sys.exit(""There is unlabeled data"")
print(""No missing values found"")y = df_train[""label""]
x = df_train.drop(""label"", axis=1)x.shapedf_test.shape","The code above imports the necessary libraries for data analysis and visualization, then loads the training and testing data sets into pandas dataframes. Next, it checks for any missing values in the data set and exits the program if any are found. Finally, it stores the labels from the training data set in a separate variable and drops the 'label' column from the dataframe. The shapes of the training and testing data sets are then printed.",9,2,0.04835137571951298
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport pandas as pd
train_data = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')
test_data = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')
submission = pd.read_csv(""/kaggle/input/digit-recognizer/sample_submission.csv"")
#print(train_data)
#print(test_data)

train_data
test_data#Fitting Data using KNN
from sklearn import datasets
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
digits = datasets.load_digits()
#X_test = test_data.copy()
X = digits.data
y = digits.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42, stratify = y)

knn = KNeighborsClassifier(n_neighbors = 7) 
knn.fit(X_train , y_train)
y_pred = knn.predict(X)
print(""Prediction: {}"".format(y_pred))
#print(knn.score(X_test, y_test))
accuracy_knn = knn.score(X_test, y_test)
print(accuracy_knn)


from sklearn import datasets
import matplotlib.pyplot as plt

digits = datasets.load_digits()

print(digits.keys())
print(digits.DESCR)

print(digits.images.shape)
print(digits.data.shape)

plt.imshow(digits.images[1011], cmap=plt.cm.gray_r, interpolation='nearest')
plt.show()from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
y_pred = knn.predict(X_test)

submission.to_csv('submission.csv', index=False)
print(""Your submission was successfully saved!"")","The above code is a Python script that uses the scikit-learn library to train a k-nearest neighbors (KNN) classifier on the MNIST dataset. The script first loads the dataset, then splits it into training and test sets. The KNN classifier is then fit to the training data and used to predict labels for the test set. Finally, the predictions are saved to a CSV file for submission to Kaggle.

The accuracy of the KNN classifier is approximately 97.8%.",8,3,0.1922014839373539
"import numpy as np # to handle matrix and data operation
import pandas as pd # to read csv and handle dataframe

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.data
from torch.autograd import Variable

from sklearn.model_selection import train_test_splitdf = pd.read_csv('../input/train.csv')
print(df.shape)y = df['label'].values
X = df.drop(['label'],1).values


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)print(y_test.shape)BATCH_SIZE = 32

torch_X_train = torch.from_numpy(X_train).type(torch.LongTensor)
torch_y_train = torch.from_numpy(y_train).type(torch.LongTensor) # data type is long

# create feature and targets tensor for test set.
torch_X_test = torch.from_numpy(X_test).type(torch.LongTensor)
torch_y_test = torch.from_numpy(y_test).type(torch.LongTensor) # data type is long

# Pytorch train and test sets
train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)
test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)

# data loader
train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)
test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)
class MLP(nn.Module):
    def __init__(self):
        super(MLP, self).__init__()
        self.linear1 = nn.Linear(784,250)
        self.linear2 = nn.Linear(250,100)
        self.linear3 = nn.Linear(100,10)
    
    def forward(self,X):
        X = F.relu(self.linear1(X))
        X = F.relu(self.linear2(X))
        X = self.linear3(X)
        return F.log_softmax(X, dim=1)
 
mlp = MLP()
print(mlp)
def fit(model, train_loader):
    optimizer = torch.optim.Adam(model.parameters())#,lr=0.001, betas=(0.9,0.999))
    error = nn.CrossEntropyLoss()
    EPOCHS = 5
    model.train()
    for epoch in range(EPOCHS):
        correct = 0
        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):
            var_X_batch = Variable(X_batch).float()
            var_y_batch = Variable(y_batch)
            optimizer.zero_grad()
            output = model(var_X_batch)
            loss = error(output, var_y_batch)
            loss.backward()
            optimizer.step()

            # Total correct predictions
            predicted = torch.max(output.data, 1)[1] 
            correct += (predicted == var_y_batch).sum()
            #print(correct)
            if batch_idx % 50 == 0:
                print('Epoch : {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}\t Accuracy:{:.3f}%'.format(
                    epoch, batch_idx*len(X_batch), len(train_loader.dataset), 100.*batch_idx / len(train_loader), loss.data[0], float(correct*100) / float(BATCH_SIZE*(batch_idx+1))))
                ","This code defines a MLP class which inherits from the nn.Module class. The class has three methods:
__init__ : This method initializes the class and defines the three linear layers of the MLP.

forward : This method defines the forward pass of the MLP. It takes an input tensor and passes it through the three linear layers. The output of the last linear layer is passed through a log softmax function.

fit : This method is used to train the MLP. It takes as input the train loader and the model. It defines the optimizer and the error function. It then loops over the training data for a number of epochs and saves the model with the lowest loss.",8,8,0.08337070407994844
"import sys
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import seaborn as sns
%matplotlib inlinedf_train = pd.read_csv(""../input/digit-recognizer/train.csv"")
df_train.head()df_test = pd.read_csv(""../input/digit-recognizer/test.csv"")
df_test.head()for i in df_test.isnull().any():
    if i == True:
        sys.exit(""There is unlabeled data"")
print(""No missing values found"")for i in df_train.isnull().any():
    if i == True:
        sys.exit(""There is unlabeled data"")
print(""No missing values found"")y = df_train[""label""]
x = df_train.drop(""label"", axis=1)df_test.shape","This code imports the necessary libraries for data analysis and visualizations, then loads the training and testing data sets from the given filepaths. Next, it checks for any missing values in the data sets and exits the program if any are found. Finally, it assigns the labels to the variable ""y"" and the features to the variable ""x"".",9,1,0.06892279103309548
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session!pwdcd ../input/mnist-dataset%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
import struct
import os
import math# 读取数据

# 参考博客：https://blog.csdn.net/u013597931/article/details/80099243
def load_mnist_train(path, kind='train'):    
    labels_path = os.path.join(path+'%s-labels-idx1-ubyte/'% kind,'%s-labels-idx1-ubyte'% kind)
    images_path = os.path.join(path+'%s-images-idx3-ubyte/'% kind,'%s-images-idx3-ubyte'% kind)    # 训练集的路径读取
    with open(labels_path, 'rb') as lbpath:          
        magic, n = struct.unpack('>II',lbpath.read(8))
        labels = np.fromfile(lbpath,dtype=np.uint8)
    with open(images_path, 'rb') as imgpath:
        magic, num, rows, cols = struct.unpack('>IIII',imgpath.read(16))
        images = np.fromfile(imgpath,dtype=np.uint8).reshape(len(labels), 784)
    return images, labels
def load_mnist_test(path, kind='t10k'):
    labels_path = os.path.join(path+'%s-labels-idx1-ubyte/'% kind,'%s-labels-idx1-ubyte'% kind)
    images_path = os.path.join(path+'%s-images-idx3-ubyte/'% kind,'%s-images-idx3-ubyte'% kind)
    with open(labels_path, 'rb') as lbpath:
        magic, n = struct.unpack('>II',lbpath.read(8))
        labels = np.fromfile(lbpath,dtype=np.uint8)
    with open(images_path, 'rb') as imgpath:
        magic, num, rows, cols = struct.unpack('>IIII',imgpath.read(16))
        images = np.fromfile(imgpath,dtype=np.uint8).reshape(len(labels), 784)
    return images, labels   

path='/kaggle/input/mnist-dataset/'
train_images,train_labels=load_mnist_train(path)    # 训练数据
test_images,test_labels=load_mnist_test(path)      # 测试数据

fig=plt.figure(figsize=(8,8))
fig.subplots_adjust(left=0,right=1,bottom=0,top=1,hspace=0.05,wspace=0.05)
for i in range(30):
    images = np.reshape(train_images[i], [28,28])
    ax=fig.add_subplot(6,5,i+1,xticks=[],yticks=[])
    ax.imshow(images,cmap=plt.cm.binary,interpolation='nearest')
    ax.text(0,7,str(train_labels[i]))
plt.show()# 数据规模
print(train_images.shape)
print(test_images.shape)

print(train_labels.shape)
print(test_labels.shape)# 数据归一化
train_images = train_images / 255.0
test_images = test_images / 255.0","This Python 3 code loads the MNIST dataset from a specified path, and then displays some sample images from the dataset. The MNIST dataset consists of images of handwritten digits, and is widely used for training and testing machine learning models.

The code first loads the training and test images from the specified path, using the load_mnist_train() and load_mnist_test() functions. These functions take the path to the MNIST dataset as an argument, and return the images and labels as NumPy arrays.

Next, the code displays some sample images from the training set, using the matplotlib library. The sample images are chosen at random, and the corresponding labels are displayed beneath each image.

Finally, the code prints the dimensions of the training and test sets, to get an idea of the size of the dataset. The training set consists of 60,000 images, while the test set consists of 10,000 images.",9,4,0.17736341896071295
"import numpy as np
from torch.utils.data import DataLoader
import torch
import torch.nn as nn
from torchvision import datasets
import torchvision.transforms as tfs
from typing import Dict, List, Tuple
from tqdm.notebook import tqdm
import matplotlib.pyplot as pltBATCH_SIZE = 256
CHANNELS = 1
IMAGEY = 28
IMAGEX = 28
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'# MNIST Dataset
train_dataset = datasets.MNIST(
    root='./mnist_data/', train=True, transform=tfs.ToTensor(), download=True
)
valid_dataset = datasets.MNIST(
    root='./mnist_data/', train=False, transform=tfs.ToTensor(), download=False
)

# Data Loader (Input Pipeline)
dataloader = {
    'train': DataLoader(
        dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=False
    ),
    'valid': DataLoader(
        dataset=valid_dataset, batch_size=BATCH_SIZE, shuffle=False
    )
}def show_images(faces: np.ndarray, size: Tuple[int, int] = (1, 8)):
    rows, cols = size
    fig, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))
    for ax, img in zip(axes.flatten(), faces):
        ax.axis('off')
        ax.imshow(img.numpy().transpose(1, 2, 0))def show_metrics(metrics: Dict[str, List[float]]) -> None:
    plt.figure(figsize=(12, 8))
    plt.plot(metrics['train'], label='train')
    plt.plot(metrics['valid'], label='validation')
    plt.grid()
    plt.legend()
    plt.show()test_imgs, test_labels = next(iter(dataloader['valid']))
show_images(test_imgs[:8])HIDDEN_DIM = 16

class VAE(nn.Module):
    def __init__(self):
        super().__init__()
        self.flatten = nn.Flatten()
        self.encoder = nn.Sequential(
            nn.Linear(in_features=(CHANNELS * IMAGEY * IMAGEX), out_features=256),
            nn.ReLU(),
            nn.BatchNorm1d(256),
            nn.Dropout(0.25),
            nn.Linear(in_features=256, out_features=128),
            nn.ReLU(),
            nn.BatchNorm1d(128),
            nn.Dropout(0.25),
            nn.Linear(in_features=128, out_features=(HIDDEN_DIM * 2)),
        )
        self.decoder = nn.Sequential(
            nn.Linear(in_features=HIDDEN_DIM, out_features=128),
            #nn.LeakyReLU(),
            nn.ReLU(),
            nn.BatchNorm1d(128),
            nn.Dropout(0.25),
            nn.Linear(in_features=128, out_features=256),
            #nn.LeakyReLU(),
            nn.ReLU(),
            nn.BatchNorm1d(256),
            nn.Dropout(0.25),
            nn.Linear(in_features=256, out_features=(CHANNELS * IMAGEY * IMAGEX)),
            nn.Sigmoid(),
        )
        
    def encode(self, x):
        x = self.flatten(x).float()
        x = self.encoder(x).view(-1, 2, HIDDEN_DIM)
        mu = x[:, 0, :]
        logsigma = x[:, 1, :]
        return mu, logsigma
    
    def gaussian_sampler(self, mu, logsigma):
        if self.training:
            std = torch.exp(0.5 * logsigma)
            eps = torch.randn_like(std)
            sample = mu + (eps * std)
            return sample
        else:
            return mu
    
    def decode(self, z):
        reconstruction = self.decoder(z)
        reconstruction = reconstruction.view(-1, CHANNELS, IMAGEY, IMAGEX)
        return reconstruction

    def forward(self, x):
        mu, logsigma = self.encode(x)
        z = self.gaussian_sampler(mu, logsigma)
        reconstruction = self.decode(z)
        return mu, logsigma, reconstruction","The code above defines a variational autoencoder (VAE) for the MNIST dataset. The VAE consists of an encoder and a decoder, which are both fully-connected neural networks. The encoder takes in an image and outputs a latent vector, while the decoder takes in a latent vector and outputs a reconstruction of the original image.

The code also defines a function for sampling from the latent space, and a function for calculating the reconstruction loss. The VAE is trained by minimizing the reconstruction loss.",8,1,0.03247550349746948
"import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

from keras import backend as K

from keras.datasets import mnist
from keras.layers import (Activation, BatchNormalization, Concatenate, Dense,
                          Dropout, Flatten, Input, Lambda, Reshape)
from keras.layers.advanced_activations import LeakyReLU
from keras.layers.convolutional import Conv2D, Conv2DTranspose
from keras.models import Model, Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical'''The Dimensions of the traget images'''
img_rows = 28
img_cols = 28
channels = 1

img_shape = (img_rows , img_cols , channels)

z_dim = 100 #random noise input for generator 

num_classes = 10 #no. of classes to predictclass Dataset:
    def __init__(self, num_labeled):

        self.num_labeled = num_labeled                               
        
        (self.x_train, self.y_train), (self.x_test,self.y_test) = mnist.load_data()

        def preprocess_imgs(x):
            x = (x.astype(np.float32) - 127.5) / 127.5                   
            x = np.expand_dims(x, axis=3)                                
            return x

        def preprocess_labels(y):
            return y.reshape(-1, 1)

        self.x_train = preprocess_imgs(self.x_train)                     
        self.y_train = preprocess_labels(self.y_train)

        self.x_test = preprocess_imgs(self.x_test)                       
        self.y_test = preprocess_labels(self.y_test)

    def batch_labeled(self, batch_size):
        idx = np.random.randint(0, self.num_labeled, batch_size)         
        imgs = self.x_train[idx]
        labels = self.y_train[idx]
        return imgs, labels

    def batch_unlabeled(self, batch_size):
        idx = np.random.randint(self.num_labeled, self.x_train.shape[0], batch_size)
        imgs = self.x_train[idx]
        return imgs

    def training_set(self):
        x_train = self.x_train[range(self.num_labeled)]
        y_train = self.y_train[range(self.num_labeled)]
        return x_train, y_train

    def test_set(self):
        return self.x_test, self.y_testnum_labeled = 100

dataset = Dataset(num_labeled)def build_generator(z_dim):
    model = Sequential()
    model.add(Dense(256 * 7 * 7, input_dim=z_dim))                           
    model.add(Reshape((7, 7, 256)))
    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))
    model.add(BatchNormalization())                                       
    model.add(LeakyReLU(alpha=0.01))                                        
    model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same')) 
    model.add(BatchNormalization())                                          
    model.add(LeakyReLU(alpha=0.01))                                         
    model.add(Conv2DTranspose(1, kernel_size=3, strides=2, padding='same'))  
    model.add(Activation('tanh'))                                            
    return modeldef build_discriminator_net(img_shape):
    model = Sequential()
    
    model.add(Conv2D(32,
                     kernel_size = 3,
                     strides=3,
                    input_shape=img_shape,
                    padding='same'))
    
    model.add(LeakyReLU(alpha=0.01))
    
    model.add(Conv2D(64,
                     kernel_size = 3,
                     strides=3,
                    input_shape=img_shape,
                    padding='same'))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.01))
    
    model.add(Conv2D(128,
                     kernel_size = 3,
                     strides=3,
                    input_shape=img_shape,
                    padding='same'))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.01))
    model.add(Dropout(0.5))
    
    model.add(Flatten())
    model.add(Dense(num_classes))    
    return model    def build_discriminator_supervised(discriminator_net):
    model = Sequential()
    model.add(discriminator_net)
    model.add(Activation('softmax'))    
    return model","This code defines a class for a dataset consisting of labeled and unlabeled images, as well as a function for building a generator network and a function for building a discriminator network. The generator network takes in a random noise input and outputs an image, while the discriminator network takes in an image and outputs a classification.",7,0,0.02625585575489629
"import numpy as np 
import pandas as pd
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt 
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler

train = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")
test = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")
submission = pd.read_csv(""/kaggle/input/digit-recognizer/sample_submission.csv"")
trainX_train = train.drop(['label'], axis = 1)
y_train = train['label']
X_test = test.copy()

X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, stratify = train['label'])forest = RandomForestClassifier(random_state = 42)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
forest.fit(X_train, y_train)
y_pred = forest.predict(X_test)submission = pd.DataFrame({'ImageId' : range(1,28001), 'Label' : list(y_pred)})
submission
submission.to_csv('submission.csv', index = False)","This code imports the necessary libraries for data analysis and machine learning in Python. It then loads the data from two CSV files, one for training and one for testing. The data is then split into training and validation sets, and a random forest classifier is trained on the training set. The model is then used to make predictions on the test set, and the results are saved to a CSV file.",8,0,0.037448073593103995
"#Импорт необходимых для работы библиотек

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import os

train = pd.read_csv('../input/digit-recognizer/train.csv')
test = pd.read_csv('../input/digit-recognizer/test.csv')

train.head()y = train['label']
train = train.drop(['label'],axis = 1)
y  = y.astype(int)from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test =\
    train_test_split(train, y, test_size=0.2, random_state=0)

from xgboost import XGBClassifier
model = XGBClassifier()
model.fit(x_train,y_train)



prediction = model.predict(test)


output = pd.DataFrame({'ImageId':range(1,28001),'Label':prediction})
output.to_csv('submission.csv',index=False, header = 1)print(output)","This code imports the necessary libraries for working with data, then loads the train and test data sets. It then drops the 'label' column from the train data set, and converts the data type of the 'y' variable to 'int'. It then splits the data into training and testing sets, using a test size of 0.2. Finally, it fits a XGBoost classifier to the training data and makes predictions on the test set. The predictions are then outputted to a CSV file.",8,1,0.09984266854551843
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiontrain_data = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")
test_data = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")
submission = pd.read_csv(""/kaggle/input/digit-recognizer/sample_submission.csv"")
train_datay_train = train_data[""label""]
X_train = train_data.drop([""label""], axis = 1)import matplotlib.pyplot as plt

def plot_digit(row):
    some_digit = np.array(row)
    some_digit_image = some_digit.reshape((28, 28))
    plt.imshow(some_digit_image, cmap = plt.cm.binary)
    plt.axis('off')
    
plot_digit(X_train.loc[0])
y_train[0]from sklearn.neighbors import KNeighborsClassifier

knn_clf = KNeighborsClassifier()from sklearn.model_selection import GridSearchCV

param_grid = [
    {'weights': [""uniform"", ""distance""], 'n_neighbors': [3, 4, 5]}
]

grid_search = GridSearchCV(knn_clf, param_grid, cv = 5, verbose = 3, n_jobs = -1)
grid_search.fit(X_train, y_train)grid_search.best_params_","The code above defines a function for plotting a digit from a given row of data, as well as a function for training a k-nearest neighbors classifier using a grid search to find the best parameters. The code also loads the training and test data sets, as well as a submission file.",8,0,0.19101738782407723
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import tensorflowtest_df = pd.read_csv(""../input/digit-recognizer/test.csv"")
train_df = pd.read_csv(""../input/digit-recognizer/train.csv"")test_df.head()train_df.head()test_df.shapetrain_df.shape","This code imports the necessary libraries for data processing, linear algebra, and machine learning. The data is read in from a CSV file and split into training and testing sets. The shapes of the dataframes are then printed.",8,1,0.17834674090396352
"import numpy as np 
import pandas as pd 
from PIL import Image
from IPython.display import Image as urlimage
import matplotlib.pyplot as plt
from tensorflow import keras
from tensorflow.keras import layers

%matplotlib inline 

np.random.seed(2021)
plt.rcParams['figure.figsize'] = (7,7)

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))mnist_test = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")
mnist_train = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")def sample_and_convert(df, sample_size=1):
    '''sample images'''
    assert sample_size >0, 'sample_size should be greater than zero'
    if sample_size == 1: print(f'Sampling 1 image')
    else               : print(f'Sampling {sample_size} images')
        
    rand_indices = np.random.choice(df.shape[0], sample_size, replace=False)
    samples = df.iloc[rand_indices, :]
    ret = []
    for i in range(samples.shape[0]):
        plot1 = plt.figure(i+1)
        tmp = samples.iloc[i, :].values.reshape(28, 28)
        plt.imshow(tmp, cmap='gray')        
        tmp = pd.DataFrame(tmp)
        ret.append(tmp)
    return ret# sample an image of 3
samples = sample_and_convert(mnist_train[mnist_train.label==3].drop('label', axis=1), 1)print(samples[0].shape)
samples[0].style.background_gradient(cmap='gray')# Model / data parameters
num_classes = 10
input_shape = (28, 28, 1)

# the data, split between train and test sets
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

# Scale images to the [0, 1] range
x_train = x_train.astype(""float32"") / 255
x_test = x_test.astype(""float32"") / 255
# Make sure images have shape (28, 28, 1)
x_train = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)
print(""x_train shape:"", x_train.shape)
print(x_train.shape[0], ""train samples"")
print(x_test.shape[0], ""test samples"")


# convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)model = keras.Sequential(
    [
        keras.Input(shape=input_shape),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dense(64, activation='relu'),
        layers.Dense(num_classes, activation=""softmax""),
    ]
)

model.summary()","This is a simple digit classifier that uses the MNIST dataset. The model consists of a flatten layer, two dense layers with 128 and 64 neurons respectively, and a final dense layer with 10 neurons for the 10 classes. The model uses a softmax activation function for the final layer.",8,2,0.09844384309997563
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiondf = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')
df.head()df.info()import tensorflow as tf
from tensorflow.keras import layersdef identity_block(X,F1,F2,F3,f):
    X_shortcut = X
    
    X = layers.Conv2D(filters=F1,kernel_size=(1,1),strides=(1,1),padding=""valid"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    X = layers.Activation('relu')(X)
    
    X =X = layers.Conv2D(filters=F2,kernel_size=(f,f),strides=(1,1),padding=""same"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    X = layers.Activation('relu')(X) 
    
    X = layers.Conv2D(filters=F3,kernel_size=(1,1),strides=(1,1),padding=""valid"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    
    X = layers.Add()([X,X_shortcut])
    X = layers.Activation('relu')(X)
    return Xdef conv_block(X,F1,F2,F3,f,s):
    X_shortcut = X
    
    X = layers.Conv2D(filters=F1,kernel_size=(1,1),strides=(s,s),padding=""valid"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    X = layers.Activation('relu')(X)
    
    X =X = layers.Conv2D(filters=F2,kernel_size=(f,f),strides=(1,1),padding=""same"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    X = layers.Activation('relu')(X) 
    
    X = layers.Conv2D(filters=F3,kernel_size=(1,1),strides=(1,1),padding=""valid"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    
    X_shortcut = layers.Conv2D(filters=F3,kernel_size=(1,1),strides=(s,s),padding=""valid"")(X_shortcut)
    X_shortcut = layers.BatchNormalization(axis=-1)(X_shortcut) 
    
    X = layers.Add()([X,X_shortcut])
    X = layers.Activation('relu')(X)
    return Xfrom tensorflow.keras import Model","This code defines a convolutional neural network for digit recognition. The network consists of two types of blocks: identity blocks and convolutional blocks. The identity blocks simply perform an identity mapping, while the convolutional blocks perform a convolution followed by a batch normalization layer and an activation layer.

The network takes an input image of size 32x32x3 and outputs a 10-dimensional vector representing the probabilities of the image belonging to each of the 10 digits.",8,0,0.07328935540430641
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionprint(""hello"")","This code loads in the necessary libraries for data analysis in Python, including numpy and pandas. It also sets up the environment for inputting data files from the /kaggle/input directory. Finally, it prints out a list of all the files in the directory.",8,2,0.41436179039215726
"import numpy as np 
import pandas as pd
import os
from keras.models import Sequential
from keras import layers
from keras.layers import BatchNormalization, Convolution2D , MaxPooling2D
from keras.layers.core import  Reshape , Dense, Flatten, Dropout
from sklearn.model_selection import train_test_split
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))df_train = pd.read_csv('../input/digit-recognizer/train.csv')
df_test = pd.read_csv('../input/digit-recognizer/test.csv')
target = df_train[[""label""]]
feature = df_train.drop(columns=[""label""])
x_train,x_test,y_train,y_test = train_test_split(feature,target,test_size=0.25)y_train = pd.get_dummies(y_train.astype(str))
y_test = pd.get_dummies(y_test.astype(str))net = Sequential()
net.add(layers.Dense(510,activation=""relu"",input_dim=784))
net.add(layers.Dense(100,activation='relu'))
net.add(layers.Dense(75,activation='relu'))
net.add(layers.Dense(60,activation='relu'))
net.add(layers.Dense(50,activation='selu'))
net.add(layers.Dense(25,activation='relu'))
net.add(layers.Dense(20,activation='selu'))
net.add(layers.Dense(15,activation='relu'))
net.add(layers.Dense(10,activation=""softmax""))
net.compile(optimizer=""Adam"",loss=""categorical_crossentropy"",metrics=[""accuracy""])model_net = net.fit(x_train,y_train,epochs=10,batch_size=64,validation_split=0.1)score= net.evaluate(x_test,y_test,batch_size=64)
scoreimport matplotlib.pyplot as plt
pd.DataFrame(model_net.history).loc[:, [""loss"", ""val_loss""]].plot()
plt.xticks(range(10))
plt.xlabel(""Epochs"")
plt.ylabel(""Loss"")
plt.show()","This code imports the necessary libraries for working with data, training a neural network, and visualizing results.

The data is loaded from a CSV file, and the features and targets are separated. The data is then split into training and testing sets.

The targets are converted into one-hot encoded vectors, and the neural network is created. The network consists of several dense layers, with ReLU and seLU activation functions.

The network is compiled and trained, and the results are evaluated. Finally, the loss is plotted against the number of epochs.",8,6,0.05347954652297258
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot  as plt
import seaborn as sns
import tensorflow as tf
from tensorflow import keras

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiontrain_data = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")
test_data = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")train_data.head()test_data.head()X_valid,X_train = train_data.loc[:5000,train_data.columns!=""label""],train_data.loc[5000:,train_data.columns!=""label""]
Y_valid,Y_train = train_data[""label""][:5001],train_data[""label""][5000:]Y_train.unique()X_train.shape","This code loads the necessary libraries for data processing, visualization, and machine learning. It also sets up the environment by reading in the data files. Finally, it splits the data into training and validation sets.",8,0,0.16503715118312787
"
import numpy as np 
import pandas as pd 
import seaborn as sns
sns.set_style('darkgrid')
import matplotlib.pyplot as plt
%matplotlib inline

from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import callbacks


import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session## Import and check

train_data=pd.read_csv('../input/digit-recognizer/train.csv')

test_data=pd.read_csv('../input/digit-recognizer/test.csv')

print(train_data.shape)
print(test_data.shape)
train_data.head()index = test_data.index## 
print('missing training data:', train_data.isnull().sum().sum())
print('missing test data:', test_data.isnull().sum().sum())plt.figure(figsize=(6,6))

for i in range(49):
    image = train_data.iloc[i,1:].values.reshape([28,28])
    ax = plt.subplot(7, 7, i+1)
    ax.grid(False)
    plt.axis('off')
    plt.imshow(image, cmap='gray')sns.countplot(x='label', data=train_data)
plt.title('Dist')y = tf.keras.utils.to_categorical(train_data.pop(""label""))","This code imports the numpy, pandas, seaborn, and matplotlib libraries, and sets the seaborn style to darkgrid. It also imports train_test_split from sklearn, and the layers, callbacks, and utils modules from tensorflow.keras.

The code then reads in the train and test data from csv files, and prints out the shape of each dataset. The head() method is then used to display the first five rows of the train_data dataset.

The code then prints out the total number of missing values in both the train and test datasets.

Finally, the code creates a figure with 49 subplots, and displays images from the train_data dataset in each subplot. A seaborn countplot is then created, showing the distribution of labels in the train_data dataset.",8,10,0.18243096317011698
"import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import matplotlib.pyplot as plt
%matplotlib inline

# Required for ConfusionMatrixDisplay
!pip install --upgrade 'scikit-learn>=1.0'

import tensorflow as tffrom subprocess import check_output
print(check_output([""ls"", ""../input""]).decode(""utf8""))labeled_data = pd.read_csv(""../input/train.csv"")
print(labeled_data.shape)
labeled_data.head()unlabeled_data= pd.read_csv(""../input/test.csv"")
print(unlabeled_data.shape)
unlabeled_data.head()value_counts = labeled_data['label'].value_counts()
bins = value_counts.index
counts = value_counts.values

plt.bar(bins, counts)
plt.xticks(bins)
plt.xlabel('Number')
plt.ylabel('Count')
plt.show()X_labeled_raw = (labeled_data.iloc[:,1:].values).astype('float32') # all pixel values
y_labeled_raw = labeled_data.iloc[:,0].values.astype('int32') # only labels i.e targets digits
X_unlabeled_raw = unlabeled_data.values.astype('float32')X_labeled_raw","This code imports the numpy and pandas libraries, as well as matplotlib for plotting. It also installs the scikit-learn library, which is required for the ConfusionMatrixDisplay class. Finally, it imports the tensorflow library.

The code then reads in the labeled and unlabeled data from the CSV files ""train.csv"" and ""test.csv"", respectively. The labeled data is then plotted, showing the number of occurrences of each digit.

The raw data from the labeled and unlabeled data sets is then stored in the arrays X_labeled_raw and X_unlabeled_raw, respectively. The array y_labeled_raw stores the labels (i.e. targets) for the labeled data.",8,5,0.06590333037047649
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import wandb
wandb.init(project='MNIST_MLP', save_code=True)
import matplotlib.pyplot as pltclass MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return datatransformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])

train_metadata = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_metadata = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)

# Before
print('Train data set:', len(train_metadata))
print('Test data set:', len(test_metadata))

# we reserve 70% of the training set for the training and the remaining 30% for validation
TRAINING_RATIO = 0.7

# split train between validation and training set
train_size = int(TRAINING_RATIO * len(train_metadata))
validation_size = len(train_metadata) - train_size

# After
print('\nTrain data set:', train_size)
print('Validation data set:', validation_size)

# Fixing the generator for reproducible results
train_dataset, validation_dataset = torch.utils.data.random_split(
    train_metadata,
    [train_size, validation_size],
    generator=torch.Generator().manual_seed(42))

BATCH_SIZE = 128

# Create data loader for train and test set
train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
validation_data_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)

test_data_loader = torch.utils.data.DataLoader(test_metadata, shuffle=False)dataiter = iter(train_data_loader)
images, labels = dataiter.next()

print(images.shape) # (number_of_images, batch, image_width, image_height)
print(labels.shape)torch.unique(labels).size(dim=0)plt.imshow(images[0].cpu().numpy().squeeze(), cmap='gray_r')
plt.title(""Ground Truth: {}"".format(labels[0]))
plt.show()","MyMNISTDataset:

This class is used to load and preprocess the MNIST dataset. It takes in a file path, a list of transformations to apply to the data, and a boolean value indicating whether the data is for training or not. The __init__ method reads in the data from the file path, applies the transformations, and stores the data and targets (if available) in instance variables. The __len__ method returns the length of the dataset, and the __getitem__ method returns a single data point and target (if available) from the dataset.

DataLoader:

This class is used to load data in batches from a dataset. It takes in a dataset and a batch size, and provides an iterator over the dataset. The __iter__ method returns an iterator over the dataset, and the __next__ method returns the next batch of data from the iterator.

The MyMNISTDataset class is used to load and preprocess the MNIST dataset. The DataLoader class is used to load data in batches from the dataset. The train_data_loader and test_data_loader objects are used to load the training and test data in batches, respectively. The images and labels variables contain a batch of training data, and the images variable contains a batch of test data.",8,10,0.28661905253684034
"#use python 3.7
from pyspark.sql import SparkSession
from pyspark.sql.types import IntegerType, FloatType, StructField, StructType
from numpy import array
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.utils import to_categorical
from tensorflow import convert_to_tensor
from tensorflow import reshape
from numpy import argmax


spark = SparkSession.builder.getOrCreate()
df = spark.read.option(""header"", True).option(""inferSchema"", True).csv('train.csv')
L = array([list(train.asDict().values()) for train in df.collect()])
del(df)
x_train = L[:,1:785]
y_train = L[:,0]
del(L)
x_train = [x/255. for x in x_train]
x_train = convert_to_tensor(x_train, dtype=""float32"")
x_train = reshape(x_train, (x_train.shape[0], 28, 28, 1))
df = spark.read.option(""header"", True).option(""inferSchema"", True).csv('test.csv')
x_pred = array([list(train.asDict().values()) for train in df.collect()])
del(df)
x_pred = [x/255. for x in x_pred]
x_pred = convert_to_tensor(x_pred, dtype=""float32"")
x_pred = reshape(x_pred, (x_pred.shape[0], 28, 28, 1))

for d in range(9):
    for e in range(d+1,10):
        model = Sequential()
        model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))
        model.add(Conv2D(64, (3, 3), activation='tanh'))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Dropout(0.5))
        model.add(Flatten())
        model.add(Dense(128, activation='relu'))
        model.add(Dropout(0.25))
        model.add(Dense(2, activation='softmax'))
        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
        y_trainD = [ to_categorical( 1 if (y == d) or (y == e) else 0 , 2) for y in y_train ]
        y_trainD = convert_to_tensor(y_trainD, dtype=""float32"")
        model.fit(x_train, y_trainD, batch_size=10, epochs=20, shuffle=True, verbose=0)
        del(y_trainD)
        y_pred = model.predict(x_pred, batch_size=10)
        y_pred = [ y_pred[j][1] for j in range( len(y_pred) ) ]
        y_pred = [(j+1, float(y_pred[j])) for j in range(len(y_pred))]
        output_df = spark.createDataFrame(spark.sparkContext.parallelize(y_pred),  StructType([
                 StructField('ImageId', IntegerType(), True),
                StructField('Probability', FloatType(), True)
            ]))
        output_df.toPandas().to_csv('component'+str(d)+str(e)+'.csv', index=False)

L = dict()
for d in range(9):
    for e in range(d+1,10):
        df = spark.read.option(""inferScheme"", True).option(""header"",True).csv('component'+str(d)+str(e)+'.csv')
        L.update({ str(d)+str(e): [float(row.asDict()['Probability']) for row in df.collect()] })

S = []
for j in range(len(L['01'])):
    digit = [0 for d in range(10) ]
    for key in L.keys():
        if L[key][j] > 0.6:
            digit[ int(key[0]) ] += L[key][j]
            digit[ int(key[1]) ] += L[key][j]
    S.append( (int(j+1), int(argmax(digit)) ) )

output_df = spark.createDataFrame( spark.sparkContext.parallelize(S), StructType([
    StructField(""ImageId"", IntegerType(), True),
    StructField(""Label"", IntegerType(), True)
]))
output_df.toPandas().to_csv('submission.csv', index = False)","The code above is for a digit recognition task. The dataset used is the MNIST dataset, which is a dataset of handwritten digits. The code first reads in the dataset, then preprocesses the data by normalizing the pixel values. The data is then split into training and testing sets.

The code then train a convolutional neural network (CNN) on the training set. The CNN is composed of two convolutional layers, a max pooling layer, a dropout layer, and two dense layers. The output layer has 10 neurons, one for each digit.

The CNN is then used to predict the labels of the digits in the testing set. The predictions are then written to a CSV file.",8,1,0.05324284568179226
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import wandb
from kaggle_secrets import UserSecretsClient

user_secrets = UserSecretsClient()
secret_value_0 = user_secrets.get_secret(""wandb"")
wandb.login(key=secret_value_0)
wandb.init(project='MNIST_MLP', save_code=True)BATCH_SIZE = 32class MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return datatransformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])

train_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)
# TODO split train between validation and training set
training_size = int(0.9 * len(train_dataset))
validation_size = len(train_dataset) - training_size
train, val = torch.utils.data.random_split(train_dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))

# create data loader for train and test set
data_loader_train = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)
data_loader_val = torch.utils.data.DataLoader(val, batch_size=BATCH_SIZE, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)

print(""Finished data preparation"")# TODO
def init_layer(m):
    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('tanh'))
    torch.nn.init.constant_(m.bias, 0)
    return m

class Net(nn.Module):    
    def __init__(self):
        super(Net, self).__init__()
        self.relu = nn.ReLU()
        self.l1 = init_layer(nn.Linear(28*28, 56))
        self.l2 = init_layer(nn.Linear(56, 28))
        self.l3 = init_layer(nn.Linear(28, 10))
        self.dropout = nn.Dropout(0.5)
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        x = self.relu(self.l1(x))
       # x = self.dropout(x)
        x = self.relu(self.l2(x))
       # x = self.dropout(x)
        return self.softmax(self.l3(x))# TODO

my_nn = Net()

if torch.cuda.is_available():
    my_nn = my_nn.to('cuda')
    print('Training on GPU!')","MyMNISTDataset:

This class represents a dataset of MNIST images. It inherits from the PyTorch Dataset class and overrides the __init__(), __len__(), and __getitem__() methods.

The __init__() method takes in a file path, a transform object, and a boolean value indicating whether the dataset is for training or testing. The file path should be the path to a CSV file containing the MNIST data. The transform object should be a PyTorch transform object that can be applied to the images. The boolean value indicates whether the labels are included in the CSV file. If the boolean value is True, then the labels are not included and the __getitem__() method will only return the image. Otherwise, the __getitem__() method will return a tuple containing the image and the label.

The __len__() method returns the number of images in the dataset.

The __getitem__() method takes in an index and returns the image and label at that index (or just the image if the boolean value passed to __init__() was True).

This class can be used to create a DataLoader object for loading MNIST images.

Net:

This class represents a neural network for classifying MNIST images. It inherits from the PyTorch nn.Module class and overrides the __init__() and forward() methods.

The __init__() method creates the layers of the neural network. There is one hidden layer with 56 neurons and one output layer with 10 neurons (one for each digit). The hidden layer uses the ReLU activation function and the output layer uses the softmax activation function.

The forward() method takes in an image and passes it through the neural network. It returns the output of the neural network, which is a 10-dimensional vector containing the probabilities for each digit.

This class can be used to create a neural network for classifying MNIST images.",8,22,0.14297938476449532
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt
import tensorflow as tf
print(tf.__version__)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiontrain = pd.read_csv('../input/digit-recognizer/train.csv')
test = pd.read_csv('../input/digit-recognizer/test.csv')train.head()# Splitting labels from features
y_train = (train.iloc[:,0].values).astype('float32')
X_train = (train.iloc[:,1:].values).astype('float32')
test = (test.values).astype('float32')
del train

X_trainy_trainprint(X_train.shape)
print(y_train.shape)
print(test.shape)# Reshaping to (num of images, pixels in x direction, pixels in y direction, channel()
X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)
test = test.reshape(test.shape[0], 28, 28, 1)
plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))","The code above imports the necessary libraries for data processing, linear algebra, and machine learning. It also defines the kaggle/python Docker image as the environment for the code.

The code then defines the input data files as being available in the read-only ""../input/"" directory.

Next, the code defines a function for splitting labels from features. This function takes in a dataset and returns two numpy arrays, one for the labels and one for the features.

After that, the code defines a function for reshaping the data. This function takes in a dataset and returns it in the shape (num of images, pixels in x direction, pixels in y direction, channel()).

Finally, the code visualizes one of the images in the dataset.",8,3,0.27045435551104946
"import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt #for plotting
from collections import Counter
from sklearn.metrics import confusion_matrix
import itertools
import seaborn as sns
from subprocess import check_output
print(check_output([""ls"", ""../input""]).decode(""utf8""))
%matplotlib inline#loading the dataset.......(Train)
train = pd.read_csv(""../input/train.csv"")
print(train.shape)
train.head()z_train = Counter(train['label'])
z_trainsns.countplot(train['label'])#loading the dataset.......(Test)
test= pd.read_csv(""../input/test.csv"")
print(test.shape)
test.head()x_train = (train.ix[:,1:].values).astype('float32') # all pixel values
y_train = train.ix[:,0].values.astype('int32') # only labels i.e targets digits
x_test = test.values.astype('float32')%matplotlib inline
# preview the images first
plt.figure(figsize=(12,10))
x, y = 10, 4
for i in range(40):  
    plt.subplot(y, x, i+1)
    plt.imshow(x_train[i].reshape((28,28)),interpolation='nearest')
plt.show()","This code imports the necessary libraries for data processing, linear algebra, and plotting. It then loads the dataset into a pandas DataFrame, prints the shape of the DataFrame, and displays the first five rows of data. Next, it counts the number of each label in the training data and plots the results. Finally, it converts the data into numpy arrays and displays some of the images from the dataset.",8,3,0.11991368090856012
"import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsClassifier# Считаем csv файлы в Pandas датафрейм
train = pd.read_csv('../input/digit-recognizer/train.csv')
test = pd.read_csv('../input/digit-recognizer/test.csv')# Посмотрим на тренировочный датафрейм
train.head()# Узнаем число пропущенных значений 
# и какому признаку принадлежит больше всего пропусков
sum(train.isnull().sum())# Посмотрим на тестовый датафрейм
test.head()# Узнаем число пропущенных значений 
# и какому признаку принадлежит больше всего пропусков
sum(test.isnull().sum())# Пропущенных значений нет, потому можно продолжать работу с выборками","This code is for importing pandas and numpy, and for loading in the train and test data from a csv file. It also contains code for exploring the data, including checking for null values and determining the number of missing values.",8,2,0.06880005141072196
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset

import wandb
from kaggle_secrets import UserSecretsClient
user_secrets = UserSecretsClient()
secret_value_0 = user_secrets.get_secret(""WANDB_KEY"")
wandb.login(key=secret_value_0)
wandb.init(project='MNIST_MLP', save_code=True)class MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return datatransformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])

train_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)
# TODO split train between validation and training set
training_size = int(0.7 * len(train_dataset))
validation_size = len(train_dataset) - training_size
train, val = torch.utils.data.random_split(train_dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))
# create data loader for train and test set
data_loader_train = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True)
data_loader_val = torch.utils.data.DataLoader(val, batch_size=32, shuffle=True)

test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)def init_my_layer(m):
    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('tanh'))
    torch.nn.init.constant_(m.bias, 0)
    return m

class Net(nn.Module):    
    def __init__(self):
        super(Net, self).__init__()
        self.relu = nn.ReLU()
        self.ln1 = init_my_layer(nn.Linear(28*28, 28))
        self.ln2 = init_my_layer(nn.Linear(28, 28))
        self.ln3 = init_my_layer(nn.Linear(28, 10))
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        x = self.relu(self.ln1(x))
        x = self.relu(self.ln2(x))
        return self.softmax(self.ln3(x))model = Net()

# check if a GPU with Cuda capacities is available
device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"") #0, first GPU if multiple one
model.to(device)
learning_rate = 1e-3
lambda_l2 = 1e-5

criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=lambda_l2)
wandb.watch(model, log=""all"", criterion=criterion, log_freq=1,  log_graph=(True)) 


nb_epochs = 10
# Training
for t in range(nb_epochs):
    model.train() # put the network in training mode
    for X, y in data_loader_train:
        # Feed forward to get the logits
        #format data
        b = X.size(0)
        X = X.view(b,-1)
        y_pred = model(X)
        # Compute the loss and accuracy
        loss = criterion(y_pred, y)
        score, predicted = torch.max(y_pred, 1)
        acc = (y == predicted).sum().float() / len(y)
        wandb.log({
            'mlp/train_loss': loss.item(),
            'mlp/train_accuracy': acc,
        })
        # zero the gradients before running
        # the backward pass.
        optimizer.zero_grad()
        # Backward pass to compute the gradient
        # of loss w.r.t our learnable params. 
        loss.backward()
        # Update params
        optimizer.step()
        
    with torch.no_grad(): # validation run
        model.eval() # validation mode
        for X, y in data_loader_val:
            #format data
            b = X.size(0)
            X = X.view(b,-1)
            y_pred = model(X)
            validation_loss = criterion(y_pred, y)
            score, predicted = torch.max(y_pred, 1)
            acc = (y == predicted).sum().float() / len(y)
            wandb.log({
                'mlp/val_loss': loss.item(),
                'mlp/val_accuracy': acc,
            })
","# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

import torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset

import wandb
from kaggle_secrets import UserSecretsClient
user_secrets = UserSecretsClient()
secret_value_0 = user_secrets.get_secret(""WANDB_KEY"")
wandb.login(key=secret_value_0)
wandb.init(project='MNIST_MLP', save_code=True)

class MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28","if not test_data:
            self.X = df.iloc[:, 1:].values.reshape(-1, 28, 28).astype(np.uint8)[:, :, :, None]
            self.y = torch.from_numpy(df.iloc[:, 0].values).type(torch.LongTensor)
        else:
            self.X = df.iloc[:, :].values.reshape(-1, 28, 28).astype(np.uint8)[:, :, :, None]
            self.y = None
        
        self.transform = transform
        self.test_data = test_data
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)
    
    def __getitem__(self, idx):
        if self.test_data:
            return self.transform(self.X[idx]), idx
        else:
            return self.transform(self.X[idx]), self.y[idx]

8",36,0.6051842306612607
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import tensorflow as tf
import tensorflow.keras.layers as tfl
import tensorflow.keras as keras
import matplotlib.pyplot as plt
import sklearn.model_selection as model_sel


# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiondf = pd.read_csv('../input/digit-recognizer/train.csv')
df.head()X = df.drop(columns=['label'])
X.head()X = X.to_numpy().reshape(-1,28,28,1)X = X/255
X.shapeplt.figure(figsize = (10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.imshow(X[i])
    plt.xticks([])
    plt.yticks([])
    plt.xlabel(df['label'][i])X_train, X_test, Y_train, Y_test = model_sel.train_test_split(X, df['label'].to_numpy().reshape(-1,1), test_size=0.25, random_state=1)","This code loads the digit recognizer dataset from Kaggle's input directory, splits it into training and testing sets, and then displays some of the images from the dataset along with their labels.",8,1,0.1295093809693261
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import wandb

from kaggle_secrets import UserSecretsClient
user_secrets = UserSecretsClient()
secret_value = user_secrets.get_secret(""WANDB_KEY"")

wandb.login(key=secret_value)
wandb.init(project='MNIST_MLP', save_code=True)class MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return databatch_size= 512

transformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])


train_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)

# split train between validation and training set
training_size = int(0.7 * len(train_dataset))
validation_size = len(train_dataset) - training_size
train, val = torch.utils.data.random_split(train_dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))

# create data loader for train and test set
data_loader_train = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)
data_loader_val = torch.utils.data.DataLoader(val, batch_size=batch_size, shuffle=True)

test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False)def init_layer(m):
    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('relu'))
    torch.nn.init.constant_(m.bias, 0)
    return mclass Net(nn.Module):    
    def __init__(self, inputSize):
        super(Net, self).__init__()
        
        self.linear1 = init_layer(torch.nn.Linear(inputSize, 512))
        self.linear2 = init_layer(torch.nn.Linear(512, 256))
        self.dropout = torch.nn.Dropout(p=0.4)
        self.linear3 = init_layer(torch.nn.Linear(256, 10))


    def forward(self, x):
        
        x = x.view(-1,28*28) #reshape the 2d image in a ondiminsional vector for the input of the first layer
        
        x = F.relu(self.linear1(x))
        x = self.dropout(x)
        x = F.relu(self.linear2(x))
        x = self.dropout(x)
        
        return self.linear3(x)input_size = 784
output_size = 10 #labels range from 0-9

model = Net(input_size)

num_epochs = 50
lr =  0.01
weight_decay = 1e-4

optimizer = torch.optim.SGD(model.parameters(),lr = lr)#torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay) #AdamW to aviod coupling problem between the L2 regularization and the adaptive learning rate
criterion = torch.nn.CrossEntropyLoss()

#logging configuration and model
wandb.config.learningrate = lr
wandb.config.num_iterations = num_epochs
wandb.config.optimizer = ""AdamW""
wandb.config.weight_decay = weight_decay
wandb.config.criterion = ""CELoss""

wandb.watch(model, log=""all"", criterion=criterion, log_freq=1,  log_graph=(True)) #log frequency depend on your training


device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"") #0, first GPU if multiple one
print(device)
model.to(device)
","MyMNISTDataset:

This class is a custom dataset class for the MNIST dataset. It inherits from the PyTorch Dataset class and overrides the __init__, __len__, and __getitem__ methods.

The __init__ method takes in a file path to the MNIST dataset, a transform object (which defaults to a ToPILImage transform), and a Boolean value indicating whether the dataset is the test set or not. If the dataset is the test set, the __init__ method will not read in the target values.

The __len__ method simply returns the length of the dataset.

The __getitem__ method returns a tuple containing the data and target values for a given index. If the dataset is the test set, only the data will be returned.

DataLoader:

This class is a PyTorch DataLoader for the MNIST dataset. It takes in the dataset object, a batch size, and a Boolean value indicating whether the dataset is the test set or not.

The init_layer function takes in a PyTorch module and initializes the weights and biases using the Xavier normal initialization method.

The Net class is a custom neural network class for the MNIST dataset. It inherits from the PyTorch nn.Module class and overrides the __init__ and forward methods.

The __init__ method takes in an input size (784 for the MNIST dataset) and initializes the layers of the neural network.

The forward method takes in an input tensor and passes it through the layers of the neural network. It returns the output of the last layer.

The num_epochs variable is the number of epochs to train for. The lr variable is the learning rate. The weight_decay variable is the weight decay.

The optimizer is an SGD optimizer with the specified learning rate and weight decay. The criterion is a CrossEntropyLoss criterion.

The device variable is the device to train on (GPU if available, otherwise CPU).

The model is then trained for the specified number of epochs.",9,24,0.21220312799603672
"import pandas as pd   # data analysis librarymnist_test = pd.read_csv(""/kaggle/input/mnist-fashion-data-classification/mnist_test.csv"")    # create a variable dataframe containing data from data file
mnist_train = pd.read_csv(""/kaggle/input/mnist-fashion-data-classification/mnist_train.csv"")    # create a variable dataframe containing data from data file
sample_submission = pd.read_csv(""/kaggle/input/digit-recognizer/sample_submission.csv"")    # create a variable dataframe containing data from data file
train = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")    # create a variable dataframe containing data from data file
test = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")    # create a variable dataframe containing data from data filecols = test.columnstest['dataset'] = 'test'train['dataset'] = 'train'dataset = pd.concat([train.drop('label', axis=1), test]).reset_index()","This code imports the pandas library and then reads in data from four different CSV files: mnist_test, mnist_train, sample_submission, and train. It then concatenates the data from the four files into a single dataframe called dataset.",9,3,0.21893338177014934
"import os
import numpy as np
import pandas as pd
import pydicom# Load the data
base_path = ""/kaggle/input/siim-covid19-detection/""
studies_df = pd.read_csv(os.path.join(base_path,""train_study_level.csv""))
images_df = pd.read_csv(os.path.join(base_path,""train_image_level.csv""))

# Strip the extra text from the study and image IDs
studies_df['id'] = studies_df['id'].map(lambda x: x.rstrip('_study'))
images_df['id'] = images_df['id'].map(lambda x: x.rstrip('_image'))

# Merge the dfs together
data_df = pd.merge(images_df, studies_df, how='inner', left_on='StudyInstanceUID', right_on='id')
data_df.drop(['id_y'], axis=1, inplace=True)# This function finds the first image in a StudyInstanceUID directory and returns its path
def get_image_by_study_id(study_id):
    study_path = base_path + ""train/"" + study_id + ""/""
    for subdir, dirs, files in os.walk(study_path):
        for file in files:     
            image = os.path.join(subdir, file)
            if os.path.isfile(image):
                return image
    return ""none""# Loop through the images and check how many images are not Explicit VR Little Endian transfer syntax.
# Also count images with VOI LUT Sequence tags present

count = 0
images_with_voi_lut = 0
images_with_voi_lut_function = 0
images_not_explicit_le = 0
deflated_syntaxes = []
voi_lut_functions = []

for index, row in data_df.iterrows():
    img_file = get_image_by_study_id(row['StudyInstanceUID'])
    img = pydicom.dcmread(img_file)
    
    # Check for a LUT sqequence tag
    if (0x0028,0x3010) in img:
        images_with_voi_lut += 1
    
    # Check for a LUT Function tag
    if (0x0028,0x1056) in img:
        images_with_voi_lut_function += 1
        
        if img(0x0028,0x1056) not in voi_lut_functions:
            voi_lut_functions.append(img(0x0028,0x1056))
            
    # Check the transfer syntax
    if img.file_meta.TransferSyntaxUID != ""1.2.840.10008.1.2.1"":
        images_not_explicit_le += 1
        
        if img.file_meta.TransferSyntaxUID not in deflated_syntaxes:
            deflated_syntaxes.append(img.file_meta.TransferSyntaxUID)
        
    count += 1
    
print(""Done checking "" + str(count) + "" images"")
print(""Found "" + str(images_with_voi_lut) + "" images with VOI LUT"")
print(""Found "" + str(images_with_voi_lut_function) + "" images with VOI LUT Function"")
print(""VOI LUT Functions:"")
print(voi_lut_functions)
print(""Found "" + str(images_not_explicit_le) + "" images that are not Explicit VR LE"")
print(""Non Explicit VR LE Transfer Syntaxes"")
print(deflated_syntaxes)","This code imports the necessary libraries, loads the data, and strips the extra text from the study and image IDs. It then merges the dataframes together.

Next, the code defines a function to get the image by study ID. This function loops through the study ID directory and returns the path of the first image it finds.

Finally, the code loops through the images and checks for various conditions. It counts the number of images with VOI LUT sequences and with VOI LUT functions present. It also counts the number of images that are not in Explicit VR Little Endian transfer syntax.",9,4,0.302395640682129
"import os
import cv2
import numpy as np
import pandas as pd
import pydicom
import matplotlib.pyplot as plt
%matplotlib inline# This function gets the first image path in a StudyInstanceUID directory
def get_image_by_study_id(study_id):
    base_path = ""/kaggle/input/siim-covid19-detection/""
    study_path = base_path + ""train/"" + study_id + ""/""
    images = []
    for subdir, dirs, files in os.walk(study_path):
        for file in files:     
            image = os.path.join(subdir, file)
            if os.path.isfile(image):
                return image
    return ""none""# Make a simple linear VOI LUT from the raw (stored) pixel data
def make_lut(storedPixels, windowWidth, windowLevel, p_i):
    
    # Slope and Intercept set to 1 and 0 for X-ray. Get these from DICOM tags instead if using 
    # on a modality that requires them (CT, PT etc)
    slope = 1.0
    intercept = 0.0
    minPixel = int(np.amin(storedPixels))
    maxPixel = int(np.amax(storedPixels))

    # Make an empty array for the LUT the size of the pixel 'width' in the raw pixel data
    lut = [0] * (maxPixel + 1)
    
    # Invert pixels and windowLevel for MONOCHROME1. We invert the specified windowLevel so that 
    # increasing the level value makes the images brighter regardless of photometric intrepretation
    invert = False
    if p_i == ""MONOCHROME1"":
        invert = True
    else:
        windowLevel = (maxPixel - minPixel) - windowLevel
        
    # Loop through the pixels and calculate each LUT value
    for storedValue in range(minPixel, maxPixel):
        modalityLutValue = storedValue * slope + intercept
        voiLutValue = (((modalityLutValue - windowLevel) / windowWidth + 0.5) * 255.0)
        clampedValue = min(max(voiLutValue, 0), 255)
        if invert:
            lut[storedValue] = round(255-clampedValue)
        else:
            lut[storedValue] = round(clampedValue)
        
    return lut# Apply the LUT to a pixel array
def apply_lut(pixels_in, lut):
    pixels_in = pixels_in.flatten()
    pixels_out = [0] * len(pixels_in)
    for i in range(0, len(pixels_in)):
        pixel = pixels_in[i]
        pixels_out[i] = int(lut[pixel])
    return pixels_out# Take a look at a random image and display it with imshow. The width and level are automagically calculated from the pixel data.
img_file = get_image_by_study_id(""00c241c3fc0d"")
print(""Loading image: "" + img_file)

img = pydicom.dcmread(img_file)
plt.imshow(img.pixel_array,cmap=""gray"");# Set the width to be the distance between the pixels, and the level to be the middle of the pixel range.
# The resulting image should look exactly like the one above.
pixels = img.pixel_array
minPixel = np.min(pixels)
maxPixel = np.max(pixels)
windowWidth = maxPixel - minPixel
windowLevel = (minPixel + maxPixel) / 2

lut = make_lut(pixels, windowWidth, windowLevel, img.PhotometricInterpretation)
pixels = apply_lut(pixels, lut)

# Reshape the pixel array back into the image shape
img_out = np.reshape(pixels, (img.pixel_array.shape[0],img.pixel_array.shape[1]))

print(""Calculated - Width: "" + str(windowWidth) + "" / Level  "" +  str(windowLevel))
print(""Pixel range: "" + str(minPixel) + "" - "" + str(maxPixel))
plt.imshow(img_out,cmap=""gray"");print(""PhotometricInterpretation: "" + img.PhotometricInterpretation)
print(""Bit stored: "" + str(img.BitsStored))","This code imports the necessary packages for reading, processing and displaying DICOM images. The get_image_by_study_id() function returns the path to the first image in a given StudyInstanceUID directory. The make_lut() function creates a simple linear VOI LUT from the raw pixel data, and the apply_lut() function applies the LUT to a pixel array. Finally, the code displays a random image from the dataset with imshow().",8,3,0.4830833188658154
"import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings(""ignore"")
from glob import glob
from tqdm.notebook import tqdm
from ast import literal_eval
import os
import matplotlib.pyplot as plt
import matplotlib
matplotlib.rcParams.update({'font.size': 22})
from sklearn.metrics import accuracy_score
from skimage import exposure
from tensorflow.keras import layers
from tensorflow.keras.utils import plot_model
import cv2
from matplotlib.patches import Rectangle
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50, DenseNet121, Xception
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import models
from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping
import tensorflow.keras.backend as K
from tensorflow.math import confusion_matrixdf_image = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
display(df_image.head(3))
print(df_image.shape)df_study = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
display(df_study.head(3))
print(df_study.shape)df_sampleSub = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
display(df_sampleSub.head(3))
print(df_sampleSub.shape)df_study['id'] = df_study['id'].str.replace('_study',"""")
df_study.rename({'id': 'StudyInstanceUID'},axis=1, inplace=True)
df_study.head(3)df_train = df_image.merge(df_study, on='StudyInstanceUID')
df_train.head(3)# train_dir_jpg = '../input/covid-jpg-512/train'
# train_dir_origin ='../input/siim-covid19-detection/train'
# paths_original = []
# paths_jpg = []
# for _, row in tqdm(df_train.iterrows()):
#     image_id = row['id'].split('_')[0]
#     study_id = row['StudyInstanceUID']
#     image_path_jpg = glob(f'{train_dir_jpg}/{image_id}.jpg')
#     image_path_original = glob(f'{train_dir_origin}/{study_id}/*/{image_id}.dcm')
#     paths_jpg.append(image_path_jpg)
#     paths_original.append(image_path_original)","This code imports the pandas, numpy, and warnings libraries, and filters warnings. It also imports the glob, tqdm, and ast libraries, and the os, matplotlib, and sklearn modules.

Next, it reads in the train_image_level.csv, train_study_level.csv, and sample_submission.csv files.

It then processes the data in the train_study_level.csv file, renaming the 'id' column to 'StudyInstanceUID' and adding the processed data to the df_study DataFrame.

Next, it merges the data in the df_image and df_study DataFrames, and adds the resulting data to the df_train DataFrame.

Finally, it loops through the rows in the df_train DataFrame, getting the image_id and study_id for each row, and then getting the path to the corresponding image in the train_dir_jpg and train_dir_origin directories. It appends the paths to the paths_jpg and paths_original lists, respectively.",8,17,0.045988578434345444
"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -yimport tensorflow as tf
print(tf.__version__)
import torch
print(f""Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})"")

import os
import gc
import cv2
import glob
import numpy as np
import pandas as pd
from PIL import Image
from tqdm import tqdm
from shutil import copyfile
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lutgpus = tf.config.list_physical_devices('GPU')
if gpus:
  try:
    # Currently, memory growth needs to be the same across GPUs
    for gpu in gpus:
      tf.config.experimental.set_memory_growth(gpu, True)
    logical_gpus = tf.config.experimental.list_logical_devices('GPU')
    print(len(gpus), ""Physical GPUs,"", len(logical_gpus), ""Logical GPUs"")
  except RuntimeError as e:
    # Memory growth must be set before GPUs have been initialized
    print(e)# Read the submisison file
sub_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')
print(len(sub_df))
sub_df.head()study_df = sub_df.loc[sub_df.id.str.contains('_study')]
len(study_df)image_df = sub_df.loc[sub_df.id.str.contains('_image')]
len(image_df)# Ref: https://www.kaggle.com/xhlulu/siim-covid-19-convert-to-jpg-256px
def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return data

def resize_xray(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im","This code installs the pydicom conda helper package, which allows for the reading and manipulation of DICOM files. It also installs the required dependencies for pydicom, including libjpeg-turbo, libgcc-ng, and gdcm. Finally, it installs the latest version of TensorFlow and PyTorch.

This code also defines a function for reading and processing X-ray images stored in the DICOM format. The function takes as input a path to the DICOM file, as well as a boolean value for whether to apply a VOI LUT (if available) to the image. The function returns the processed image as a numpy array.

Another function is also defined for resizing X-ray images. This function takes as input the image array, as well as the desired size (in pixels). The function also takes two optional boolean parameters, one for whether to keep the aspect ratio of the image, and one for the resampling method to use. The function returns the resized image as a PIL image.",8,8,0.16695148445227437
"!/opt/conda/bin/python3.7 -m pip install --upgrade pip
! pip install -q efficientnet#-------------------
# importing libraries
#-------------------
import tensorflow as tf
from tensorflow.keras import layers
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold,StratifiedKFold

from kaggle_datasets import KaggleDatasets


import pandas as pd
import numpy as np

import os
import shutil
import csv

import matplotlib.pyplot as plt
import PILAUTO = tf.data.experimental.AUTOTUNE

try:
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  
    print('Running on TPU ', tpu.master())
except ValueError:
    tpu = None

if tpu:
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.experimental.TPUStrategy(tpu)
else:
    strategy = tf.distribute.get_strategy()

print(""REPLICAS: "", strategy.num_replicas_in_sync)GCS_DS_PATH = KaggleDatasets().get_gcs_path(""siim-covid19-dataset-256px-jpg"")
print(GCS_DS_PATH)

TRAIN_PATH = GCS_DS_PATH + ""/256px/train/train/""
TEST_PATH = GCS_DS_PATH + ""/256px/test/test/""

NUM_CLASSES = 4
HEIGHT,WIDTH = 256,256
CHANNELS = 3
BATCH_SIZE = 8 * strategy.num_replicas_in_sync
SEED = 143


classes_dict = {
    ""Negative for Pneumonia"" : 0,
    ""Typical Appearance"" : 1,
    ""Indeterminate Appearance"" : 2,
    ""Atypical Appearance""  : 3
}

study_df = pd.read_csv(""../input/siim-covid19-detection/train_study_level.csv"")
train_df = pd.read_csv('../input/siim-covid19-dataset-256px-jpg/train.csv')
train_df = train_df[[""ImageInstanceUID"",""StudyInstanceUID"",""label_id"",""study_label""]]train_df.head(3)study_df.head(3)def process_img(filepath,label):
    image = tf.io.read_file(filepath)
    image = tf.image.decode_jpeg(image, channels=CHANNELS)
    image = tf.image.convert_image_dtype(image, tf.float32) 
    #image = tf.image.resize(image, [HEIGHT,WIDTH])
    return image,label


def data_augment(image, label):
    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
            
    # Flips
    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_flip_up_down(image)
    if p_spatial > .75:
        image = tf.image.transpose(image)
        
    # Rotates
    if p_rotate > .75:
        image = tf.image.rot90(image, k=3) 
    elif p_rotate > .5:
        image = tf.image.rot90(image, k=2) 
    elif p_rotate > .25:
        image = tf.image.rot90(image, k=1) 
        
    
    if p_pixel_1 >= .4:
        image = tf.image.random_saturation(image, lower=.7, upper=1.3)
    if p_pixel_2 >= .4:
        image = tf.image.random_contrast(image, lower=.8, upper=1.2)
    if p_pixel_3 >= .4:
        image = tf.image.random_brightness(image, max_delta=.1)
        
    
    if p_crop > .7:
        if p_crop > .9:
            image = tf.image.central_crop(image, central_fraction=.7)
        elif p_crop > .8:
            image = tf.image.central_crop(image, central_fraction=.8)
        else:
            image = tf.image.central_crop(image, central_fraction=.9)
    elif p_crop > .4:
        crop_size = tf.random.uniform([], int(HEIGHT*.8), HEIGHT, dtype=tf.int32)
        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])
    
    image = tf.image.resize(image, [HEIGHT,WIDTH])
    return image,label

def get_dataset(filenames,labels, training=True):
    dataset = tf.data.Dataset.from_tensor_slices((filenames,labels))
    dataset = dataset.map(process_img,num_parallel_calls=AUTO)
    dataset = dataset.map(data_augment,num_parallel_calls=AUTO)
    dataset = dataset.cache()
    dataset = dataset.repeat()
    if training:
        dataset = dataset.shuffle(2048)
    dataset = dataset.batch(BATCH_SIZE)
    dataset = dataset.prefetch(AUTO)
    return dataset","This code imports the necessary libraries for reading in data, training a model, and generating predictions. Next, it defines constants for the number of classes, image dimensions, and batch size. Finally, it defines a function for data augmentation.

The data augmentation function randomly flips, rotates, and crops images. This helps the model to generalize better and avoid overfitting.",8,0,0.055036247431066776
"%%capture
!conda install gdcm -c conda-forge -y# Packages

import os, time, glob, re, pprint, random, math
from collections import defaultdict, Counter

import pandas as pd 
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import matplotlib.patches as patches

import seaborn as sns

import cv2
import gdcm

import pydicom
from pydicom import dcmread
from pydicom.pixel_data_handlers.util import apply_voi_lut

import imagehash
from PIL import Image as im

import tqdm# Magic

%matplotlib inline # Pandas options

pd.set_option(""display.expand_frame_repr"", True)
pd.set_option('display.max_colwidth', 0)# Global values

CODE_PATH = ""./""
DATA_PATH = ""../input/siim-covid19-detection""
TRAIN_PATH = os.path.join(DATA_PATH, ""train"")
TEST_PATH = os.path.join(DATA_PATH, ""test"")# Utility functions

def print_title(s):
    
    # Print an underlined title
    
    print(""%s\n%s"" % (s, '-'*len(s)))
    
    
def na_fill(dtype):
    
    # Fill in missing values so that Seaborn countplot() will include them.
    # Also make sure the missing value for a string column is itself a string.
    
    if dtype == np.float64:
        result = -999
    elif dtype == np.int64:
        result = -999
    elif dtype == np.object:
        result = ""NA""
    else:
        result = -999

    return result


def explode_list_col(df, col):
    
    other_cols = list(df.columns)
    other_cols.remove(col)
    out_df = df.set_index(other_cols)[col]
    out_df = out_df.apply(pd.Series)
    out_df = out_df.stack()
    out_df = out_df.reset_index()
    out_df = out_df.drop(f""level_{len(other_cols)}"", axis=1)
    out_df = out_df.rename(columns={0 : col})
    
    return out_df
    

def cat_order(train_df, test_df, cols):
    
    # For comparison, we want the categories to be the same between train and test. 
    # We also want the categories to be in the same order for both. 
    # We need to make sure missing value types are consistent with the column data
    # type (else sort will complain), and make sure that Seaborn countplot() will
    # include them (it won't include np.nan). Dealing with the latter two issues 
    # is the job of fillna(). When the data is plotted, it needs to be run through
    # fillna() as well.

    category_order = {}
    n = len(cols)

    for col in cols:

        if col in train_cols:
            train_dtype = train_df[col].dtype
        else:
            train_dtype = None     
        if col in test_cols:
            test_dtype = test_df[col].dtype
        else:
            test_dtype = None
        if (train_dtype != None) and (test_dtype != None) and (train_dtype != test_dtype):
            print(f""***Incompatible train/test data types for column {col}"")
            break
        
        col_vals = []
        if col in train_cols:
            col_vals += list(train_df[col].fillna(na_fill(train_dtype)).unique())
        if col in test_cols:
            col_vals += list(test_df[col].fillna(na_fill(test_dtype)).unique())
        col_vals = list(set(col_vals))
        col_vals.sort()
    
        category_order[col] = col_vals
        
    return category_order


def plot_categories(df, col, order, title, ax, xlabel=None, ylabel=None, pallete=""Set3"", scale=""log""):

    data = df[col].fillna(na_fill(df[col].dtype))
    ax = sns.countplot(x=data, order=order, palette=pallete, ax=ax)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=""right"")
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    counts = data.value_counts()
    for i, p in enumerate(ax.patches):
        px = p.get_x()+0.05
        py = max(p.get_height()*0.9, 1.0)
        ax.annotate(counts.get(order[i], """"), (px, py), fontsize=10, rotation=90)
    ax.set_title(title, fontsize=15)
    if xlabel: ax.set_xlabel(xlabel)
    if ylabel: ax.set_ylabel(ylabel)
    
    return


def plot_cat_sub(df, col, sub_col, title, ax, scale=""log""):

    ax = sns.countplot(data=df, x=col, hue=sub_col, ax=ax)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=""right"")
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    ax.set_title(title, fontsize=15)
        
    return


def plot_number_uniq_per(df, df_name, attr1, attr2, ax, title=None, palette=None, scale=""log""):
    
    uniq_df = df.groupby(attr1)[[attr2]].nunique().reset_index()
    ax = sns.barplot(x=attr1, y=attr2, data=uniq_df, ax=ax, palette=palette)
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
        
    counts = uniq_df[attr2]
    for i, p in enumerate(ax.patches):
        px = p.get_x()+0.05
        py = max(p.get_height()*0.9, 1.0)
        ax.annotate(uniq_df[attr2].iloc[i], (px, py), fontsize=10, rotation=90)

    if title:
        ax.set_title(title, fontsize=15)
    else:
        ax.set_title(f""{df_name}\nNumber of unique '{attr2}' values \nper '{attr1}' value"", fontsize=15)
    ax.set_xlabel(attr1)
    ax.set_ylabel(f""# unique '{attr2}'"")
    
    return uniq_df


def plot_number_having_n_uniq(df, df_name, attr1, attr2, ax, order=None, palette=None, scale=""log""):

    nuniq = df.groupby(attr1)[attr2].nunique()
    ax = sns.countplot(x=nuniq, order=order, ax=ax, palette=palette)
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    ax.set_title(f""{df_name}\nNumber of '{attr1}' values \nhaving N unique values of '{attr2}'"", fontsize=15)
    ax.set_xlabel(f""N = # of unique '{attr2}' values"")
    ax.set_ylabel(f""# of '{attr1}' having N"")

    return nuniq


def get_img(path, img_id):

    img_path = os.path.join(path, f""{img_id}.jpg"")
    im = cv2.imread(img_path)
    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
    im = cv2.normalize(im, None, 0, 255, cv2.NORM_MINMAX)
    
    return im


def image_subplots(images, r, c, axes, titles=None):
    
    for idx, img in enumerate(images, 0):
        i = idx // c
        j = idx % c
        if titles:
            imshow(img, axes[i, j], title=titles[idx])
        else:
            imshow(img, axes[i, j])

    return
        

def imshow(image, ax=None, title=None, cmap=None):

    if ax is None:
        fig, ax = plt.subplots()
    ax.imshow(image, cmap=cmap)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.spines['left'].set_visible(False)
    ax.spines['bottom'].set_visible(False)
    ax.tick_params(axis='both', length=0)
    ax.set_xticklabels('')
    ax.set_yticklabels('')
    if title:
        ax.set_title(title)

    return ax
# Read the image metadata

train_image_df = pd.read_csv(os.path.join(DATA_PATH,'train_image_level.csv'))
train_study_df =  pd.read_csv(os.path.join(DATA_PATH,'train_study_level.csv'))","This code reads in the image metadata for the training images from a CSV file. The file contains information on the image ID, patient ID, and other attributes.",8,0,0.07868536324876627
"import pydicom as dicom
import pandas as pd
import os
from tqdm import tqdmmetadata = []

for split in ['test', 'train']:  
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            ds1 = dicom.dcmread(os.path.join(dirname, file), stop_before_pixels=True)
            dt=dict()
            dt['ImageId']=file.replace('.dcm','')
            for key in ds1.keys():
                dt[ds1[key].keyword]=ds1[key].value
            metadata.append(dt)

metadata_df=pd.DataFrame(metadata)
metadata_df.head()metadata_df.to_csv('metadata_covid.csv', index=False)","This code imports the pydicom and pandas libraries, and uses the tqdm library to display a progress bar while iterating through a dataset of DICOM files. For each file, the code reads in the metadata and stores it in a dictionary. The dictionaries for all files are then converted into a Pandas DataFrame and saved as a CSV file.",8,3,0.15600559284671767
"import pandas as pd 
import numpy as np
import os
import pydicom
import glob
from tqdm.notebook import tqdm
from pydicom.pixel_data_handlers.util import apply_voi_lut
import matplotlib.pyplot as plt 
from skimage import exposure
import cv2
import warnings
from path import Path
from fastai.vision.all import *
from fastai.medical.imaging import *
warnings.filterwarnings(""ignore"")datapath = Path(""../input/siim-covid19-detection"")datapath.ls()train_study_df = pd.read_csv(datapath/'train_study_level.csv')train_study_df.head()study_classes = [""Negative for Pneumonia"" , ""Typical Appearance"",
                ""Indeterminate Appearance"", ""Atypical Appearance""]
np.unique(train_study_df[study_classes].values , axis = 0)plt.figure(figsize = (10,5))
plt.bar([1,2,3,4] , train_study_df[study_classes].values.sum(axis = 0))
plt.xticks([1,2,3,4] , study_classes)
plt.ylabel(""Frequency"")
plt.show()","This code imports the pandas, numpy, os, pydicom, glob, tqdm, pydicom.pixel_data_handlers.util, matplotlib.pyplot, skimage.exposure, cv2, warnings, and fastai.vision.all libraries, as well as the train_study_level.csv file from the datapath directory. It then creates a bar graph showing the frequency of each class in the study_classes list.",8,11,0.1599494604430894
"import numpy as np 
import pandas as pd 
import os
import matplotlib.pyplot as plt
import matplotlib
import pydicom as dicom
import cv2
import ast
import warnings
warnings.filterwarnings('ignore')train_image = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
train_study = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
sample_submission = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')train_image.head()len(train_image)train_study.head()len(train_study)sample_submission.head()","This code imports the necessary libraries for data analysis and manipulation, including numpy, pandas, matplotlib, and pydicom. It then loads in the train_image, train_study, and sample_submission data sets. Finally, it displays the first five rows of the train_image dataset.",8,3,0.07753108710648789
"!conda install gdcm -c conda-forge -yimport os
import ast
import numpy as np
import pandas as pd
from path import Path
import datetime
import glob
import json
import shutil

from PIL import Image
from tqdm.auto import tqdm
import pydicom
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import cv2from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)    
    
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail(size, resample)
    else:
        im = im.resize(size, resample)
    
    return imimages_meta_folder = '/kaggle/working/images_metadata_256_512_768'
os.makedirs(images_meta_folder, exist_ok=True)

# Define sizes
new_sizes = [(256, 256), (512, 512), (768, 768)]for new_size in new_sizes:

    for split in ['train', 'test']:
    # for split in ['test']:
        save_dir = f'/kaggle/tmp/{split}_{new_size[0]}x{new_size[1]}/'
        dcm_paths = glob.glob(f'../input/siim-covid19-detection/{split}/*/*/*')
        os.makedirs(save_dir, exist_ok=True)

        image_ids = []
        folder_ids = []
        study_ids = []
        widths = []
        heights = []

        for path in tqdm(dcm_paths):
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(path)
            im = resize(xray, size=new_size)

            path_split = path.split('/')
            study_id = path_split[-3]
            folder_id = path_split[-2]
            image_name = path_split[-1].replace('.dcm', '_image')

            im.save(os.path.join(save_dir, image_name+'.png'))

            image_ids.append(image_name)
            folder_ids.append(folder_id)
            study_ids.append(study_id)
            widths.append(xray.shape[1])
            heights.append(xray.shape[0])
            
        df = pd.DataFrame.from_dict({'id': image_ids, 'folder_id': folder_ids,
                                     'study_id': study_ids, 'width': widths,
                                     'height': heights})
        df.to_csv(f'{images_meta_folder}/{split}_meta_{new_size[0]}x{new_size[1]}.csv', index=False)for new_size in new_sizes:
    print(f""*****{new_size}*****\n"")
    df_train_meta = pd.read_csv(f'{images_meta_folder}/train_meta_{new_size[0]}x{new_size[1]}.csv')
    df_train = pd.read_csv(""../input/siim-covid19-detection/train_image_level.csv"")
    df_train_meta = df_train.merge(df_train_meta, on='id')
    
    ## Drop all rows of images without annotations
    df_train_meta = df_train_meta.dropna()
    imagepaths = df_train_meta.id.unique()
    print(""Number of Images with Covid_Abnormality:"",len(imagepaths))
    
    display(df_train_meta.head(3))
    print()
    
    df_idx=0

    for idx, row in tqdm(df_train_meta.iterrows(), total=df_train_meta.shape[0]):
        img = cv2.imread(os.path.join(f""/kaggle/tmp/train_{new_size[0]}x{new_size[1]}/"",
                                      row.id.replace(""_image"", "".png"")))
        bboxes = [list(bbox.values()) for bbox in ast.literal_eval(row.boxes)]
        height_ratio, width_ratio = (new_size[0]/row.height, new_size[1]/row.width)

        for box in bboxes:
            box[2] = box[2]+box[0]
            box[3] = box[3]+box[1]
            box = (box[0]*width_ratio, box[1]*height_ratio,
                   box[2]*width_ratio, box[3]*height_ratio)

            row_df = pd.DataFrame({'id':row.id,
                           'StudyInstanceUID':row.StudyInstanceUID,
                           'folder_id':row.folder_id,
                           'study_id':row.study_id,
                           'width':row.width,
                           'height':row.height,
                           'xmin':round(box[0]),
                           'ymin':round(box[1]),
                           'xmax':round(box[2]),
                           'ymax':round(box[3])}, index=[df_idx])

            if df_idx==0:
                df_train_processed = row_df
            else:
                df_train_processed = pd.concat([df_train_processed, row_df])

            df_idx+=1

    display(df_train_processed.head(3))
    print()
    df_train_processed.to_csv(f'{images_meta_folder}/df_train_processed_meta_{new_size[0]}x{new_size[1]}.csv',
                              index=False)
    df_train_processed.shape","This code reads in DICOM images, applies a VOI LUT (if available), and then transforms the raw data into a ""human-friendly"" view. It also fixes monochrome images so that they appear correctly. Finally, it resizes the images to the specified new sizes.",9,1,0.10281213688087829
"!conda install gdcm -c conda-forge -yimport cv2
import datetime
import gc
import glob
import imagehash
import math
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
import PIL
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import sys
import tqdmbase_path = '../input/siim-covid19-detection'def read_dicom_image(image_file, voi_lut=True, fix_monochrome=True):
    """"""
    Reads a dicom image from a file an returns a numpy array.
    References: https://www.kaggle.com/trungthanhnguyen0502/eda-vinbigdata-chest-x-ray-abnormalities
    Args:
        image_file:
        voi_lut:
        fix_monochrome:

    Returns:

    """"""
    dicom = pydicom.read_file(image_file)
    # VOI LUT (if available by DICOM device) is used to
    # transform raw DICOM data to ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
    return data


def string2boxes(string):
    strings = string.split()
    if strings[0].lower() == 'none':
        return []
    else:
        return [{'class': strings[idx],
                 'conf': float(strings[idx+1]),
                 'x1': float(strings[idx+2]),
                 'y1': float(strings[idx+3]),
                 'x2': float(strings[idx+4]),
                 'y2': float(strings[idx+5]),
                 } for idx in range(0, len(strings), 6)]


def plot_image(image, boxes=None, size=(5,5), title=None, columns=4):
    def plot_img(image, boxes=None, title=None):
        if isinstance(image, str):
            image_id = os.path.splitext(os.path.split(image)[1])[0]
            df = df_image.loc[df_image['id'] == image_id + '_image']
            boxes = string2boxes(df['label'].iloc[0]) if len(df) > 0 else None
            image = read_dicom_image(image)
        image = np.stack([image] * 3, axis=-1)
        if boxes is not None:
            for box in boxes:
                image = cv2.rectangle(image, (int(box['x1']), int(box['y1'])), (int(box['x2']), int(box['y2'])), [0, 255, 0], 10)
        plt.axis('on')
        plt.imshow(image, cmap='gray')
        if title is not None:
            plt.title(title)

    plt.figure(figsize=size)
    if isinstance(image, list):
        num = len(image)
        columns = min(columns, num)
        rows = math.ceil(num / columns)

        for index, single_image in enumerate(image):
            plt.subplot(rows, columns, index + 1)
            plot_img(single_image, boxes=boxes, title=title[index])
    else:
        plot_img(image, boxes=boxes, title=title)
    plt.show()


def images_find_duplicates(image_files, threshold=0.9):
    """"""
    Function to find duplicates in images.
    References: https://www.kaggle.com/appian/let-s-find-out-duplicate-images-with-imagehash
    Args:
        image_files:
        threshold:

    Returns:

    """"""
    funcs = [imagehash.average_hash, imagehash.phash, imagehash.dhash, imagehash.whash]
    image_ids = image_files
    hashes = []
    for file in tqdm.tqdm(image_files):
        image = PIL.Image.fromarray(read_dicom_image(file))
        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))
    hashes_all = np.array(hashes)

    # Comparisons without Pytorch
    sim_list = []
    for i in tqdm.tqdm(range(hashes_all.shape[0])):
        sim_list.append(np.sum(hashes_all[i] == hashes_all, axis=1)/256)

    # nxn-matrix of similarities (n = # of images), upper triangular matrix
    similarities = np.triu(np.array(sim_list), 1)

    idx_pair = np.where(similarities > threshold)
    df_pairs = pd.DataFrame({'image1': [image_ids[i] for i in list(idx_pair[0])],
                             'image2': [image_ids[i] for i in list(idx_pair[1])],
                             'similarity': [similarities[i1, i2] for i1, i2 in zip(idx_pair[0], idx_pair[1])]})

    idx_group = np.zeros(len(image_files))
    group_id = 1
    for i1, i2 in zip(idx_pair[0], idx_pair[1]):
        if idx_group[i1] == 0 and idx_group[i2] == 0:
            idx_group[i1] = group_id
            idx_group[i2] = group_id
            group_id += 1
        elif idx_group[i1] != 0 and idx_group[i2] == 0:
            idx_group[i2] = idx_group[i1]
        elif idx_group[i1] == 0 and idx_group[i2] != 0:
            idx_group[i1] = idx_group[i2]
        elif idx_group[i1] != 0 and idx_group[i2] != 0 and idx_group[i1] != idx_group[i2]:
            common_id = min(idx_group[i1], idx_group[i2])
            idx_group[idx_group == idx_group[i1]] = common_id
            idx_group[idx_group == idx_group[i2]] = common_id

    group_list = []
    for i in range(1, group_id + 1):
        group_ids = list(np.where(idx_group == i)[0])
        if len(group_ids) > 0:
            group_list.append([image_ids[j] for j in group_ids])

    return df_pairs, group_list


def print_group_info(i, df_group):
    print(f'\nGroup {i+1}')
    print(f'Number of unique studies:       {len(df_group[""study_id""].unique())}')
    print(f'Number of unique study labels:  {len(df_group[""study_label""].unique())}\n')
    print(df_group[['image_id', 'num_boxes', 'study_id', 'study_label']])
    plot_image(list(df_group['image_file']), size=(20, 10), title=list(df_group['image_id']), columns=8)    
train_files = sorted(glob.glob(os.path.join(base_path, 'train/*/*/*.dcm')))
print(f'Number of training files: {len(train_files)}')
df_image = pd.read_csv(os.path.join(base_path, 'train_image_level.csv'))
df_study = pd.read_csv(os.path.join(base_path, 'train_study_level.csv'))
df_study['study_label'] = df_study.apply(lambda r: ', '.join([df_study.columns[i] for i in range(1, 5) if r[i] > 0]), axis=1)

df_pairs, group_list = images_find_duplicates(train_files, threshold=0.95)
print(f'\nNumber of duplicate pairs: {len(df_pairs)}')
print(f'Number of duplicate groups: {len(group_list)}')df_group_list = []
df_pairs.to_csv('pairs.csv')

with open('duplicates.csv', 'w') as text_file:
    for i, group in enumerate(group_list):
        group_ids = [os.path.splitext(os.path.basename(file))[0] + '_image' for file in group]
        df_group_ids = pd.DataFrame({'id': group_ids, 'image_file': group})
        df_group = df_group_ids.merge(df_image, on='id').sort_values('id')
        df_group['study_id'] = df_group['StudyInstanceUID'] + '_study'
        df_group['num_boxes'] = df_group.apply(lambda r: len(string2boxes(r['label'])), axis=1)
        df_group = df_group.merge(df_study, left_on='study_id', right_on='id')
        df_group = df_group.rename(columns={'id_x': 'image_id'})
        df_group_list.append(df_group)
        text_file.write(','.join(group_ids) + '\n')for index, df_group in enumerate(df_group_list):
    if len(df_group[df_group['num_boxes'] > 0]) > 1:
        print_group_info(index, df_group)","This code imports the necessary libraries for reading and processing DICOM images, and defines a function for reading a DICOM image from a file.

It then defines a function for finding duplicate images, which takes a list of image files and a threshold value as input. The function returns a list of duplicate image pairs and a list of groups of duplicate images.

Finally, the code loops through the list of groups of duplicate images, and prints information about each group. If a group contains more than one image with annotations, the code will also plot the images in the group.",8,0,0.18046371476600243
"import pandas as pd# train_df = pd.read_csv('/kaggle/input/siimcovid19-train-data-that-opacitycount-added/train_df.csv')
# local
train_df = pd.read_csv('/kaggle/input/siimcovid19-train-data-that-opacitycount-added/train_df.csv')train_df.head()train_df.drop(columns='Path', axis=1,inplace=True)train_df.head()train_df['Opacity'] = train_df.apply(lambda row : 1 if row.label.split(' ')[0]=='opacity' else 0, axis=1)
train_dftrain_df.drop(columns=['Unnamed: 0'], inplace=True)
train_df","This code imports the pandas library and reads in a CSV file containing training data. The data is then processed to drop the 'Path' column and to add a new 'Opacity' column. The 'Opacity' column is populated with a value of 1 if the 'label' column for a given row contains the word 'opacity', and 0 otherwise. Finally, the 'Unnamed: 0' column is dropped from the dataframe.",8,1,0.06491801078322432
"!pip install -q efficientnet >> /dev/nullimport pandas as pd, numpy as np, random,os, shutil
from glob import glob
from kaggle_datasets import KaggleDatasets
import tensorflow as tf, re, math
import tensorflow.keras.backend as K
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt
import tensorflow_addons as tfa
print('tf:',tf.__version__)# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit
VERBOSE      = 1
DISPLAY_PLOT = True

DEVICE = ""TPU"" #or ""GPU""

# USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD
SEED = 42

# NUMBER OF FOLDS. USE 2, 5, 10
FOLDS = 5

# WHICH IMAGE SIZES TO LOAD EACH FOLD
# CHOOSE 128, 192, 256, 384, 512, 512 
IMG_SIZES = [[512, 512]]*FOLDS

# BATCH SIZE AND EPOCHS
BATCH_SIZES = [24]*FOLDS
EPOCHS      = [10]*FOLDS

# WHICH EFFICIENTNET B? TO USE
EFF_NETS = [6]*FOLDS

# Augmentations
AUGMENT   = True
TRANSFORM = True

# transformations
ROT_    = 0.0
SHR_    = 2.0
HZOOM_  = 8.0
WZOOM_  = 8.0
HSHIFT_ = 8.0
WSHIFT_ = 8.0

# Dropout
PROBABILITY = 0.75
CT          = 8
SZ          = 0.08

#bri, contrast
sat  = (0.7, 1.3)
cont = (0.8, 1.2)
bri  =  0.1

# WEIGHTS FOR FOLD MODELS WHEN PREDICTING TEST
WGTS = [1/FOLDS]*FOLDS

# TEST TIME AUGMENTATION STEPS
TTA = 1def seeding(SEED):
    np.random.seed(SEED)
    random.seed(SEED)
    os.environ['PYTHONHASHSEED'] = str(SEED)
    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)
    tf.random.set_seed(SEED)
    print('seeding done!!!')
seeding(SEED)if DEVICE == ""TPU"":
    print(""connecting to TPU..."")
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        print('Running on TPU ', tpu.master())
    except ValueError:
        print(""Could not connect to TPU"")
        tpu = None

    if tpu:
        try:
            print(""initializing  TPU ..."")
            tf.config.experimental_connect_to_cluster(tpu)
            tf.tpu.experimental.initialize_tpu_system(tpu)
            strategy = tf.distribute.experimental.TPUStrategy(tpu)
            print(""TPU initialized"")
        except _:
            print(""failed to initialize TPU"")
    else:
        DEVICE = ""GPU""

if DEVICE != ""TPU"":
    print(""Using default strategy for CPU and single GPU"")
    strategy = tf.distribute.get_strategy()

if DEVICE == ""GPU"":
    print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
    

AUTO     = tf.data.experimental.AUTOTUNE
REPLICAS = strategy.num_replicas_in_sync
print(f'REPLICAS: {REPLICAS}')GCS_PATH = [None]*FOLDS
for i,k in enumerate(IMG_SIZES):
    GCS_PATH[i] = KaggleDatasets().get_gcs_path('siimcovid19-%ix%i-tfrec-dataset'%(k[0],k[1]))
files_train = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/train*.tfrec')))
files_test  = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/test*.tfrec')))
num_train_files = len(files_train)
num_test_files  = len(files_test)
print('train_files:',num_train_files)
print('test_files:',num_test_files)train_df = pd.read_csv('../input/siim-covid19-yolov5-2class-labels/meta.csv')
train_df.head(2)","This code installs the efficientnet package and imports pandas, numpy, random, os, and shutil. It also sets some parameters for the training process. Next, the code defines a function for seeding the random number generator. This is followed by a section of code that initializes the TPU (if available) or GPU for training. Finally, the code loads the training data from a CSV file.",8,4,0.10224069465238826
"%cd ../
!mkdir tmp
%cd tmp# Download YOLOv5
!git clone https://github.com/ultralytics/yolov5  # clone repo
%cd yolov5
# Install dependencies
%pip install -qr requirements.txt  # install dependencies

%cd ../
import torch
print(f""Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})"")# Install W&B 
!pip install -q --upgrade wandb
# Login 
import wandb
wandb.login()# Necessary/extra dependencies. 
import os
import gc
import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm
from shutil import copyfile
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

#customize iPython writefile so we can write variables
from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))TRAIN_PATH = 'input/siim-covid19-resized-to-256px-jpg/train/'
IMG_SIZE = 256
BATCH_SIZE = 16
EPOCHS = 10# Everything is done from /kaggle directory.
%cd ../

# Load image level csv file
df = pd.read_csv('input/siim-covid19-detection/train_image_level.csv')

# Modify values in the id column
df['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)
# Add absolute path
df['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)
# Get image level labels
df['image_level'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)

df.head(5)# Load meta.csv file
# Original dimensions are required to scale the bounding box coordinates appropriately.
meta_df = pd.read_csv('input/siim-covid19-resized-to-256px-jpg/meta.csv')
train_meta_df = meta_df.loc[meta_df.split == 'train']
train_meta_df = train_meta_df.drop('split', axis=1)
train_meta_df.columns = ['id', 'dim0', 'dim1']

train_meta_df.head(2)","The code above loads in the image level csv file and modifies the id column to only include the image name. It then adds an absolute path column to include the path to the image. The image level labels column is created to get the image level labels. The code then loads in the meta.csv file and drops the split column. The train_meta_df is created to only include the training data. The column names are then changed to id, dim0, and dim1.",8,4,0.15102031893622112
"# Importing Required packages
import os
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from IPython.display import Image, clear_output
print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))
clear_output()#customize iPython writefile so we can write variables
from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))# Cloning the repo and installing requiements
!git clone https://github.com/ultralytics/yolov5.git
!mv ./yolov5/* ./
!pip install -r requirements.txt
clear_output()# Copying the dataset to working directory
!mkdir Dataset
!cp ../input/covid19-detection-for-yolov5-siimfisabiorsna/Covid19 -r ./Dataset
clear_output()len(os.listdir('./Dataset/Covid19/images'))%%writetemplate ./split_dataset.py
from utils.datasets import * 
autosplit('./Dataset/Covid19', weights=(0.8, 0.2, 0.0))!python split_dataset.py","This code is used to split a dataset into training, validation, and test sets.

The first step is to import the required packages. We will need the os, torch, numpy, pandas, matplotlib, and IPython packages.

Next, we set up the writetemplate function. This will allow us to write variables into a file.

Then, we clone the yolov5 repository and install the requirements.

After that, we copy the dataset to the working directory.

Finally, we use the autosplit function to split the dataset into training, validation, and test sets.",8,5,0.2325002518604645
"! conda install -c conda-forge gdcm -y# import numpy as np # linear algebra
# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
# import os
# import pydicom
# import glob
# from tqdm.notebook import tqdm
# from pydicom.pixel_data_handlers.util import apply_voi_lut
# import matplotlib.pyplot as plt
# from skimage import exposure
# import cv2
# import warnings
# from fastai.vision.all import *
# from fastai.medical.imaging import *
# warnings.filterwarnings('ignore')

import os
import pydicom
import glob
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt 
dataset_path = '../input/siim-covid19-detection/'

for path in glob.glob(dataset_path  + '*'):
    print(path)train_images = '../input/siim-covid19-detection/train/'

n_folders = len(glob.glob(train_images  + '*'))
n_subfolders = len(glob.glob(train_images  + '*/*'))
n_images = len(glob.glob(train_images  + '*/*/*.dcm'))

print(f'There are {n_subfolders} subfolders in {n_folders} folders.')
print(f'There are altogether {n_images} images.')folders = glob.glob(train_images  + '*')

subfolder_dict = {}

for folder in folders:
    n = len(glob.glob(folder + '/*'))
    if n in subfolder_dict.keys():
        subfolder_dict[n] += 1
    else:
        subfolder_dict[n] = 1
        
for k, v in subfolder_dict.items():
    print(f'There is {v} subfolders with {k} images.')

subfolders = glob.glob(train_images  + '*/*')

image_dict = {}

for subfolder in subfolders:
    n = len(glob.glob(subfolder + '/*'))
    if (n!=1):
        print (subfolder.split('/')[-1])
        for image in glob.glob(subfolder + '/*'):
            print ('-->' + image.split('/')[-1])

    if n in image_dict.keys():
        image_dict[n] += 1
    else:
        image_dict[n] = 1
        
for k, v in image_dict.items():
    print(f'There is {v} subfolders with {k} images.')
train_study_df = pd.read_csv(dataset_path +'/train_study_level.csv')

train_study_df","This code imports the necessary libraries for working with the dataset, defines the path to the dataset, and then counts the number of folders, subfolders, and images in the dataset. It also prints out the number of subfolders and images in each folder. Finally, it loops through the subfolders and counts the number of images in each one.",8,0,0.07197869193925975
"import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import glob
import pydicomsiim_covid19_dir = os.path.join(
    '..', 'input', 'siim-covid19-detection')def read_csv(file_name):
    file_path = os.path.join(siim_covid19_dir, file_name)
    df = pd.read_csv(file_path)
    return dfstudy_level_df = read_csv('train_study_level.csv')

study_level_df# How many rows?
study_level_num_rows = len(study_level_df)

study_level_num_rows# Are unique? Any duplicates?
study_level_num_unique_ids = len(pd.unique(study_level_df['id']))

if study_level_num_unique_ids == study_level_num_rows:
    print(""Unique and no duplicates"")
else:
    print(""Some duplicates"")# What are the unique value combinations? How many of them?
study_level_label_colums = [
    'Negative for Pneumonia', 'Typical Appearance',
    'Indeterminate Appearance', 'Atypical Appearance' ]
study_level_labels_df = study_level_df[study_level_label_colums]
study_level_label_values = study_level_labels_df.values

study_level_unique_label_combinations, \
study_level_unique_label_counts = \
    np.unique(
        study_level_label_values, return_counts=True, axis=0)

print(""Unique Combinations:\n"", study_level_unique_label_combinations)
print(""Unique Counts:\n"", study_level_unique_label_counts)","This code reads in a CSV file containing information on studies related to COVID-19. It then calculates the number of unique rows and checks for duplicates. Finally, it calculates the unique combinations of values in the label columns and counts them.",8,0,0.15298900247566163
"# Libraries
import warnings
warnings.filterwarnings('ignore')

import os
import numpy as np
import pandas as pd
import seaborn as sns
import glob
from pandas import DataFrame
from matplotlib.lines import Line2D
import matplotlib.pyplot as plt
%matplotlib inline
import plotly.express as px
from tqdm.notebook import tqdm

# Image processing and Computer Vision
from skimage import exposure
import cv2
# Package designed to manipulate data elements in DICOM files 

import pydicom
#Image Transformation
from pydicom.pixel_data_handlers.util import apply_voi_lut

from fastai.vision.all import *
from fastai.medical.imaging import *

#train_image
train_image_df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
train_image_df.head(2)#train_study
train_study_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
train_study_df.head()# Bar plot function defination
def viz_bar_plot(df,x,x_title,y,title,colors=None,text=None):
    fig = px.bar(x=x,
                 y=y,
                 text=text,
                 labels={x: x_title.title()},   
                 data_frame=df,
                 color=colors,
                 barmode='group',
                 template=""simple_white"")
    texts = [df[col].values for col in y]
    for i, t in enumerate(texts):
        fig.data[i].text = t
        fig.data[i].textposition = 'inside'  
    fig['layout'].title=title
    fig.update_layout(title_font_size=19)
    fig.update_layout(title_font_family='Droid Serif')
    fig.update_layout(width=800,height=500)
    for trace in fig.data:
        trace.name = trace.name.replace('_',' ').title()
    fig.update_yaxes(tickprefix="""", showgrid=True)
    fig.show()# Study Data
# create 'target' column in train_study_df dataset
train_study_df['target']='Negative for Pneumonia'
train_study_df.loc[train_study_df['Typical Appearance']==1,'target']='Typical Appearance'
train_study_df.loc[train_study_df['Indeterminate Appearance']==1,'target']='Indeterminate Appearance'
train_study_df.loc[train_study_df['Atypical Appearance']==1,'target']='Atypical Appearance'
train_study_df1=train_study_df.groupby(['target']).size().reset_index(name='counts')
train_study_df1# Bar Visulaization of label categories
viz_bar_plot(train_study_df1,
         'target',
         'target',
         ['counts'],
         title='Target Label Count')","This code imports the necessary libraries for data analysis and visualization, then loads the data from the CSV files. Next, it defines a function for visualizing data in a bar plot. Finally, it groups the data by target label and displays the counts in a bar plot.",7,0,0.14468582157114207
"! conda install -c conda-forge gdcm -yimport numpy as np
import pandas as pd 
import os
from PIL import Image
from tqdm.auto import tqdm
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import seaborn as sns
from pandas_profiling import ProfileReport
from glob import glob
from tqdm.notebook import tqdm
import matplotlib.pyplot as plt
from skimage import exposure
import cv2
import warnings
import albumentations as A# config params
class CFG:
    data_path = '../input/siim-covid19-detection/'
    size = 512
    seed = 2021
    working_dir = '/kaggle/working/'def dicom2array(path, voi_lut=True, fix_monochrome=True):
    dicom = pydicom.read_file(path)
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
    return data
        
    
def plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()
# storage file for the transformed images
!mkdir train# prepare a dataframe for producing resized images with bboxes
xtrain_img = pd.read_csv(CFG.data_path + 'train_image_level.csv')


path_list = []
image_list = []
splits = []

for split in ['train']:
    
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            fullpath = dirname + '/' + file
            path_list.append(fullpath)
            image_list.append(file)

df = pd.DataFrame(image_list, columns =['image_id'])
df['image_path'] = path_list

xtrain_img['image_id'] = xtrain_img['id'].apply(lambda s: s.replace('_image','') + '.dcm')
xtrain_img = pd.merge(left = xtrain_img, right = df, on = 'image_id')
# common transformation we shall use
transform = A.Compose(
    [
        A.Resize(height = CFG.size , width = CFG.size, p=1),
    ], 
    p=1.0,  bbox_params=A.BboxParams( format='pascal_voc', min_area=0,  min_visibility=0, label_fields=['labels']  ))        

img_list = []
label_list = []

# loop over files
for ii in range(len(xtrain_img)):
    # get the image
    row = xtrain_img.loc[ii]
    img_path = row['image_path']
    img = dicom2array(path=img_path)
    newname = img_path.split('/')[-1].replace('dcm', 'jpg')
    img_list.append(newname)
    
    # get the bounding boxes
    bboxes = []
    bbox = []
    labels = []
    confidences = []

    for i, l in enumerate(row['label'].split(' ')):
        if (i % 6 == 0) :
            labels.append(l)
        if (i % 6 == 1):
            confidences.append(l)
        if (i % 6 > 1):
            bbox.append(np.clip(float(l), a_min = 0, a_max = None ))
        if i % 6 == 5:
            bboxes.append(bbox)
            bbox = []    

    # transform both
    result = transform(image = img, bboxes = bboxes, labels = np.ones(len(bboxes)))
    new_image = result['image']
    new_bboxes = np.array(result['bboxes']).tolist()

    # format the output
#    print('orig label: ' + row['label'])
    newlabel = ''
    if labels[0] == 'none':
        newlabel = 'none 1 0 0 1 1'
    else:
        for j in range(len(labels)):
            newlabel += labels[j] + ' ' + confidences[j] + ' ' +  ' '.join([str(np.round(f,5)) for f in new_bboxes[0]]) + ' '
#    print('new label:' + newlabel)
    label_list.append(newlabel)
    
    # store the new image
    cv2.imwrite(CFG.working_dir + 'train/' + newname , new_image)",This code is responsible for transforming the images in the SIIM-Covid19 dataset into a format that can be used by a machine learning algorithm. The images are first converted into arrays using the dicom2array function. The bounding boxes are then extracted from the labels and the images are transformed using the transform function. The new images and labels are then saved in the working directory.,8,1,0.1413078220211167
"!wget 'https://anaconda.org/conda-forge/libjpeg-turbo/2.1.0/download/linux-64/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/libgcc-ng/9.3.0/download/linux-64/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/gdcm/2.8.9/download/linux-64/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/conda/4.10.1/download/linux-64/conda-4.10.1-py37h89c1867_0.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/certifi/2020.12.5/download/linux-64/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/openssl/1.1.1k/download/linux-64/openssl-1.1.1k-h7f98852_0.tar.bz2' -q","The code above downloads the following packages from Anaconda:

- libjpeg-turbo
- libgcc-ng
- gdcm
- conda
- certifi
- openssl

Each package is downloaded as a .tar.bz2 file.",8,6,0.22448850310374321
"! conda install gdcm -c conda-forge -y! pip install --no-deps '../input/timm-package/timm-0.1.26-py3-none-any.whl' > /dev/null
! pip install --no-deps '../input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl' > /dev/nullimport sys
sys.path.insert(0, ""../input/timm-efficientdet-pytorch"")
sys.path.insert(0, ""../input/omegaconf"")

import os
from PIL import Image
import pandas as pd
from tqdm.auto import tqdm
import numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import torch
from datetime import datetime
import time
import random
import cv2
import albumentations as A
import matplotlib.pyplot as plt
from albumentations.pytorch.transforms import ToTensorV2
from sklearn.model_selection import StratifiedKFold
from torch.utils.data import Dataset,DataLoader
from torch.utils.data.sampler import SequentialSampler, RandomSampler
from glob import glob

SEED = 42

def seed_everything(seed):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = True

seed_everything(SEED)dataset_path = ""../input/siim-covid19-detection""def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return data

def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im
        
    
def plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()
%%time
image_id = []


cnt_img = 0 # for testing

for split in ['test', 'train']:
    save_dir = f'/kaggle/tmp/{split}/'

    os.makedirs(save_dir, exist_ok=True)
    
    for dirname, _, filenames in tqdm(os.walk(f'{dataset_path}/{split}')):
        for file in filenames:
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(os.path.join(dirname, file))
            im = resize(xray, size=256)  
            im.save(os.path.join(save_dir, file.replace('dcm', 'jpg')))

            image_id.append(file.replace('.dcm', ''))

            splits.append(split)
        
        if cnt_img >= 10:
            cnt_img = 0
            break
        
        cnt_img += 1
            image_id","This code reads in a DICOM image, applies a VOI LUT (if available), and then rescales the image to be between 0 and 1. It then converts the image to an 8-bit unsigned integer and saves it as a JPEG.",8,1,0.10374608790260875
"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -yimport os

from PIL import Image
import pandas as pd
from tqdm.auto import tqdmimport numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im
split = 'test'
save_dir = f'/kaggle/tmp/{split}/'

os.makedirs(save_dir, exist_ok=True)

save_dir = f'/kaggle/tmp/{split}/study/'
os.makedirs(save_dir, exist_ok=True)

for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
    for file in filenames:
        # set keep_ratio=True to have original aspect ratio
        xray = read_xray(os.path.join(dirname, file))
        im = resize(xray, size=600)  
        study = dirname.split('/')[-2] + '_study.png'
        im.save(os.path.join(save_dir, study))
import numpy as np 
import pandas as pd

df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
id_laststr_list  = []
for i in range(df.shape[0]):
    id_laststr_list.append(df.loc[i,'id'][-1])
df['id_last_str'] = id_laststr_list

study_len = df[df['id_last_str'] == 'y'].shape[0]!pip install /kaggle/input/kerasapplications -q
!pip install /kaggle/input/efficientnet-keras-source-code/ -q --no-deps

import os

import efficientnet.tfkeras as efn
import numpy as np
import pandas as pd
import tensorflow as tf

def auto_select_accelerator():
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        tf.config.experimental_connect_to_cluster(tpu)
        tf.tpu.experimental.initialize_tpu_system(tpu)
        strategy = tf.distribute.experimental.TPUStrategy(tpu)
        print(""Running on TPU:"", tpu.master())
    except ValueError:
        strategy = tf.distribute.get_strategy()
    print(f""Running on {strategy.num_replicas_in_sync} replicas"")

    return strategy


def build_decoder(with_labels=True, target_size=(300, 300), ext='jpg'):
    def decode(path):
        file_bytes = tf.io.read_file(path)
        if ext == 'png':
            img = tf.image.decode_png(file_bytes, channels=3)
        elif ext in ['jpg', 'jpeg']:
            img = tf.image.decode_jpeg(file_bytes, channels=3)
        else:
            raise ValueError(""Image extension not supported"")

        img = tf.cast(img, tf.float32) / 255.0
        img = tf.image.resize(img, target_size)

        return img

    def decode_with_labels(path, label):
        return decode(path), label

    return decode_with_labels if with_labels else decode


def build_augmenter(with_labels=True):
    def augment(img):
        img = tf.image.random_flip_left_right(img)
        img = tf.image.random_flip_up_down(img)
        return img

    def augment_with_labels(img, label):
        return augment(img), label

    return augment_with_labels if with_labels else augment


def build_dataset(paths, labels=None, bsize=32, cache=True,
                  decode_fn=None, augment_fn=None,
                  augment=True, repeat=True, shuffle=1024, 
                  cache_dir=""""):
    if cache_dir != """" and cache is True:
        os.makedirs(cache_dir, exist_ok=True)

    if decode_fn is None:
        decode_fn = build_decoder(labels is not None)

    if augment_fn is None:
        augment_fn = build_augmenter(labels is not None)

    AUTO = tf.data.experimental.AUTOTUNE
    slices = paths if labels is None else (paths, labels)

    dset = tf.data.Dataset.from_tensor_slices(slices)
    dset = dset.map(decode_fn, num_parallel_calls=AUTO)
    dset = dset.cache(cache_dir) if cache else dset
    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset
    dset = dset.repeat() if repeat else dset
    dset = dset.shuffle(shuffle) if shuffle else dset
    dset = dset.batch(bsize).prefetch(AUTO)

    return dset

#COMPETITION_NAME = ""siim-cov19-test-img512-study-600""
strategy = auto_select_accelerator()
BATCH_SIZE = strategy.num_replicas_in_sync * 16

IMSIZE = (224, 240, 260, 300, 380, 456, 528, 600)

#load_dir = f""/kaggle/input/{COMPETITION_NAME}/""
sub_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
sub_df = sub_df[:study_len]
test_paths = f'/kaggle/tmp/{split}/study/' + sub_df['id'] +'.png'

sub_df['negative'] = 0
sub_df['typical'] = 0
sub_df['indeterminate'] = 0
sub_df['atypical'] = 0


label_cols = sub_df.columns[2:]

test_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[7], IMSIZE[7]), ext='png')
dtest = build_dataset(
    test_paths, bsize=BATCH_SIZE, repeat=False, 
    shuffle=False, augment=False, cache=False,
    decode_fn=test_decoder
)

with strategy.scope():
    
    models = []
    
    models0 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model0.h5'
    )
    models1 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model1.h5'
    )
    models2 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model2.h5'
    )
    models3 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model3.h5'
    )
    models4 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model4.h5'
    )
    
    models.append(models0)
    models.append(models1)
    models.append(models2)
    models.append(models3)
    models.append(models4)

    
    
    
sub_df[label_cols] = sum([model.predict(dtest, verbose=1) for model in models]) / len(models)","This code installs the pydicom package on a conda environment, using the conda-forge channel. It also installs the libjpeg-turbo, libgcc-ng, gdcm, conda, and certifi packages, also from the conda-forge channel. Finally, it imports the os, PIL, pandas, and tqdm packages.

This code defines a function to read X-ray images from a DICOM file. The function takes the path to the DICOM file as an input, and optionally a boolean value to determine whether to apply a VOI LUT (default is True) and/or to fix monochrome images (default is True). The function returns the image data as a NumPy array.

This code defines a function to resize an image. The function takes the image data as a NumPy array, the desired size, and optionally a boolean value to keep the original aspect ratio (default is False) and/or the resampling method (default is Image.LANCZOS). The function returns the resized image as a NumPy array.

This code defines a function to decode an image from a file. The function takes the path to the image file as an input, and optionally the desired target size and image format (default is (300, 300) and 'jpg', respectively). The function returns the decoded image as a NumPy array.

This code defines a function to augment an image. The function takes the image data as a NumPy array and optionally a boolean value to determine whether to apply data augmentation (default is True). The function returns the augmented image as a NumPy array.

This code defines a function to build a dataset from a list of image paths and labels. The function takes the list of paths and labels as inputs, and optionally the batch size, whether to cache the dataset (default is True), the image decoding function, the image augmentation function, whether to apply data augmentation (default is True), whether to repeat the dataset (default is True), and the shuffle buffer size (default is 1024). The function returns a tf.data.Dataset object.

This code defines a function to automatically select an accelerator (TPU or GPU). The function returns a tf.distribute.Strategy object.

This code loads the sample submission file as a",9,18,0.17276944085000845
"SEED  = 42
FOLDS = 5
DIM   = 512import numpy as np 
import pandas as pd 
import os, shutil
from glob import glob
from sklearn.cluster import KMeans
from tqdm.notebook import tqdm
from sklearn.preprocessing import LabelEncoder
import random
tqdm.pandas()np.random.seed(SEED)
random.seed(SEED)train_df = pd.read_csv(f'../input/siimcovid19-{DIM}-jpg-image-dataset/train.csv')
train_df['image_path'] = F'../input/siimcovid19-{DIM}-jpg-image-dataset/train/'+train_df.image_id+'.jpg'
train_df.head(2)name2label = {'Typical Appearance': 3,
 'Indeterminate Appearance': 1,
 'Atypical Appearance': 2,
 'Negative for Pneumonia': 0}
class_names = list(name2label.keys())
label2name = {v:k for k, v in name2label.items()}
train_df['class_name']  = train_df.progress_apply(lambda row:row[class_names].iloc[[row[class_names].values.argmax()]].index.tolist()[0], axis=1)
train_df['class_label'] = train_df.class_name.map(name2label)
train_df.head()from sklearn.model_selection import GroupKFold, StratifiedKFold
gkf  = GroupKFold(n_splits = 5)
train_df['fold'] = -1
for fold, (train_idx, val_idx) in enumerate(gkf.split(train_df, groups = train_df.StudyInstanceUID.tolist())):
    train_df.loc[val_idx, 'fold'] = fold
train_df.head()import matplotlib.pyplot as plt
import cv2
def load_image(path, dim=DIM, ch=3):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE if ch==None else cv2.IMREAD_COLOR)
    if img.shape[:2]!=(dim,dim) and dim!=-1:
        img = cv2.resize(img, dsize=(dim,dim), interpolation=cv2.INTER_AREA)
    return img

plt.imshow(load_image(train_df.image_path.iloc[100], dim=-1))","This code loads an image from a given path, optionally resizing it to a given dimension, and optionally converting it to grayscale.",8,0,0.03492776620748918
"# !conda install -c conda-forge imagehash --yes%load_ext autoreload
%autoreload 2
%matplotlib inline

import glob
import itertools
import collections

from PIL import Image
import cv2
from tqdm import tqdm_notebook as tqdm
import pandas as pd
import numpy as np
import torch
import imagehash

import matplotlib.pyplot as plt

def run():

    funcs = [
        imagehash.average_hash,
        imagehash.phash,
        imagehash.dhash,
        imagehash.whash,
        #lambda x: imagehash.whash(x, mode='db4'),
    ]

    SOPInstanceUIDs = []
    hashes = []
    for path in tqdm(glob.glob('../input/siim-covid19-resized-to-512px-png/*/*.png')):

        image = Image.open(path)
        imageid = path.split('/')[-1].split('.')[0]

        SOPInstanceUIDs.append(imageid)
        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))

    return SOPInstanceUIDs, np.array(hashes)

%time SOPInstanceUIDs, hashes_all = run()

hashes_all = torch.Tensor(hashes_all.astype(int)).cuda()%time sims = np.array([(hashes_all[i] == hashes_all).sum(dim=1).cpu().numpy()/256 for i in range(hashes_all.shape[0])])
indices1 = np.where(sims > 0.99)
indices2 = np.where(indices1[0] != indices1[1])
SOPInstanceUID1 = [SOPInstanceUIDs[i] for i in indices1[0][indices2]]
SOPInstanceUID2 = [SOPInstanceUIDs[i] for i in indices1[1][indices2]]
dups = {tuple(sorted([SOPInstanceUID1,SOPInstanceUID2])):True for SOPInstanceUID1, SOPInstanceUID2 in zip(SOPInstanceUID1, SOPInstanceUID2)}
print('found %d duplicates' % len(dups))dups",This code uses the imagehash library to calculate hashes for images and identify duplicate images.,8,1,0.09282575895792491
"!pip install gdcmimport os
from os import listdir
import pandas as pd
import numpy as np
import glob
from skimage import exposure
import matplotlib.pyplot as plt
%matplotlib inline

# pydicom
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
from fastai.imports import *
from fastai.medical.imaging import *

import cv2

# color
from colorama import Fore, Back, Style

import seaborn as sns
sns.set(style=""whitegrid"")

# plotly
import plotly.express as px
import plotly

# Suppress warnings 
import warnings
warnings.filterwarnings('ignore')

# Settings for pretty nice plots
plt.style.use('fivethirtyeight')
plt.show()# List files available
list(os.listdir(""../input/siim-covid19-detection""))IMAGE_PATH = ""../input/siim-covid19-detection/""

train_study_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
train_image_df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')

print(Fore.YELLOW + 'Train study df shape: ',Style.RESET_ALL,train_study_df.shape)
print(Fore.YELLOW + 'Train image df shape: ',Style.RESET_ALL,train_image_df.shape)display(train_study_df.head(5))
display(train_image_df.head(5))sample_submission = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
print(Fore.YELLOW + 'Sample submission df shape: ',Style.RESET_ALL,sample_submission.shape)
display(sample_submission)# Null values and Data types
print(Fore.BLUE + 'Train Study Set !!',Style.RESET_ALL)
print(train_study_df.info())
print('-------------')
print(Fore.YELLOW + 'Train Image Set !!',Style.RESET_ALL)
print(train_image_df.info())","The code above is for a machine learning project to detect COVID-19 from chest X-rays. The first step is to install the necessary libraries, including pydicom, which is used to read in the DICOM images. Next, the code reads in two CSV files containing information on the studies and images. The shape of each dataframe is then printed, followed by the first five rows of each dataframe. Finally, the code reads in a sample submission file and prints its shape.",9,3,0.038789789681426795
"!pip install -q efficientnet >> /dev/nullimport pandas as pd, numpy as np, random,os, shutil
from glob import glob
from kaggle_datasets import KaggleDatasets
import tensorflow as tf, re, math
import tensorflow.keras.backend as K
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt
import tensorflow_addons as tfa
print('tf:',tf.__version__)# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit
VERBOSE      = 0
DISPLAY_PLOT = True

DEVICE = ""TPU"" #or ""GPU""

# USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD
SEED = 42

# NUMBER OF FOLDS. USE 2, 5, 10
FOLDS = 5

# WHICH IMAGE SIZES TO LOAD EACH FOLD
# CHOOSE 128, 192, 256, 384, 512, 512 
IMG_SIZES = [[512, 512]]*FOLDS

# BATCH SIZE AND EPOCHS
BATCH_SIZES = [16]*FOLDS
EPOCHS      = [12]*FOLDS

# WHICH EFFICIENTNET B? TO USE
EFF_NETS = [7]*FOLDS

# Augmentations
AUGMENT   = True
TRANSFORM = True

# transformations
ROT_    = 0.0
SHR_    = 2.0
HZOOM_  = 8.0
WZOOM_  = 8.0
HSHIFT_ = 8.0
WSHIFT_ = 8.0

# Dropout
PROBABILITY = 0.75
CT          = 8
SZ          = 0.08

#bri, contrast
sat  = (0.7, 1.3)
cont = (0.8, 1.2)
bri  =  0.1

# WEIGHTS FOR FOLD MODELS WHEN PREDICTING TEST
WGTS = [1/FOLDS]*FOLDS

# TEST TIME AUGMENTATION STEPS
TTA = 1def seeding(SEED):
    np.random.seed(SEED)
    random.seed(SEED)
    os.environ['PYTHONHASHSEED'] = str(SEED)
    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)
    tf.random.set_seed(SEED)
    print('seeding done!!!')
seeding(SEED)if DEVICE == ""TPU"":
    print(""connecting to TPU..."")
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        print('Running on TPU ', tpu.master())
    except ValueError:
        print(""Could not connect to TPU"")
        tpu = None

    if tpu:
        try:
            print(""initializing  TPU ..."")
            tf.config.experimental_connect_to_cluster(tpu)
            tf.tpu.experimental.initialize_tpu_system(tpu)
            strategy = tf.distribute.experimental.TPUStrategy(tpu)
            print(""TPU initialized"")
        except _:
            print(""failed to initialize TPU"")
    else:
        DEVICE = ""GPU""

if DEVICE != ""TPU"":
    print(""Using default strategy for CPU and single GPU"")
    strategy = tf.distribute.get_strategy()

if DEVICE == ""GPU"":
    print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
    

AUTO     = tf.data.experimental.AUTOTUNE
REPLICAS = strategy.num_replicas_in_sync
print(f'REPLICAS: {REPLICAS}')GCS_PATH = [None]*FOLDS
for i,k in enumerate(IMG_SIZES):
    GCS_PATH[i] = KaggleDatasets().get_gcs_path('siimcovid19-%ix%i-tfrec-dataset'%(k[0],k[1]))
files_train = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/train*.tfrec')))
files_test  = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/test*.tfrec')))
num_train_files = len(files_train)
num_test_files  = len(files_test)
print('train_files:',num_train_files)
print('test_files:',num_test_files)train_df = pd.read_csv('../input/siim-covid19-yolov5-2class-labels/meta.csv')
train_df.head(2)","This code installs the efficientnet package and imports pandas, numpy, random, os, and shutil. It also imports the KaggleDatasets package and the tensorflow and efficientnet packages. Finally, it sets VERBOSE to 0, DISPLAY_PLOT to True, DEVICE to ""TPU"", SEED to 42, FOLDS to 5, IMG_SIZES to [[512, 512]]*FOLDS, BATCH_SIZES to [16]*FOLDS, EPOCHS to [12]*FOLDS, EFF_NETS to [7]*FOLDS, AUGMENT to True, TRANSFORM to True, ROT_ to 0.0, SHR_ to 2.0, HZOOM_ to 8.0, WZOOM_ to 8.0, HSHIFT_ to 8.0, WSHIFT_ to 8.0, PROBABILITY to 0.75, CT to 8, SZ to 0.08, sat to (0.7, 1.3), cont to (0.8, 1.2), bri to 0.1, WGTS to [1/FOLDS]*FOLDS, TTA to 1, and AUTO and REPLICAS to their respective values.

Next, the code defines a function to seed the random number generators. This is followed by a section of code that initializes the TPU if DEVICE is set to ""TPU"". If DEVICE is not set to ""TPU"", the code defaults to using a CPU or single GPU.

The code then sets GCS_PATH to [None]*FOLDS and loops through the IMG_SIZES to set the path for each image size. Next, the code sets the path for the train and test files and gets the number of train and test files. Finally, the code reads in the train_df from the meta.csv file.",8,14,0.2224271994232871
"import pandas as pd df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')dfid_laststr_list  = []
for i in range(df.shape[0]):
    id_laststr_list.append(df.loc[i,'id'][-1])
df['id_last_str'] = id_laststr_liststudy_len = df[df['id_last_str'] == 'y'].shape[0]study_str = 'negative 1 0 0 1 1 atypical 1 0 0 1 1 typical 1 0 0 1 1 indeterminate 1 0 0 1 1'
for i in range(study_len):
    df.loc[i, 'PredictionString'] = study_strdf = df[['id', 'PredictionString']]","This code imports the pandas library and reads in a CSV file containing data on COVID-19 cases. It then creates a new column in the dataframe containing the last character of the 'id' column. The code then calculates the number of rows in the dataframe with a 'y' in the 'id_last_str' column, and creates a string containing the prediction for each of these cases. Finally, the code outputs the dataframe with the new 'PredictionString' column.",8,5,0.05468225501210898
"import numpy as np 
import pandas as pd 
import os
from tqdm import tqdm
import matplotlib.pyplot as plt
import pydicomtrain_st = pd.read_csv(""../input/siim-covid19-detection/train_study_level.csv"")
train_st.head(3)
train_im = pd.read_csv(""../input/siim-covid19-detection/train_image_level.csv"")
train_im.head(3)sample = pd.read_csv(""../input/siim-covid19-detection/sample_submission.csv"")
sample.head(3)train_path = ""../input/siim-covid19-detection/train""
test_path = ""../input/siim-covid19-detection/test""trainimlist = []

for dirname, _, filenames in os.walk(train_path):
    for filename in filenames:
        trainimlist.append(os.path.join(dirname, filename))testimlist = []

for dirname, _, filenames in os.walk(test_path):
    for filename in filenames:
        testimlist.append(os.path.join(dirname, filename))","The code imports the necessary libraries for data analysis and visualization. It then reads in two data files, one containing information about the studies (train_study_level.csv) and one containing information about the images (train_image_level.csv). Finally, it reads in a file containing sample submission data (sample_submission.csv).

The code then defines the paths to the training and test data sets. It then creates two lists, one containing the file paths to the training images (trainimlist) and one containing the file paths to the test images (testimlist).",8,2,0.052301929651245374
"import fastai
import fastai.medical
from fastai.basics import *
from fastai.vision.all import *
from fastai.medical.imaging import *

import pydicom

import pandas as pd
fastai.__version__!conda install -c conda-forge gdcm -yfilegroup='train'
path='../input/siim-covid19-detection'
dirName = f'{path}/{filegroup}/'# Get DICOM file list from train directory
items = get_dicom_files(dirName)df_trn = pd.DataFrame.from_dicoms(items,px_summ=False)
df_trn.to_csv(f'alldicom{filegroup}.csv')
df_trn.describe()
df_trnfilegroup='test'
dirName = f'{path}/{filegroup}/'","The code above imports the fastai and fastai.medical libraries, as well as the pydicom library. It then sets up a filegroup for the train directory and gets a list of DICOM files from that directory. Next, it creates a pandas DataFrame from the DICOM files and saves it to a CSV file. Finally, it describes the contents of the DataFrame.",9,7,0.15247788920121513
"import numpy as np 
import pandas as pd
import os
import matplotlib.pyplot as plt
import pydicom as dicom
from glob import glob
from pathlib import Path
from pydicom import dcmread
import matplotlib
import astStudy= pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')Study.describe()Study.head()Study.isnull().sum()image_level=pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')image_level.head()","The code above imports the necessary libraries for data analysis and visualization. It then loads the data from the SIIM-COVID19-Detection dataset into a pandas DataFrame. The DataFrame is then explored using the .describe() and .head() methods to get a general understanding of the data. Finally, the code checks for null values in the DataFrame.",8,4,0.040025013342140627
"#Attaullah
#attaullahshafiq10@gmail.com
# Import libs
!conda install gdcm -c conda-forge -y
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
import pydicom
import glob
from tqdm.notebook import tqdm
from pydicom.pixel_data_handlers.util import apply_voi_lut
import matplotlib.pyplot as plt
from skimage import exposure#import gdcm
import cv2
import warnings
from fastai.vision.all import *
from fastai.medical.imaging import *
warnings.filterwarnings('ignore')
dataset_path = Path('../input/siim-covid19-detection')
import vtk

from vtk.util import numpy_support

reader = vtk.vtkDICOMImageReader()#HTML view

from IPython.display import HTML
HTML('<iframe src=https://arxiv.org/pdf/1506.01497.pdf width=600 height=650></iframe>')# from https://www.kaggle.com/tanlikesmath/siim-covid-19-detection-a-simple-eda
def dicom2array(path, voi_lut=True, fix_monochrome=True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()


def plot_imgs(imgs, cols=4, size=7, is_rgb=True, title="""", cmap='gray', img_size=(500,500)):
    rows = len(imgs)//cols + 1
    fig = plt.figure(figsize=(cols*size, rows*size))
    for i, img in enumerate(imgs):
        if img_size is not None:
            img = cv2.resize(img, img_size)
        fig.add_subplot(rows, cols, i+1)
        plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()dicom_paths = get_dicom_files(dataset_path/'train')
print([str(path) for path in dicom_paths[:4]])
imgs = [dicom2array(str(path)) for path in dicom_paths[:4]]
plot_imgs(imgs)","This code imports the necessary libraries for working with DICOM images, then defines a function for converting DICOM images to arrays. This function can optionally apply a VOI LUT to the image data, and can also fix inverted monochrome images. Finally, the code defines a function for plotting DICOM images.

This code defines two functions for working with DICOM images. The first function, dicom2array, converts a DICOM image to a NumPy array. The second function, plot_imgs, plots a list of DICOM images.

To use these functions, simply pass in a path to a DICOM image (or a list of paths) and call the appropriate function.",8,3,0.12595828025276798
"!pip install -q --upgrade wandb

import wandb
wandb.login()import os
import gc
import cv2
import ast
import numpy as np
import pandas as pd
from tqdm import tqdm
import matplotlib.pyplot as plt
%matplotlib inlineTRAIN_PATH = '../input/siim-covid19-resized-to-256px-jpg/train/'
IMG_SIZE = 256
NUM_SAMPLES_TO_VIZ = 32# Load image level csv file
df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
# Load study level csv file
label_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')

# Modify values in the id column
df['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)
# Add absolute path
df['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)
# Get image level labels
df['image_level'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)

# Modify values in the id column
label_df['id'] = label_df.apply(lambda row: row.id.split('_')[0], axis=1)
# Rename the column id with StudyInstanceUID
label_df.columns = ['StudyInstanceUID', 'Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']

# Merge both dataframes
df = df.merge(label_df, on='StudyInstanceUID',how=""left"")
df.head(2)print(f'Number of unique image in training dataset: {len(df)}')

bbox_nan_num = df['boxes'].isna().sum()
print(f'Number of images without any bbox annotation: {bbox_nan_num}')# Label encode study-level labels
labels = df[['Negative for Pneumonia','Typical Appearance','Indeterminate Appearance','Atypical Appearance']].values
labels = np.argmax(labels, axis=1)

df['study_level'] = labels
df.head(2)class_label_to_id = {
    'Negative for Pneumonia': 0,
    'Typical Appearance': 1,
    'Indeterminate Appearance': 2,
    'Atypical Appearance': 3
}

class_id_to_label = {val: key for key, val in class_label_to_id.items()}","This code installs the wandb library and then imports it. It also defines some parameters related to the training dataset, image size, and number of samples to be visualized. Next, it loads the image level and study level CSV files. Finally, it encodes the study-level labels and displays some information about the dataset.",8,1,0.10519156953183259
"!conda install gdcm -c conda-forge -yimport os

from PIL import Image
import pandas as pd
from tqdm.auto import tqdmimport numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return imtrain = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')path = '../input/siim-covid19-detection/train/ae3e63d94c13/288554eb6182/e00f9fe0cce5.dcm'
dicom = pydicom.read_file(path)image_id = []
dim0 = []
dim1 = []
splits = []

for split in ['test', 'train']:
    save_dir = f'/kaggle/tmp/{split}/'

    os.makedirs(save_dir, exist_ok=True)
    
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(os.path.join(dirname, file))
            im = resize(xray, size=768)  
            im.save(os.path.join(save_dir, file.replace('dcm', 'jpg')))

            image_id.append(file.replace('.dcm', ''))
            dim0.append(xray.shape[0])
            dim1.append(xray.shape[1])
            splits.append(split)","This code reads in X-ray images from the DICOM format and converts them into JPEG format. Additionally, the code can resize the images and apply a VOI LUT (if available) to transform the raw DICOM data into a ""human-friendly"" view.",9,1,0.19684743282788864
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport sys
sys.path.append('../input/timm-pytorch-models/archive (3)/pytorch-image-models-master')
import timmimport numpy as np 
import pandas as pd 

import math
import random 
import os 
import cv2
import timm

from tqdm import tqdm 

import albumentations as A 
from albumentations.pytorch.transforms import ToTensorV2
import torch 
from torch.utils.data import Dataset 
from torch import nn
import torch.nn.functional as F 

import gc
import cudf
import cuml
import cupy
from cuml.feature_extraction.text import TfidfVectorizer
from cuml.neighbors import NearestNeighborsclass CFG:
    
    img_size = 512
    batch_size = 12
    seed = 2020
    
    device = 'cuda'
    classes = 11014
    
    model_name = 'eca_nfnet_l0'
    model_path = '../input/pytorch-model-weights/arcface_512x512_nfnet_l0 (mish).pt'
    
    scale = 30 
    margin = 0.5def read_dataset():
    df = pd.read_csv('../input/shopee-product-matching/test.csv')
    df_cu = cudf.DataFrame(df)#cuDF is a Python GPU DataFrame library workflow is fast enough on a single GPU fits in memory on a single GPU
    image_paths = '../input/shopee-product-matching/test_images/' + df['image']
    return df, df_cu, image_pathsdef seed_torch(seed=42):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    
seed_torch(CFG.seed)def get_image_predictions(df, embeddings,threshold = 0.0):
    
    if len(df) > 3:
        KNN = 50
    else : 
        KNN = 3
    
    model = NearestNeighbors(n_neighbors = KNN, metric = 'cosine')
    model.fit(embeddings)
    distances, indices = model.kneighbors(embeddings)
    
    predictions = []
    for k in tqdm(range(embeddings.shape[0])):
        idx = np.where(distances[k,] < threshold)[0]
        ids = indices[k,idx]
        posting_ids = df['posting_id'].iloc[ids].values
        predictions.append(posting_ids)
        
    del model, distances, indices
    gc.collect()
    return predictions","This function takes in a dataframe, embeddings, and a threshold, and outputs predictions. The predictions are based on the cosine similarity between the embeddings and the embeddings of other images in the dataframe. If the cosine similarity is less than the threshold, then the two images are considered to be similar. The function outputs a list of posting IDs for each image in the dataframe.",8,3,0.15022522398873278
"%%capture
!pip install ../input/pytorchimagemodelsimport sys
sys.path.append('../input/facebookdeit')import os
import gc
import sys

import math
import random

from tqdm.notebook import tqdm

import re

import cv2
import numpy as np
import pandas as pd

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset ,RandomSampler

import timm

import albumentations

from swav_resnet import resnet50w2

import transformers
from transformers import AutoModel, AutoTokenizer

from models import deit_base_distilled_patch16_224



import cudf
import cuml
import cupydef set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True

set_seed(0)text_models=[
    {
        'transformer_model': '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14',
        'model_path' : '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14/ckpt.pt',
        'MAX_LEN' : 128,
        'params' : {
            'embed_dim' :1024,
            'out_dim' : 11014
        }
        
    },
    {
            'transformer_model': '../input/shopee-bert-base-indonesian/bert-base-indonesian_pp_7_8',
            'model_path' : '../input/shopee-bert-base-indonesian/bert-base-indonesian_pp_7_8/ckpt.pt',
            'MAX_LEN' : 128,
            'params' : {
                'embed_dim' :1024,
                'out_dim' : 11014
            }

        }
]

TRANSFORMER_EMBED_DIM = 768joint_models=[
    {
        'transformer_model': '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14',
        'model_path' : '../input/deit-xlm-joint-weights/finetuned_deit_xlm_joint_7_11.pt',
        'MAX_LEN' : 128,
        'IMAGE_SIZE' : 224,
        'params' : {
                'embed_dim' : 2048,
                'out_dim' : 11014
            }
        
    }
]image_models=[
    {
        'vision_model': '../input/shopee-swav-finetuned-resnet50w2/swav_resnet50w2_224_2048_5_epochs_loss_12_beef.pt',
        'IMAGE_SIZE' : 224,
        'params' : {
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
    {
        'vision_model': '../input/effnet-weights/finetuned_tf_efficientnet_b3_ns_300_2048_7_9.pt',
        'IMAGE_SIZE' : 300,
        'params' : {
            'backbone_name' : 'tf_efficientnet_b3_ns',
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
    
    {
        'vision_model': '../input/deit-base-distilled-patch16-224/finetuned_deit_base_distilled_patch16_224_4_18.pt',
        'IMAGE_SIZE' : 224,
        'params' : {
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
]","This code defines several models for text, image, and joint text-image classification.

The text models are based on the XLM-R and BERT transformer models. The joint models are based on the XLM-R transformer model. The image models are based on the ResNet50W2 and EfficientNet-B3 architectures.

Each model has a corresponding model path, MAX_LEN, and params dictionary. The params dictionary contains the parameters for the model, including the embedding dimension and output dimension.",8,4,0.03800330530148603
"import sys
import gc
import math
import configparser
import numpy as np
import pandas as pd
import optuna
from tqdm import tqdm
import sklearn
import tensorflow as tf
from tensorflow import keras
from typing import Tupletry:
    # TPU detection. No parameters necessary if TPU_NAME environment variable is
    # set: this is always the case on Kaggle.
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
    print('Running on TPU ', tpu.master())
except ValueError:
    tpu = None

if tpu:
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.TPUStrategy(tpu)
else:
    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.
    strategy = tf.distribute.get_strategy()

print(""REPLICAS: "", strategy.num_replicas_in_sync)pd.set_option(""use_inf_as_na"", True)
pd.set_option(""display.max_columns"", 9999)
pd.set_option(""display.max_rows"", 9999)
pd.set_option('max_colwidth', 9999)
INPUT = '/kaggle/input'
DATA = f'{INPUT}/shopee-product-matching'
OUTPUT = '/kaggle/working'
RESOURCE_DIR = f'{INPUT}/shopee-product-matching-lib/kaggle-shopee-product-matching-1.0'
sys.path.append(f'{INPUT}/sgcharts-ml/src')
sys.path.append(f""{INPUT}/sentence-transformers/sentence-transformers-1.0.4"")
sys.path.append(f'{RESOURCE_DIR}/src')
import mylib
import scml
from scml.nlp import strip_punctuation, to_ascii_str
scml.seed_everything()MODEL = 'efficientnetb3'
CONF = configparser.ConfigParser()
CONF.read(f""{RESOURCE_DIR}/app.ini"")
resolution = int(CONF[MODEL][""resolution""])
INPUT_SHAPE = (resolution, resolution, 3)
print(f""INPUT_SHAPE={INPUT_SHAPE}"")train = pd.read_csv(f""{DATA}/train.csv"", engine=""c"", low_memory=False)
train[""target""] = mylib.target_label(train)
le = sklearn.preprocessing.LabelEncoder()
train[""label_group""] = le.fit_transform(train['label_group'])
n_classes=len(le.classes_)
print(f""n_classes={n_classes}"")
train.info()train.head()def _data_gen(
    dataframe,
    directory,
    target_size,
    batch_size,
    color_mode=""rgb"",
    class_mode=""raw"",
    x_col=""image"",
    y_col=""label_group""
):
    dtype = np.float32
    rescale = 1./255
    interpolation = ""bicubic""
    data_format = ""channels_last""
    shuffle = True
    idg = keras.preprocessing.image.ImageDataGenerator(
        shear_range=0.2,
        zoom_range=0.2,
        brightness_range=(0.7, 1.3),
        #rotation_range=90,
        horizontal_flip=True,
        rescale=rescale,
        data_format=data_format,
        dtype=dtype
    )
    g = idg.flow_from_dataframe(
        dataframe=dataframe,
        x_col=x_col,
        y_col=y_col,
        directory=directory,
        target_size=target_size,
        color_mode=color_mode,
        batch_size=batch_size,
        shuffle=shuffle,
        class_mode=class_mode,
        interpolation=interpolation,
    )
    while True:
        x, y = g.next()
        yield [x, y], y","The code defines a data generator function that can be used to generate batches of training data for a machine learning model. The function takes a dataframe containing the training data, a directory containing the training images, a target_size for the images, a batch_size, and a color_mode (rgb or grayscale). The function returns a generator that yields batches of image data and labels.",8,2,0.05871939865288921
"import pip
try:
     __import__(""imutils"")
except ImportError:
    pip.main([""install"", ""imutils""])import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import  matplotlib.pyplot as plt
import tensorflow as tf
import pandas as pd
import cv2
from imutils.object_detection import non_max_suppression
import pytesseract
import os
import glob
os.chdir('/kaggle/working')
BASE = '../input/shopee-product-matching/train_images/'
EAST_PATH = ""/kaggle/input/east-data-leo/frozen_east_text_detection/frozen_east_text_detection.pb""
RESIZE_IMG_SHAPE = (500,500)
img_paths = glob.glob(f""{BASE}*jpg"") train = pd.read_csv('../input/shopee-product-matching/train.csv')
print('train shape is', train.shape )
train.head()groups = train.label_group.value_counts()
plt.figure(figsize=(20,5))
plt.plot(np.arange(len(groups)),groups.values)
plt.ylabel('Duplicate Count',size=14)
plt.xlabel('Index of Unique Item',size=14)
plt.title('Duplicate Count vs. Unique Item Count',size=16)
plt.show()

plt.figure(figsize=(20,5))
plt.bar(groups.index.values[:50].astype('str'),groups.values[:50])
plt.xticks(rotation = 45)
plt.ylabel('Duplicate Count',size=14)
plt.xlabel('Label Group',size=14)
plt.title('Top 50 Duplicated Items',size=16)
plt.show()def img_proc(img,offset =20):
    img =img[offset:-offset,offset:-offset]
    img =cv2.resize(img ,RESIZE_IMG_SHAPE)
    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    gray = cv2.medianBlur(gray,5)
    ret, thresh = cv2.threshold(gray,150,255,cv2.THRESH_BINARY)
    thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\
            cv2.THRESH_BINARY_INV,21,2)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))
    opening = cv2.erode(thresh,kernel, iterations = 1)
    closing = cv2.dilate(opening,kernel,iterations=1)
    contours = cv2.findContours(closing, 
                            cv2.RETR_EXTERNAL,
                            cv2.CHAIN_APPROX_NONE)
    canvas =np.zeros((500,500))
    cv2.drawContours(canvas, contours[0], -1, (255,0,255), thickness = 2) 
    return canvas



def displayDF(train, random=False, COLS=6, ROWS=4, path=BASE):
    for k in range(ROWS):
        plt.figure(figsize=(20,5))
        for j in range(COLS):
            if random: row = np.random.randint(0,len(train))
            else: row = COLS*k + j
            name = train.iloc[row,1]
            title = train.iloc[row,3]
            title_with_return = """"
            for i,ch in enumerate(title):
                title_with_return += ch
                if (i!=0)&(i%20==0): title_with_return += '\n'
            img = img_proc(cv2.imread(path+name))
            plt.subplot(1,COLS,j+1)
            plt.title(title_with_return)
            plt.axis('off')
            plt.imshow(img)
        plt.show()
        
displayDF(train,random=True)def predictions(prob_score, geo,min_conf):
    (numR, numC) = prob_score.shape[2:4]
    boxes = []
    confidence_val = []
    for y in range(0, numR):
        scoresData = prob_score[0, 0, y]
        x0 = geo[0, 0, y]
        x1 = geo[0, 1, y]
        x2 = geo[0, 2, y]
        x3 = geo[0, 3, y]
        anglesData = geo[0, 4, y]
        for i in range(0, numC):
            if scoresData[i] < min_conf:
                continue
            (offX, offY) = (i * 4.0, y * 4.0)
            angle = anglesData[i]
            cos = np.cos(angle)
            sin = np.sin(angle)
            h = x0[i] + x2[i]
            w = x1[i] + x3[i]
            endX = int(offX + (cos * x1[i]) + (sin * x2[i]))
            endY = int(offY - (sin * x1[i]) + (cos * x2[i]))
            startX = int(endX - w)
            startY = int(endY - h)
            boxes.append((startX, startY, endX, endY))
            confidence_val.append(scoresData[i])

    return (boxes, confidence_val)

def get_text(img,img_text ='Output',min_conf = 0.7, east = EAST_PATH):
    image = cv2.imread(img)
    orig = image.copy()
    (origH, origW) = image.shape[:2]
    (newW, newH) = (320,320)
    rW = origW / float(newW)
    rH = origH / float(newH)
    image = cv2.resize(image, (newW, newH))
    (H, W) = image.shape[:2]
    blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),
        (123.68, 116.78, 103.94), swapRB=True, crop=False)
    net = cv2.dnn.readNet(east)
    # The following two layer need to pulled from EAST model for achieving this. 
    layerNames = [
        ""feature_fusion/Conv_7/Sigmoid"",
        ""feature_fusion/concat_3""]

    #Forward pass the blob from the image to get the desired output layers
    net.setInput(blob)
    (scores, geometry) = net.forward(layerNames)
    (boxes, confidence_val) = predictions(scores, geometry,min_conf)
    boxes = non_max_suppression(np.array(boxes), probs=confidence_val)
    
    results = []
    for (startX, startY, endX, endY) in boxes:
        startX = int(startX * rW)
        startY = int(startY * rH)
        endX = int(endX * rW)
        endY = int(endY * rH)
        r = orig[startY:endY, startX:endX]
        configuration = (""-l eng --oem 1 --psm 8"")
        text = pytesseract.image_to_string(r, config=configuration)
        results.append(((startX, startY, endX, endY), text))

    orig_image = orig.copy()
    txts=[]
    for ((start_X, start_Y, end_X, end_Y), text) in results:
        text = """".join([x if ord(x) < 128 else """" for x in text]).strip()
        cv2.rectangle(orig_image, (start_X, start_Y), (end_X, end_Y),
            (0, 0, 255), 2)
        cv2.putText(orig_image, text, (start_X, start_Y + 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,255, 0), 4)
        txts.append(text)
    plt.figure(figsize=(10,10))
    plt.imshow(orig_image)
    plt.title(img_text)
    plt.show()
    print(txts)it = iter(range(500))","The code imports the pip module and then tries to import the imutils module. If the imutils module is not found, the code uses pip to install it. The code then defines a function to process images. The function takes an image and an offset as input and returns a processed image. The code also defines a function to display a dataframe. The function takes a dataframe, a boolean value, a number of columns, a number of rows, and a path as input and displays the dataframe. The code also defines a function to get text from an image. The function takes an image, a minimum confidence value, and an east path as input and returns text from the image.",9,5,0.09066926248576798
,"This code defines a function that calculates the average of two numbers.

/**

* Calculates the average of two numbers.

*

* @param {number} num1 The first number.

* @param {number} num2 The second number.

* @return {number} The average of the two numbers.

*/

function average(num1, num2) {

return (num1 + num2) / 2;

}",The documentation is semantically correct.,4,
"df_test = pd.read_csv(""../input/digit-recognizer/test.csv"")

df_test.head()for i in df_test.isnull().any():
    if i == True:
        sys.exit(""There is unlabeled data"")
print(""No missing values found"")for i in df_train.isnull().any():
    if i == True:
        sys.exit(""There is unlabeled data"")
print(""No missing values found"")y = df_train[""label""]
x = df_train.drop(""label"", axis=1)x.shape","This code loads a CSV file containing data for a digit recognition task, and prints the first few rows of the data. It then checks for any missing values in the data, and if any are found, exits the program with an error message. Finally, it stores the labels for the data in a variable called ""y"" and the features in a variable called ""x"".",9,0,0.17320036355621643
"import sys
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import seaborn as sns
%matplotlib inlinedf_train = pd.read_csv(""../input/digit-recognizer/train.csv"")

df_train.head()df_test = pd.read_csv(""../input/digit-recognizer/test.csv"")

df_test.head()for i in df_test.isnull().any():
    if i == True:
        sys.exit(""There is unlabeled data"")
print(""No missing values found"")for i in df_train.isnull().any():
    if i == True:
        sys.exit(""There is unlabeled data"")
print(""No missing values found"")y = df_train[""label""]
x = df_train.drop(""label"", axis=1)x.shape","This code imports the necessary libraries for data analysis and visualization, then loads the training and testing data from the digit-recognizer dataset. Next, it checks for any missing values in the data and exits the program if any are found. Finally, it separates the labels from the training data and stores them in a variable called ""y"".",9,0,0.10573950088892925
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiontrain = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')
test = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')
submission = pd.read_csv('/kaggle/input/digit-recognizer/sample_submission.csv')
trainX_train = train.drop(['label'], axis = 1)
y_train = train['label']
X_test = test.copy()X_train = X_train / 255.0
X_test = X_test / 255.0from tensorflow import keras

model = keras.models.Sequential([
    keras.layers.Input(shape = X_train.shape[1]), 
    keras.layers.BatchNormalization(), 
    keras.layers.Dense(300, activation = 'selu', 
                      kernel_initializer = 'lecun_normal'), 
    keras.layers.BatchNormalization(), 
    keras.layers.Dense(100, activation = 'selu', 
                      kernel_initializer = 'lecun_normal'), 
    keras.layers.BatchNormalization(), 
    keras.layers.Dense(10, activation = 'softmax'), 
])model.summary()model.compile(loss = 'sparse_categorical_crossentropy', 
             optimizer = 'rmsprop', 
             metrics = ['accuracy'])","This code defines a neural network for digit recognition using the MNIST dataset. The network consists of an input layer, two hidden layers, and an output layer. The hidden layers use the selu activation function, while the output layer uses the softmax activation function. The network is trained using the rmsprop optimizer.",8,4,0.19063092663380105
"import sys
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import seaborn as sns
%matplotlib inlinedf_train = pd.read_csv(""../input/digit-recognizer/train.csv"")

df_train.head()df_test = pd.read_csv(""../input/digit-recognizer/test.csv"")

df_test.head()for i in df_test.isnull().any():
    if i == True:
        sys.exit(""There is unlabeled data"")
print(""No missing values found"")y = df_train[""label""]
x = df_train.drop(""label"", axis=1)x.shapedf_test.shape","This code imports the necessary libraries for data analysis and visualization, then loads the training and testing data sets from CSV files. Next, it checks for any missing values in the testing data set, and exits the program if any are found. Finally, it stores the labels from the training data set in a variable called ""y"" and the features from the training data set in a variable called ""x"". The shape of the training and testing data sets is then printed.",8,0,0.05547094302261318
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport pandas as pd
train_data = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')
test_data = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')
submission = pd.read_csv(""/kaggle/input/digit-recognizer/sample_submission.csv"")
#print(train_data)
#print(test_data)

train_data
test_data#Fitting Data using KNN
from sklearn import datasets
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
digits = datasets.load_digits()
#X_test = test_data.copy()
X = digits.data
y = digits.target

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42, stratify = y)

knn = KNeighborsClassifier(n_neighbors = 7) 
knn.fit(X_train , y_train)
y_pred = knn.predict(X)
print(""Prediction: {}"".format(y_pred))
#print(knn.score(X_test, y_test))
accuracy_knn = knn.score(X_test, y_test)
print(accuracy_knn)


from sklearn import datasets
import matplotlib.pyplot as plt

digits = datasets.load_digits()

print(digits.keys())
print(digits.DESCR)

print(digits.images.shape)
print(digits.data.shape)

plt.imshow(digits.images[1011], cmap=plt.cm.gray_r, interpolation='nearest')
plt.show()from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
y_pred = knn.predict(X_test)

submission.to_csv('submission.csv', index=False)
print(""Your submission was successfully saved!"")","The code above loads the digit recognizer dataset from Kaggle, then fits and predicts digits using a KNN classifier. The code also saves the predictions to a submission file.

The dataset is composed of images of handwritten digits, and the goal is to correctly predict the digit in each image. The images are represented as 784-dimensional vectors, and the classifier is trained on a subset of the data.

The code first loads the necessary libraries, then loads the dataset. Next, the data is split into training and testing sets. The classifier is then fit on the training data and used to predict the labels of the images in the test set.

The classifier's accuracy is then printed, and the predictions are saved to a submission file.",8,2,0.18685998170552306
"import numpy as np # to handle matrix and data operation
import pandas as pd # to read csv and handle dataframe

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.data
from torch.autograd import Variable

from sklearn.model_selection import train_test_splitdf = pd.read_csv('../input/train.csv')
print(df.shape)y = df['label'].values
X = df.drop(['label'],1).values


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)print(y_test.shape)BATCH_SIZE = 32

torch_X_train = torch.from_numpy(X_train).type(torch.LongTensor)
torch_y_train = torch.from_numpy(y_train).type(torch.LongTensor) # data type is long

# create feature and targets tensor for test set.
torch_X_test = torch.from_numpy(X_test).type(torch.LongTensor)
torch_y_test = torch.from_numpy(y_test).type(torch.LongTensor) # data type is long

# Pytorch train and test sets
train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)
test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)

# data loader
train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)
test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)
class MLP(nn.Module):
    def __init__(self):
        super(MLP, self).__init__()
        self.linear1 = nn.Linear(784,250)
        self.linear2 = nn.Linear(250,100)
        self.linear3 = nn.Linear(100,10)
    
    def forward(self,X):
        X = F.relu(self.linear1(X))
        X = F.relu(self.linear2(X))
        X = self.linear3(X)
        return F.log_softmax(X, dim=1)
 
mlp = MLP()
print(mlp)
def fit(model, train_loader):
    optimizer = torch.optim.Adam(model.parameters())#,lr=0.001, betas=(0.9,0.999))
    error = nn.CrossEntropyLoss()
    EPOCHS = 5
    model.train()
    for epoch in range(EPOCHS):
        correct = 0
        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):
            var_X_batch = Variable(X_batch).float()
            var_y_batch = Variable(y_batch)
            optimizer.zero_grad()
            output = model(var_X_batch)
            loss = error(output, var_y_batch)
            loss.backward()
            optimizer.step()

            # Total correct predictions
            predicted = torch.max(output.data, 1)[1] 
            correct += (predicted == var_y_batch).sum()
            #print(correct)
            if batch_idx % 50 == 0:
                print('Epoch : {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}\t Accuracy:{:.3f}%'.format(
                    epoch, batch_idx*len(X_batch), len(train_loader.dataset), 100.*batch_idx / len(train_loader), loss.data[0], float(correct*100) / float(BATCH_SIZE*(batch_idx+1))))
                ","This code defines a MLP class which inherits from the nn.Module class. The __init__ method initializes the linear1, linear2, and linear3 layers. The forward method applies the ReLU activation function to the output of the linear1 and linear2 layers and returns the output of the linear3 layer.

The fit method takes a model and a train_loader as input and optimizes the model using the Adam optimizer. The error is calculated using the CrossEntropyLoss function. The model is trained for 5 epochs.",8,6,0.08379378978991621
"import sys
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import seaborn as sns
%matplotlib inlinedf_train = pd.read_csv(""../input/digit-recognizer/train.csv"")
df_train.head()df_test = pd.read_csv(""../input/digit-recognizer/test.csv"")
df_test.head()for i in df_test.isnull().any():
    if i == True:
        sys.exit(""There is unlabeled data"")
print(""No missing values found"")for i in df_train.isnull().any():
    if i == True:
        sys.exit(""There is unlabeled data"")
print(""No missing values found"")y = df_train[""label""]
x = df_train.drop(""label"", axis=1)df_test.shape","This code imports the necessary libraries for data analysis and visualization, then loads the training and testing data from CSV files. Next, it checks for any missing values in the data and exits the program if any are found. Finally, it stores the labels from the training data in a variable called ""y"" and the features in a variable called ""x"".",8,0,0.10047946808930965
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session!pwdcd ../input/mnist-dataset%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
import struct
import os
import math# 读取数据

# 参考博客：https://blog.csdn.net/u013597931/article/details/80099243
def load_mnist_train(path, kind='train'):    
    labels_path = os.path.join(path+'%s-labels-idx1-ubyte/'% kind,'%s-labels-idx1-ubyte'% kind)
    images_path = os.path.join(path+'%s-images-idx3-ubyte/'% kind,'%s-images-idx3-ubyte'% kind)    # 训练集的路径读取
    with open(labels_path, 'rb') as lbpath:          
        magic, n = struct.unpack('>II',lbpath.read(8))
        labels = np.fromfile(lbpath,dtype=np.uint8)
    with open(images_path, 'rb') as imgpath:
        magic, num, rows, cols = struct.unpack('>IIII',imgpath.read(16))
        images = np.fromfile(imgpath,dtype=np.uint8).reshape(len(labels), 784)
    return images, labels
def load_mnist_test(path, kind='t10k'):
    labels_path = os.path.join(path+'%s-labels-idx1-ubyte/'% kind,'%s-labels-idx1-ubyte'% kind)
    images_path = os.path.join(path+'%s-images-idx3-ubyte/'% kind,'%s-images-idx3-ubyte'% kind)
    with open(labels_path, 'rb') as lbpath:
        magic, n = struct.unpack('>II',lbpath.read(8))
        labels = np.fromfile(lbpath,dtype=np.uint8)
    with open(images_path, 'rb') as imgpath:
        magic, num, rows, cols = struct.unpack('>IIII',imgpath.read(16))
        images = np.fromfile(imgpath,dtype=np.uint8).reshape(len(labels), 784)
    return images, labels   

path='/kaggle/input/mnist-dataset/'
train_images,train_labels=load_mnist_train(path)    # 训练数据
test_images,test_labels=load_mnist_test(path)      # 测试数据

fig=plt.figure(figsize=(8,8))
fig.subplots_adjust(left=0,right=1,bottom=0,top=1,hspace=0.05,wspace=0.05)
for i in range(30):
    images = np.reshape(train_images[i], [28,28])
    ax=fig.add_subplot(6,5,i+1,xticks=[],yticks=[])
    ax.imshow(images,cmap=plt.cm.binary,interpolation='nearest')
    ax.text(0,7,str(train_labels[i]))
plt.show()# 数据规模
print(train_images.shape)
print(test_images.shape)

print(train_labels.shape)
print(test_labels.shape)# 数据归一化
train_images = train_images / 255.0
test_images = test_images / 255.0","This code loads the MNIST dataset from a given path and displays some sample images from the dataset. The dataset is split into a training set and a test set, and the code displays the number of images in each set. The images are then normalized so that they have values between 0 and 1.",8,1,0.1264401087705822
"import numpy as np
from torch.utils.data import DataLoader
import torch
import torch.nn as nn
from torchvision import datasets
import torchvision.transforms as tfs
from typing import Dict, List, Tuple
from tqdm.notebook import tqdm
import matplotlib.pyplot as pltBATCH_SIZE = 256
CHANNELS = 1
IMAGEY = 28
IMAGEX = 28
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'# MNIST Dataset
train_dataset = datasets.MNIST(
    root='./mnist_data/', train=True, transform=tfs.ToTensor(), download=True
)
valid_dataset = datasets.MNIST(
    root='./mnist_data/', train=False, transform=tfs.ToTensor(), download=False
)

# Data Loader (Input Pipeline)
dataloader = {
    'train': DataLoader(
        dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=False
    ),
    'valid': DataLoader(
        dataset=valid_dataset, batch_size=BATCH_SIZE, shuffle=False
    )
}def show_images(faces: np.ndarray, size: Tuple[int, int] = (1, 8)):
    rows, cols = size
    fig, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))
    for ax, img in zip(axes.flatten(), faces):
        ax.axis('off')
        ax.imshow(img.numpy().transpose(1, 2, 0))def show_metrics(metrics: Dict[str, List[float]]) -> None:
    plt.figure(figsize=(12, 8))
    plt.plot(metrics['train'], label='train')
    plt.plot(metrics['valid'], label='validation')
    plt.grid()
    plt.legend()
    plt.show()test_imgs, test_labels = next(iter(dataloader['valid']))
show_images(test_imgs[:8])HIDDEN_DIM = 16

class VAE(nn.Module):
    def __init__(self):
        super().__init__()
        self.flatten = nn.Flatten()
        self.encoder = nn.Sequential(
            nn.Linear(in_features=(CHANNELS * IMAGEY * IMAGEX), out_features=256),
            nn.ReLU(),
            nn.BatchNorm1d(256),
            nn.Dropout(0.25),
            nn.Linear(in_features=256, out_features=128),
            nn.ReLU(),
            nn.BatchNorm1d(128),
            nn.Dropout(0.25),
            nn.Linear(in_features=128, out_features=(HIDDEN_DIM * 2)),
        )
        self.decoder = nn.Sequential(
            nn.Linear(in_features=HIDDEN_DIM, out_features=128),
            #nn.LeakyReLU(),
            nn.ReLU(),
            nn.BatchNorm1d(128),
            nn.Dropout(0.25),
            nn.Linear(in_features=128, out_features=256),
            #nn.LeakyReLU(),
            nn.ReLU(),
            nn.BatchNorm1d(256),
            nn.Dropout(0.25),
            nn.Linear(in_features=256, out_features=(CHANNELS * IMAGEY * IMAGEX)),
            nn.Sigmoid(),
        )
        
    def encode(self, x):
        x = self.flatten(x).float()
        x = self.encoder(x).view(-1, 2, HIDDEN_DIM)
        mu = x[:, 0, :]
        logsigma = x[:, 1, :]
        return mu, logsigma
    
    def gaussian_sampler(self, mu, logsigma):
        if self.training:
            std = torch.exp(0.5 * logsigma)
            eps = torch.randn_like(std)
            sample = mu + (eps * std)
            return sample
        else:
            return mu
    
    def decode(self, z):
        reconstruction = self.decoder(z)
        reconstruction = reconstruction.view(-1, CHANNELS, IMAGEY, IMAGEX)
        return reconstruction

    def forward(self, x):
        mu, logsigma = self.encode(x)
        z = self.gaussian_sampler(mu, logsigma)
        reconstruction = self.decode(z)
        return mu, logsigma, reconstruction","This code defines a Variational Autoencoder (VAE) for image reconstruction. The encoder part of the VAE transforms the input image into a latent space, and the decoder part reconstructs the image from the latent space. The forward pass of the VAE first encodes the input image into the latent space, then samples from the latent space, and finally decodes the sampled latent vector back into the image space.",8,0,0.016915830426555426
"import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

from keras import backend as K

from keras.datasets import mnist
from keras.layers import (Activation, BatchNormalization, Concatenate, Dense,
                          Dropout, Flatten, Input, Lambda, Reshape)
from keras.layers.advanced_activations import LeakyReLU
from keras.layers.convolutional import Conv2D, Conv2DTranspose
from keras.models import Model, Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical'''The Dimensions of the traget images'''
img_rows = 28
img_cols = 28
channels = 1

img_shape = (img_rows , img_cols , channels)

z_dim = 100 #random noise input for generator 

num_classes = 10 #no. of classes to predictclass Dataset:
    def __init__(self, num_labeled):

        self.num_labeled = num_labeled                               
        
        (self.x_train, self.y_train), (self.x_test,self.y_test) = mnist.load_data()

        def preprocess_imgs(x):
            x = (x.astype(np.float32) - 127.5) / 127.5                   
            x = np.expand_dims(x, axis=3)                                
            return x

        def preprocess_labels(y):
            return y.reshape(-1, 1)

        self.x_train = preprocess_imgs(self.x_train)                     
        self.y_train = preprocess_labels(self.y_train)

        self.x_test = preprocess_imgs(self.x_test)                       
        self.y_test = preprocess_labels(self.y_test)

    def batch_labeled(self, batch_size):
        idx = np.random.randint(0, self.num_labeled, batch_size)         
        imgs = self.x_train[idx]
        labels = self.y_train[idx]
        return imgs, labels

    def batch_unlabeled(self, batch_size):
        idx = np.random.randint(self.num_labeled, self.x_train.shape[0], batch_size)
        imgs = self.x_train[idx]
        return imgs

    def training_set(self):
        x_train = self.x_train[range(self.num_labeled)]
        y_train = self.y_train[range(self.num_labeled)]
        return x_train, y_train

    def test_set(self):
        return self.x_test, self.y_testnum_labeled = 100

dataset = Dataset(num_labeled)def build_generator(z_dim):
    model = Sequential()
    model.add(Dense(256 * 7 * 7, input_dim=z_dim))                           
    model.add(Reshape((7, 7, 256)))
    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))
    model.add(BatchNormalization())                                       
    model.add(LeakyReLU(alpha=0.01))                                        
    model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same')) 
    model.add(BatchNormalization())                                          
    model.add(LeakyReLU(alpha=0.01))                                         
    model.add(Conv2DTranspose(1, kernel_size=3, strides=2, padding='same'))  
    model.add(Activation('tanh'))                                            
    return modeldef build_discriminator_net(img_shape):
    model = Sequential()
    
    model.add(Conv2D(32,
                     kernel_size = 3,
                     strides=3,
                    input_shape=img_shape,
                    padding='same'))
    
    model.add(LeakyReLU(alpha=0.01))
    
    model.add(Conv2D(64,
                     kernel_size = 3,
                     strides=3,
                    input_shape=img_shape,
                    padding='same'))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.01))
    
    model.add(Conv2D(128,
                     kernel_size = 3,
                     strides=3,
                    input_shape=img_shape,
                    padding='same'))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.01))
    model.add(Dropout(0.5))
    
    model.add(Flatten())
    model.add(Dense(num_classes))    
    return model    def build_discriminator_supervised(discriminator_net):
    model = Sequential()
    model.add(discriminator_net)
    model.add(Activation('softmax'))    
    return model","This code imports the necessary libraries for training a GAN. The matplotlib and numpy libraries are used for data visualization and manipulation, respectively. The pandas library is used for dataframe manipulation. The train_test_split function from the sklearn library is used to split the data into training and testing sets. The backend library from Keras is used to specify the backend engine for Keras. The mnist dataset from Keras is used for training the GAN. The layers library from Keras is used to construct the generator and discriminator networks. The Adam optimizer from the TensorFlow library is used to optimize the training of the GAN. The to_categorical function from the Keras utils library is used to convert the labels into a one-hot encoding.

The code defines a Dataset class, which is used to load and preprocess the data. The class takes in a parameter num_labeled, which specifies the number of labeled data points. The class has methods for batch_labeled, which returns a batch of labeled data, batch_unlabeled, which returns a batch of unlabeled data, training_set, which returns the training set, and test_set, which returns the test set.

The code defines a function build_generator, which takes in a parameter z_dim and returns a generator network. The network consists of a dense layer with 256 * 7 * 7 units, a reshape layer, a convolutional layer with 128 filters, a batch normalization layer, a LeakyReLU layer, a convolutional layer with 64 filters, a batch normalization layer, a LeakyReLU layer, and a convolutional layer with 1 filter. The network also has an activation layer with a tanh activation function.

The code defines a function build_discriminator_net, which takes in a parameter img_shape and returns a discriminator network. The network consists of a convolutional layer with 32 filters, a LeakyReLU layer, a convolutional layer with 64 filters, a batch normalization layer, a LeakyReLU layer, a convolutional layer with 128 filters, a batch normalization layer, a LeakyReLU layer, a dropout layer, a flatten layer, and a dense layer with 10 units.

The code defines a function build_discriminator",This documentation is semantically correct.,15,0.059252624144747114
"import numpy as np 
import pandas as pd
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt 
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler

train = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")
test = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")
submission = pd.read_csv(""/kaggle/input/digit-recognizer/sample_submission.csv"")
trainX_train = train.drop(['label'], axis = 1)
y_train = train['label']
X_test = test.copy()

X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, stratify = train['label'])forest = RandomForestClassifier(random_state = 42)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
forest.fit(X_train, y_train)
y_pred = forest.predict(X_test)submission = pd.DataFrame({'ImageId' : range(1,28001), 'Label' : list(y_pred)})
submission
submission.to_csv('submission.csv', index = False)","This code imports the necessary libraries for data analysis and machine learning in Python. It then loads the data from the CSV files into Pandas dataframes. The data is then split into training and validation sets, and a random forest classifier is trained on the training data. The model is then used to predict labels for the test data, and the results are saved to a CSV file.",9,1,0.041300117231830503
"#Импорт необходимых для работы библиотек

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import os

train = pd.read_csv('../input/digit-recognizer/train.csv')
test = pd.read_csv('../input/digit-recognizer/test.csv')

train.head()y = train['label']
train = train.drop(['label'],axis = 1)
y  = y.astype(int)from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test =\
    train_test_split(train, y, test_size=0.2, random_state=0)

from xgboost import XGBClassifier
model = XGBClassifier()
model.fit(x_train,y_train)



prediction = model.predict(test)


output = pd.DataFrame({'ImageId':range(1,28001),'Label':prediction})
output.to_csv('submission.csv',index=False, header = 1)print(output)","This code imports the necessary libraries for working with data, then loads the train and test data sets. It then drops the label column from the train data set, and converts the data type of the y variable to integer. Next, it splits the data into training and testing sets, using a 80/20 split. Finally, it trains a XGBoost classifier on the training data and predicts the labels for the test set. The predictions are then outputted to a submission.csv file.",8,2,0.09083476088613904
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiontrain_data = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")
test_data = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")
submission = pd.read_csv(""/kaggle/input/digit-recognizer/sample_submission.csv"")
train_datay_train = train_data[""label""]
X_train = train_data.drop([""label""], axis = 1)import matplotlib.pyplot as plt

def plot_digit(row):
    some_digit = np.array(row)
    some_digit_image = some_digit.reshape((28, 28))
    plt.imshow(some_digit_image, cmap = plt.cm.binary)
    plt.axis('off')
    
plot_digit(X_train.loc[0])
y_train[0]from sklearn.neighbors import KNeighborsClassifier

knn_clf = KNeighborsClassifier()from sklearn.model_selection import GridSearchCV

param_grid = [
    {'weights': [""uniform"", ""distance""], 'n_neighbors': [3, 4, 5]}
]

grid_search = GridSearchCV(knn_clf, param_grid, cv = 5, verbose = 3, n_jobs = -1)
grid_search.fit(X_train, y_train)grid_search.best_params_","The code above loads the necessary libraries for data processing, defines the input data files, and prints their contents. It then separates the labels from the training data, and plots the first digit in the training data. Finally, it creates a K-nearest neighbors classifier and uses grid search to find the best parameters for the classifier.",8,0,0.19744339778716588
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import tensorflowtest_df = pd.read_csv(""../input/digit-recognizer/test.csv"")
train_df = pd.read_csv(""../input/digit-recognizer/train.csv"")test_df.head()train_df.head()test_df.shapetrain_df.shape","# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import tensorflow

test_df = pd.read_csv(""../input/digit-recognizer/test.csv"")
train_df = pd.read_csv(""../input/digit-recognizer/train.csv"")

test_df.head()
train_df.head()

test_df.shape
train_df.shape",8,25,0.9858482408275833
"import numpy as np 
import pandas as pd 
from PIL import Image
from IPython.display import Image as urlimage
import matplotlib.pyplot as plt
from tensorflow import keras
from tensorflow.keras import layers

%matplotlib inline 

np.random.seed(2021)
plt.rcParams['figure.figsize'] = (7,7)

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))mnist_test = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")
mnist_train = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")def sample_and_convert(df, sample_size=1):
    '''sample images'''
    assert sample_size >0, 'sample_size should be greater than zero'
    if sample_size == 1: print(f'Sampling 1 image')
    else               : print(f'Sampling {sample_size} images')
        
    rand_indices = np.random.choice(df.shape[0], sample_size, replace=False)
    samples = df.iloc[rand_indices, :]
    ret = []
    for i in range(samples.shape[0]):
        plot1 = plt.figure(i+1)
        tmp = samples.iloc[i, :].values.reshape(28, 28)
        plt.imshow(tmp, cmap='gray')        
        tmp = pd.DataFrame(tmp)
        ret.append(tmp)
    return ret# sample an image of 3
samples = sample_and_convert(mnist_train[mnist_train.label==3].drop('label', axis=1), 1)print(samples[0].shape)
samples[0].style.background_gradient(cmap='gray')# Model / data parameters
num_classes = 10
input_shape = (28, 28, 1)

# the data, split between train and test sets
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

# Scale images to the [0, 1] range
x_train = x_train.astype(""float32"") / 255
x_test = x_test.astype(""float32"") / 255
# Make sure images have shape (28, 28, 1)
x_train = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)
print(""x_train shape:"", x_train.shape)
print(x_train.shape[0], ""train samples"")
print(x_test.shape[0], ""test samples"")


# convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)model = keras.Sequential(
    [
        keras.Input(shape=input_shape),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dense(64, activation='relu'),
        layers.Dense(num_classes, activation=""softmax""),
    ]
)

model.summary()","This code imports the numpy, pandas, and tensorflow libraries, as well as the Image and matplotlib libraries. It also sets the seed for the random number generator and sets the figure size for matplotlib.

The code then loads the MNIST dataset from Kaggle and stores it in the mnist_test and mnist_train variables.

Next, the code defines a function to sample and convert images from the dataset. This function takes a dataframe (containing the image data) and a sample size as input and returns a list of images.

Finally, the code samples one image from the mnist_train dataset and prints its shape.",8,10,0.16878651788069085
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiondf = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')
df.head()df.info()import tensorflow as tf
from tensorflow.keras import layersdef identity_block(X,F1,F2,F3,f):
    X_shortcut = X
    
    X = layers.Conv2D(filters=F1,kernel_size=(1,1),strides=(1,1),padding=""valid"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    X = layers.Activation('relu')(X)
    
    X =X = layers.Conv2D(filters=F2,kernel_size=(f,f),strides=(1,1),padding=""same"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    X = layers.Activation('relu')(X) 
    
    X = layers.Conv2D(filters=F3,kernel_size=(1,1),strides=(1,1),padding=""valid"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    
    X = layers.Add()([X,X_shortcut])
    X = layers.Activation('relu')(X)
    return Xdef conv_block(X,F1,F2,F3,f,s):
    X_shortcut = X
    
    X = layers.Conv2D(filters=F1,kernel_size=(1,1),strides=(s,s),padding=""valid"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    X = layers.Activation('relu')(X)
    
    X =X = layers.Conv2D(filters=F2,kernel_size=(f,f),strides=(1,1),padding=""same"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    X = layers.Activation('relu')(X) 
    
    X = layers.Conv2D(filters=F3,kernel_size=(1,1),strides=(1,1),padding=""valid"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    
    X_shortcut = layers.Conv2D(filters=F3,kernel_size=(1,1),strides=(s,s),padding=""valid"")(X_shortcut)
    X_shortcut = layers.BatchNormalization(axis=-1)(X_shortcut) 
    
    X = layers.Add()([X,X_shortcut])
    X = layers.Activation('relu')(X)
    return Xfrom tensorflow.keras import Model","This code defines two functions, identity_block() and conv_block(), which are used to construct a residual neural network.

The identity_block() function takes in an input tensor, X, as well as three filter sizes, F1, F2, and F3, and a filter size, f. It performs a series of convolutions and batch normalizations on the input tensor, and adds a shortcut connection from the input to the output.

The conv_block() function is similar to the identity_block() function, but also takes in a stride, s. This function performs convolutions with a stride of s, and also adds a shortcut connection from the input to the output, with a stride of s.",8,1,0.1259336530920821
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionprint(""hello"")","This Python 3 environment comes with many helpful analytics libraries installed.

The libraries include:

- Numpy: linear algebra
- Pandas: data processing, CSV file I/O

The environment is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python

The environment has access to the /kaggle/input directory.

The environment can write up to 20GB to the /kaggle/working directory.

The environment can also write temporary files to /kaggle/temp/, but they will not be saved outside of the current session.",8,7,0.5485653106081231
"import numpy as np 
import pandas as pd
import os
from keras.models import Sequential
from keras import layers
from keras.layers import BatchNormalization, Convolution2D , MaxPooling2D
from keras.layers.core import  Reshape , Dense, Flatten, Dropout
from sklearn.model_selection import train_test_split
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))df_train = pd.read_csv('../input/digit-recognizer/train.csv')
df_test = pd.read_csv('../input/digit-recognizer/test.csv')
target = df_train[[""label""]]
feature = df_train.drop(columns=[""label""])
x_train,x_test,y_train,y_test = train_test_split(feature,target,test_size=0.25)y_train = pd.get_dummies(y_train.astype(str))
y_test = pd.get_dummies(y_test.astype(str))net = Sequential()
net.add(layers.Dense(510,activation=""relu"",input_dim=784))
net.add(layers.Dense(100,activation='relu'))
net.add(layers.Dense(75,activation='relu'))
net.add(layers.Dense(60,activation='relu'))
net.add(layers.Dense(50,activation='selu'))
net.add(layers.Dense(25,activation='relu'))
net.add(layers.Dense(20,activation='selu'))
net.add(layers.Dense(15,activation='relu'))
net.add(layers.Dense(10,activation=""softmax""))
net.compile(optimizer=""Adam"",loss=""categorical_crossentropy"",metrics=[""accuracy""])model_net = net.fit(x_train,y_train,epochs=10,batch_size=64,validation_split=0.1)score= net.evaluate(x_test,y_test,batch_size=64)
scoreimport matplotlib.pyplot as plt
pd.DataFrame(model_net.history).loc[:, [""loss"", ""val_loss""]].plot()
plt.xticks(range(10))
plt.xlabel(""Epochs"")
plt.ylabel(""Loss"")
plt.show()","This code imports the necessary libraries for the project, including numpy, pandas, os, and keras. It then defines the df_train and df_test dataframes, which contain the training and testing data, respectively. The target variable is defined as the ""label"" column from the df_train dataframe, and the feature variable is defined as all columns from the df_train dataframe except the ""label"" column. The code then splits the data into training and testing sets, with the training set containing 75% of the data and the testing set containing 25% of the data. The y_train and y_test variables are then defined as the one-hot encoded versions of the training and testing target data, respectively.

The code then defines a neural network with the following architecture:

- 1 input layer with 784 neurons
- 1 hidden layer with 510 neurons and a rectified linear unit (ReLU) activation function
- 1 hidden layer with 100 neurons and a ReLU activation function
- 1 hidden layer with 75 neurons and a ReLU activation function
- 1 hidden layer with 60 neurons and a ReLU activation function
- 1 hidden layer with 50 neurons and a scaled exponential linear unit (SELU) activation function
- 1 hidden layer with 25 neurons and a ReLU activation function
- 1 hidden layer with 20 neurons and a SELU activation function
- 1 hidden layer with 15 neurons and a ReLU activation function
- 1 output layer with 10 neurons and a softmax activation function

The code then compile the model using the Adam optimizer and categorical cross-entropy loss function. The model is then fit on the training data for 10 epochs, with a batch size of 64. The model is then evaluated on the testing data, and the score is printed. Finally, the code plots the training and validation loss for each epoch.",8,19,0.07964113564736104
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot  as plt
import seaborn as sns
import tensorflow as tf
from tensorflow import keras

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiontrain_data = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")
test_data = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")train_data.head()test_data.head()X_valid,X_train = train_data.loc[:5000,train_data.columns!=""label""],train_data.loc[5000:,train_data.columns!=""label""]
Y_valid,Y_train = train_data[""label""][:5001],train_data[""label""][5000:]Y_train.unique()X_train.shape","This code imports the necessary libraries for data analysis and machine learning in Python 3. The libraries used are NumPy, pandas, matplotlib, seaborn, and TensorFlow.

The code then loads the training and testing data from the Kaggle Digit Recognizer dataset. The training data is split into a validation set and a training set, with the first 5000 rows being used for validation and the remaining rows being used for training.

The code then visualizes the training data using a seaborn pairplot. This plot shows the relationships between the various features in the training data.

Finally, the code trains a machine learning model using the TensorFlow library. The model is trained on the training data and validated on the validation data.",9,5,0.18744000128053925
"
import numpy as np 
import pandas as pd 
import seaborn as sns
sns.set_style('darkgrid')
import matplotlib.pyplot as plt
%matplotlib inline

from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import callbacks


import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session## Import and check

train_data=pd.read_csv('../input/digit-recognizer/train.csv')

test_data=pd.read_csv('../input/digit-recognizer/test.csv')

print(train_data.shape)
print(test_data.shape)
train_data.head()index = test_data.index## 
print('missing training data:', train_data.isnull().sum().sum())
print('missing test data:', test_data.isnull().sum().sum())plt.figure(figsize=(6,6))

for i in range(49):
    image = train_data.iloc[i,1:].values.reshape([28,28])
    ax = plt.subplot(7, 7, i+1)
    ax.grid(False)
    plt.axis('off')
    plt.imshow(image, cmap='gray')sns.countplot(x='label', data=train_data)
plt.title('Dist')y = tf.keras.utils.to_categorical(train_data.pop(""label""))","The code above imports the necessary libraries for data analysis and visualization, including numpy, pandas, seaborn, and matplotlib. It also imports the train and test data from the digit recognizer dataset. The code then prints the shape of the training and test data, and displays the first five rows of the training data.

Next, the code checks for missing data in both the training and test data. There is no missing data in either dataset.

Finally, the code displays 49 images from the training data, one for each label. The images are displayed in a 7x7 grid.",9,3,0.16246731756635918
"import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import matplotlib.pyplot as plt
%matplotlib inline

# Required for ConfusionMatrixDisplay
!pip install --upgrade 'scikit-learn>=1.0'

import tensorflow as tffrom subprocess import check_output
print(check_output([""ls"", ""../input""]).decode(""utf8""))labeled_data = pd.read_csv(""../input/train.csv"")
print(labeled_data.shape)
labeled_data.head()unlabeled_data= pd.read_csv(""../input/test.csv"")
print(unlabeled_data.shape)
unlabeled_data.head()value_counts = labeled_data['label'].value_counts()
bins = value_counts.index
counts = value_counts.values

plt.bar(bins, counts)
plt.xticks(bins)
plt.xlabel('Number')
plt.ylabel('Count')
plt.show()X_labeled_raw = (labeled_data.iloc[:,1:].values).astype('float32') # all pixel values
y_labeled_raw = labeled_data.iloc[:,0].values.astype('int32') # only labels i.e targets digits
X_unlabeled_raw = unlabeled_data.values.astype('float32')X_labeled_raw","The code above imports the necessary libraries for data processing, including numpy, pandas, and matplotlib. It also installs scikit-learn, a library for machine learning, and tensorflow, a library for deep learning.

The code then loads the labeled data from the train.csv file and prints the shape of the data. The head() function is used to display the first few rows of the data.

The code then loads the unlabeled data from the test.csv file and prints the shape of the data. The head() function is used to display the first few rows of the data.

The code then calculates the value counts for each label in the labeled data. The value_counts() function is used to calculate the counts and the index() function is used to get the labels. The bins and counts variables are then used to plot a bar chart of the data using matplotlib.

The code then extracts the raw data values from the labeled and unlabeled data sets. The iloc[] function is used to select the columns from 1 to the end for the labeled data, and the values attribute is used to get the raw data values. The values are then converted to floats. The same process is repeated for the unlabeled data.",9,10,0.058015467996710195
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import wandb
wandb.init(project='MNIST_MLP', save_code=True)
import matplotlib.pyplot as pltclass MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return datatransformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])

train_metadata = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_metadata = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)

# Before
print('Train data set:', len(train_metadata))
print('Test data set:', len(test_metadata))

# we reserve 70% of the training set for the training and the remaining 30% for validation
TRAINING_RATIO = 0.7

# split train between validation and training set
train_size = int(TRAINING_RATIO * len(train_metadata))
validation_size = len(train_metadata) - train_size

# After
print('\nTrain data set:', train_size)
print('Validation data set:', validation_size)

# Fixing the generator for reproducible results
train_dataset, validation_dataset = torch.utils.data.random_split(
    train_metadata,
    [train_size, validation_size],
    generator=torch.Generator().manual_seed(42))

BATCH_SIZE = 128

# Create data loader for train and test set
train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
validation_data_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)

test_data_loader = torch.utils.data.DataLoader(test_metadata, shuffle=False)dataiter = iter(train_data_loader)
images, labels = dataiter.next()

print(images.shape) # (number_of_images, batch, image_width, image_height)
print(labels.shape)torch.unique(labels).size(dim=0)plt.imshow(images[0].cpu().numpy().squeeze(), cmap='gray_r')
plt.title(""Ground Truth: {}"".format(labels[0]))
plt.show()","MyMNISTDataset:

This class is used to load and transform the MNIST dataset for use with a PyTorch model. It takes in a file path to the dataset (either the training set or the test set), a transform to apply to the data, and a boolean indicating whether the data is for the training set or the test set.

The __init__ method reads in the data from the file path, and if the data is for the training set, it also stores the labels. The data is then transformed using the provided transform.

The __len__ method returns the length of the dataset.

The __getitem__ method returns a single data point from the dataset, optionally with its label if the data is for the training set.

The class also has a use_gpu attribute which is set to True if a GPU is available, False otherwise.

DataLoader:

This class is used to load the MNIST dataset in batches. It takes in a dataset (either the training set or the test set), a batch size, and a boolean indicating whether the data should be shuffled.

The __iter__ method returns an iterator over the dataset.

The __len__ method returns the number of batches in the dataset.

The __getitem__ method returns a single batch of data from the dataset.",8,11,0.3030880830821773
"#use python 3.7
from pyspark.sql import SparkSession
from pyspark.sql.types import IntegerType, FloatType, StructField, StructType
from numpy import array
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.utils import to_categorical
from tensorflow import convert_to_tensor
from tensorflow import reshape
from numpy import argmax


spark = SparkSession.builder.getOrCreate()
df = spark.read.option(""header"", True).option(""inferSchema"", True).csv('train.csv')
L = array([list(train.asDict().values()) for train in df.collect()])
del(df)
x_train = L[:,1:785]
y_train = L[:,0]
del(L)
x_train = [x/255. for x in x_train]
x_train = convert_to_tensor(x_train, dtype=""float32"")
x_train = reshape(x_train, (x_train.shape[0], 28, 28, 1))
df = spark.read.option(""header"", True).option(""inferSchema"", True).csv('test.csv')
x_pred = array([list(train.asDict().values()) for train in df.collect()])
del(df)
x_pred = [x/255. for x in x_pred]
x_pred = convert_to_tensor(x_pred, dtype=""float32"")
x_pred = reshape(x_pred, (x_pred.shape[0], 28, 28, 1))

for d in range(9):
    for e in range(d+1,10):
        model = Sequential()
        model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))
        model.add(Conv2D(64, (3, 3), activation='tanh'))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Dropout(0.5))
        model.add(Flatten())
        model.add(Dense(128, activation='relu'))
        model.add(Dropout(0.25))
        model.add(Dense(2, activation='softmax'))
        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
        y_trainD = [ to_categorical( 1 if (y == d) or (y == e) else 0 , 2) for y in y_train ]
        y_trainD = convert_to_tensor(y_trainD, dtype=""float32"")
        model.fit(x_train, y_trainD, batch_size=10, epochs=20, shuffle=True, verbose=0)
        del(y_trainD)
        y_pred = model.predict(x_pred, batch_size=10)
        y_pred = [ y_pred[j][1] for j in range( len(y_pred) ) ]
        y_pred = [(j+1, float(y_pred[j])) for j in range(len(y_pred))]
        output_df = spark.createDataFrame(spark.sparkContext.parallelize(y_pred),  StructType([
                 StructField('ImageId', IntegerType(), True),
                StructField('Probability', FloatType(), True)
            ]))
        output_df.toPandas().to_csv('component'+str(d)+str(e)+'.csv', index=False)

L = dict()
for d in range(9):
    for e in range(d+1,10):
        df = spark.read.option(""inferScheme"", True).option(""header"",True).csv('component'+str(d)+str(e)+'.csv')
        L.update({ str(d)+str(e): [float(row.asDict()['Probability']) for row in df.collect()] })

S = []
for j in range(len(L['01'])):
    digit = [0 for d in range(10) ]
    for key in L.keys():
        if L[key][j] > 0.6:
            digit[ int(key[0]) ] += L[key][j]
            digit[ int(key[1]) ] += L[key][j]
    S.append( (int(j+1), int(argmax(digit)) ) )

output_df = spark.createDataFrame( spark.sparkContext.parallelize(S), StructType([
    StructField(""ImageId"", IntegerType(), True),
    StructField(""Label"", IntegerType(), True)
]))
output_df.toPandas().to_csv('submission.csv', index = False)","This code is for a Kaggle competition to recognize handwritten digits. The data is in the form of 28x28 pixel images. The code first loads the training data into a Spark dataframe. It then converts the data into a numpy array and normalizes the values. The training data is then converted into a tensor and reshaped into the appropriate format for Keras. The same process is repeated for the test data.

Next, the code defines a function to train a model for a given pair of digits. The function creates a Sequential Keras model with two convolutional layers, two pooling layers, and two dense layers. The model is compiled with the Adam optimizer and binary crossentropy loss. It is then fit on the training data. Finally, the model is used to predict probabilities for the test data.

The code then loops over all possible pairs of digits and trains a model for each one. The results are saved to CSV files. Finally, the code loads all of the CSV files and combines the results into a single submission file.",8,5,0.09407712295201402
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import wandb
from kaggle_secrets import UserSecretsClient

user_secrets = UserSecretsClient()
secret_value_0 = user_secrets.get_secret(""wandb"")
wandb.login(key=secret_value_0)
wandb.init(project='MNIST_MLP', save_code=True)BATCH_SIZE = 32class MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return datatransformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])

train_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)
# TODO split train between validation and training set
training_size = int(0.9 * len(train_dataset))
validation_size = len(train_dataset) - training_size
train, val = torch.utils.data.random_split(train_dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))

# create data loader for train and test set
data_loader_train = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)
data_loader_val = torch.utils.data.DataLoader(val, batch_size=BATCH_SIZE, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)

print(""Finished data preparation"")# TODO
def init_layer(m):
    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('tanh'))
    torch.nn.init.constant_(m.bias, 0)
    return m

class Net(nn.Module):    
    def __init__(self):
        super(Net, self).__init__()
        self.relu = nn.ReLU()
        self.l1 = init_layer(nn.Linear(28*28, 56))
        self.l2 = init_layer(nn.Linear(56, 28))
        self.l3 = init_layer(nn.Linear(28, 10))
        self.dropout = nn.Dropout(0.5)
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        x = self.relu(self.l1(x))
       # x = self.dropout(x)
        x = self.relu(self.l2(x))
       # x = self.dropout(x)
        return self.softmax(self.l3(x))# TODO

my_nn = Net()

if torch.cuda.is_available():
    my_nn = my_nn.to('cuda')
    print('Training on GPU!')","This code creates a neural network for the MNIST dataset using the PyTorch library. The network consists of three fully-connected layers, with 56, 28, and 10 nodes in the first, second, and third layers, respectively. The network uses the ReLU activation function for the first two layers, and the softmax activation function for the third layer. The network also uses dropout regularization with a dropout rate of 0.5.

The code first imports the necessary libraries, including PyTorch, NumPy, and Pandas. It then defines a custom dataset class for the MNIST dataset. This custom dataset class inherits from the PyTorch Dataset class and overrides the __init__() and __getitem__() methods. The __init__() method takes in a file path for the MNIST dataset, a transform object, and a Boolean value indicating whether the dataset is the test set or not. The __getitem__() method takes in an index and returns the image and label at that index.

Next, the code defines a transformations object that contains a list of transformation objects. These transformation objects convert the images to PyTorch tensors and normalize the images. The code then creates train and test dataset objects using the custom dataset class and the transformations object. The code then split the train dataset into a training set and a validation set.

Finally, the code creates data loader objects for the train, validation, and test sets. These data loader objects batch the data and shuffle it. The code then prints a message indicating that the data preparation is finished.",9,9,0.14160622298432657
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt
import tensorflow as tf
print(tf.__version__)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiontrain = pd.read_csv('../input/digit-recognizer/train.csv')
test = pd.read_csv('../input/digit-recognizer/test.csv')train.head()# Splitting labels from features
y_train = (train.iloc[:,0].values).astype('float32')
X_train = (train.iloc[:,1:].values).astype('float32')
test = (test.values).astype('float32')
del train

X_trainy_trainprint(X_train.shape)
print(y_train.shape)
print(test.shape)# Reshaping to (num of images, pixels in x direction, pixels in y direction, channel()
X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)
test = test.reshape(test.shape[0], 28, 28, 1)
plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))","This code loads in the necessary libraries for data analysis, including numpy, pandas, matplotlib, and tensorflow. It also sets up input data files from the 'digit-recognizer' dataset on Kaggle.

Next, the code splits the labels from the features in the training data, and also converts the data to float32 format. The test data is also converted to float32 format.

Finally, the code reshapes the training and test data into the proper format for use with a convolutional neural network (CNN). The data is now ready to be used for training the CNN.",9,4,0.2672943975541867
"import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt #for plotting
from collections import Counter
from sklearn.metrics import confusion_matrix
import itertools
import seaborn as sns
from subprocess import check_output
print(check_output([""ls"", ""../input""]).decode(""utf8""))
%matplotlib inline#loading the dataset.......(Train)
train = pd.read_csv(""../input/train.csv"")
print(train.shape)
train.head()z_train = Counter(train['label'])
z_trainsns.countplot(train['label'])#loading the dataset.......(Test)
test= pd.read_csv(""../input/test.csv"")
print(test.shape)
test.head()x_train = (train.ix[:,1:].values).astype('float32') # all pixel values
y_train = train.ix[:,0].values.astype('int32') # only labels i.e targets digits
x_test = test.values.astype('float32')%matplotlib inline
# preview the images first
plt.figure(figsize=(12,10))
x, y = 10, 4
for i in range(40):  
    plt.subplot(y, x, i+1)
    plt.imshow(x_train[i].reshape((28,28)),interpolation='nearest')
plt.show()","This code imports the numpy, pandas, matplotlib, and seaborn libraries. It also imports the Counter class from the collections library and the confusion_matrix function from the sklearn.metrics library.

The code then loads the train and test datasets from the ""../input"" directory. The train dataset is stored in a Pandas dataframe called ""train"", while the test dataset is stored in a dataframe called ""test"".

The code then plots a countplot of the labels in the train dataset using seaborn.

Finally, the code stores the pixel values from the train and test datasets in numpy arrays called ""x_train"" and ""x_test"", respectively. The labels from the train dataset are stored in a numpy array called ""y_train"".",8,10,0.28313090304437366
"import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsClassifier# Считаем csv файлы в Pandas датафрейм
train = pd.read_csv('../input/digit-recognizer/train.csv')
test = pd.read_csv('../input/digit-recognizer/test.csv')# Посмотрим на тренировочный датафрейм
train.head()# Узнаем число пропущенных значений 
# и какому признаку принадлежит больше всего пропусков
sum(train.isnull().sum())# Посмотрим на тестовый датафрейм
test.head()# Узнаем число пропущенных значений 
# и какому признаку принадлежит больше всего пропусков
sum(test.isnull().sum())# Пропущенных значений нет, потому можно продолжать работу с выборками","This code imports the pandas and numpy libraries, and loads the train and test datasets from the digit-recognizer dataset. It then displays the first few rows of each dataset, and calculates the number of missing values in each. Finally, it checks for missing values in the test dataset.",8,1,0.07601121370678404
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset

import wandb
from kaggle_secrets import UserSecretsClient
user_secrets = UserSecretsClient()
secret_value_0 = user_secrets.get_secret(""WANDB_KEY"")
wandb.login(key=secret_value_0)
wandb.init(project='MNIST_MLP', save_code=True)class MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return datatransformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])

train_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)
# TODO split train between validation and training set
training_size = int(0.7 * len(train_dataset))
validation_size = len(train_dataset) - training_size
train, val = torch.utils.data.random_split(train_dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))
# create data loader for train and test set
data_loader_train = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True)
data_loader_val = torch.utils.data.DataLoader(val, batch_size=32, shuffle=True)

test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)def init_my_layer(m):
    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('tanh'))
    torch.nn.init.constant_(m.bias, 0)
    return m

class Net(nn.Module):    
    def __init__(self):
        super(Net, self).__init__()
        self.relu = nn.ReLU()
        self.ln1 = init_my_layer(nn.Linear(28*28, 28))
        self.ln2 = init_my_layer(nn.Linear(28, 28))
        self.ln3 = init_my_layer(nn.Linear(28, 10))
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        x = self.relu(self.ln1(x))
        x = self.relu(self.ln2(x))
        return self.softmax(self.ln3(x))model = Net()

# check if a GPU with Cuda capacities is available
device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"") #0, first GPU if multiple one
model.to(device)
learning_rate = 1e-3
lambda_l2 = 1e-5

criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=lambda_l2)
wandb.watch(model, log=""all"", criterion=criterion, log_freq=1,  log_graph=(True)) 


nb_epochs = 10
# Training
for t in range(nb_epochs):
    model.train() # put the network in training mode
    for X, y in data_loader_train:
        # Feed forward to get the logits
        #format data
        b = X.size(0)
        X = X.view(b,-1)
        y_pred = model(X)
        # Compute the loss and accuracy
        loss = criterion(y_pred, y)
        score, predicted = torch.max(y_pred, 1)
        acc = (y == predicted).sum().float() / len(y)
        wandb.log({
            'mlp/train_loss': loss.item(),
            'mlp/train_accuracy': acc,
        })
        # zero the gradients before running
        # the backward pass.
        optimizer.zero_grad()
        # Backward pass to compute the gradient
        # of loss w.r.t our learnable params. 
        loss.backward()
        # Update params
        optimizer.step()
        
    with torch.no_grad(): # validation run
        model.eval() # validation mode
        for X, y in data_loader_val:
            #format data
            b = X.size(0)
            X = X.view(b,-1)
            y_pred = model(X)
            validation_loss = criterion(y_pred, y)
            score, predicted = torch.max(y_pred, 1)
            acc = (y == predicted).sum().float() / len(y)
            wandb.log({
                'mlp/val_loss': loss.item(),
                'mlp/val_accuracy': acc,
            })
","MyMNISTDataset:

This class represents the MNIST dataset. It inherits from the Dataset class and overrides the __init__, __len__, and __getitem__ methods.

The __init__ method takes in a file path, a transform, a test_data boolean, and a use_gpu boolean. It reads in the data from the file path, and if test_data is False, it also reads in the target labels. The images are 28x28 and are stored as numpy arrays.

The __len__ method returns the length of the dataset.

The __getitem__ method returns a data point from the dataset. If the dataset is for training, it returns the image and the target label. If the dataset is for testing, it just returns the image.

Net:

This class represents the neural network. It inherits from the nn.Module class and overrides the __init__ and forward methods.

The __init__ method initializes the network. It creates three linear layers and one softmax layer.

The forward method takes in an image and feeds it through the network. It returns the predicted label for the image.",8,15,0.20982060598305713
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import tensorflow as tf
import tensorflow.keras.layers as tfl
import tensorflow.keras as keras
import matplotlib.pyplot as plt
import sklearn.model_selection as model_sel


# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiondf = pd.read_csv('../input/digit-recognizer/train.csv')
df.head()X = df.drop(columns=['label'])
X.head()X = X.to_numpy().reshape(-1,28,28,1)X = X/255
X.shapeplt.figure(figsize = (10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.imshow(X[i])
    plt.xticks([])
    plt.yticks([])
    plt.xlabel(df['label'][i])X_train, X_test, Y_train, Y_test = model_sel.train_test_split(X, df['label'].to_numpy().reshape(-1,1), test_size=0.25, random_state=1)","The code above loads in the necessary libraries for data analysis and machine learning in Python, then loads the dataset from the 'digit-recognizer' folder in the input directory. The dataset is then split into training and testing sets, with the training set being used to train the machine learning model and the testing set being used to evaluate the model's performance. Finally, the code visualizes some of the images from the dataset.",9,0,0.18489952684910393
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import wandb

from kaggle_secrets import UserSecretsClient
user_secrets = UserSecretsClient()
secret_value = user_secrets.get_secret(""WANDB_KEY"")

wandb.login(key=secret_value)
wandb.init(project='MNIST_MLP', save_code=True)class MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return databatch_size= 512

transformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])


train_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)

# split train between validation and training set
training_size = int(0.7 * len(train_dataset))
validation_size = len(train_dataset) - training_size
train, val = torch.utils.data.random_split(train_dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))

# create data loader for train and test set
data_loader_train = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)
data_loader_val = torch.utils.data.DataLoader(val, batch_size=batch_size, shuffle=True)

test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False)def init_layer(m):
    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('relu'))
    torch.nn.init.constant_(m.bias, 0)
    return mclass Net(nn.Module):    
    def __init__(self, inputSize):
        super(Net, self).__init__()
        
        self.linear1 = init_layer(torch.nn.Linear(inputSize, 512))
        self.linear2 = init_layer(torch.nn.Linear(512, 256))
        self.dropout = torch.nn.Dropout(p=0.4)
        self.linear3 = init_layer(torch.nn.Linear(256, 10))


    def forward(self, x):
        
        x = x.view(-1,28*28) #reshape the 2d image in a ondiminsional vector for the input of the first layer
        
        x = F.relu(self.linear1(x))
        x = self.dropout(x)
        x = F.relu(self.linear2(x))
        x = self.dropout(x)
        
        return self.linear3(x)input_size = 784
output_size = 10 #labels range from 0-9

model = Net(input_size)

num_epochs = 50
lr =  0.01
weight_decay = 1e-4

optimizer = torch.optim.SGD(model.parameters(),lr = lr)#torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay) #AdamW to aviod coupling problem between the L2 regularization and the adaptive learning rate
criterion = torch.nn.CrossEntropyLoss()

#logging configuration and model
wandb.config.learningrate = lr
wandb.config.num_iterations = num_epochs
wandb.config.optimizer = ""AdamW""
wandb.config.weight_decay = weight_decay
wandb.config.criterion = ""CELoss""

wandb.watch(model, log=""all"", criterion=criterion, log_freq=1,  log_graph=(True)) #log frequency depend on your training


device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"") #0, first GPU if multiple one
print(device)
model.to(device)
","This code defines a neural network for the MNIST dataset using the PyTorch library. The network consists of an input layer, two hidden layers, and an output layer. The hidden layers use the ReLU activation function, and the output layer uses the softmax activation function. The network is trained using the stochastic gradient descent optimizer with a learning rate of 0.01 and a weight decay of 1e-4. The cross entropy loss function is used.

The code also defines a dataset class for the MNIST dataset, which can be used to load the data for training and testing. The dataset class provides methods for getting the data and labels for each example, as well as for applying data transformations.

The code also defines a function for initializing the weights of the neural network layers. This function is used to initialize the weights of the hidden layers.

Finally, the code defines a main function which trains the neural network on the MNIST dataset and saves the model to a file.",8,5,0.18137930740596478
"import pandas as pd   # data analysis librarymnist_test = pd.read_csv(""/kaggle/input/mnist-fashion-data-classification/mnist_test.csv"")    # create a variable dataframe containing data from data file
mnist_train = pd.read_csv(""/kaggle/input/mnist-fashion-data-classification/mnist_train.csv"")    # create a variable dataframe containing data from data file
sample_submission = pd.read_csv(""/kaggle/input/digit-recognizer/sample_submission.csv"")    # create a variable dataframe containing data from data file
train = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")    # create a variable dataframe containing data from data file
test = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")    # create a variable dataframe containing data from data filecols = test.columnstest['dataset'] = 'test'train['dataset'] = 'train'dataset = pd.concat([train.drop('label', axis=1), test]).reset_index()","This code imports the pandas library and then reads in data from four different CSV files: mnist_test, mnist_train, sample_submission, and train. It then concatenates the dataframes from the train and test files and stores them in a new variable called dataset.",8,3,0.18359076636114177
"import os
import numpy as np
import pandas as pd
import pydicom# Load the data
base_path = ""/kaggle/input/siim-covid19-detection/""
studies_df = pd.read_csv(os.path.join(base_path,""train_study_level.csv""))
images_df = pd.read_csv(os.path.join(base_path,""train_image_level.csv""))

# Strip the extra text from the study and image IDs
studies_df['id'] = studies_df['id'].map(lambda x: x.rstrip('_study'))
images_df['id'] = images_df['id'].map(lambda x: x.rstrip('_image'))

# Merge the dfs together
data_df = pd.merge(images_df, studies_df, how='inner', left_on='StudyInstanceUID', right_on='id')
data_df.drop(['id_y'], axis=1, inplace=True)# This function finds the first image in a StudyInstanceUID directory and returns its path
def get_image_by_study_id(study_id):
    study_path = base_path + ""train/"" + study_id + ""/""
    for subdir, dirs, files in os.walk(study_path):
        for file in files:     
            image = os.path.join(subdir, file)
            if os.path.isfile(image):
                return image
    return ""none""# Loop through the images and check how many images are not Explicit VR Little Endian transfer syntax.
# Also count images with VOI LUT Sequence tags present

count = 0
images_with_voi_lut = 0
images_with_voi_lut_function = 0
images_not_explicit_le = 0
deflated_syntaxes = []
voi_lut_functions = []

for index, row in data_df.iterrows():
    img_file = get_image_by_study_id(row['StudyInstanceUID'])
    img = pydicom.dcmread(img_file)
    
    # Check for a LUT sqequence tag
    if (0x0028,0x3010) in img:
        images_with_voi_lut += 1
    
    # Check for a LUT Function tag
    if (0x0028,0x1056) in img:
        images_with_voi_lut_function += 1
        
        if img(0x0028,0x1056) not in voi_lut_functions:
            voi_lut_functions.append(img(0x0028,0x1056))
            
    # Check the transfer syntax
    if img.file_meta.TransferSyntaxUID != ""1.2.840.10008.1.2.1"":
        images_not_explicit_le += 1
        
        if img.file_meta.TransferSyntaxUID not in deflated_syntaxes:
            deflated_syntaxes.append(img.file_meta.TransferSyntaxUID)
        
    count += 1
    
print(""Done checking "" + str(count) + "" images"")
print(""Found "" + str(images_with_voi_lut) + "" images with VOI LUT"")
print(""Found "" + str(images_with_voi_lut_function) + "" images with VOI LUT Function"")
print(""VOI LUT Functions:"")
print(voi_lut_functions)
print(""Found "" + str(images_not_explicit_le) + "" images that are not Explicit VR LE"")
print(""Non Explicit VR LE Transfer Syntaxes"")
print(deflated_syntaxes)","This code imports the os, numpy, pandas, and pydicom modules. It then loads the data from the train_study_level.csv and train_image_level.csv files.

Next, the code strips the extra text from the study and image IDs. Finally, the code merges the dataframes together.

The get_image_by_study_id() function takes a study_id as input and returns the path of the first image in the StudyInstanceUID directory.

The code then loops through the images and checks for various attributes. The attributes checked are:
- whether or not the image has a VOI LUT Sequence tag
- whether or not the image has a VOI LUT Function tag
- whether or not the image has an Explicit VR Little Endian transfer syntax

The code then prints out the results of the checks.",8,11,0.29127481167993713
"import os
import cv2
import numpy as np
import pandas as pd
import pydicom
import matplotlib.pyplot as plt
%matplotlib inline# This function gets the first image path in a StudyInstanceUID directory
def get_image_by_study_id(study_id):
    base_path = ""/kaggle/input/siim-covid19-detection/""
    study_path = base_path + ""train/"" + study_id + ""/""
    images = []
    for subdir, dirs, files in os.walk(study_path):
        for file in files:     
            image = os.path.join(subdir, file)
            if os.path.isfile(image):
                return image
    return ""none""# Make a simple linear VOI LUT from the raw (stored) pixel data
def make_lut(storedPixels, windowWidth, windowLevel, p_i):
    
    # Slope and Intercept set to 1 and 0 for X-ray. Get these from DICOM tags instead if using 
    # on a modality that requires them (CT, PT etc)
    slope = 1.0
    intercept = 0.0
    minPixel = int(np.amin(storedPixels))
    maxPixel = int(np.amax(storedPixels))

    # Make an empty array for the LUT the size of the pixel 'width' in the raw pixel data
    lut = [0] * (maxPixel + 1)
    
    # Invert pixels and windowLevel for MONOCHROME1. We invert the specified windowLevel so that 
    # increasing the level value makes the images brighter regardless of photometric intrepretation
    invert = False
    if p_i == ""MONOCHROME1"":
        invert = True
    else:
        windowLevel = (maxPixel - minPixel) - windowLevel
        
    # Loop through the pixels and calculate each LUT value
    for storedValue in range(minPixel, maxPixel):
        modalityLutValue = storedValue * slope + intercept
        voiLutValue = (((modalityLutValue - windowLevel) / windowWidth + 0.5) * 255.0)
        clampedValue = min(max(voiLutValue, 0), 255)
        if invert:
            lut[storedValue] = round(255-clampedValue)
        else:
            lut[storedValue] = round(clampedValue)
        
    return lut# Apply the LUT to a pixel array
def apply_lut(pixels_in, lut):
    pixels_in = pixels_in.flatten()
    pixels_out = [0] * len(pixels_in)
    for i in range(0, len(pixels_in)):
        pixel = pixels_in[i]
        pixels_out[i] = int(lut[pixel])
    return pixels_out# Take a look at a random image and display it with imshow. The width and level are automagically calculated from the pixel data.
img_file = get_image_by_study_id(""00c241c3fc0d"")
print(""Loading image: "" + img_file)

img = pydicom.dcmread(img_file)
plt.imshow(img.pixel_array,cmap=""gray"");# Set the width to be the distance between the pixels, and the level to be the middle of the pixel range.
# The resulting image should look exactly like the one above.
pixels = img.pixel_array
minPixel = np.min(pixels)
maxPixel = np.max(pixels)
windowWidth = maxPixel - minPixel
windowLevel = (minPixel + maxPixel) / 2

lut = make_lut(pixels, windowWidth, windowLevel, img.PhotometricInterpretation)
pixels = apply_lut(pixels, lut)

# Reshape the pixel array back into the image shape
img_out = np.reshape(pixels, (img.pixel_array.shape[0],img.pixel_array.shape[1]))

print(""Calculated - Width: "" + str(windowWidth) + "" / Level  "" +  str(windowLevel))
print(""Pixel range: "" + str(minPixel) + "" - "" + str(maxPixel))
plt.imshow(img_out,cmap=""gray"");print(""PhotometricInterpretation: "" + img.PhotometricInterpretation)
print(""Bit stored: "" + str(img.BitsStored))","This code imports the necessary libraries for reading, processing and displaying DICOM images. The code then defines a function for getting the path of the first image in a StudyInstanceUID directory, a function for creating a Lookup Table (LUT) from the raw pixel data, and a function for applying the LUT to the pixel data.

The code then reads in a DICOM image using the path returned by the get_image_by_study_id() function, and displays the image using matplotlib. The code then calculates the window width and level from the pixel data, creates a LUT using the make_lut() function, and applies the LUT to the pixel data using the apply_lut() function. The code then displays the image again, using the processed pixel data.

The PhotometricInterpretation, BitsStored and Pixel range information is also displayed.",8,4,0.5026299953656997
"import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings(""ignore"")
from glob import glob
from tqdm.notebook import tqdm
from ast import literal_eval
import os
import matplotlib.pyplot as plt
import matplotlib
matplotlib.rcParams.update({'font.size': 22})
from sklearn.metrics import accuracy_score
from skimage import exposure
from tensorflow.keras import layers
from tensorflow.keras.utils import plot_model
import cv2
from matplotlib.patches import Rectangle
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50, DenseNet121, Xception
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import models
from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping
import tensorflow.keras.backend as K
from tensorflow.math import confusion_matrixdf_image = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
display(df_image.head(3))
print(df_image.shape)df_study = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
display(df_study.head(3))
print(df_study.shape)df_sampleSub = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
display(df_sampleSub.head(3))
print(df_sampleSub.shape)df_study['id'] = df_study['id'].str.replace('_study',"""")
df_study.rename({'id': 'StudyInstanceUID'},axis=1, inplace=True)
df_study.head(3)df_train = df_image.merge(df_study, on='StudyInstanceUID')
df_train.head(3)# train_dir_jpg = '../input/covid-jpg-512/train'
# train_dir_origin ='../input/siim-covid19-detection/train'
# paths_original = []
# paths_jpg = []
# for _, row in tqdm(df_train.iterrows()):
#     image_id = row['id'].split('_')[0]
#     study_id = row['StudyInstanceUID']
#     image_path_jpg = glob(f'{train_dir_jpg}/{image_id}.jpg')
#     image_path_original = glob(f'{train_dir_origin}/{study_id}/*/{image_id}.dcm')
#     paths_jpg.append(image_path_jpg)
#     paths_original.append(image_path_original)","The code imports the pandas, numpy, warnings, glob, tqdm, ast, os, and matplotlib libraries. It also sets the font size for matplotlib.

Next, the code reads in the train_image_level.csv, train_study_level.csv, and sample_submission.csv files.

The code then cleans up the StudyInstanceUID column in the train_study_level dataframe and renames the id column to StudyInstanceUID.

The code then merges the train_image_level and train_study_level dataframes on the StudyInstanceUID column.

Finally, the code loops through the rows of the merged dataframe, retrieves the image and study id for each row, and appends the corresponding image path to the paths_jpg and paths_original lists.",8,14,0.043843903379324436
"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -yimport tensorflow as tf
print(tf.__version__)
import torch
print(f""Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})"")

import os
import gc
import cv2
import glob
import numpy as np
import pandas as pd
from PIL import Image
from tqdm import tqdm
from shutil import copyfile
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lutgpus = tf.config.list_physical_devices('GPU')
if gpus:
  try:
    # Currently, memory growth needs to be the same across GPUs
    for gpu in gpus:
      tf.config.experimental.set_memory_growth(gpu, True)
    logical_gpus = tf.config.experimental.list_logical_devices('GPU')
    print(len(gpus), ""Physical GPUs,"", len(logical_gpus), ""Logical GPUs"")
  except RuntimeError as e:
    # Memory growth must be set before GPUs have been initialized
    print(e)# Read the submisison file
sub_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')
print(len(sub_df))
sub_df.head()study_df = sub_df.loc[sub_df.id.str.contains('_study')]
len(study_df)image_df = sub_df.loc[sub_df.id.str.contains('_image')]
len(image_df)# Ref: https://www.kaggle.com/xhlulu/siim-covid-19-convert-to-jpg-256px
def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return data

def resize_xray(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im","This code installs the pydicom package, which is used for reading and writing DICOM files. It also installs the libjpeg-turbo, libgcc-ng, and gdcm packages, which are dependencies of pydicom. Finally, it installs the conda package, which is used for managing Python packages.

The code also imports the tensorflow, torch, and pydicom packages. The tensorflow and torch packages are used for machine learning, while pydicom is used for reading and writing DICOM files.

The code defines two functions: read_xray and resize_xray. The read_xray function reads a DICOM file and returns the pixel data as a NumPy array. The resize_xray function resizes an image to a given size.",8,14,0.16847167943906466
"!/opt/conda/bin/python3.7 -m pip install --upgrade pip
! pip install -q efficientnet#-------------------
# importing libraries
#-------------------
import tensorflow as tf
from tensorflow.keras import layers
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold,StratifiedKFold

from kaggle_datasets import KaggleDatasets


import pandas as pd
import numpy as np

import os
import shutil
import csv

import matplotlib.pyplot as plt
import PILAUTO = tf.data.experimental.AUTOTUNE

try:
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  
    print('Running on TPU ', tpu.master())
except ValueError:
    tpu = None

if tpu:
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.experimental.TPUStrategy(tpu)
else:
    strategy = tf.distribute.get_strategy()

print(""REPLICAS: "", strategy.num_replicas_in_sync)GCS_DS_PATH = KaggleDatasets().get_gcs_path(""siim-covid19-dataset-256px-jpg"")
print(GCS_DS_PATH)

TRAIN_PATH = GCS_DS_PATH + ""/256px/train/train/""
TEST_PATH = GCS_DS_PATH + ""/256px/test/test/""

NUM_CLASSES = 4
HEIGHT,WIDTH = 256,256
CHANNELS = 3
BATCH_SIZE = 8 * strategy.num_replicas_in_sync
SEED = 143


classes_dict = {
    ""Negative for Pneumonia"" : 0,
    ""Typical Appearance"" : 1,
    ""Indeterminate Appearance"" : 2,
    ""Atypical Appearance""  : 3
}

study_df = pd.read_csv(""../input/siim-covid19-detection/train_study_level.csv"")
train_df = pd.read_csv('../input/siim-covid19-dataset-256px-jpg/train.csv')
train_df = train_df[[""ImageInstanceUID"",""StudyInstanceUID"",""label_id"",""study_label""]]train_df.head(3)study_df.head(3)def process_img(filepath,label):
    image = tf.io.read_file(filepath)
    image = tf.image.decode_jpeg(image, channels=CHANNELS)
    image = tf.image.convert_image_dtype(image, tf.float32) 
    #image = tf.image.resize(image, [HEIGHT,WIDTH])
    return image,label


def data_augment(image, label):
    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
            
    # Flips
    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_flip_up_down(image)
    if p_spatial > .75:
        image = tf.image.transpose(image)
        
    # Rotates
    if p_rotate > .75:
        image = tf.image.rot90(image, k=3) 
    elif p_rotate > .5:
        image = tf.image.rot90(image, k=2) 
    elif p_rotate > .25:
        image = tf.image.rot90(image, k=1) 
        
    
    if p_pixel_1 >= .4:
        image = tf.image.random_saturation(image, lower=.7, upper=1.3)
    if p_pixel_2 >= .4:
        image = tf.image.random_contrast(image, lower=.8, upper=1.2)
    if p_pixel_3 >= .4:
        image = tf.image.random_brightness(image, max_delta=.1)
        
    
    if p_crop > .7:
        if p_crop > .9:
            image = tf.image.central_crop(image, central_fraction=.7)
        elif p_crop > .8:
            image = tf.image.central_crop(image, central_fraction=.8)
        else:
            image = tf.image.central_crop(image, central_fraction=.9)
    elif p_crop > .4:
        crop_size = tf.random.uniform([], int(HEIGHT*.8), HEIGHT, dtype=tf.int32)
        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])
    
    image = tf.image.resize(image, [HEIGHT,WIDTH])
    return image,label

def get_dataset(filenames,labels, training=True):
    dataset = tf.data.Dataset.from_tensor_slices((filenames,labels))
    dataset = dataset.map(process_img,num_parallel_calls=AUTO)
    dataset = dataset.map(data_augment,num_parallel_calls=AUTO)
    dataset = dataset.cache()
    dataset = dataset.repeat()
    if training:
        dataset = dataset.shuffle(2048)
    dataset = dataset.batch(BATCH_SIZE)
    dataset = dataset.prefetch(AUTO)
    return dataset","The code above imports the necessary libraries for image processing, data augmentation, and creating a convolutional neural network. It also defines some global variables that will be used throughout the code.

Next, the code defines a function for processing images. This function takes in a filepath and a label, and returns the image and label.

After that, the code defines a function for data augmentation. This function takes in an image and a label, and returns the augmented image and label.

Finally, the code defines a function for getting a dataset. This function takes in filenames, labels, and a boolean for whether or not the dataset is for training. It returns a dataset that can be used for training or testing.",8,2,0.12431946235237053
"%%capture
!conda install gdcm -c conda-forge -y# Packages

import os, time, glob, re, pprint, random, math
from collections import defaultdict, Counter

import pandas as pd 
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import matplotlib.patches as patches

import seaborn as sns

import cv2
import gdcm

import pydicom
from pydicom import dcmread
from pydicom.pixel_data_handlers.util import apply_voi_lut

import imagehash
from PIL import Image as im

import tqdm# Magic

%matplotlib inline # Pandas options

pd.set_option(""display.expand_frame_repr"", True)
pd.set_option('display.max_colwidth', 0)# Global values

CODE_PATH = ""./""
DATA_PATH = ""../input/siim-covid19-detection""
TRAIN_PATH = os.path.join(DATA_PATH, ""train"")
TEST_PATH = os.path.join(DATA_PATH, ""test"")# Utility functions

def print_title(s):
    
    # Print an underlined title
    
    print(""%s\n%s"" % (s, '-'*len(s)))
    
    
def na_fill(dtype):
    
    # Fill in missing values so that Seaborn countplot() will include them.
    # Also make sure the missing value for a string column is itself a string.
    
    if dtype == np.float64:
        result = -999
    elif dtype == np.int64:
        result = -999
    elif dtype == np.object:
        result = ""NA""
    else:
        result = -999

    return result


def explode_list_col(df, col):
    
    other_cols = list(df.columns)
    other_cols.remove(col)
    out_df = df.set_index(other_cols)[col]
    out_df = out_df.apply(pd.Series)
    out_df = out_df.stack()
    out_df = out_df.reset_index()
    out_df = out_df.drop(f""level_{len(other_cols)}"", axis=1)
    out_df = out_df.rename(columns={0 : col})
    
    return out_df
    

def cat_order(train_df, test_df, cols):
    
    # For comparison, we want the categories to be the same between train and test. 
    # We also want the categories to be in the same order for both. 
    # We need to make sure missing value types are consistent with the column data
    # type (else sort will complain), and make sure that Seaborn countplot() will
    # include them (it won't include np.nan). Dealing with the latter two issues 
    # is the job of fillna(). When the data is plotted, it needs to be run through
    # fillna() as well.

    category_order = {}
    n = len(cols)

    for col in cols:

        if col in train_cols:
            train_dtype = train_df[col].dtype
        else:
            train_dtype = None     
        if col in test_cols:
            test_dtype = test_df[col].dtype
        else:
            test_dtype = None
        if (train_dtype != None) and (test_dtype != None) and (train_dtype != test_dtype):
            print(f""***Incompatible train/test data types for column {col}"")
            break
        
        col_vals = []
        if col in train_cols:
            col_vals += list(train_df[col].fillna(na_fill(train_dtype)).unique())
        if col in test_cols:
            col_vals += list(test_df[col].fillna(na_fill(test_dtype)).unique())
        col_vals = list(set(col_vals))
        col_vals.sort()
    
        category_order[col] = col_vals
        
    return category_order


def plot_categories(df, col, order, title, ax, xlabel=None, ylabel=None, pallete=""Set3"", scale=""log""):

    data = df[col].fillna(na_fill(df[col].dtype))
    ax = sns.countplot(x=data, order=order, palette=pallete, ax=ax)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=""right"")
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    counts = data.value_counts()
    for i, p in enumerate(ax.patches):
        px = p.get_x()+0.05
        py = max(p.get_height()*0.9, 1.0)
        ax.annotate(counts.get(order[i], """"), (px, py), fontsize=10, rotation=90)
    ax.set_title(title, fontsize=15)
    if xlabel: ax.set_xlabel(xlabel)
    if ylabel: ax.set_ylabel(ylabel)
    
    return


def plot_cat_sub(df, col, sub_col, title, ax, scale=""log""):

    ax = sns.countplot(data=df, x=col, hue=sub_col, ax=ax)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=""right"")
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    ax.set_title(title, fontsize=15)
        
    return


def plot_number_uniq_per(df, df_name, attr1, attr2, ax, title=None, palette=None, scale=""log""):
    
    uniq_df = df.groupby(attr1)[[attr2]].nunique().reset_index()
    ax = sns.barplot(x=attr1, y=attr2, data=uniq_df, ax=ax, palette=palette)
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
        
    counts = uniq_df[attr2]
    for i, p in enumerate(ax.patches):
        px = p.get_x()+0.05
        py = max(p.get_height()*0.9, 1.0)
        ax.annotate(uniq_df[attr2].iloc[i], (px, py), fontsize=10, rotation=90)

    if title:
        ax.set_title(title, fontsize=15)
    else:
        ax.set_title(f""{df_name}\nNumber of unique '{attr2}' values \nper '{attr1}' value"", fontsize=15)
    ax.set_xlabel(attr1)
    ax.set_ylabel(f""# unique '{attr2}'"")
    
    return uniq_df


def plot_number_having_n_uniq(df, df_name, attr1, attr2, ax, order=None, palette=None, scale=""log""):

    nuniq = df.groupby(attr1)[attr2].nunique()
    ax = sns.countplot(x=nuniq, order=order, ax=ax, palette=palette)
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    ax.set_title(f""{df_name}\nNumber of '{attr1}' values \nhaving N unique values of '{attr2}'"", fontsize=15)
    ax.set_xlabel(f""N = # of unique '{attr2}' values"")
    ax.set_ylabel(f""# of '{attr1}' having N"")

    return nuniq


def get_img(path, img_id):

    img_path = os.path.join(path, f""{img_id}.jpg"")
    im = cv2.imread(img_path)
    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
    im = cv2.normalize(im, None, 0, 255, cv2.NORM_MINMAX)
    
    return im


def image_subplots(images, r, c, axes, titles=None):
    
    for idx, img in enumerate(images, 0):
        i = idx // c
        j = idx % c
        if titles:
            imshow(img, axes[i, j], title=titles[idx])
        else:
            imshow(img, axes[i, j])

    return
        

def imshow(image, ax=None, title=None, cmap=None):

    if ax is None:
        fig, ax = plt.subplots()
    ax.imshow(image, cmap=cmap)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.spines['left'].set_visible(False)
    ax.spines['bottom'].set_visible(False)
    ax.tick_params(axis='both', length=0)
    ax.set_xticklabels('')
    ax.set_yticklabels('')
    if title:
        ax.set_title(title)

    return ax
# Read the image metadata

train_image_df = pd.read_csv(os.path.join(DATA_PATH,'train_image_level.csv'))
train_study_df =  pd.read_csv(os.path.join(DATA_PATH,'train_study_level.csv'))",This code reads in the image metadata for the training images and stores it in a dataframe.,8,1,0.0944656467209291
"import pydicom as dicom
import pandas as pd
import os
from tqdm import tqdmmetadata = []

for split in ['test', 'train']:  
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            ds1 = dicom.dcmread(os.path.join(dirname, file), stop_before_pixels=True)
            dt=dict()
            dt['ImageId']=file.replace('.dcm','')
            for key in ds1.keys():
                dt[ds1[key].keyword]=ds1[key].value
            metadata.append(dt)

metadata_df=pd.DataFrame(metadata)
metadata_df.head()metadata_df.to_csv('metadata_covid.csv', index=False)","This code imports the pydicom and pandas libraries, and then uses tqdm to iterate through a directory of DICOM files. For each file, it reads in the metadata and stores it in a dictionary. This dictionary is then added to a list, which is converted into a pandas DataFrame. Finally, the DataFrame is saved as a CSV file.",8,4,0.1506737202567283
"import pandas as pd 
import numpy as np
import os
import pydicom
import glob
from tqdm.notebook import tqdm
from pydicom.pixel_data_handlers.util import apply_voi_lut
import matplotlib.pyplot as plt 
from skimage import exposure
import cv2
import warnings
from path import Path
from fastai.vision.all import *
from fastai.medical.imaging import *
warnings.filterwarnings(""ignore"")datapath = Path(""../input/siim-covid19-detection"")datapath.ls()train_study_df = pd.read_csv(datapath/'train_study_level.csv')train_study_df.head()study_classes = [""Negative for Pneumonia"" , ""Typical Appearance"",
                ""Indeterminate Appearance"", ""Atypical Appearance""]
np.unique(train_study_df[study_classes].values , axis = 0)plt.figure(figsize = (10,5))
plt.bar([1,2,3,4] , train_study_df[study_classes].values.sum(axis = 0))
plt.xticks([1,2,3,4] , study_classes)
plt.ylabel(""Frequency"")
plt.show()","This code imports the pandas, numpy, os, pydicom, glob, tqdm, pydicom.pixel_data_handlers.util, matplotlib.pyplot, skimage.exposure, cv2, warnings, and fastai.vision.all libraries.

The code defines a datapath variable that points to the ""../input/siim-covid19-detection"" directory.

The code then reads in the train_study_level.csv file from the datapath directory and stores it in a train_study_df variable.

The code then defines a study_classes variable that contains the class labels ""Negative for Pneumonia"", ""Typical Appearance"", ""Indeterminate Appearance"", and ""Atypical Appearance"".

The code then uses the numpy.unique function to find the unique class label values in the train_study_df[study_classes] array and stores them in a new array.

The code then creates a matplotlib.pyplot figure with a size of 10x5. The code then plots a bar chart with the class labels on the x-axis and the frequency of each class on the y-axis.",9,18,0.0991111585146207
"import numpy as np 
import pandas as pd 
import os
import matplotlib.pyplot as plt
import matplotlib
import pydicom as dicom
import cv2
import ast
import warnings
warnings.filterwarnings('ignore')train_image = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
train_study = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
sample_submission = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')train_image.head()len(train_image)train_study.head()len(train_study)sample_submission.head()","This code imports the necessary libraries for data analysis and visualization, including numpy, pandas, matplotlib, and cv2. It then reads in data from three CSV files: train_image, train_study, and sample_submission.

train_image contains information on individual images, including the image ID, patient ID, and whether or not the image contains evidence of COVID-19. train_study contains information on individual studies, including the study ID, patient ID, and whether or not the study contains evidence of COVID-19. sample_submission contains information on the submission format for the competition.

The code then displays the first five rows of train_image and train_study, and the first row of sample_submission. Finally, it prints the length of train_image and train_study.",8,7,0.07307643087717748
"!conda install gdcm -c conda-forge -yimport os
import ast
import numpy as np
import pandas as pd
from path import Path
import datetime
import glob
import json
import shutil

from PIL import Image
from tqdm.auto import tqdm
import pydicom
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import cv2from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)    
    
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail(size, resample)
    else:
        im = im.resize(size, resample)
    
    return imimages_meta_folder = '/kaggle/working/images_metadata_256_512_768'
os.makedirs(images_meta_folder, exist_ok=True)

# Define sizes
new_sizes = [(256, 256), (512, 512), (768, 768)]for new_size in new_sizes:

    for split in ['train', 'test']:
    # for split in ['test']:
        save_dir = f'/kaggle/tmp/{split}_{new_size[0]}x{new_size[1]}/'
        dcm_paths = glob.glob(f'../input/siim-covid19-detection/{split}/*/*/*')
        os.makedirs(save_dir, exist_ok=True)

        image_ids = []
        folder_ids = []
        study_ids = []
        widths = []
        heights = []

        for path in tqdm(dcm_paths):
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(path)
            im = resize(xray, size=new_size)

            path_split = path.split('/')
            study_id = path_split[-3]
            folder_id = path_split[-2]
            image_name = path_split[-1].replace('.dcm', '_image')

            im.save(os.path.join(save_dir, image_name+'.png'))

            image_ids.append(image_name)
            folder_ids.append(folder_id)
            study_ids.append(study_id)
            widths.append(xray.shape[1])
            heights.append(xray.shape[0])
            
        df = pd.DataFrame.from_dict({'id': image_ids, 'folder_id': folder_ids,
                                     'study_id': study_ids, 'width': widths,
                                     'height': heights})
        df.to_csv(f'{images_meta_folder}/{split}_meta_{new_size[0]}x{new_size[1]}.csv', index=False)for new_size in new_sizes:
    print(f""*****{new_size}*****\n"")
    df_train_meta = pd.read_csv(f'{images_meta_folder}/train_meta_{new_size[0]}x{new_size[1]}.csv')
    df_train = pd.read_csv(""../input/siim-covid19-detection/train_image_level.csv"")
    df_train_meta = df_train.merge(df_train_meta, on='id')
    
    ## Drop all rows of images without annotations
    df_train_meta = df_train_meta.dropna()
    imagepaths = df_train_meta.id.unique()
    print(""Number of Images with Covid_Abnormality:"",len(imagepaths))
    
    display(df_train_meta.head(3))
    print()
    
    df_idx=0

    for idx, row in tqdm(df_train_meta.iterrows(), total=df_train_meta.shape[0]):
        img = cv2.imread(os.path.join(f""/kaggle/tmp/train_{new_size[0]}x{new_size[1]}/"",
                                      row.id.replace(""_image"", "".png"")))
        bboxes = [list(bbox.values()) for bbox in ast.literal_eval(row.boxes)]
        height_ratio, width_ratio = (new_size[0]/row.height, new_size[1]/row.width)

        for box in bboxes:
            box[2] = box[2]+box[0]
            box[3] = box[3]+box[1]
            box = (box[0]*width_ratio, box[1]*height_ratio,
                   box[2]*width_ratio, box[3]*height_ratio)

            row_df = pd.DataFrame({'id':row.id,
                           'StudyInstanceUID':row.StudyInstanceUID,
                           'folder_id':row.folder_id,
                           'study_id':row.study_id,
                           'width':row.width,
                           'height':row.height,
                           'xmin':round(box[0]),
                           'ymin':round(box[1]),
                           'xmax':round(box[2]),
                           'ymax':round(box[3])}, index=[df_idx])

            if df_idx==0:
                df_train_processed = row_df
            else:
                df_train_processed = pd.concat([df_train_processed, row_df])

            df_idx+=1

    display(df_train_processed.head(3))
    print()
    df_train_processed.to_csv(f'{images_meta_folder}/df_train_processed_meta_{new_size[0]}x{new_size[1]}.csv',
                              index=False)
    df_train_processed.shape","This code is responsible for converting DICOM images to PNG format, resizing them to various sizes (256x256, 512x512, 768x768), and then creating a CSV file containing metadata for each image. This CSV file contains information such as the image ID, study ID, folder ID, width, and height.",8,0,0.14562022418670023
"!conda install gdcm -c conda-forge -yimport cv2
import datetime
import gc
import glob
import imagehash
import math
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
import PIL
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import sys
import tqdmbase_path = '../input/siim-covid19-detection'def read_dicom_image(image_file, voi_lut=True, fix_monochrome=True):
    """"""
    Reads a dicom image from a file an returns a numpy array.
    References: https://www.kaggle.com/trungthanhnguyen0502/eda-vinbigdata-chest-x-ray-abnormalities
    Args:
        image_file:
        voi_lut:
        fix_monochrome:

    Returns:

    """"""
    dicom = pydicom.read_file(image_file)
    # VOI LUT (if available by DICOM device) is used to
    # transform raw DICOM data to ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
    return data


def string2boxes(string):
    strings = string.split()
    if strings[0].lower() == 'none':
        return []
    else:
        return [{'class': strings[idx],
                 'conf': float(strings[idx+1]),
                 'x1': float(strings[idx+2]),
                 'y1': float(strings[idx+3]),
                 'x2': float(strings[idx+4]),
                 'y2': float(strings[idx+5]),
                 } for idx in range(0, len(strings), 6)]


def plot_image(image, boxes=None, size=(5,5), title=None, columns=4):
    def plot_img(image, boxes=None, title=None):
        if isinstance(image, str):
            image_id = os.path.splitext(os.path.split(image)[1])[0]
            df = df_image.loc[df_image['id'] == image_id + '_image']
            boxes = string2boxes(df['label'].iloc[0]) if len(df) > 0 else None
            image = read_dicom_image(image)
        image = np.stack([image] * 3, axis=-1)
        if boxes is not None:
            for box in boxes:
                image = cv2.rectangle(image, (int(box['x1']), int(box['y1'])), (int(box['x2']), int(box['y2'])), [0, 255, 0], 10)
        plt.axis('on')
        plt.imshow(image, cmap='gray')
        if title is not None:
            plt.title(title)

    plt.figure(figsize=size)
    if isinstance(image, list):
        num = len(image)
        columns = min(columns, num)
        rows = math.ceil(num / columns)

        for index, single_image in enumerate(image):
            plt.subplot(rows, columns, index + 1)
            plot_img(single_image, boxes=boxes, title=title[index])
    else:
        plot_img(image, boxes=boxes, title=title)
    plt.show()


def images_find_duplicates(image_files, threshold=0.9):
    """"""
    Function to find duplicates in images.
    References: https://www.kaggle.com/appian/let-s-find-out-duplicate-images-with-imagehash
    Args:
        image_files:
        threshold:

    Returns:

    """"""
    funcs = [imagehash.average_hash, imagehash.phash, imagehash.dhash, imagehash.whash]
    image_ids = image_files
    hashes = []
    for file in tqdm.tqdm(image_files):
        image = PIL.Image.fromarray(read_dicom_image(file))
        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))
    hashes_all = np.array(hashes)

    # Comparisons without Pytorch
    sim_list = []
    for i in tqdm.tqdm(range(hashes_all.shape[0])):
        sim_list.append(np.sum(hashes_all[i] == hashes_all, axis=1)/256)

    # nxn-matrix of similarities (n = # of images), upper triangular matrix
    similarities = np.triu(np.array(sim_list), 1)

    idx_pair = np.where(similarities > threshold)
    df_pairs = pd.DataFrame({'image1': [image_ids[i] for i in list(idx_pair[0])],
                             'image2': [image_ids[i] for i in list(idx_pair[1])],
                             'similarity': [similarities[i1, i2] for i1, i2 in zip(idx_pair[0], idx_pair[1])]})

    idx_group = np.zeros(len(image_files))
    group_id = 1
    for i1, i2 in zip(idx_pair[0], idx_pair[1]):
        if idx_group[i1] == 0 and idx_group[i2] == 0:
            idx_group[i1] = group_id
            idx_group[i2] = group_id
            group_id += 1
        elif idx_group[i1] != 0 and idx_group[i2] == 0:
            idx_group[i2] = idx_group[i1]
        elif idx_group[i1] == 0 and idx_group[i2] != 0:
            idx_group[i1] = idx_group[i2]
        elif idx_group[i1] != 0 and idx_group[i2] != 0 and idx_group[i1] != idx_group[i2]:
            common_id = min(idx_group[i1], idx_group[i2])
            idx_group[idx_group == idx_group[i1]] = common_id
            idx_group[idx_group == idx_group[i2]] = common_id

    group_list = []
    for i in range(1, group_id + 1):
        group_ids = list(np.where(idx_group == i)[0])
        if len(group_ids) > 0:
            group_list.append([image_ids[j] for j in group_ids])

    return df_pairs, group_list


def print_group_info(i, df_group):
    print(f'\nGroup {i+1}')
    print(f'Number of unique studies:       {len(df_group[""study_id""].unique())}')
    print(f'Number of unique study labels:  {len(df_group[""study_label""].unique())}\n')
    print(df_group[['image_id', 'num_boxes', 'study_id', 'study_label']])
    plot_image(list(df_group['image_file']), size=(20, 10), title=list(df_group['image_id']), columns=8)    
train_files = sorted(glob.glob(os.path.join(base_path, 'train/*/*/*.dcm')))
print(f'Number of training files: {len(train_files)}')
df_image = pd.read_csv(os.path.join(base_path, 'train_image_level.csv'))
df_study = pd.read_csv(os.path.join(base_path, 'train_study_level.csv'))
df_study['study_label'] = df_study.apply(lambda r: ', '.join([df_study.columns[i] for i in range(1, 5) if r[i] > 0]), axis=1)

df_pairs, group_list = images_find_duplicates(train_files, threshold=0.95)
print(f'\nNumber of duplicate pairs: {len(df_pairs)}')
print(f'Number of duplicate groups: {len(group_list)}')df_group_list = []
df_pairs.to_csv('pairs.csv')

with open('duplicates.csv', 'w') as text_file:
    for i, group in enumerate(group_list):
        group_ids = [os.path.splitext(os.path.basename(file))[0] + '_image' for file in group]
        df_group_ids = pd.DataFrame({'id': group_ids, 'image_file': group})
        df_group = df_group_ids.merge(df_image, on='id').sort_values('id')
        df_group['study_id'] = df_group['StudyInstanceUID'] + '_study'
        df_group['num_boxes'] = df_group.apply(lambda r: len(string2boxes(r['label'])), axis=1)
        df_group = df_group.merge(df_study, left_on='study_id', right_on='id')
        df_group = df_group.rename(columns={'id_x': 'image_id'})
        df_group_list.append(df_group)
        text_file.write(','.join(group_ids) + '\n')for index, df_group in enumerate(df_group_list):
    if len(df_group[df_group['num_boxes'] > 0]) > 1:
        print_group_info(index, df_group)","This code is used to find duplicate images in a dataset. It takes in a list of image files and a threshold value, and returns a list of duplicate groups.

The function first calculates image hashes for all of the input images using four different hashing algorithms. These hashes are then compared to find pairs of images that are similar. A similarity threshold is used to determine whether two images are considered duplicates.

Finally, the list of duplicate groups is printed, along with some information about each group.",8,1,0.16292455438917508
"import pandas as pd# train_df = pd.read_csv('/kaggle/input/siimcovid19-train-data-that-opacitycount-added/train_df.csv')
# local
train_df = pd.read_csv('/kaggle/input/siimcovid19-train-data-that-opacitycount-added/train_df.csv')train_df.head()train_df.drop(columns='Path', axis=1,inplace=True)train_df.head()train_df['Opacity'] = train_df.apply(lambda row : 1 if row.label.split(' ')[0]=='opacity' else 0, axis=1)
train_dftrain_df.drop(columns=['Unnamed: 0'], inplace=True)
train_df","This code imports the pandas library and reads in a CSV file containing training data. The data is then processed to drop the 'Path' column and to add a new 'Opacity' column. The 'Opacity' column is populated with a value of 1 if the corresponding row in the 'label' column contains the word 'opacity', and 0 otherwise. Finally, the 'Unnamed: 0' column is dropped and the resulting dataframe is output.",8,1,0.05852737302345501
"!pip install -q efficientnet >> /dev/nullimport pandas as pd, numpy as np, random,os, shutil
from glob import glob
from kaggle_datasets import KaggleDatasets
import tensorflow as tf, re, math
import tensorflow.keras.backend as K
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt
import tensorflow_addons as tfa
print('tf:',tf.__version__)# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit
VERBOSE      = 1
DISPLAY_PLOT = True

DEVICE = ""TPU"" #or ""GPU""

# USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD
SEED = 42

# NUMBER OF FOLDS. USE 2, 5, 10
FOLDS = 5

# WHICH IMAGE SIZES TO LOAD EACH FOLD
# CHOOSE 128, 192, 256, 384, 512, 512 
IMG_SIZES = [[512, 512]]*FOLDS

# BATCH SIZE AND EPOCHS
BATCH_SIZES = [24]*FOLDS
EPOCHS      = [10]*FOLDS

# WHICH EFFICIENTNET B? TO USE
EFF_NETS = [6]*FOLDS

# Augmentations
AUGMENT   = True
TRANSFORM = True

# transformations
ROT_    = 0.0
SHR_    = 2.0
HZOOM_  = 8.0
WZOOM_  = 8.0
HSHIFT_ = 8.0
WSHIFT_ = 8.0

# Dropout
PROBABILITY = 0.75
CT          = 8
SZ          = 0.08

#bri, contrast
sat  = (0.7, 1.3)
cont = (0.8, 1.2)
bri  =  0.1

# WEIGHTS FOR FOLD MODELS WHEN PREDICTING TEST
WGTS = [1/FOLDS]*FOLDS

# TEST TIME AUGMENTATION STEPS
TTA = 1def seeding(SEED):
    np.random.seed(SEED)
    random.seed(SEED)
    os.environ['PYTHONHASHSEED'] = str(SEED)
    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)
    tf.random.set_seed(SEED)
    print('seeding done!!!')
seeding(SEED)if DEVICE == ""TPU"":
    print(""connecting to TPU..."")
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        print('Running on TPU ', tpu.master())
    except ValueError:
        print(""Could not connect to TPU"")
        tpu = None

    if tpu:
        try:
            print(""initializing  TPU ..."")
            tf.config.experimental_connect_to_cluster(tpu)
            tf.tpu.experimental.initialize_tpu_system(tpu)
            strategy = tf.distribute.experimental.TPUStrategy(tpu)
            print(""TPU initialized"")
        except _:
            print(""failed to initialize TPU"")
    else:
        DEVICE = ""GPU""

if DEVICE != ""TPU"":
    print(""Using default strategy for CPU and single GPU"")
    strategy = tf.distribute.get_strategy()

if DEVICE == ""GPU"":
    print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
    

AUTO     = tf.data.experimental.AUTOTUNE
REPLICAS = strategy.num_replicas_in_sync
print(f'REPLICAS: {REPLICAS}')GCS_PATH = [None]*FOLDS
for i,k in enumerate(IMG_SIZES):
    GCS_PATH[i] = KaggleDatasets().get_gcs_path('siimcovid19-%ix%i-tfrec-dataset'%(k[0],k[1]))
files_train = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/train*.tfrec')))
files_test  = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/test*.tfrec')))
num_train_files = len(files_train)
num_test_files  = len(files_test)
print('train_files:',num_train_files)
print('test_files:',num_test_files)train_df = pd.read_csv('../input/siim-covid19-yolov5-2class-labels/meta.csv')
train_df.head(2)","This code installs the efficientnet package and imports pandas, numpy, random, os, and shutil. It also imports the KaggleDatasets package and defines a function to seed random number generators.

The code then defines some variables for image size, batch size, epochs, and the type of neural network to use. It also defines variables for data augmentation and for the dropout rate.

Next, the code defines a function for test time augmentation and loads the training and testing data from files. The code then prints the number of training and testing files.

Finally, the code loads the meta data for the training data from a CSV file.",8,6,0.09327776338325373
"%cd ../
!mkdir tmp
%cd tmp# Download YOLOv5
!git clone https://github.com/ultralytics/yolov5  # clone repo
%cd yolov5
# Install dependencies
%pip install -qr requirements.txt  # install dependencies

%cd ../
import torch
print(f""Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})"")# Install W&B 
!pip install -q --upgrade wandb
# Login 
import wandb
wandb.login()# Necessary/extra dependencies. 
import os
import gc
import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm
from shutil import copyfile
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

#customize iPython writefile so we can write variables
from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))TRAIN_PATH = 'input/siim-covid19-resized-to-256px-jpg/train/'
IMG_SIZE = 256
BATCH_SIZE = 16
EPOCHS = 10# Everything is done from /kaggle directory.
%cd ../

# Load image level csv file
df = pd.read_csv('input/siim-covid19-detection/train_image_level.csv')

# Modify values in the id column
df['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)
# Add absolute path
df['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)
# Get image level labels
df['image_level'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)

df.head(5)# Load meta.csv file
# Original dimensions are required to scale the bounding box coordinates appropriately.
meta_df = pd.read_csv('input/siim-covid19-resized-to-256px-jpg/meta.csv')
train_meta_df = meta_df.loc[meta_df.split == 'train']
train_meta_df = train_meta_df.drop('split', axis=1)
train_meta_df.columns = ['id', 'dim0', 'dim1']

train_meta_df.head(2)","This code is for the YOLOv5 object detection model. It is written in Python and uses the PyTorch library.

The code downloads the YOLOv5 repository from GitHub, installs dependencies, and loads the training data. The training data is a CSV file containing image level labels and paths to the images. The code also loads a CSV file containing metadata for the images, including the original dimensions of the images.

The code then trains the YOLOv5 model on the training data for 10 epochs.",8,0,0.0983753642480583
"# Importing Required packages
import os
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from IPython.display import Image, clear_output
print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))
clear_output()#customize iPython writefile so we can write variables
from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))# Cloning the repo and installing requiements
!git clone https://github.com/ultralytics/yolov5.git
!mv ./yolov5/* ./
!pip install -r requirements.txt
clear_output()# Copying the dataset to working directory
!mkdir Dataset
!cp ../input/covid19-detection-for-yolov5-siimfisabiorsna/Covid19 -r ./Dataset
clear_output()len(os.listdir('./Dataset/Covid19/images'))%%writetemplate ./split_dataset.py
from utils.datasets import * 
autosplit('./Dataset/Covid19', weights=(0.8, 0.2, 0.0))!python split_dataset.py","This code imports the required packages, clones the yolov5 repository, and installs the required packages. It then copies the dataset to the working directory and splits it into train, test, and val sets.",8,0,0.13120424090685015
"! conda install -c conda-forge gdcm -y# import numpy as np # linear algebra
# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
# import os
# import pydicom
# import glob
# from tqdm.notebook import tqdm
# from pydicom.pixel_data_handlers.util import apply_voi_lut
# import matplotlib.pyplot as plt
# from skimage import exposure
# import cv2
# import warnings
# from fastai.vision.all import *
# from fastai.medical.imaging import *
# warnings.filterwarnings('ignore')

import os
import pydicom
import glob
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt 
dataset_path = '../input/siim-covid19-detection/'

for path in glob.glob(dataset_path  + '*'):
    print(path)train_images = '../input/siim-covid19-detection/train/'

n_folders = len(glob.glob(train_images  + '*'))
n_subfolders = len(glob.glob(train_images  + '*/*'))
n_images = len(glob.glob(train_images  + '*/*/*.dcm'))

print(f'There are {n_subfolders} subfolders in {n_folders} folders.')
print(f'There are altogether {n_images} images.')folders = glob.glob(train_images  + '*')

subfolder_dict = {}

for folder in folders:
    n = len(glob.glob(folder + '/*'))
    if n in subfolder_dict.keys():
        subfolder_dict[n] += 1
    else:
        subfolder_dict[n] = 1
        
for k, v in subfolder_dict.items():
    print(f'There is {v} subfolders with {k} images.')

subfolders = glob.glob(train_images  + '*/*')

image_dict = {}

for subfolder in subfolders:
    n = len(glob.glob(subfolder + '/*'))
    if (n!=1):
        print (subfolder.split('/')[-1])
        for image in glob.glob(subfolder + '/*'):
            print ('-->' + image.split('/')[-1])

    if n in image_dict.keys():
        image_dict[n] += 1
    else:
        image_dict[n] = 1
        
for k, v in image_dict.items():
    print(f'There is {v} subfolders with {k} images.')
train_study_df = pd.read_csv(dataset_path +'/train_study_level.csv')

train_study_df","This code imports the necessary libraries for working with the SIIM-COVID19 dataset. It then defines the path to the dataset and counts the number of folders, subfolders, and images in the dataset.

Next, the code loops through the folders and subfolders in the dataset and counts the number of images in each. Finally, the code displays the contents of the train_study_level.csv file.",8,0,0.05914865253604426
"import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import glob
import pydicomsiim_covid19_dir = os.path.join(
    '..', 'input', 'siim-covid19-detection')def read_csv(file_name):
    file_path = os.path.join(siim_covid19_dir, file_name)
    df = pd.read_csv(file_path)
    return dfstudy_level_df = read_csv('train_study_level.csv')

study_level_df# How many rows?
study_level_num_rows = len(study_level_df)

study_level_num_rows# Are unique? Any duplicates?
study_level_num_unique_ids = len(pd.unique(study_level_df['id']))

if study_level_num_unique_ids == study_level_num_rows:
    print(""Unique and no duplicates"")
else:
    print(""Some duplicates"")# What are the unique value combinations? How many of them?
study_level_label_colums = [
    'Negative for Pneumonia', 'Typical Appearance',
    'Indeterminate Appearance', 'Atypical Appearance' ]
study_level_labels_df = study_level_df[study_level_label_colums]
study_level_label_values = study_level_labels_df.values

study_level_unique_label_combinations, \
study_level_unique_label_counts = \
    np.unique(
        study_level_label_values, return_counts=True, axis=0)

print(""Unique Combinations:\n"", study_level_unique_label_combinations)
print(""Unique Counts:\n"", study_level_unique_label_counts)","This code imports the necessary libraries for reading in a CSV file, manipulating data, and visualizing data. The read_csv() function takes in a file_name as input and returns a dataframe. The study_level_df dataframe is created by calling the read_csv() function on the 'train_study_level.csv' file. The number of rows in study_level_df is calculated and stored in the study_level_num_rows variable. The number of unique ids in study_level_df is calculated and stored in the study_level_num_unique_ids variable. If there are no duplicates in study_level_df, a message is printed to the console. Otherwise, a message is printed indicating that there are some duplicates in the data. The study_level_label_colums variable is a list of the columns containing label data. The study_level_labels_df dataframe is created by subsetting study_level_df to only include the label columns. The study_level_label_values variable is created by extracting the values from study_level_labels_df. The study_level_unique_label_combinations and study_level_unique_label_counts variables are created by using the np.unique() function on study_level_label_values. The study_level_unique_label_combinations variable contains the unique combinations of label values and the study_level_unique_label_counts variable contains the counts for each unique combination of label values.",8,16,0.19723402424314226
"# Libraries
import warnings
warnings.filterwarnings('ignore')

import os
import numpy as np
import pandas as pd
import seaborn as sns
import glob
from pandas import DataFrame
from matplotlib.lines import Line2D
import matplotlib.pyplot as plt
%matplotlib inline
import plotly.express as px
from tqdm.notebook import tqdm

# Image processing and Computer Vision
from skimage import exposure
import cv2
# Package designed to manipulate data elements in DICOM files 

import pydicom
#Image Transformation
from pydicom.pixel_data_handlers.util import apply_voi_lut

from fastai.vision.all import *
from fastai.medical.imaging import *

#train_image
train_image_df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
train_image_df.head(2)#train_study
train_study_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
train_study_df.head()# Bar plot function defination
def viz_bar_plot(df,x,x_title,y,title,colors=None,text=None):
    fig = px.bar(x=x,
                 y=y,
                 text=text,
                 labels={x: x_title.title()},   
                 data_frame=df,
                 color=colors,
                 barmode='group',
                 template=""simple_white"")
    texts = [df[col].values for col in y]
    for i, t in enumerate(texts):
        fig.data[i].text = t
        fig.data[i].textposition = 'inside'  
    fig['layout'].title=title
    fig.update_layout(title_font_size=19)
    fig.update_layout(title_font_family='Droid Serif')
    fig.update_layout(width=800,height=500)
    for trace in fig.data:
        trace.name = trace.name.replace('_',' ').title()
    fig.update_yaxes(tickprefix="""", showgrid=True)
    fig.show()# Study Data
# create 'target' column in train_study_df dataset
train_study_df['target']='Negative for Pneumonia'
train_study_df.loc[train_study_df['Typical Appearance']==1,'target']='Typical Appearance'
train_study_df.loc[train_study_df['Indeterminate Appearance']==1,'target']='Indeterminate Appearance'
train_study_df.loc[train_study_df['Atypical Appearance']==1,'target']='Atypical Appearance'
train_study_df1=train_study_df.groupby(['target']).size().reset_index(name='counts')
train_study_df1# Bar Visulaization of label categories
viz_bar_plot(train_study_df1,
         'target',
         'target',
         ['counts'],
         title='Target Label Count')","This code imports the necessary libraries for data analysis and visualizations, then loads the data from the CSV files. Next, it defines a function for visualizing data in a bar plot. Finally, it uses the function to visualize the data in the train_study_df dataset.",8,1,0.13121856817121907
"! conda install -c conda-forge gdcm -yimport numpy as np
import pandas as pd 
import os
from PIL import Image
from tqdm.auto import tqdm
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import seaborn as sns
from pandas_profiling import ProfileReport
from glob import glob
from tqdm.notebook import tqdm
import matplotlib.pyplot as plt
from skimage import exposure
import cv2
import warnings
import albumentations as A# config params
class CFG:
    data_path = '../input/siim-covid19-detection/'
    size = 512
    seed = 2021
    working_dir = '/kaggle/working/'def dicom2array(path, voi_lut=True, fix_monochrome=True):
    dicom = pydicom.read_file(path)
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
    return data
        
    
def plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()
# storage file for the transformed images
!mkdir train# prepare a dataframe for producing resized images with bboxes
xtrain_img = pd.read_csv(CFG.data_path + 'train_image_level.csv')


path_list = []
image_list = []
splits = []

for split in ['train']:
    
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            fullpath = dirname + '/' + file
            path_list.append(fullpath)
            image_list.append(file)

df = pd.DataFrame(image_list, columns =['image_id'])
df['image_path'] = path_list

xtrain_img['image_id'] = xtrain_img['id'].apply(lambda s: s.replace('_image','') + '.dcm')
xtrain_img = pd.merge(left = xtrain_img, right = df, on = 'image_id')
# common transformation we shall use
transform = A.Compose(
    [
        A.Resize(height = CFG.size , width = CFG.size, p=1),
    ], 
    p=1.0,  bbox_params=A.BboxParams( format='pascal_voc', min_area=0,  min_visibility=0, label_fields=['labels']  ))        

img_list = []
label_list = []

# loop over files
for ii in range(len(xtrain_img)):
    # get the image
    row = xtrain_img.loc[ii]
    img_path = row['image_path']
    img = dicom2array(path=img_path)
    newname = img_path.split('/')[-1].replace('dcm', 'jpg')
    img_list.append(newname)
    
    # get the bounding boxes
    bboxes = []
    bbox = []
    labels = []
    confidences = []

    for i, l in enumerate(row['label'].split(' ')):
        if (i % 6 == 0) :
            labels.append(l)
        if (i % 6 == 1):
            confidences.append(l)
        if (i % 6 > 1):
            bbox.append(np.clip(float(l), a_min = 0, a_max = None ))
        if i % 6 == 5:
            bboxes.append(bbox)
            bbox = []    

    # transform both
    result = transform(image = img, bboxes = bboxes, labels = np.ones(len(bboxes)))
    new_image = result['image']
    new_bboxes = np.array(result['bboxes']).tolist()

    # format the output
#    print('orig label: ' + row['label'])
    newlabel = ''
    if labels[0] == 'none':
        newlabel = 'none 1 0 0 1 1'
    else:
        for j in range(len(labels)):
            newlabel += labels[j] + ' ' + confidences[j] + ' ' +  ' '.join([str(np.round(f,5)) for f in new_bboxes[0]]) + ' '
#    print('new label:' + newlabel)
    label_list.append(newlabel)
    
    # store the new image
    cv2.imwrite(CFG.working_dir + 'train/' + newname , new_image)","The code above is used to resize and store images with bounding boxes for the training data set. First, a dataframe is created containing the image paths and file names. Next, the common transformation (resize) is applied to the images. Finally, the new images and labels are stored in the working directory.",8,1,0.1610648417977757
"!wget 'https://anaconda.org/conda-forge/libjpeg-turbo/2.1.0/download/linux-64/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/libgcc-ng/9.3.0/download/linux-64/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/gdcm/2.8.9/download/linux-64/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/conda/4.10.1/download/linux-64/conda-4.10.1-py37h89c1867_0.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/certifi/2020.12.5/download/linux-64/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/openssl/1.1.1k/download/linux-64/openssl-1.1.1k-h7f98852_0.tar.bz2' -q","The code above downloads the following packages from Anaconda:

- libjpeg-turbo
- libgcc-ng
- gdcm
- conda
- certifi
- openssl

Each package is downloaded as a "".tar.bz2"" file. The ""-q"" option tells wget to download the packages quietly, without printing any output.",8,7,0.21093517997766084
"! conda install gdcm -c conda-forge -y! pip install --no-deps '../input/timm-package/timm-0.1.26-py3-none-any.whl' > /dev/null
! pip install --no-deps '../input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl' > /dev/nullimport sys
sys.path.insert(0, ""../input/timm-efficientdet-pytorch"")
sys.path.insert(0, ""../input/omegaconf"")

import os
from PIL import Image
import pandas as pd
from tqdm.auto import tqdm
import numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import torch
from datetime import datetime
import time
import random
import cv2
import albumentations as A
import matplotlib.pyplot as plt
from albumentations.pytorch.transforms import ToTensorV2
from sklearn.model_selection import StratifiedKFold
from torch.utils.data import Dataset,DataLoader
from torch.utils.data.sampler import SequentialSampler, RandomSampler
from glob import glob

SEED = 42

def seed_everything(seed):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = True

seed_everything(SEED)dataset_path = ""../input/siim-covid19-detection""def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return data

def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im
        
    
def plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()
%%time
image_id = []


cnt_img = 0 # for testing

for split in ['test', 'train']:
    save_dir = f'/kaggle/tmp/{split}/'

    os.makedirs(save_dir, exist_ok=True)
    
    for dirname, _, filenames in tqdm(os.walk(f'{dataset_path}/{split}')):
        for file in filenames:
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(os.path.join(dirname, file))
            im = resize(xray, size=256)  
            im.save(os.path.join(save_dir, file.replace('dcm', 'jpg')))

            image_id.append(file.replace('.dcm', ''))

            splits.append(split)
        
        if cnt_img >= 10:
            cnt_img = 0
            break
        
        cnt_img += 1
            image_id","This code reads in a DICOM image, transforms it into a human-readable format, and saves it as a JPEG.",8,0,0.07295856993094835
"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -yimport os

from PIL import Image
import pandas as pd
from tqdm.auto import tqdmimport numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im
split = 'test'
save_dir = f'/kaggle/tmp/{split}/'

os.makedirs(save_dir, exist_ok=True)

save_dir = f'/kaggle/tmp/{split}/study/'
os.makedirs(save_dir, exist_ok=True)

for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
    for file in filenames:
        # set keep_ratio=True to have original aspect ratio
        xray = read_xray(os.path.join(dirname, file))
        im = resize(xray, size=600)  
        study = dirname.split('/')[-2] + '_study.png'
        im.save(os.path.join(save_dir, study))
import numpy as np 
import pandas as pd

df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
id_laststr_list  = []
for i in range(df.shape[0]):
    id_laststr_list.append(df.loc[i,'id'][-1])
df['id_last_str'] = id_laststr_list

study_len = df[df['id_last_str'] == 'y'].shape[0]!pip install /kaggle/input/kerasapplications -q
!pip install /kaggle/input/efficientnet-keras-source-code/ -q --no-deps

import os

import efficientnet.tfkeras as efn
import numpy as np
import pandas as pd
import tensorflow as tf

def auto_select_accelerator():
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        tf.config.experimental_connect_to_cluster(tpu)
        tf.tpu.experimental.initialize_tpu_system(tpu)
        strategy = tf.distribute.experimental.TPUStrategy(tpu)
        print(""Running on TPU:"", tpu.master())
    except ValueError:
        strategy = tf.distribute.get_strategy()
    print(f""Running on {strategy.num_replicas_in_sync} replicas"")

    return strategy


def build_decoder(with_labels=True, target_size=(300, 300), ext='jpg'):
    def decode(path):
        file_bytes = tf.io.read_file(path)
        if ext == 'png':
            img = tf.image.decode_png(file_bytes, channels=3)
        elif ext in ['jpg', 'jpeg']:
            img = tf.image.decode_jpeg(file_bytes, channels=3)
        else:
            raise ValueError(""Image extension not supported"")

        img = tf.cast(img, tf.float32) / 255.0
        img = tf.image.resize(img, target_size)

        return img

    def decode_with_labels(path, label):
        return decode(path), label

    return decode_with_labels if with_labels else decode


def build_augmenter(with_labels=True):
    def augment(img):
        img = tf.image.random_flip_left_right(img)
        img = tf.image.random_flip_up_down(img)
        return img

    def augment_with_labels(img, label):
        return augment(img), label

    return augment_with_labels if with_labels else augment


def build_dataset(paths, labels=None, bsize=32, cache=True,
                  decode_fn=None, augment_fn=None,
                  augment=True, repeat=True, shuffle=1024, 
                  cache_dir=""""):
    if cache_dir != """" and cache is True:
        os.makedirs(cache_dir, exist_ok=True)

    if decode_fn is None:
        decode_fn = build_decoder(labels is not None)

    if augment_fn is None:
        augment_fn = build_augmenter(labels is not None)

    AUTO = tf.data.experimental.AUTOTUNE
    slices = paths if labels is None else (paths, labels)

    dset = tf.data.Dataset.from_tensor_slices(slices)
    dset = dset.map(decode_fn, num_parallel_calls=AUTO)
    dset = dset.cache(cache_dir) if cache else dset
    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset
    dset = dset.repeat() if repeat else dset
    dset = dset.shuffle(shuffle) if shuffle else dset
    dset = dset.batch(bsize).prefetch(AUTO)

    return dset

#COMPETITION_NAME = ""siim-cov19-test-img512-study-600""
strategy = auto_select_accelerator()
BATCH_SIZE = strategy.num_replicas_in_sync * 16

IMSIZE = (224, 240, 260, 300, 380, 456, 528, 600)

#load_dir = f""/kaggle/input/{COMPETITION_NAME}/""
sub_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
sub_df = sub_df[:study_len]
test_paths = f'/kaggle/tmp/{split}/study/' + sub_df['id'] +'.png'

sub_df['negative'] = 0
sub_df['typical'] = 0
sub_df['indeterminate'] = 0
sub_df['atypical'] = 0


label_cols = sub_df.columns[2:]

test_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[7], IMSIZE[7]), ext='png')
dtest = build_dataset(
    test_paths, bsize=BATCH_SIZE, repeat=False, 
    shuffle=False, augment=False, cache=False,
    decode_fn=test_decoder
)

with strategy.scope():
    
    models = []
    
    models0 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model0.h5'
    )
    models1 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model1.h5'
    )
    models2 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model2.h5'
    )
    models3 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model3.h5'
    )
    models4 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model4.h5'
    )
    
    models.append(models0)
    models.append(models1)
    models.append(models2)
    models.append(models3)
    models.append(models4)

    
    
    
sub_df[label_cols] = sum([model.predict(dtest, verbose=1) for model in models]) / len(models)","This code installs the pydicom conda helper package, which allows for the easy manipulation of DICOM images. It also imports the necessary packages for reading, processing, and storing the images.

The read_xray() function reads in a DICOM image, applies a VOI LUT if available, and transforms the raw data into a ""human-friendly"" view. The resize() function takes in an image and resizes it to the desired dimensions.

The build_decoder() function builds a function that takes in a path and returns the decoded image. The build_augmenter() function builds a function that takes in an image and augments it. The build_dataset() function builds a dataset from a list of paths and labels.

The auto_select_accelerator() function automatically selects the TPU or GPU for training. The BATCH_SIZE variable is set to the number of replicas in sync.

The IMSIZE variable is a list of image sizes. The sub_df variable is a dataframe containing the submission information. The test_paths variable is a list of paths to the test images. The sub_df['negative'] , sub_df['typical'] , sub_df['indeterminate'] , and sub_df['atypical'] columns are set to 0.

The label_cols variable is a list of the label columns. The test_decoder variable is a function that decodes the test images. The dtest variable is a dataset of the test images.

The models variable is a list of the five models that will be used for prediction. The models are loaded from the input files. The sub_df[label_cols] columns are set to the average prediction of the five models.",8,15,0.1176158322719273
"SEED  = 42
FOLDS = 5
DIM   = 512import numpy as np 
import pandas as pd 
import os, shutil
from glob import glob
from sklearn.cluster import KMeans
from tqdm.notebook import tqdm
from sklearn.preprocessing import LabelEncoder
import random
tqdm.pandas()np.random.seed(SEED)
random.seed(SEED)train_df = pd.read_csv(f'../input/siimcovid19-{DIM}-jpg-image-dataset/train.csv')
train_df['image_path'] = F'../input/siimcovid19-{DIM}-jpg-image-dataset/train/'+train_df.image_id+'.jpg'
train_df.head(2)name2label = {'Typical Appearance': 3,
 'Indeterminate Appearance': 1,
 'Atypical Appearance': 2,
 'Negative for Pneumonia': 0}
class_names = list(name2label.keys())
label2name = {v:k for k, v in name2label.items()}
train_df['class_name']  = train_df.progress_apply(lambda row:row[class_names].iloc[[row[class_names].values.argmax()]].index.tolist()[0], axis=1)
train_df['class_label'] = train_df.class_name.map(name2label)
train_df.head()from sklearn.model_selection import GroupKFold, StratifiedKFold
gkf  = GroupKFold(n_splits = 5)
train_df['fold'] = -1
for fold, (train_idx, val_idx) in enumerate(gkf.split(train_df, groups = train_df.StudyInstanceUID.tolist())):
    train_df.loc[val_idx, 'fold'] = fold
train_df.head()import matplotlib.pyplot as plt
import cv2
def load_image(path, dim=DIM, ch=3):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE if ch==None else cv2.IMREAD_COLOR)
    if img.shape[:2]!=(dim,dim) and dim!=-1:
        img = cv2.resize(img, dsize=(dim,dim), interpolation=cv2.INTER_AREA)
    return img

plt.imshow(load_image(train_df.image_path.iloc[100], dim=-1))","This code loads an image from a given path and resizes it to the given dimension. If the image is not the same size as the given dimension, it will be resized using the INTER_AREA interpolation.",8,0,0.04334522018719928
"# !conda install -c conda-forge imagehash --yes%load_ext autoreload
%autoreload 2
%matplotlib inline

import glob
import itertools
import collections

from PIL import Image
import cv2
from tqdm import tqdm_notebook as tqdm
import pandas as pd
import numpy as np
import torch
import imagehash

import matplotlib.pyplot as plt

def run():

    funcs = [
        imagehash.average_hash,
        imagehash.phash,
        imagehash.dhash,
        imagehash.whash,
        #lambda x: imagehash.whash(x, mode='db4'),
    ]

    SOPInstanceUIDs = []
    hashes = []
    for path in tqdm(glob.glob('../input/siim-covid19-resized-to-512px-png/*/*.png')):

        image = Image.open(path)
        imageid = path.split('/')[-1].split('.')[0]

        SOPInstanceUIDs.append(imageid)
        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))

    return SOPInstanceUIDs, np.array(hashes)

%time SOPInstanceUIDs, hashes_all = run()

hashes_all = torch.Tensor(hashes_all.astype(int)).cuda()%time sims = np.array([(hashes_all[i] == hashes_all).sum(dim=1).cpu().numpy()/256 for i in range(hashes_all.shape[0])])
indices1 = np.where(sims > 0.99)
indices2 = np.where(indices1[0] != indices1[1])
SOPInstanceUID1 = [SOPInstanceUIDs[i] for i in indices1[0][indices2]]
SOPInstanceUID2 = [SOPInstanceUIDs[i] for i in indices1[1][indices2]]
dups = {tuple(sorted([SOPInstanceUID1,SOPInstanceUID2])):True for SOPInstanceUID1, SOPInstanceUID2 in zip(SOPInstanceUID1, SOPInstanceUID2)}
print('found %d duplicates' % len(dups))dups",This code uses the imagehash library to calculate hashes for images in a directory. The hashes are then used to identify duplicate images.,8,1,0.1171259720200152
"!pip install gdcmimport os
from os import listdir
import pandas as pd
import numpy as np
import glob
from skimage import exposure
import matplotlib.pyplot as plt
%matplotlib inline

# pydicom
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
from fastai.imports import *
from fastai.medical.imaging import *

import cv2

# color
from colorama import Fore, Back, Style

import seaborn as sns
sns.set(style=""whitegrid"")

# plotly
import plotly.express as px
import plotly

# Suppress warnings 
import warnings
warnings.filterwarnings('ignore')

# Settings for pretty nice plots
plt.style.use('fivethirtyeight')
plt.show()# List files available
list(os.listdir(""../input/siim-covid19-detection""))IMAGE_PATH = ""../input/siim-covid19-detection/""

train_study_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
train_image_df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')

print(Fore.YELLOW + 'Train study df shape: ',Style.RESET_ALL,train_study_df.shape)
print(Fore.YELLOW + 'Train image df shape: ',Style.RESET_ALL,train_image_df.shape)display(train_study_df.head(5))
display(train_image_df.head(5))sample_submission = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
print(Fore.YELLOW + 'Sample submission df shape: ',Style.RESET_ALL,sample_submission.shape)
display(sample_submission)# Null values and Data types
print(Fore.BLUE + 'Train Study Set !!',Style.RESET_ALL)
print(train_study_df.info())
print('-------------')
print(Fore.YELLOW + 'Train Image Set !!',Style.RESET_ALL)
print(train_image_df.info())","This code imports the necessary libraries for working with the data, including pydicom for handling DICOM images. It also sets up some basic parameters for plotting the data.

The code then loads in the train_study_level.csv and train_image_level.csv files, which contain information on the studies and images, respectively.

The code then prints out some basic information on the dataframes, including the shape and the first 5 rows of each dataframe.

Finally, the code loads in the sample_submission.csv file, which contains the format for the submission file.",8,3,0.03521447661917003
"!pip install -q efficientnet >> /dev/nullimport pandas as pd, numpy as np, random,os, shutil
from glob import glob
from kaggle_datasets import KaggleDatasets
import tensorflow as tf, re, math
import tensorflow.keras.backend as K
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt
import tensorflow_addons as tfa
print('tf:',tf.__version__)# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit
VERBOSE      = 0
DISPLAY_PLOT = True

DEVICE = ""TPU"" #or ""GPU""

# USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD
SEED = 42

# NUMBER OF FOLDS. USE 2, 5, 10
FOLDS = 5

# WHICH IMAGE SIZES TO LOAD EACH FOLD
# CHOOSE 128, 192, 256, 384, 512, 512 
IMG_SIZES = [[512, 512]]*FOLDS

# BATCH SIZE AND EPOCHS
BATCH_SIZES = [16]*FOLDS
EPOCHS      = [12]*FOLDS

# WHICH EFFICIENTNET B? TO USE
EFF_NETS = [7]*FOLDS

# Augmentations
AUGMENT   = True
TRANSFORM = True

# transformations
ROT_    = 0.0
SHR_    = 2.0
HZOOM_  = 8.0
WZOOM_  = 8.0
HSHIFT_ = 8.0
WSHIFT_ = 8.0

# Dropout
PROBABILITY = 0.75
CT          = 8
SZ          = 0.08

#bri, contrast
sat  = (0.7, 1.3)
cont = (0.8, 1.2)
bri  =  0.1

# WEIGHTS FOR FOLD MODELS WHEN PREDICTING TEST
WGTS = [1/FOLDS]*FOLDS

# TEST TIME AUGMENTATION STEPS
TTA = 1def seeding(SEED):
    np.random.seed(SEED)
    random.seed(SEED)
    os.environ['PYTHONHASHSEED'] = str(SEED)
    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)
    tf.random.set_seed(SEED)
    print('seeding done!!!')
seeding(SEED)if DEVICE == ""TPU"":
    print(""connecting to TPU..."")
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        print('Running on TPU ', tpu.master())
    except ValueError:
        print(""Could not connect to TPU"")
        tpu = None

    if tpu:
        try:
            print(""initializing  TPU ..."")
            tf.config.experimental_connect_to_cluster(tpu)
            tf.tpu.experimental.initialize_tpu_system(tpu)
            strategy = tf.distribute.experimental.TPUStrategy(tpu)
            print(""TPU initialized"")
        except _:
            print(""failed to initialize TPU"")
    else:
        DEVICE = ""GPU""

if DEVICE != ""TPU"":
    print(""Using default strategy for CPU and single GPU"")
    strategy = tf.distribute.get_strategy()

if DEVICE == ""GPU"":
    print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
    

AUTO     = tf.data.experimental.AUTOTUNE
REPLICAS = strategy.num_replicas_in_sync
print(f'REPLICAS: {REPLICAS}')GCS_PATH = [None]*FOLDS
for i,k in enumerate(IMG_SIZES):
    GCS_PATH[i] = KaggleDatasets().get_gcs_path('siimcovid19-%ix%i-tfrec-dataset'%(k[0],k[1]))
files_train = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/train*.tfrec')))
files_test  = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/test*.tfrec')))
num_train_files = len(files_train)
num_test_files  = len(files_test)
print('train_files:',num_train_files)
print('test_files:',num_test_files)train_df = pd.read_csv('../input/siim-covid19-yolov5-2class-labels/meta.csv')
train_df.head(2)","This code loads the Siim-Covid19 dataset from Kaggle. The dataset contains images of X-rays of patients with Covid-19. The code then prints the number of training and testing files in the dataset. Finally, it loads the metadata for the dataset, which contains information on the patients in the dataset.",8,1,0.03184473712945084
"import pandas as pd df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')dfid_laststr_list  = []
for i in range(df.shape[0]):
    id_laststr_list.append(df.loc[i,'id'][-1])
df['id_last_str'] = id_laststr_liststudy_len = df[df['id_last_str'] == 'y'].shape[0]study_str = 'negative 1 0 0 1 1 atypical 1 0 0 1 1 typical 1 0 0 1 1 indeterminate 1 0 0 1 1'
for i in range(study_len):
    df.loc[i, 'PredictionString'] = study_strdf = df[['id', 'PredictionString']]","This code imports the pandas library and reads in a CSV file containing sample submission data.

Next, it creates an empty list called id_laststr_list.

Then, it loops through all the rows in the dataframe, appending the last character of the 'id' column to the list.

After that, it creates a new column in the dataframe called 'id_last_str' and assigns the list as its values.

Next, it calculates the number of rows in the dataframe that have a 'y' in the 'id_last_str' column.

Then, it creates a string called 'study_str'.

Finally, it loops through all the rows in the dataframe with a 'y' in the 'id_last_str' column and assigns the 'study_str' string as the value for the 'PredictionString' column.",8,11,0.07100618016439061
"import numpy as np 
import pandas as pd 
import os
from tqdm import tqdm
import matplotlib.pyplot as plt
import pydicomtrain_st = pd.read_csv(""../input/siim-covid19-detection/train_study_level.csv"")
train_st.head(3)
train_im = pd.read_csv(""../input/siim-covid19-detection/train_image_level.csv"")
train_im.head(3)sample = pd.read_csv(""../input/siim-covid19-detection/sample_submission.csv"")
sample.head(3)train_path = ""../input/siim-covid19-detection/train""
test_path = ""../input/siim-covid19-detection/test""trainimlist = []

for dirname, _, filenames in os.walk(train_path):
    for filename in filenames:
        trainimlist.append(os.path.join(dirname, filename))testimlist = []

for dirname, _, filenames in os.walk(test_path):
    for filename in filenames:
        testimlist.append(os.path.join(dirname, filename))","The code imports the necessary libraries for data manipulation, analysis, and visualization.

It then loads the data from the input files into pandas dataframes.

The code then defines the path to the training and testing data.

Finally, the code loops through the training and testing data folders to generate a list of all the images in each folder.",9,1,0.03626633037611154
"import fastai
import fastai.medical
from fastai.basics import *
from fastai.vision.all import *
from fastai.medical.imaging import *

import pydicom

import pandas as pd
fastai.__version__!conda install -c conda-forge gdcm -yfilegroup='train'
path='../input/siim-covid19-detection'
dirName = f'{path}/{filegroup}/'# Get DICOM file list from train directory
items = get_dicom_files(dirName)df_trn = pd.DataFrame.from_dicoms(items,px_summ=False)
df_trn.to_csv(f'alldicom{filegroup}.csv')
df_trn.describe()
df_trnfilegroup='test'
dirName = f'{path}/{filegroup}/'","The code above imports the fastai and fastai.medical libraries, and then uses the get_dicom_files() function to get a list of DICOM files from a directory. The code then creates a Pandas dataframe from the DICOM files, and saves it to a CSV file. Finally, the code displays some basic statistics about the dataframe.",8,5,0.12944775439878034
"import numpy as np 
import pandas as pd
import os
import matplotlib.pyplot as plt
import pydicom as dicom
from glob import glob
from pathlib import Path
from pydicom import dcmread
import matplotlib
import astStudy= pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')Study.describe()Study.head()Study.isnull().sum()image_level=pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')image_level.head()","This code imports the necessary libraries for working with data from the SIIM-CoVid19 detection dataset. It then loads the data from the study_level and image_level CSV files. Finally, it generates some basic statistics about the data and visualizes the data.",8,0,0.06412730033689229
"#Attaullah
#attaullahshafiq10@gmail.com
# Import libs
!conda install gdcm -c conda-forge -y
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
import pydicom
import glob
from tqdm.notebook import tqdm
from pydicom.pixel_data_handlers.util import apply_voi_lut
import matplotlib.pyplot as plt
from skimage import exposure#import gdcm
import cv2
import warnings
from fastai.vision.all import *
from fastai.medical.imaging import *
warnings.filterwarnings('ignore')
dataset_path = Path('../input/siim-covid19-detection')
import vtk

from vtk.util import numpy_support

reader = vtk.vtkDICOMImageReader()#HTML view

from IPython.display import HTML
HTML('<iframe src=https://arxiv.org/pdf/1506.01497.pdf width=600 height=650></iframe>')# from https://www.kaggle.com/tanlikesmath/siim-covid-19-detection-a-simple-eda
def dicom2array(path, voi_lut=True, fix_monochrome=True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()


def plot_imgs(imgs, cols=4, size=7, is_rgb=True, title="""", cmap='gray', img_size=(500,500)):
    rows = len(imgs)//cols + 1
    fig = plt.figure(figsize=(cols*size, rows*size))
    for i, img in enumerate(imgs):
        if img_size is not None:
            img = cv2.resize(img, img_size)
        fig.add_subplot(rows, cols, i+1)
        plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()dicom_paths = get_dicom_files(dataset_path/'train')
print([str(path) for path in dicom_paths[:4]])
imgs = [dicom2array(str(path)) for path in dicom_paths[:4]]
plot_imgs(imgs)","This code imports the necessary libraries for working with DICOM files, including pydicom and matplotlib. It also sets up some basic parameters for displaying images.

Next, the code defines a function for converting DICOM files to arrays. This function takes a DICOM file path as input and returns the image data as a NumPy array.

Finally, the code calls the dicom2array function on a sample of DICOM files from the dataset. It then plots the resulting images.",8,3,0.14439935104983626
"!pip install -q --upgrade wandb

import wandb
wandb.login()import os
import gc
import cv2
import ast
import numpy as np
import pandas as pd
from tqdm import tqdm
import matplotlib.pyplot as plt
%matplotlib inlineTRAIN_PATH = '../input/siim-covid19-resized-to-256px-jpg/train/'
IMG_SIZE = 256
NUM_SAMPLES_TO_VIZ = 32# Load image level csv file
df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
# Load study level csv file
label_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')

# Modify values in the id column
df['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)
# Add absolute path
df['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)
# Get image level labels
df['image_level'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)

# Modify values in the id column
label_df['id'] = label_df.apply(lambda row: row.id.split('_')[0], axis=1)
# Rename the column id with StudyInstanceUID
label_df.columns = ['StudyInstanceUID', 'Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']

# Merge both dataframes
df = df.merge(label_df, on='StudyInstanceUID',how=""left"")
df.head(2)print(f'Number of unique image in training dataset: {len(df)}')

bbox_nan_num = df['boxes'].isna().sum()
print(f'Number of images without any bbox annotation: {bbox_nan_num}')# Label encode study-level labels
labels = df[['Negative for Pneumonia','Typical Appearance','Indeterminate Appearance','Atypical Appearance']].values
labels = np.argmax(labels, axis=1)

df['study_level'] = labels
df.head(2)class_label_to_id = {
    'Negative for Pneumonia': 0,
    'Typical Appearance': 1,
    'Indeterminate Appearance': 2,
    'Atypical Appearance': 3
}

class_id_to_label = {val: key for key, val in class_label_to_id.items()}","This code installs the wandb library, which is used for visualizing data. It then imports the wandb library and login() function.

The code then defines some variables:

- TRAIN_PATH is the path to the training data
- IMG_SIZE is the size of the images in the training data
- NUM_SAMPLES_TO_VIZ is the number of samples to visualize

The code then loads two CSV files: one containing image-level data, and one containing study-level data.

The code then modifies the values in the id column of the image-level dataframe, and adds the absolute path to each image. The code also gets the image-level labels from the image-level dataframe.

The code then modifies the values in the id column of the study-level dataframe, and renames the id column to StudyInstanceUID. The code then merges the two dataframes.

The code then prints the number of unique images in the training dataset, and the number of images without any bounding box annotation.

The code then label encodes the study-level labels, and adds them to the dataframe.

The code then defines a dictionary mapping class labels to class ids, and another dictionary mapping class ids to class labels.",8,14,0.15518713515506669
"!conda install gdcm -c conda-forge -yimport os

from PIL import Image
import pandas as pd
from tqdm.auto import tqdmimport numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return imtrain = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')path = '../input/siim-covid19-detection/train/ae3e63d94c13/288554eb6182/e00f9fe0cce5.dcm'
dicom = pydicom.read_file(path)image_id = []
dim0 = []
dim1 = []
splits = []

for split in ['test', 'train']:
    save_dir = f'/kaggle/tmp/{split}/'

    os.makedirs(save_dir, exist_ok=True)
    
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(os.path.join(dirname, file))
            im = resize(xray, size=768)  
            im.save(os.path.join(save_dir, file.replace('dcm', 'jpg')))

            image_id.append(file.replace('.dcm', ''))
            dim0.append(xray.shape[0])
            dim1.append(xray.shape[1])
            splits.append(split)","This code reads in a DICOM image, applies a VOI LUT (if available), and then transforms the raw DICOM data into a ""human-friendly"" view. It also fixes any inverted X-rays, and rescales the image so that it is between 0 and 1. Finally, it saves the image as a JPEG.",8,1,0.18884251289749654
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport sys
sys.path.append('../input/timm-pytorch-models/archive (3)/pytorch-image-models-master')
import timmimport numpy as np 
import pandas as pd 

import math
import random 
import os 
import cv2
import timm

from tqdm import tqdm 

import albumentations as A 
from albumentations.pytorch.transforms import ToTensorV2
import torch 
from torch.utils.data import Dataset 
from torch import nn
import torch.nn.functional as F 

import gc
import cudf
import cuml
import cupy
from cuml.feature_extraction.text import TfidfVectorizer
from cuml.neighbors import NearestNeighborsclass CFG:
    
    img_size = 512
    batch_size = 12
    seed = 2020
    
    device = 'cuda'
    classes = 11014
    
    model_name = 'eca_nfnet_l0'
    model_path = '../input/pytorch-model-weights/arcface_512x512_nfnet_l0 (mish).pt'
    
    scale = 30 
    margin = 0.5def read_dataset():
    df = pd.read_csv('../input/shopee-product-matching/test.csv')
    df_cu = cudf.DataFrame(df)#cuDF is a Python GPU DataFrame library workflow is fast enough on a single GPU fits in memory on a single GPU
    image_paths = '../input/shopee-product-matching/test_images/' + df['image']
    return df, df_cu, image_pathsdef seed_torch(seed=42):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    
seed_torch(CFG.seed)def get_image_predictions(df, embeddings,threshold = 0.0):
    
    if len(df) > 3:
        KNN = 50
    else : 
        KNN = 3
    
    model = NearestNeighbors(n_neighbors = KNN, metric = 'cosine')
    model.fit(embeddings)
    distances, indices = model.kneighbors(embeddings)
    
    predictions = []
    for k in tqdm(range(embeddings.shape[0])):
        idx = np.where(distances[k,] < threshold)[0]
        ids = indices[k,idx]
        posting_ids = df['posting_id'].iloc[ids].values
        predictions.append(posting_ids)
        
    del model, distances, indices
    gc.collect()
    return predictions","The code above defines a function for reading in a dataset, seed_torch() for seeding the random number generator, and get_image_predictions() for generating image predictions.

The read_dataset() function reads in a CSV file containing image data and returns a dataframe, a CUDF dataframe, and a list of image paths.

The seed_torch() function seeds the random number generator with the specified seed.

The get_image_predictions() function takes in a dataframe, an array of embeddings, and a threshold. It returns a list of predictions, where each prediction is a list of posting IDs of images that are similar to the image represented by the embedding.",8,4,0.17162205013431633
"%%capture
!pip install ../input/pytorchimagemodelsimport sys
sys.path.append('../input/facebookdeit')import os
import gc
import sys

import math
import random

from tqdm.notebook import tqdm

import re

import cv2
import numpy as np
import pandas as pd

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset ,RandomSampler

import timm

import albumentations

from swav_resnet import resnet50w2

import transformers
from transformers import AutoModel, AutoTokenizer

from models import deit_base_distilled_patch16_224



import cudf
import cuml
import cupydef set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True

set_seed(0)text_models=[
    {
        'transformer_model': '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14',
        'model_path' : '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14/ckpt.pt',
        'MAX_LEN' : 128,
        'params' : {
            'embed_dim' :1024,
            'out_dim' : 11014
        }
        
    },
    {
            'transformer_model': '../input/shopee-bert-base-indonesian/bert-base-indonesian_pp_7_8',
            'model_path' : '../input/shopee-bert-base-indonesian/bert-base-indonesian_pp_7_8/ckpt.pt',
            'MAX_LEN' : 128,
            'params' : {
                'embed_dim' :1024,
                'out_dim' : 11014
            }

        }
]

TRANSFORMER_EMBED_DIM = 768joint_models=[
    {
        'transformer_model': '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14',
        'model_path' : '../input/deit-xlm-joint-weights/finetuned_deit_xlm_joint_7_11.pt',
        'MAX_LEN' : 128,
        'IMAGE_SIZE' : 224,
        'params' : {
                'embed_dim' : 2048,
                'out_dim' : 11014
            }
        
    }
]image_models=[
    {
        'vision_model': '../input/shopee-swav-finetuned-resnet50w2/swav_resnet50w2_224_2048_5_epochs_loss_12_beef.pt',
        'IMAGE_SIZE' : 224,
        'params' : {
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
    {
        'vision_model': '../input/effnet-weights/finetuned_tf_efficientnet_b3_ns_300_2048_7_9.pt',
        'IMAGE_SIZE' : 300,
        'params' : {
            'backbone_name' : 'tf_efficientnet_b3_ns',
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
    
    {
        'vision_model': '../input/deit-base-distilled-patch16-224/finetuned_deit_base_distilled_patch16_224_4_18.pt',
        'IMAGE_SIZE' : 224,
        'params' : {
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
]","This code defines several models for text, image, and joint text-image representation learning. The text models are based on the transformer architecture, specifically XLM-R and BERT, while the image models are based on ResNet50 and EfficientNet. The joint model is a combination of the XLM-R transformer and the DeiT base distilled Patch16 model.

The code provides parameters for each model, including the model path, the maximum length of input sequences, the image size, and the output dimension.",8,4,0.038791893144897734
"import sys
import gc
import math
import configparser
import numpy as np
import pandas as pd
import optuna
from tqdm import tqdm
import sklearn
import tensorflow as tf
from tensorflow import keras
from typing import Tupletry:
    # TPU detection. No parameters necessary if TPU_NAME environment variable is
    # set: this is always the case on Kaggle.
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
    print('Running on TPU ', tpu.master())
except ValueError:
    tpu = None

if tpu:
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.TPUStrategy(tpu)
else:
    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.
    strategy = tf.distribute.get_strategy()

print(""REPLICAS: "", strategy.num_replicas_in_sync)pd.set_option(""use_inf_as_na"", True)
pd.set_option(""display.max_columns"", 9999)
pd.set_option(""display.max_rows"", 9999)
pd.set_option('max_colwidth', 9999)
INPUT = '/kaggle/input'
DATA = f'{INPUT}/shopee-product-matching'
OUTPUT = '/kaggle/working'
RESOURCE_DIR = f'{INPUT}/shopee-product-matching-lib/kaggle-shopee-product-matching-1.0'
sys.path.append(f'{INPUT}/sgcharts-ml/src')
sys.path.append(f""{INPUT}/sentence-transformers/sentence-transformers-1.0.4"")
sys.path.append(f'{RESOURCE_DIR}/src')
import mylib
import scml
from scml.nlp import strip_punctuation, to_ascii_str
scml.seed_everything()MODEL = 'efficientnetb3'
CONF = configparser.ConfigParser()
CONF.read(f""{RESOURCE_DIR}/app.ini"")
resolution = int(CONF[MODEL][""resolution""])
INPUT_SHAPE = (resolution, resolution, 3)
print(f""INPUT_SHAPE={INPUT_SHAPE}"")train = pd.read_csv(f""{DATA}/train.csv"", engine=""c"", low_memory=False)
train[""target""] = mylib.target_label(train)
le = sklearn.preprocessing.LabelEncoder()
train[""label_group""] = le.fit_transform(train['label_group'])
n_classes=len(le.classes_)
print(f""n_classes={n_classes}"")
train.info()train.head()def _data_gen(
    dataframe,
    directory,
    target_size,
    batch_size,
    color_mode=""rgb"",
    class_mode=""raw"",
    x_col=""image"",
    y_col=""label_group""
):
    dtype = np.float32
    rescale = 1./255
    interpolation = ""bicubic""
    data_format = ""channels_last""
    shuffle = True
    idg = keras.preprocessing.image.ImageDataGenerator(
        shear_range=0.2,
        zoom_range=0.2,
        brightness_range=(0.7, 1.3),
        #rotation_range=90,
        horizontal_flip=True,
        rescale=rescale,
        data_format=data_format,
        dtype=dtype
    )
    g = idg.flow_from_dataframe(
        dataframe=dataframe,
        x_col=x_col,
        y_col=y_col,
        directory=directory,
        target_size=target_size,
        color_mode=color_mode,
        batch_size=batch_size,
        shuffle=shuffle,
        class_mode=class_mode,
        interpolation=interpolation,
    )
    while True:
        x, y = g.next()
        yield [x, y], y","The code above defines a function for generating image data from a pandas dataframe. The function takes several arguments:

dataframe: the pandas dataframe containing the image data
directory: the directory containing the images
target_size: the target size of the images
batch_size: the batch size
color_mode: the color mode (rgb or grayscale)
class_mode: the class mode (raw or categorical)
x_col: the column containing the image filenames
y_col: the column containing the image labels

The function returns a generator that yields batches of image data and labels.",8,4,0.07824543889465782
"import pip
try:
     __import__(""imutils"")
except ImportError:
    pip.main([""install"", ""imutils""])import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import  matplotlib.pyplot as plt
import tensorflow as tf
import pandas as pd
import cv2
from imutils.object_detection import non_max_suppression
import pytesseract
import os
import glob
os.chdir('/kaggle/working')
BASE = '../input/shopee-product-matching/train_images/'
EAST_PATH = ""/kaggle/input/east-data-leo/frozen_east_text_detection/frozen_east_text_detection.pb""
RESIZE_IMG_SHAPE = (500,500)
img_paths = glob.glob(f""{BASE}*jpg"") train = pd.read_csv('../input/shopee-product-matching/train.csv')
print('train shape is', train.shape )
train.head()groups = train.label_group.value_counts()
plt.figure(figsize=(20,5))
plt.plot(np.arange(len(groups)),groups.values)
plt.ylabel('Duplicate Count',size=14)
plt.xlabel('Index of Unique Item',size=14)
plt.title('Duplicate Count vs. Unique Item Count',size=16)
plt.show()

plt.figure(figsize=(20,5))
plt.bar(groups.index.values[:50].astype('str'),groups.values[:50])
plt.xticks(rotation = 45)
plt.ylabel('Duplicate Count',size=14)
plt.xlabel('Label Group',size=14)
plt.title('Top 50 Duplicated Items',size=16)
plt.show()def img_proc(img,offset =20):
    img =img[offset:-offset,offset:-offset]
    img =cv2.resize(img ,RESIZE_IMG_SHAPE)
    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    gray = cv2.medianBlur(gray,5)
    ret, thresh = cv2.threshold(gray,150,255,cv2.THRESH_BINARY)
    thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\
            cv2.THRESH_BINARY_INV,21,2)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))
    opening = cv2.erode(thresh,kernel, iterations = 1)
    closing = cv2.dilate(opening,kernel,iterations=1)
    contours = cv2.findContours(closing, 
                            cv2.RETR_EXTERNAL,
                            cv2.CHAIN_APPROX_NONE)
    canvas =np.zeros((500,500))
    cv2.drawContours(canvas, contours[0], -1, (255,0,255), thickness = 2) 
    return canvas



def displayDF(train, random=False, COLS=6, ROWS=4, path=BASE):
    for k in range(ROWS):
        plt.figure(figsize=(20,5))
        for j in range(COLS):
            if random: row = np.random.randint(0,len(train))
            else: row = COLS*k + j
            name = train.iloc[row,1]
            title = train.iloc[row,3]
            title_with_return = """"
            for i,ch in enumerate(title):
                title_with_return += ch
                if (i!=0)&(i%20==0): title_with_return += '\n'
            img = img_proc(cv2.imread(path+name))
            plt.subplot(1,COLS,j+1)
            plt.title(title_with_return)
            plt.axis('off')
            plt.imshow(img)
        plt.show()
        
displayDF(train,random=True)def predictions(prob_score, geo,min_conf):
    (numR, numC) = prob_score.shape[2:4]
    boxes = []
    confidence_val = []
    for y in range(0, numR):
        scoresData = prob_score[0, 0, y]
        x0 = geo[0, 0, y]
        x1 = geo[0, 1, y]
        x2 = geo[0, 2, y]
        x3 = geo[0, 3, y]
        anglesData = geo[0, 4, y]
        for i in range(0, numC):
            if scoresData[i] < min_conf:
                continue
            (offX, offY) = (i * 4.0, y * 4.0)
            angle = anglesData[i]
            cos = np.cos(angle)
            sin = np.sin(angle)
            h = x0[i] + x2[i]
            w = x1[i] + x3[i]
            endX = int(offX + (cos * x1[i]) + (sin * x2[i]))
            endY = int(offY - (sin * x1[i]) + (cos * x2[i]))
            startX = int(endX - w)
            startY = int(endY - h)
            boxes.append((startX, startY, endX, endY))
            confidence_val.append(scoresData[i])

    return (boxes, confidence_val)

def get_text(img,img_text ='Output',min_conf = 0.7, east = EAST_PATH):
    image = cv2.imread(img)
    orig = image.copy()
    (origH, origW) = image.shape[:2]
    (newW, newH) = (320,320)
    rW = origW / float(newW)
    rH = origH / float(newH)
    image = cv2.resize(image, (newW, newH))
    (H, W) = image.shape[:2]
    blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),
        (123.68, 116.78, 103.94), swapRB=True, crop=False)
    net = cv2.dnn.readNet(east)
    # The following two layer need to pulled from EAST model for achieving this. 
    layerNames = [
        ""feature_fusion/Conv_7/Sigmoid"",
        ""feature_fusion/concat_3""]

    #Forward pass the blob from the image to get the desired output layers
    net.setInput(blob)
    (scores, geometry) = net.forward(layerNames)
    (boxes, confidence_val) = predictions(scores, geometry,min_conf)
    boxes = non_max_suppression(np.array(boxes), probs=confidence_val)
    
    results = []
    for (startX, startY, endX, endY) in boxes:
        startX = int(startX * rW)
        startY = int(startY * rH)
        endX = int(endX * rW)
        endY = int(endY * rH)
        r = orig[startY:endY, startX:endX]
        configuration = (""-l eng --oem 1 --psm 8"")
        text = pytesseract.image_to_string(r, config=configuration)
        results.append(((startX, startY, endX, endY), text))

    orig_image = orig.copy()
    txts=[]
    for ((start_X, start_Y, end_X, end_Y), text) in results:
        text = """".join([x if ord(x) < 128 else """" for x in text]).strip()
        cv2.rectangle(orig_image, (start_X, start_Y), (end_X, end_Y),
            (0, 0, 255), 2)
        cv2.putText(orig_image, text, (start_X, start_Y + 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,255, 0), 4)
        txts.append(text)
    plt.figure(figsize=(10,10))
    plt.imshow(orig_image)
    plt.title(img_text)
    plt.show()
    print(txts)it = iter(range(500))","This code imports the pip module and tries to import the imutils module. If the imutils module is not found, it uses pip to install it. The code then imports numpy, pandas, matplotlib, and tensorflow.

The code then sets the working directory to the 'train_images' folder and sets BASE to '../input/shopee-product-matching/train_images/'. It then sets EAST_PATH to ""/kaggle/input/east-data-leo/frozen_east_text_detection/frozen_east_text_detection.pb"".

The code then defines a function to resize images and another function to display dataframes. The code then displays a random dataframe.

The code then defines a function to get text from an image using pytesseract. The code then displays an image with the text overlayed.",8,13,0.08767545080308563
,"This code defines a function that calculates the average of two numbers.

/**

* Returns the average of two numbers.

*

* @param {number} a The first number.

* @param {number} b The second number.

* @return {number} The average of the two numbers.

*/

function average(a, b) {

return (a + b) / 2;

}",8,3,
"for i in df_train.isnull().any():
    if i == True:
        sys.exit(""There is unlabeled data"")
print(""No missing values found"")y = df_train[""label""]
x = df_train.drop(""label"", axis=1)df_test.shape","This code checks for missing values in the dataframe df_train, and if any are found, exits the program with an error message. Otherwise, it prints a message indicating that no missing values were found.",8,2,0.239805806290099
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session!pwdcd ../input/mnist-dataset%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
import struct
import os
import math# 读取数据

# 参考博客：https://blog.csdn.net/u013597931/article/details/80099243
def load_mnist_train(path, kind='train'):    
    labels_path = os.path.join(path+'%s-labels-idx1-ubyte/'% kind,'%s-labels-idx1-ubyte'% kind)
    images_path = os.path.join(path+'%s-images-idx3-ubyte/'% kind,'%s-images-idx3-ubyte'% kind)    # 训练集的路径读取
    with open(labels_path, 'rb') as lbpath:          
        magic, n = struct.unpack('>II',lbpath.read(8))
        labels = np.fromfile(lbpath,dtype=np.uint8)
    with open(images_path, 'rb') as imgpath:
        magic, num, rows, cols = struct.unpack('>IIII',imgpath.read(16))
        images = np.fromfile(imgpath,dtype=np.uint8).reshape(len(labels), 784)
    return images, labels
def load_mnist_test(path, kind='t10k'):
    labels_path = os.path.join(path+'%s-labels-idx1-ubyte/'% kind,'%s-labels-idx1-ubyte'% kind)
    images_path = os.path.join(path+'%s-images-idx3-ubyte/'% kind,'%s-images-idx3-ubyte'% kind)
    with open(labels_path, 'rb') as lbpath:
        magic, n = struct.unpack('>II',lbpath.read(8))
        labels = np.fromfile(lbpath,dtype=np.uint8)
    with open(images_path, 'rb') as imgpath:
        magic, num, rows, cols = struct.unpack('>IIII',imgpath.read(16))
        images = np.fromfile(imgpath,dtype=np.uint8).reshape(len(labels), 784)
    return images, labels   

path='/kaggle/input/mnist-dataset/'
train_images,train_labels=load_mnist_train(path)    # 训练数据
test_images,test_labels=load_mnist_test(path)      # 测试数据

fig=plt.figure(figsize=(8,8))
fig.subplots_adjust(left=0,right=1,bottom=0,top=1,hspace=0.05,wspace=0.05)
for i in range(30):
    images = np.reshape(train_images[i], [28,28])
    ax=fig.add_subplot(6,5,i+1,xticks=[],yticks=[])
    ax.imshow(images,cmap=plt.cm.binary,interpolation='nearest')
    ax.text(0,7,str(train_labels[i]))
plt.show()# 数据规模
print(train_images.shape)
print(test_images.shape)

print(train_labels.shape)
print(test_labels.shape)# 数据归一化
train_images = train_images / 255.0
test_images = test_images / 255.0","This code loads the MNIST dataset from a given path, and stores it in two variables, train_images and train_labels for the training set, and test_images and test_labels for the test set.

The MNIST dataset is a set of handwritten digits, each of which is 28x28 pixels in size. The code above loads the dataset and displays some sample images from it.

The dataset is already split into a training set and a test set, so no further splitting is necessary. However, the data is not normalized, so the code above normalizes it by dividing each image by 255.0.",8,2,0.11900948261428472
"import numpy as np
from torch.utils.data import DataLoader
import torch
import torch.nn as nn
from torchvision import datasets
import torchvision.transforms as tfs
from typing import Dict, List, Tuple
from tqdm.notebook import tqdm
import matplotlib.pyplot as pltBATCH_SIZE = 256
CHANNELS = 1
IMAGEY = 28
IMAGEX = 28
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'# MNIST Dataset
train_dataset = datasets.MNIST(
    root='./mnist_data/', train=True, transform=tfs.ToTensor(), download=True
)
valid_dataset = datasets.MNIST(
    root='./mnist_data/', train=False, transform=tfs.ToTensor(), download=False
)

# Data Loader (Input Pipeline)
dataloader = {
    'train': DataLoader(
        dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=False
    ),
    'valid': DataLoader(
        dataset=valid_dataset, batch_size=BATCH_SIZE, shuffle=False
    )
}def show_images(faces: np.ndarray, size: Tuple[int, int] = (1, 8)):
    rows, cols = size
    fig, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))
    for ax, img in zip(axes.flatten(), faces):
        ax.axis('off')
        ax.imshow(img.numpy().transpose(1, 2, 0))def show_metrics(metrics: Dict[str, List[float]]) -> None:
    plt.figure(figsize=(12, 8))
    plt.plot(metrics['train'], label='train')
    plt.plot(metrics['valid'], label='validation')
    plt.grid()
    plt.legend()
    plt.show()test_imgs, test_labels = next(iter(dataloader['valid']))
show_images(test_imgs[:8])HIDDEN_DIM = 16

class VAE(nn.Module):
    def __init__(self):
        super().__init__()
        self.flatten = nn.Flatten()
        self.encoder = nn.Sequential(
            nn.Linear(in_features=(CHANNELS * IMAGEY * IMAGEX), out_features=256),
            nn.ReLU(),
            nn.BatchNorm1d(256),
            nn.Dropout(0.25),
            nn.Linear(in_features=256, out_features=128),
            nn.ReLU(),
            nn.BatchNorm1d(128),
            nn.Dropout(0.25),
            nn.Linear(in_features=128, out_features=(HIDDEN_DIM * 2)),
        )
        self.decoder = nn.Sequential(
            nn.Linear(in_features=HIDDEN_DIM, out_features=128),
            #nn.LeakyReLU(),
            nn.ReLU(),
            nn.BatchNorm1d(128),
            nn.Dropout(0.25),
            nn.Linear(in_features=128, out_features=256),
            #nn.LeakyReLU(),
            nn.ReLU(),
            nn.BatchNorm1d(256),
            nn.Dropout(0.25),
            nn.Linear(in_features=256, out_features=(CHANNELS * IMAGEY * IMAGEX)),
            nn.Sigmoid(),
        )
        
    def encode(self, x):
        x = self.flatten(x).float()
        x = self.encoder(x).view(-1, 2, HIDDEN_DIM)
        mu = x[:, 0, :]
        logsigma = x[:, 1, :]
        return mu, logsigma
    
    def gaussian_sampler(self, mu, logsigma):
        if self.training:
            std = torch.exp(0.5 * logsigma)
            eps = torch.randn_like(std)
            sample = mu + (eps * std)
            return sample
        else:
            return mu
    
    def decode(self, z):
        reconstruction = self.decoder(z)
        reconstruction = reconstruction.view(-1, CHANNELS, IMAGEY, IMAGEX)
        return reconstruction

    def forward(self, x):
        mu, logsigma = self.encode(x)
        z = self.gaussian_sampler(mu, logsigma)
        reconstruction = self.decode(z)
        return mu, logsigma, reconstruction","The code above defines a variational autoencoder (VAE). The VAE consists of an encoder and a decoder. The encoder transforms the input data into a latent space, and the decoder maps the latent space back to the original data space.

The code defines a function for each of the VAE's components. The encode() function transforms the input data into a latent space. The gaussian_sampler() function samples from the latent space. The decode() function maps the latent space back to the original data space. The forward() function applies the encoder, gaussian_sampler, and decoder sequentially.

The code also defines a show_images() function, which displays a grid of images. The show_metrics() function displays a graph of the training and validation metrics.",8,2,0.021248496429386917
"import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

from keras import backend as K

from keras.datasets import mnist
from keras.layers import (Activation, BatchNormalization, Concatenate, Dense,
                          Dropout, Flatten, Input, Lambda, Reshape)
from keras.layers.advanced_activations import LeakyReLU
from keras.layers.convolutional import Conv2D, Conv2DTranspose
from keras.models import Model, Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical'''The Dimensions of the traget images'''
img_rows = 28
img_cols = 28
channels = 1

img_shape = (img_rows , img_cols , channels)

z_dim = 100 #random noise input for generator 

num_classes = 10 #no. of classes to predictclass Dataset:
    def __init__(self, num_labeled):

        self.num_labeled = num_labeled                               
        
        (self.x_train, self.y_train), (self.x_test,self.y_test) = mnist.load_data()

        def preprocess_imgs(x):
            x = (x.astype(np.float32) - 127.5) / 127.5                   
            x = np.expand_dims(x, axis=3)                                
            return x

        def preprocess_labels(y):
            return y.reshape(-1, 1)

        self.x_train = preprocess_imgs(self.x_train)                     
        self.y_train = preprocess_labels(self.y_train)

        self.x_test = preprocess_imgs(self.x_test)                       
        self.y_test = preprocess_labels(self.y_test)

    def batch_labeled(self, batch_size):
        idx = np.random.randint(0, self.num_labeled, batch_size)         
        imgs = self.x_train[idx]
        labels = self.y_train[idx]
        return imgs, labels

    def batch_unlabeled(self, batch_size):
        idx = np.random.randint(self.num_labeled, self.x_train.shape[0], batch_size)
        imgs = self.x_train[idx]
        return imgs

    def training_set(self):
        x_train = self.x_train[range(self.num_labeled)]
        y_train = self.y_train[range(self.num_labeled)]
        return x_train, y_train

    def test_set(self):
        return self.x_test, self.y_testnum_labeled = 100

dataset = Dataset(num_labeled)def build_generator(z_dim):
    model = Sequential()
    model.add(Dense(256 * 7 * 7, input_dim=z_dim))                           
    model.add(Reshape((7, 7, 256)))
    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))
    model.add(BatchNormalization())                                       
    model.add(LeakyReLU(alpha=0.01))                                        
    model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same')) 
    model.add(BatchNormalization())                                          
    model.add(LeakyReLU(alpha=0.01))                                         
    model.add(Conv2DTranspose(1, kernel_size=3, strides=2, padding='same'))  
    model.add(Activation('tanh'))                                            
    return modeldef build_discriminator_net(img_shape):
    model = Sequential()
    
    model.add(Conv2D(32,
                     kernel_size = 3,
                     strides=3,
                    input_shape=img_shape,
                    padding='same'))
    
    model.add(LeakyReLU(alpha=0.01))
    
    model.add(Conv2D(64,
                     kernel_size = 3,
                     strides=3,
                    input_shape=img_shape,
                    padding='same'))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.01))
    
    model.add(Conv2D(128,
                     kernel_size = 3,
                     strides=3,
                    input_shape=img_shape,
                    padding='same'))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.01))
    model.add(Dropout(0.5))
    
    model.add(Flatten())
    model.add(Dense(num_classes))    
    return model    def build_discriminator_supervised(discriminator_net):
    model = Sequential()
    model.add(discriminator_net)
    model.add(Activation('softmax'))    
    return model","This code defines a dataset class for the MNIST dataset, which is a collection of handwritten digits. The class provides methods for accessing labeled and unlabeled data, as well as a training set and a test set. The code also defines a generator and a discriminator for a GAN. The generator takes as input a 100-dimensional noise vector and outputs a 28x28 image. The discriminator takes as input a 28x28 image and outputs a 10-dimensional vector, which corresponds to the probability that the image is of each digit class.",8,1,0.03811903207210075
"import numpy as np 
import pandas as pd
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt 
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler

train = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")
test = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")
submission = pd.read_csv(""/kaggle/input/digit-recognizer/sample_submission.csv"")
trainX_train = train.drop(['label'], axis = 1)
y_train = train['label']
X_test = test.copy()

X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, stratify = train['label'])forest = RandomForestClassifier(random_state = 42)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
forest.fit(X_train, y_train)
y_pred = forest.predict(X_test)submission = pd.DataFrame({'ImageId' : range(1,28001), 'Label' : list(y_pred)})
submission
submission.to_csv('submission.csv', index = False)","This code imports the necessary libraries for the program. Next, the code sets up the training and testing data sets. The training data set is used to train the model, while the testing data set is used to evaluate the model's performance.

Next, the code fits a random forest classifier to the training data. This classifier is then used to predict the labels for the images in the testing data set. Finally, the predictions are saved to a CSV file.",8,0,0.018888970313712623
"#Импорт необходимых для работы библиотек

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import os

train = pd.read_csv('../input/digit-recognizer/train.csv')
test = pd.read_csv('../input/digit-recognizer/test.csv')

train.head()y = train['label']
train = train.drop(['label'],axis = 1)
y  = y.astype(int)from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test =\
    train_test_split(train, y, test_size=0.2, random_state=0)

from xgboost import XGBClassifier
model = XGBClassifier()
model.fit(x_train,y_train)



prediction = model.predict(test)


output = pd.DataFrame({'ImageId':range(1,28001),'Label':prediction})
output.to_csv('submission.csv',index=False, header = 1)print(output)","This code imports the necessary libraries for working with data, then loads the training and test data. Next, it splits the training data into a training set and a test set, using 80% of the data for training and 20% for testing. Finally, it trains a model using the training set and makes predictions on the test set. The predictions are then outputted to a CSV file.",9,0,0.05540648714941439
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiontrain_data = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")
test_data = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")
submission = pd.read_csv(""/kaggle/input/digit-recognizer/sample_submission.csv"")
train_datay_train = train_data[""label""]
X_train = train_data.drop([""label""], axis = 1)import matplotlib.pyplot as plt

def plot_digit(row):
    some_digit = np.array(row)
    some_digit_image = some_digit.reshape((28, 28))
    plt.imshow(some_digit_image, cmap = plt.cm.binary)
    plt.axis('off')
    
plot_digit(X_train.loc[0])
y_train[0]from sklearn.neighbors import KNeighborsClassifier

knn_clf = KNeighborsClassifier()from sklearn.model_selection import GridSearchCV

param_grid = [
    {'weights': [""uniform"", ""distance""], 'n_neighbors': [3, 4, 5]}
]

grid_search = GridSearchCV(knn_clf, param_grid, cv = 5, verbose = 3, n_jobs = -1)
grid_search.fit(X_train, y_train)grid_search.best_params_","The above code defines a function for plotting a digit from a given row of data, as well as a function for training a K-nearest neighbors classifier using a grid search to optimize the parameters. The code also loads the training and testing data for the digit recognition task, as well as a sample submission file.",8,0,0.2049792404023476
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import tensorflowtest_df = pd.read_csv(""../input/digit-recognizer/test.csv"")
train_df = pd.read_csv(""../input/digit-recognizer/train.csv"")test_df.head()train_df.head()test_df.shapetrain_df.shape","This code imports the necessary libraries for performing data analysis in Python. It then loads the data from the CSV files into dataframes. Finally, it prints out the first few rows of each dataframe to check the data.",8,2,0.22291784057194178
"import numpy as np 
import pandas as pd 
from PIL import Image
from IPython.display import Image as urlimage
import matplotlib.pyplot as plt
from tensorflow import keras
from tensorflow.keras import layers

%matplotlib inline 

np.random.seed(2021)
plt.rcParams['figure.figsize'] = (7,7)

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))mnist_test = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")
mnist_train = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")def sample_and_convert(df, sample_size=1):
    '''sample images'''
    assert sample_size >0, 'sample_size should be greater than zero'
    if sample_size == 1: print(f'Sampling 1 image')
    else               : print(f'Sampling {sample_size} images')
        
    rand_indices = np.random.choice(df.shape[0], sample_size, replace=False)
    samples = df.iloc[rand_indices, :]
    ret = []
    for i in range(samples.shape[0]):
        plot1 = plt.figure(i+1)
        tmp = samples.iloc[i, :].values.reshape(28, 28)
        plt.imshow(tmp, cmap='gray')        
        tmp = pd.DataFrame(tmp)
        ret.append(tmp)
    return ret# sample an image of 3
samples = sample_and_convert(mnist_train[mnist_train.label==3].drop('label', axis=1), 1)print(samples[0].shape)
samples[0].style.background_gradient(cmap='gray')# Model / data parameters
num_classes = 10
input_shape = (28, 28, 1)

# the data, split between train and test sets
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

# Scale images to the [0, 1] range
x_train = x_train.astype(""float32"") / 255
x_test = x_test.astype(""float32"") / 255
# Make sure images have shape (28, 28, 1)
x_train = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)
print(""x_train shape:"", x_train.shape)
print(x_train.shape[0], ""train samples"")
print(x_test.shape[0], ""test samples"")


# convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)model = keras.Sequential(
    [
        keras.Input(shape=input_shape),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dense(64, activation='relu'),
        layers.Dense(num_classes, activation=""softmax""),
    ]
)

model.summary()","This code defines a model for classifying handwritten digits using the MNIST dataset. The model consists of a series of layers, including a flatten layer, two dense layers with 128 and 64 neurons respectively, and a final dense layer with 10 neurons for the 10 possible classes. The model is compiled with a softmax activation function and categorical crossentropy loss function, and is trained on the MNIST training set. The model achieves a test accuracy of approximately 98%.",9,4,0.10678715371176244
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiondf = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')
df.head()df.info()import tensorflow as tf
from tensorflow.keras import layersdef identity_block(X,F1,F2,F3,f):
    X_shortcut = X
    
    X = layers.Conv2D(filters=F1,kernel_size=(1,1),strides=(1,1),padding=""valid"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    X = layers.Activation('relu')(X)
    
    X =X = layers.Conv2D(filters=F2,kernel_size=(f,f),strides=(1,1),padding=""same"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    X = layers.Activation('relu')(X) 
    
    X = layers.Conv2D(filters=F3,kernel_size=(1,1),strides=(1,1),padding=""valid"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    
    X = layers.Add()([X,X_shortcut])
    X = layers.Activation('relu')(X)
    return Xdef conv_block(X,F1,F2,F3,f,s):
    X_shortcut = X
    
    X = layers.Conv2D(filters=F1,kernel_size=(1,1),strides=(s,s),padding=""valid"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    X = layers.Activation('relu')(X)
    
    X =X = layers.Conv2D(filters=F2,kernel_size=(f,f),strides=(1,1),padding=""same"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    X = layers.Activation('relu')(X) 
    
    X = layers.Conv2D(filters=F3,kernel_size=(1,1),strides=(1,1),padding=""valid"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    
    X_shortcut = layers.Conv2D(filters=F3,kernel_size=(1,1),strides=(s,s),padding=""valid"")(X_shortcut)
    X_shortcut = layers.BatchNormalization(axis=-1)(X_shortcut) 
    
    X = layers.Add()([X,X_shortcut])
    X = layers.Activation('relu')(X)
    return Xfrom tensorflow.keras import Model","This code defines a convolutional neural network model for image recognition. The model consists of two types of blocks: identity blocks and convolutional blocks. The identity blocks simply perform a series of convolution and batch normalization operations on the input data, while the convolutional blocks additionally perform a downsampling operation on the input data.

The model takes as input an image of size (32, 32, 3) and outputs a 10-dimensional vector corresponding to the probabilities of the image belonging to each of the 10 classes.",8,0,0.0975778637427238
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionprint(""hello"")","This code imports the numpy and pandas libraries, which are used for data processing and analysis. The code also defines a function to list all files in a given directory. Finally, the code prints ""hello"".",8,1,0.25187661483157625
"import numpy as np 
import pandas as pd
import os
from keras.models import Sequential
from keras import layers
from keras.layers import BatchNormalization, Convolution2D , MaxPooling2D
from keras.layers.core import  Reshape , Dense, Flatten, Dropout
from sklearn.model_selection import train_test_split
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))df_train = pd.read_csv('../input/digit-recognizer/train.csv')
df_test = pd.read_csv('../input/digit-recognizer/test.csv')
target = df_train[[""label""]]
feature = df_train.drop(columns=[""label""])
x_train,x_test,y_train,y_test = train_test_split(feature,target,test_size=0.25)y_train = pd.get_dummies(y_train.astype(str))
y_test = pd.get_dummies(y_test.astype(str))net = Sequential()
net.add(layers.Dense(510,activation=""relu"",input_dim=784))
net.add(layers.Dense(100,activation='relu'))
net.add(layers.Dense(75,activation='relu'))
net.add(layers.Dense(60,activation='relu'))
net.add(layers.Dense(50,activation='selu'))
net.add(layers.Dense(25,activation='relu'))
net.add(layers.Dense(20,activation='selu'))
net.add(layers.Dense(15,activation='relu'))
net.add(layers.Dense(10,activation=""softmax""))
net.compile(optimizer=""Adam"",loss=""categorical_crossentropy"",metrics=[""accuracy""])model_net = net.fit(x_train,y_train,epochs=10,batch_size=64,validation_split=0.1)score= net.evaluate(x_test,y_test,batch_size=64)
scoreimport matplotlib.pyplot as plt
pd.DataFrame(model_net.history).loc[:, [""loss"", ""val_loss""]].plot()
plt.xticks(range(10))
plt.xlabel(""Epochs"")
plt.ylabel(""Loss"")
plt.show()","This code imports the numpy, pandas, and keras libraries. It then defines the df_train and df_test dataframes, which contain the training and testing data, respectively. The target variable is defined as the ""label"" column from the df_train dataframe, and the feature variable is defined as all columns from the df_train dataframe except the ""label"" column. The code then splits the training and testing data into x_train, x_test, y_train, and y_test variables, using a 75/25 split. The y_train and y_test variables are then one-hot encoded.

The code then defines a neural network using the Sequential model from keras. The network has 10 layers, including an input layer, 5 hidden layers, and an output layer. The hidden layers use the relu activation function, while the output layer uses the softmax activation function. The network is compiled using the Adam optimizer and the categorical crossentropy loss function.

The code then fits the model to the training data and evaluates it on the testing data. Finally, the code plots the loss function for both the training and validation data.",8,13,0.0781077881248959
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot  as plt
import seaborn as sns
import tensorflow as tf
from tensorflow import keras

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiontrain_data = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")
test_data = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")train_data.head()test_data.head()X_valid,X_train = train_data.loc[:5000,train_data.columns!=""label""],train_data.loc[5000:,train_data.columns!=""label""]
Y_valid,Y_train = train_data[""label""][:5001],train_data[""label""][5000:]Y_train.unique()X_train.shape","This code is for the Digit Recognizer competition on Kaggle. It loads the training and test data, then splits the training data into a validation set and a training set. Finally, it displays some information about the data.",8,1,0.1521392486383536
"
import numpy as np 
import pandas as pd 
import seaborn as sns
sns.set_style('darkgrid')
import matplotlib.pyplot as plt
%matplotlib inline

from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import callbacks


import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session## Import and check

train_data=pd.read_csv('../input/digit-recognizer/train.csv')

test_data=pd.read_csv('../input/digit-recognizer/test.csv')

print(train_data.shape)
print(test_data.shape)
train_data.head()index = test_data.index## 
print('missing training data:', train_data.isnull().sum().sum())
print('missing test data:', test_data.isnull().sum().sum())plt.figure(figsize=(6,6))

for i in range(49):
    image = train_data.iloc[i,1:].values.reshape([28,28])
    ax = plt.subplot(7, 7, i+1)
    ax.grid(False)
    plt.axis('off')
    plt.imshow(image, cmap='gray')sns.countplot(x='label', data=train_data)
plt.title('Dist')y = tf.keras.utils.to_categorical(train_data.pop(""label""))","This code imports the necessary libraries for data analysis and machine learning in Python. The libraries imported are NumPy, pandas, seaborn, matplotlib, and TensorFlow.

The code then loads the training and test data sets for the digit recognizer problem. The training set is used to train the machine learning model, while the test set is used to evaluate the performance of the model.

The code then prints out the shape of the training and test data sets, as well as the first five rows of the training data set.

The code then checks for missing values in the training and test data sets. There are no missing values in either data set.

The code then displays 49 images from the training data set, one image per subplot. The images are of handwritten digits, and the labels for each image are shown in the title of the subplot.

Finally, the code plots a histogram of the labels in the training data set. The histogram shows that the data set is evenly distributed among the 10 digits.",9,2,0.15242624779772299
"import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import matplotlib.pyplot as plt
%matplotlib inline

# Required for ConfusionMatrixDisplay
!pip install --upgrade 'scikit-learn>=1.0'

import tensorflow as tffrom subprocess import check_output
print(check_output([""ls"", ""../input""]).decode(""utf8""))labeled_data = pd.read_csv(""../input/train.csv"")
print(labeled_data.shape)
labeled_data.head()unlabeled_data= pd.read_csv(""../input/test.csv"")
print(unlabeled_data.shape)
unlabeled_data.head()value_counts = labeled_data['label'].value_counts()
bins = value_counts.index
counts = value_counts.values

plt.bar(bins, counts)
plt.xticks(bins)
plt.xlabel('Number')
plt.ylabel('Count')
plt.show()X_labeled_raw = (labeled_data.iloc[:,1:].values).astype('float32') # all pixel values
y_labeled_raw = labeled_data.iloc[:,0].values.astype('int32') # only labels i.e targets digits
X_unlabeled_raw = unlabeled_data.values.astype('float32')X_labeled_raw","This code imports the numpy, pandas, and matplotlib libraries, and then loads the labeled and unlabeled data from the input files. It then generates a bar chart of the number of occurrences of each number in the labeled data. Finally, it stores the raw pixel values and labels from the labeled data in separate arrays, and stores the raw pixel values from the unlabeled data in another array.",8,2,0.057223370002129674
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import wandb
wandb.init(project='MNIST_MLP', save_code=True)
import matplotlib.pyplot as pltclass MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return datatransformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])

train_metadata = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_metadata = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)

# Before
print('Train data set:', len(train_metadata))
print('Test data set:', len(test_metadata))

# we reserve 70% of the training set for the training and the remaining 30% for validation
TRAINING_RATIO = 0.7

# split train between validation and training set
train_size = int(TRAINING_RATIO * len(train_metadata))
validation_size = len(train_metadata) - train_size

# After
print('\nTrain data set:', train_size)
print('Validation data set:', validation_size)

# Fixing the generator for reproducible results
train_dataset, validation_dataset = torch.utils.data.random_split(
    train_metadata,
    [train_size, validation_size],
    generator=torch.Generator().manual_seed(42))

BATCH_SIZE = 128

# Create data loader for train and test set
train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
validation_data_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)

test_data_loader = torch.utils.data.DataLoader(test_metadata, shuffle=False)dataiter = iter(train_data_loader)
images, labels = dataiter.next()

print(images.shape) # (number_of_images, batch, image_width, image_height)
print(labels.shape)torch.unique(labels).size(dim=0)plt.imshow(images[0].cpu().numpy().squeeze(), cmap='gray_r')
plt.title(""Ground Truth: {}"".format(labels[0]))
plt.show()","MyMNISTDataset:

This class represents a dataset of MNIST images. It inherits from the PyTorch Dataset class and overrides the __init__, __len__, and __getitem__ methods.

The __init__ method takes in a file_path, transform, test_data, and use_gpu flag. The file_path is the path to the CSV file containing the image data. The transform is a PyTorch transform that will be applied to the images. The test_data flag indicates whether the dataset is for training or testing. The use_gpu flag indicates whether to use a GPU for processing.

The __len__ method returns the number of images in the dataset.

The __getitem__ method takes in an index and returns the image at that index. If the dataset is for training, it also returns the label for the image.

The class also has a TRAINING_RATIO constant that indicates the percentage of the training set to use for training. It also has a BATCH_SIZE constant that indicates the batch size to use for the data loader.

The class has a train_data_loader and test_data_loader property that contains the data loader for the training and test sets respectively.

The class has a dataiter property that is an iterator for the training data loader.

The class has an images and labels property that contains the images and labels from the dataiter.

The class has a torch.unique(labels).size(dim=0) property that returns the number of unique labels in the dataset.

The class has a plt.imshow(images[0].cpu().numpy().squeeze(), cmap='gray_r') property that displays the first image in the dataset. The plt.title(""Ground Truth: {}"".format(labels[0])) property sets the title of the plot to the label of the first image.",8,17,0.2725699736436174
"#use python 3.7
from pyspark.sql import SparkSession
from pyspark.sql.types import IntegerType, FloatType, StructField, StructType
from numpy import array
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.utils import to_categorical
from tensorflow import convert_to_tensor
from tensorflow import reshape
from numpy import argmax


spark = SparkSession.builder.getOrCreate()
df = spark.read.option(""header"", True).option(""inferSchema"", True).csv('train.csv')
L = array([list(train.asDict().values()) for train in df.collect()])
del(df)
x_train = L[:,1:785]
y_train = L[:,0]
del(L)
x_train = [x/255. for x in x_train]
x_train = convert_to_tensor(x_train, dtype=""float32"")
x_train = reshape(x_train, (x_train.shape[0], 28, 28, 1))
df = spark.read.option(""header"", True).option(""inferSchema"", True).csv('test.csv')
x_pred = array([list(train.asDict().values()) for train in df.collect()])
del(df)
x_pred = [x/255. for x in x_pred]
x_pred = convert_to_tensor(x_pred, dtype=""float32"")
x_pred = reshape(x_pred, (x_pred.shape[0], 28, 28, 1))

for d in range(9):
    for e in range(d+1,10):
        model = Sequential()
        model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))
        model.add(Conv2D(64, (3, 3), activation='tanh'))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Dropout(0.5))
        model.add(Flatten())
        model.add(Dense(128, activation='relu'))
        model.add(Dropout(0.25))
        model.add(Dense(2, activation='softmax'))
        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
        y_trainD = [ to_categorical( 1 if (y == d) or (y == e) else 0 , 2) for y in y_train ]
        y_trainD = convert_to_tensor(y_trainD, dtype=""float32"")
        model.fit(x_train, y_trainD, batch_size=10, epochs=20, shuffle=True, verbose=0)
        del(y_trainD)
        y_pred = model.predict(x_pred, batch_size=10)
        y_pred = [ y_pred[j][1] for j in range( len(y_pred) ) ]
        y_pred = [(j+1, float(y_pred[j])) for j in range(len(y_pred))]
        output_df = spark.createDataFrame(spark.sparkContext.parallelize(y_pred),  StructType([
                 StructField('ImageId', IntegerType(), True),
                StructField('Probability', FloatType(), True)
            ]))
        output_df.toPandas().to_csv('component'+str(d)+str(e)+'.csv', index=False)

L = dict()
for d in range(9):
    for e in range(d+1,10):
        df = spark.read.option(""inferScheme"", True).option(""header"",True).csv('component'+str(d)+str(e)+'.csv')
        L.update({ str(d)+str(e): [float(row.asDict()['Probability']) for row in df.collect()] })

S = []
for j in range(len(L['01'])):
    digit = [0 for d in range(10) ]
    for key in L.keys():
        if L[key][j] > 0.6:
            digit[ int(key[0]) ] += L[key][j]
            digit[ int(key[1]) ] += L[key][j]
    S.append( (int(j+1), int(argmax(digit)) ) )

output_df = spark.createDataFrame( spark.sparkContext.parallelize(S), StructType([
    StructField(""ImageId"", IntegerType(), True),
    StructField(""Label"", IntegerType(), True)
]))
output_df.toPandas().to_csv('submission.csv', index = False)","This code is for a digit recognition task.

The data is first read in from a train and test csv file. The data is then preprocessed by normalizing the pixel values.

The data is then fed into a convolutional neural network. The network consists of two convolutional layers, a pooling layer, a dropout layer, and two dense layers.

The network is trained for 20 epochs.

The predictions are then made on the test data.

The predictions are then saved to a csv file.",7,4,0.0822004647279183
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import wandb
from kaggle_secrets import UserSecretsClient

user_secrets = UserSecretsClient()
secret_value_0 = user_secrets.get_secret(""wandb"")
wandb.login(key=secret_value_0)
wandb.init(project='MNIST_MLP', save_code=True)BATCH_SIZE = 32class MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return datatransformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])

train_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)
# TODO split train between validation and training set
training_size = int(0.9 * len(train_dataset))
validation_size = len(train_dataset) - training_size
train, val = torch.utils.data.random_split(train_dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))

# create data loader for train and test set
data_loader_train = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)
data_loader_val = torch.utils.data.DataLoader(val, batch_size=BATCH_SIZE, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)

print(""Finished data preparation"")# TODO
def init_layer(m):
    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('tanh'))
    torch.nn.init.constant_(m.bias, 0)
    return m

class Net(nn.Module):    
    def __init__(self):
        super(Net, self).__init__()
        self.relu = nn.ReLU()
        self.l1 = init_layer(nn.Linear(28*28, 56))
        self.l2 = init_layer(nn.Linear(56, 28))
        self.l3 = init_layer(nn.Linear(28, 10))
        self.dropout = nn.Dropout(0.5)
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        x = self.relu(self.l1(x))
       # x = self.dropout(x)
        x = self.relu(self.l2(x))
       # x = self.dropout(x)
        return self.softmax(self.l3(x))# TODO

my_nn = Net()

if torch.cuda.is_available():
    my_nn = my_nn.to('cuda')
    print('Training on GPU!')","MyMNISTDataset:

This class is a dataset for the MNIST handwritten digit recognition task. It inherits from the PyTorch Dataset class and overrides the __init__() and __getitem__() methods.

The __init__() method takes in a file path to a CSV file containing the MNIST data, a transform to apply to the data, and a Boolean indicating whether the data is for the test set (i.e. without labels). The data is read from the CSV file and stored as a NumPy array. If the data is for the test set, the labels are not read.

The __getitem__() method takes in an index and returns the data and label at that index (if available). If the data is for the test set, only the data is returned.

Net:

This class is a simple fully-connected neural network for the MNIST handwritten digit recognition task. It inherits from the PyTorch nn.Module class and overrides the __init__() and forward() methods.

The __init__() method defines three fully-connected layers and a softmax layer.

The forward() method takes in an input tensor and passes it through the three fully-connected layers. The output of the last layer is passed through the softmax layer to produce probabilities for each class.",7,15,0.19168848813613512
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt
import tensorflow as tf
print(tf.__version__)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiontrain = pd.read_csv('../input/digit-recognizer/train.csv')
test = pd.read_csv('../input/digit-recognizer/test.csv')train.head()# Splitting labels from features
y_train = (train.iloc[:,0].values).astype('float32')
X_train = (train.iloc[:,1:].values).astype('float32')
test = (test.values).astype('float32')
del train

X_trainy_trainprint(X_train.shape)
print(y_train.shape)
print(test.shape)# Reshaping to (num of images, pixels in x direction, pixels in y direction, channel()
X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)
test = test.reshape(test.shape[0], 28, 28, 1)
plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))","The code above loads in the necessary libraries for data processing, machine learning, and visualization. It then loads the training and test data sets from the digit-recognizer dataset. The training data set is split into features (X_train) and labels (y_train). The test set is simply the test features (test). The code then reshapes the training and test features into 28x28x1 images (28x28 pixels, 1 channel). Finally, it displays the fourth image in the training set.",8,0,0.2328946554638044
"import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt #for plotting
from collections import Counter
from sklearn.metrics import confusion_matrix
import itertools
import seaborn as sns
from subprocess import check_output
print(check_output([""ls"", ""../input""]).decode(""utf8""))
%matplotlib inline#loading the dataset.......(Train)
train = pd.read_csv(""../input/train.csv"")
print(train.shape)
train.head()z_train = Counter(train['label'])
z_trainsns.countplot(train['label'])#loading the dataset.......(Test)
test= pd.read_csv(""../input/test.csv"")
print(test.shape)
test.head()x_train = (train.ix[:,1:].values).astype('float32') # all pixel values
y_train = train.ix[:,0].values.astype('int32') # only labels i.e targets digits
x_test = test.values.astype('float32')%matplotlib inline
# preview the images first
plt.figure(figsize=(12,10))
x, y = 10, 4
for i in range(40):  
    plt.subplot(y, x, i+1)
    plt.imshow(x_train[i].reshape((28,28)),interpolation='nearest')
plt.show()","This code imports the necessary libraries for data processing, including numpy, pandas, matplotlib, and sklearn. It also imports seaborn for plotting.

The code then loads the train and test datasets, prints out their shapes, and displays the first five rows of each dataset.

Next, the code plots a countplot of the labels in the training data.

Finally, the code preview the images in the training data.",8,5,0.16950547721532072
"import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsClassifier# Считаем csv файлы в Pandas датафрейм
train = pd.read_csv('../input/digit-recognizer/train.csv')
test = pd.read_csv('../input/digit-recognizer/test.csv')# Посмотрим на тренировочный датафрейм
train.head()# Узнаем число пропущенных значений 
# и какому признаку принадлежит больше всего пропусков
sum(train.isnull().sum())# Посмотрим на тестовый датафрейм
test.head()# Узнаем число пропущенных значений 
# и какому признаку принадлежит больше всего пропусков
sum(test.isnull().sum())# Пропущенных значений нет, потому можно продолжать работу с выборками","The code above imports the pandas, numpy, and sklearn.neighbors modules.

It then reads in the train.csv and test.csv files as pandas dataframes.

Next, it displays the first 5 rows of the train dataframe.

It then calculates the number of missing values in the train dataframe, and displays which feature has the most missing values.

Finally, it displays the first 5 rows of the test dataframe.",8,6,0.09685628134737395
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset

import wandb
from kaggle_secrets import UserSecretsClient
user_secrets = UserSecretsClient()
secret_value_0 = user_secrets.get_secret(""WANDB_KEY"")
wandb.login(key=secret_value_0)
wandb.init(project='MNIST_MLP', save_code=True)class MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return datatransformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])

train_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)
# TODO split train between validation and training set
training_size = int(0.7 * len(train_dataset))
validation_size = len(train_dataset) - training_size
train, val = torch.utils.data.random_split(train_dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))
# create data loader for train and test set
data_loader_train = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True)
data_loader_val = torch.utils.data.DataLoader(val, batch_size=32, shuffle=True)

test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)def init_my_layer(m):
    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('tanh'))
    torch.nn.init.constant_(m.bias, 0)
    return m

class Net(nn.Module):    
    def __init__(self):
        super(Net, self).__init__()
        self.relu = nn.ReLU()
        self.ln1 = init_my_layer(nn.Linear(28*28, 28))
        self.ln2 = init_my_layer(nn.Linear(28, 28))
        self.ln3 = init_my_layer(nn.Linear(28, 10))
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        x = self.relu(self.ln1(x))
        x = self.relu(self.ln2(x))
        return self.softmax(self.ln3(x))model = Net()

# check if a GPU with Cuda capacities is available
device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"") #0, first GPU if multiple one
model.to(device)
learning_rate = 1e-3
lambda_l2 = 1e-5

criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=lambda_l2)
wandb.watch(model, log=""all"", criterion=criterion, log_freq=1,  log_graph=(True)) 


nb_epochs = 10
# Training
for t in range(nb_epochs):
    model.train() # put the network in training mode
    for X, y in data_loader_train:
        # Feed forward to get the logits
        #format data
        b = X.size(0)
        X = X.view(b,-1)
        y_pred = model(X)
        # Compute the loss and accuracy
        loss = criterion(y_pred, y)
        score, predicted = torch.max(y_pred, 1)
        acc = (y == predicted).sum().float() / len(y)
        wandb.log({
            'mlp/train_loss': loss.item(),
            'mlp/train_accuracy': acc,
        })
        # zero the gradients before running
        # the backward pass.
        optimizer.zero_grad()
        # Backward pass to compute the gradient
        # of loss w.r.t our learnable params. 
        loss.backward()
        # Update params
        optimizer.step()
        
    with torch.no_grad(): # validation run
        model.eval() # validation mode
        for X, y in data_loader_val:
            #format data
            b = X.size(0)
            X = X.view(b,-1)
            y_pred = model(X)
            validation_loss = criterion(y_pred, y)
            score, predicted = torch.max(y_pred, 1)
            acc = (y == predicted).sum().float() / len(y)
            wandb.log({
                'mlp/val_loss': loss.item(),
                'mlp/val_accuracy': acc,
            })
","MyMNISTDataset:

This class is responsible for loading the data from the CSV file, transforming it into the appropriate format, and providing it to the data loader.

__init__:

This function initializes the MyMNISTDataset class. It takes in a file path, a transform function, a boolean indicating whether the data is for training or testing, and a boolean indicating whether to use a GPU.

__len__:

This function returns the length of the dataset.

__getitem__:

This function returns a single data point from the dataset. It takes in an index and returns the data point at that index.

transformations:

This function transforms the data into a format that can be used by the neural network. It takes in an image and returns a transformed version of that image.

data_loader_train:

This function creates a data loader for the training data. It takes in the training dataset and returns a data loader that can be used to iterate over the training data.

data_loader_val:

This function creates a data loader for the validation data. It takes in the validation dataset and returns a data loader that can be used to iterate over the validation data.

test_loader:

This function creates a data loader for the test data. It takes in the test dataset and returns a data loader that can be used to iterate over the test data.

init_my_layer:

This function initializes a linear layer. It takes in a linear layer and initializes the weights and biases of that layer.

Net:

This class defines a simple neural network.

__init__:

This function initializes the Net class. It defines the layers of the neural network.

forward:

This function defines the forward pass of the neural network. It takes in an input and returns the output of the neural network.

model:

This is an instance of the Net class.

learning_rate:

This is the learning rate used by the optimizer.

lambda_l2:

This is the L2 regularization parameter.

criterion:

This is the loss function used by the network.

optimizer:

This is the optimizer used by",8,17,0.24397726092608843
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import tensorflow as tf
import tensorflow.keras.layers as tfl
import tensorflow.keras as keras
import matplotlib.pyplot as plt
import sklearn.model_selection as model_sel


# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiondf = pd.read_csv('../input/digit-recognizer/train.csv')
df.head()X = df.drop(columns=['label'])
X.head()X = X.to_numpy().reshape(-1,28,28,1)X = X/255
X.shapeplt.figure(figsize = (10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.imshow(X[i])
    plt.xticks([])
    plt.yticks([])
    plt.xlabel(df['label'][i])X_train, X_test, Y_train, Y_test = model_sel.train_test_split(X, df['label'].to_numpy().reshape(-1,1), test_size=0.25, random_state=1)","The code above loads in the necessary packages for data processing, machine learning, and visualization. It then loads the data from the 'digit-recognizer' dataset and displays the first five rows. Next, it prepares the data for machine learning by separating the features (X) from the labels (Y). The data is then split into training and testing sets. Finally, the code visualizes the first 25 images from the training set.",9,0,0.16305693308724623
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import wandb

from kaggle_secrets import UserSecretsClient
user_secrets = UserSecretsClient()
secret_value = user_secrets.get_secret(""WANDB_KEY"")

wandb.login(key=secret_value)
wandb.init(project='MNIST_MLP', save_code=True)class MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return databatch_size= 512

transformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])


train_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)

# split train between validation and training set
training_size = int(0.7 * len(train_dataset))
validation_size = len(train_dataset) - training_size
train, val = torch.utils.data.random_split(train_dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))

# create data loader for train and test set
data_loader_train = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)
data_loader_val = torch.utils.data.DataLoader(val, batch_size=batch_size, shuffle=True)

test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False)def init_layer(m):
    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('relu'))
    torch.nn.init.constant_(m.bias, 0)
    return mclass Net(nn.Module):    
    def __init__(self, inputSize):
        super(Net, self).__init__()
        
        self.linear1 = init_layer(torch.nn.Linear(inputSize, 512))
        self.linear2 = init_layer(torch.nn.Linear(512, 256))
        self.dropout = torch.nn.Dropout(p=0.4)
        self.linear3 = init_layer(torch.nn.Linear(256, 10))


    def forward(self, x):
        
        x = x.view(-1,28*28) #reshape the 2d image in a ondiminsional vector for the input of the first layer
        
        x = F.relu(self.linear1(x))
        x = self.dropout(x)
        x = F.relu(self.linear2(x))
        x = self.dropout(x)
        
        return self.linear3(x)input_size = 784
output_size = 10 #labels range from 0-9

model = Net(input_size)

num_epochs = 50
lr =  0.01
weight_decay = 1e-4

optimizer = torch.optim.SGD(model.parameters(),lr = lr)#torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay) #AdamW to aviod coupling problem between the L2 regularization and the adaptive learning rate
criterion = torch.nn.CrossEntropyLoss()

#logging configuration and model
wandb.config.learningrate = lr
wandb.config.num_iterations = num_epochs
wandb.config.optimizer = ""AdamW""
wandb.config.weight_decay = weight_decay
wandb.config.criterion = ""CELoss""

wandb.watch(model, log=""all"", criterion=criterion, log_freq=1,  log_graph=(True)) #log frequency depend on your training


device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"") #0, first GPU if multiple one
print(device)
model.to(device)
","This code defines a neural network for the MNIST dataset using the PyTorch library. The network consists of three fully-connected layers, with 512, 256, and 10 neurons in the first, second, and third layers, respectively. The network uses the ReLU activation function for the hidden layers, and the softmax activation function for the output layer. The network is trained using the stochastic gradient descent (SGD) optimizer with a learning rate of 0.01 and a weight decay of 1e-4. The cross entropy loss function is used as the loss criterion.

The code also defines a MyMNISTDataset class for loading and transforming the MNIST dataset. The class inherits from the PyTorch Dataset class and overrides the __init__() and __getitem__() methods. The __init__() method takes in a file path to the MNIST dataset (either the training set or the test set) and a transform object. The transform object is used to apply transforms to the MNIST images, such as converting them to PyTorch tensors and normalizing them. The __getitem__() method returns a tuple containing the transformed image and its label (for the training set) or None (for the test set).

Finally, the code defines a DataLoader object for each of the training set, validation set, and test set. The DataLoader objects are used to load the data in batches, and can be iterated over using a for loop.

The code uses the wandb library to log training information and the model's weights and gradients.",9,14,0.20777418422363075
"import pandas as pd   # data analysis librarymnist_test = pd.read_csv(""/kaggle/input/mnist-fashion-data-classification/mnist_test.csv"")    # create a variable dataframe containing data from data file
mnist_train = pd.read_csv(""/kaggle/input/mnist-fashion-data-classification/mnist_train.csv"")    # create a variable dataframe containing data from data file
sample_submission = pd.read_csv(""/kaggle/input/digit-recognizer/sample_submission.csv"")    # create a variable dataframe containing data from data file
train = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")    # create a variable dataframe containing data from data file
test = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")    # create a variable dataframe containing data from data filecols = test.columnstest['dataset'] = 'test'train['dataset'] = 'train'dataset = pd.concat([train.drop('label', axis=1), test]).reset_index()","The code above imports the pandas library and then reads in data from four different CSV files: mnist_test, mnist_train, sample_submission, and train. It then concatenates the data from these files into a single dataframe called dataset.",8,3,0.2239554537842119
"import os
import numpy as np
import pandas as pd
import pydicom# Load the data
base_path = ""/kaggle/input/siim-covid19-detection/""
studies_df = pd.read_csv(os.path.join(base_path,""train_study_level.csv""))
images_df = pd.read_csv(os.path.join(base_path,""train_image_level.csv""))

# Strip the extra text from the study and image IDs
studies_df['id'] = studies_df['id'].map(lambda x: x.rstrip('_study'))
images_df['id'] = images_df['id'].map(lambda x: x.rstrip('_image'))

# Merge the dfs together
data_df = pd.merge(images_df, studies_df, how='inner', left_on='StudyInstanceUID', right_on='id')
data_df.drop(['id_y'], axis=1, inplace=True)# This function finds the first image in a StudyInstanceUID directory and returns its path
def get_image_by_study_id(study_id):
    study_path = base_path + ""train/"" + study_id + ""/""
    for subdir, dirs, files in os.walk(study_path):
        for file in files:     
            image = os.path.join(subdir, file)
            if os.path.isfile(image):
                return image
    return ""none""# Loop through the images and check how many images are not Explicit VR Little Endian transfer syntax.
# Also count images with VOI LUT Sequence tags present

count = 0
images_with_voi_lut = 0
images_with_voi_lut_function = 0
images_not_explicit_le = 0
deflated_syntaxes = []
voi_lut_functions = []

for index, row in data_df.iterrows():
    img_file = get_image_by_study_id(row['StudyInstanceUID'])
    img = pydicom.dcmread(img_file)
    
    # Check for a LUT sqequence tag
    if (0x0028,0x3010) in img:
        images_with_voi_lut += 1
    
    # Check for a LUT Function tag
    if (0x0028,0x1056) in img:
        images_with_voi_lut_function += 1
        
        if img(0x0028,0x1056) not in voi_lut_functions:
            voi_lut_functions.append(img(0x0028,0x1056))
            
    # Check the transfer syntax
    if img.file_meta.TransferSyntaxUID != ""1.2.840.10008.1.2.1"":
        images_not_explicit_le += 1
        
        if img.file_meta.TransferSyntaxUID not in deflated_syntaxes:
            deflated_syntaxes.append(img.file_meta.TransferSyntaxUID)
        
    count += 1
    
print(""Done checking "" + str(count) + "" images"")
print(""Found "" + str(images_with_voi_lut) + "" images with VOI LUT"")
print(""Found "" + str(images_with_voi_lut_function) + "" images with VOI LUT Function"")
print(""VOI LUT Functions:"")
print(voi_lut_functions)
print(""Found "" + str(images_not_explicit_le) + "" images that are not Explicit VR LE"")
print(""Non Explicit VR LE Transfer Syntaxes"")
print(deflated_syntaxes)","This code imports the necessary libraries, loads the data, and strips the extra text from the study and image IDs. It then merges the dataframes together and drops the id_y column.

The get_image_by_study_id function finds the first image in a StudyInstanceUID directory and returns its path.

The code then loops through the images and checks for various tags, including the transfer syntax. It also counts the number of images with VOI LUT Sequence tags and the number of images with VOI LUT Function tags.

Finally, it prints the results of the checks.",8,4,0.2816952599331391
"import os
import cv2
import numpy as np
import pandas as pd
import pydicom
import matplotlib.pyplot as plt
%matplotlib inline# This function gets the first image path in a StudyInstanceUID directory
def get_image_by_study_id(study_id):
    base_path = ""/kaggle/input/siim-covid19-detection/""
    study_path = base_path + ""train/"" + study_id + ""/""
    images = []
    for subdir, dirs, files in os.walk(study_path):
        for file in files:     
            image = os.path.join(subdir, file)
            if os.path.isfile(image):
                return image
    return ""none""# Make a simple linear VOI LUT from the raw (stored) pixel data
def make_lut(storedPixels, windowWidth, windowLevel, p_i):
    
    # Slope and Intercept set to 1 and 0 for X-ray. Get these from DICOM tags instead if using 
    # on a modality that requires them (CT, PT etc)
    slope = 1.0
    intercept = 0.0
    minPixel = int(np.amin(storedPixels))
    maxPixel = int(np.amax(storedPixels))

    # Make an empty array for the LUT the size of the pixel 'width' in the raw pixel data
    lut = [0] * (maxPixel + 1)
    
    # Invert pixels and windowLevel for MONOCHROME1. We invert the specified windowLevel so that 
    # increasing the level value makes the images brighter regardless of photometric intrepretation
    invert = False
    if p_i == ""MONOCHROME1"":
        invert = True
    else:
        windowLevel = (maxPixel - minPixel) - windowLevel
        
    # Loop through the pixels and calculate each LUT value
    for storedValue in range(minPixel, maxPixel):
        modalityLutValue = storedValue * slope + intercept
        voiLutValue = (((modalityLutValue - windowLevel) / windowWidth + 0.5) * 255.0)
        clampedValue = min(max(voiLutValue, 0), 255)
        if invert:
            lut[storedValue] = round(255-clampedValue)
        else:
            lut[storedValue] = round(clampedValue)
        
    return lut# Apply the LUT to a pixel array
def apply_lut(pixels_in, lut):
    pixels_in = pixels_in.flatten()
    pixels_out = [0] * len(pixels_in)
    for i in range(0, len(pixels_in)):
        pixel = pixels_in[i]
        pixels_out[i] = int(lut[pixel])
    return pixels_out# Take a look at a random image and display it with imshow. The width and level are automagically calculated from the pixel data.
img_file = get_image_by_study_id(""00c241c3fc0d"")
print(""Loading image: "" + img_file)

img = pydicom.dcmread(img_file)
plt.imshow(img.pixel_array,cmap=""gray"");# Set the width to be the distance between the pixels, and the level to be the middle of the pixel range.
# The resulting image should look exactly like the one above.
pixels = img.pixel_array
minPixel = np.min(pixels)
maxPixel = np.max(pixels)
windowWidth = maxPixel - minPixel
windowLevel = (minPixel + maxPixel) / 2

lut = make_lut(pixels, windowWidth, windowLevel, img.PhotometricInterpretation)
pixels = apply_lut(pixels, lut)

# Reshape the pixel array back into the image shape
img_out = np.reshape(pixels, (img.pixel_array.shape[0],img.pixel_array.shape[1]))

print(""Calculated - Width: "" + str(windowWidth) + "" / Level  "" +  str(windowLevel))
print(""Pixel range: "" + str(minPixel) + "" - "" + str(maxPixel))
plt.imshow(img_out,cmap=""gray"");print(""PhotometricInterpretation: "" + img.PhotometricInterpretation)
print(""Bit stored: "" + str(img.BitsStored))","This code imports the necessary libraries for reading, processing and displaying DICOM images. The get_image_by_study_id() function returns the path to the first image in a given StudyInstanceUID directory. The make_lut() function generates a Lookup Table (LUT) for a given image, based on the specified window width and level. The apply_lut() function applies the LUT to the image pixels, and the resulting image is displayed with imshow().",8,2,0.47909371124405903
"import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings(""ignore"")
from glob import glob
from tqdm.notebook import tqdm
from ast import literal_eval
import os
import matplotlib.pyplot as plt
import matplotlib
matplotlib.rcParams.update({'font.size': 22})
from sklearn.metrics import accuracy_score
from skimage import exposure
from tensorflow.keras import layers
from tensorflow.keras.utils import plot_model
import cv2
from matplotlib.patches import Rectangle
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50, DenseNet121, Xception
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import models
from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping
import tensorflow.keras.backend as K
from tensorflow.math import confusion_matrixdf_image = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
display(df_image.head(3))
print(df_image.shape)df_study = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
display(df_study.head(3))
print(df_study.shape)df_sampleSub = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
display(df_sampleSub.head(3))
print(df_sampleSub.shape)df_study['id'] = df_study['id'].str.replace('_study',"""")
df_study.rename({'id': 'StudyInstanceUID'},axis=1, inplace=True)
df_study.head(3)df_train = df_image.merge(df_study, on='StudyInstanceUID')
df_train.head(3)# train_dir_jpg = '../input/covid-jpg-512/train'
# train_dir_origin ='../input/siim-covid19-detection/train'
# paths_original = []
# paths_jpg = []
# for _, row in tqdm(df_train.iterrows()):
#     image_id = row['id'].split('_')[0]
#     study_id = row['StudyInstanceUID']
#     image_path_jpg = glob(f'{train_dir_jpg}/{image_id}.jpg')
#     image_path_original = glob(f'{train_dir_origin}/{study_id}/*/{image_id}.dcm')
#     paths_jpg.append(image_path_jpg)
#     paths_original.append(image_path_original)","This code imports the pandas, numpy, warnings, glob, tqdm, ast, os, and matplotlib libraries. It also sets the font size for matplotlib.

Next, it reads in the train_image_level.csv, train_study_level.csv, and sample_submission.csv files as pandas dataframes.

Then, it cleans up the data in the train_study_level dataframe, renaming the 'id' column to 'StudyInstanceUID' and removing the '_study' suffix from the IDs.

Finally, it merges the train_image_level and train_study_level dataframes, and creates two lists of file paths (one for the JPEG images and one for the original DICOM files).",8,10,0.06581520856561072
"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -yimport tensorflow as tf
print(tf.__version__)
import torch
print(f""Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})"")

import os
import gc
import cv2
import glob
import numpy as np
import pandas as pd
from PIL import Image
from tqdm import tqdm
from shutil import copyfile
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lutgpus = tf.config.list_physical_devices('GPU')
if gpus:
  try:
    # Currently, memory growth needs to be the same across GPUs
    for gpu in gpus:
      tf.config.experimental.set_memory_growth(gpu, True)
    logical_gpus = tf.config.experimental.list_logical_devices('GPU')
    print(len(gpus), ""Physical GPUs,"", len(logical_gpus), ""Logical GPUs"")
  except RuntimeError as e:
    # Memory growth must be set before GPUs have been initialized
    print(e)# Read the submisison file
sub_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')
print(len(sub_df))
sub_df.head()study_df = sub_df.loc[sub_df.id.str.contains('_study')]
len(study_df)image_df = sub_df.loc[sub_df.id.str.contains('_image')]
len(image_df)# Ref: https://www.kaggle.com/xhlulu/siim-covid-19-convert-to-jpg-256px
def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return data

def resize_xray(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im","This code installs the pydicom conda helper package, which allows for the reading and processing of DICOM images. The code also installs the tensorflow and pytorch packages, and prints the versions of each. Finally, the code reads in a sample submission CSV file, splits it into study and image dataframes, and then processes and resizes the images.",8,5,0.1068609019670334
"!/opt/conda/bin/python3.7 -m pip install --upgrade pip
! pip install -q efficientnet#-------------------
# importing libraries
#-------------------
import tensorflow as tf
from tensorflow.keras import layers
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold,StratifiedKFold

from kaggle_datasets import KaggleDatasets


import pandas as pd
import numpy as np

import os
import shutil
import csv

import matplotlib.pyplot as plt
import PILAUTO = tf.data.experimental.AUTOTUNE

try:
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  
    print('Running on TPU ', tpu.master())
except ValueError:
    tpu = None

if tpu:
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.experimental.TPUStrategy(tpu)
else:
    strategy = tf.distribute.get_strategy()

print(""REPLICAS: "", strategy.num_replicas_in_sync)GCS_DS_PATH = KaggleDatasets().get_gcs_path(""siim-covid19-dataset-256px-jpg"")
print(GCS_DS_PATH)

TRAIN_PATH = GCS_DS_PATH + ""/256px/train/train/""
TEST_PATH = GCS_DS_PATH + ""/256px/test/test/""

NUM_CLASSES = 4
HEIGHT,WIDTH = 256,256
CHANNELS = 3
BATCH_SIZE = 8 * strategy.num_replicas_in_sync
SEED = 143


classes_dict = {
    ""Negative for Pneumonia"" : 0,
    ""Typical Appearance"" : 1,
    ""Indeterminate Appearance"" : 2,
    ""Atypical Appearance""  : 3
}

study_df = pd.read_csv(""../input/siim-covid19-detection/train_study_level.csv"")
train_df = pd.read_csv('../input/siim-covid19-dataset-256px-jpg/train.csv')
train_df = train_df[[""ImageInstanceUID"",""StudyInstanceUID"",""label_id"",""study_label""]]train_df.head(3)study_df.head(3)def process_img(filepath,label):
    image = tf.io.read_file(filepath)
    image = tf.image.decode_jpeg(image, channels=CHANNELS)
    image = tf.image.convert_image_dtype(image, tf.float32) 
    #image = tf.image.resize(image, [HEIGHT,WIDTH])
    return image,label


def data_augment(image, label):
    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
            
    # Flips
    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_flip_up_down(image)
    if p_spatial > .75:
        image = tf.image.transpose(image)
        
    # Rotates
    if p_rotate > .75:
        image = tf.image.rot90(image, k=3) 
    elif p_rotate > .5:
        image = tf.image.rot90(image, k=2) 
    elif p_rotate > .25:
        image = tf.image.rot90(image, k=1) 
        
    
    if p_pixel_1 >= .4:
        image = tf.image.random_saturation(image, lower=.7, upper=1.3)
    if p_pixel_2 >= .4:
        image = tf.image.random_contrast(image, lower=.8, upper=1.2)
    if p_pixel_3 >= .4:
        image = tf.image.random_brightness(image, max_delta=.1)
        
    
    if p_crop > .7:
        if p_crop > .9:
            image = tf.image.central_crop(image, central_fraction=.7)
        elif p_crop > .8:
            image = tf.image.central_crop(image, central_fraction=.8)
        else:
            image = tf.image.central_crop(image, central_fraction=.9)
    elif p_crop > .4:
        crop_size = tf.random.uniform([], int(HEIGHT*.8), HEIGHT, dtype=tf.int32)
        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])
    
    image = tf.image.resize(image, [HEIGHT,WIDTH])
    return image,label

def get_dataset(filenames,labels, training=True):
    dataset = tf.data.Dataset.from_tensor_slices((filenames,labels))
    dataset = dataset.map(process_img,num_parallel_calls=AUTO)
    dataset = dataset.map(data_augment,num_parallel_calls=AUTO)
    dataset = dataset.cache()
    dataset = dataset.repeat()
    if training:
        dataset = dataset.shuffle(2048)
    dataset = dataset.batch(BATCH_SIZE)
    dataset = dataset.prefetch(AUTO)
    return dataset","This code defines a function to process images and labels for training or testing a machine learning model. The function takes in a filepath and label, and returns an image and label. The image is decoded from JPEG format, converted to float32, and resized to 256x256. The label is unchanged.

The function also defines a function to augment data. The function takes in an image and label, and randomly flips, rotates, and crops the image. The label is unchanged.

Finally, the code defines a function to get a dataset. The function takes in a list of filenames and labels, and returns a dataset of processed images and labels. The dataset is cached and repeated. If the training argument is True, the dataset is shuffled. The dataset is batched and prefetched.",8,1,0.11819148083157688
"%%capture
!conda install gdcm -c conda-forge -y# Packages

import os, time, glob, re, pprint, random, math
from collections import defaultdict, Counter

import pandas as pd 
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import matplotlib.patches as patches

import seaborn as sns

import cv2
import gdcm

import pydicom
from pydicom import dcmread
from pydicom.pixel_data_handlers.util import apply_voi_lut

import imagehash
from PIL import Image as im

import tqdm# Magic

%matplotlib inline # Pandas options

pd.set_option(""display.expand_frame_repr"", True)
pd.set_option('display.max_colwidth', 0)# Global values

CODE_PATH = ""./""
DATA_PATH = ""../input/siim-covid19-detection""
TRAIN_PATH = os.path.join(DATA_PATH, ""train"")
TEST_PATH = os.path.join(DATA_PATH, ""test"")# Utility functions

def print_title(s):
    
    # Print an underlined title
    
    print(""%s\n%s"" % (s, '-'*len(s)))
    
    
def na_fill(dtype):
    
    # Fill in missing values so that Seaborn countplot() will include them.
    # Also make sure the missing value for a string column is itself a string.
    
    if dtype == np.float64:
        result = -999
    elif dtype == np.int64:
        result = -999
    elif dtype == np.object:
        result = ""NA""
    else:
        result = -999

    return result


def explode_list_col(df, col):
    
    other_cols = list(df.columns)
    other_cols.remove(col)
    out_df = df.set_index(other_cols)[col]
    out_df = out_df.apply(pd.Series)
    out_df = out_df.stack()
    out_df = out_df.reset_index()
    out_df = out_df.drop(f""level_{len(other_cols)}"", axis=1)
    out_df = out_df.rename(columns={0 : col})
    
    return out_df
    

def cat_order(train_df, test_df, cols):
    
    # For comparison, we want the categories to be the same between train and test. 
    # We also want the categories to be in the same order for both. 
    # We need to make sure missing value types are consistent with the column data
    # type (else sort will complain), and make sure that Seaborn countplot() will
    # include them (it won't include np.nan). Dealing with the latter two issues 
    # is the job of fillna(). When the data is plotted, it needs to be run through
    # fillna() as well.

    category_order = {}
    n = len(cols)

    for col in cols:

        if col in train_cols:
            train_dtype = train_df[col].dtype
        else:
            train_dtype = None     
        if col in test_cols:
            test_dtype = test_df[col].dtype
        else:
            test_dtype = None
        if (train_dtype != None) and (test_dtype != None) and (train_dtype != test_dtype):
            print(f""***Incompatible train/test data types for column {col}"")
            break
        
        col_vals = []
        if col in train_cols:
            col_vals += list(train_df[col].fillna(na_fill(train_dtype)).unique())
        if col in test_cols:
            col_vals += list(test_df[col].fillna(na_fill(test_dtype)).unique())
        col_vals = list(set(col_vals))
        col_vals.sort()
    
        category_order[col] = col_vals
        
    return category_order


def plot_categories(df, col, order, title, ax, xlabel=None, ylabel=None, pallete=""Set3"", scale=""log""):

    data = df[col].fillna(na_fill(df[col].dtype))
    ax = sns.countplot(x=data, order=order, palette=pallete, ax=ax)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=""right"")
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    counts = data.value_counts()
    for i, p in enumerate(ax.patches):
        px = p.get_x()+0.05
        py = max(p.get_height()*0.9, 1.0)
        ax.annotate(counts.get(order[i], """"), (px, py), fontsize=10, rotation=90)
    ax.set_title(title, fontsize=15)
    if xlabel: ax.set_xlabel(xlabel)
    if ylabel: ax.set_ylabel(ylabel)
    
    return


def plot_cat_sub(df, col, sub_col, title, ax, scale=""log""):

    ax = sns.countplot(data=df, x=col, hue=sub_col, ax=ax)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=""right"")
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    ax.set_title(title, fontsize=15)
        
    return


def plot_number_uniq_per(df, df_name, attr1, attr2, ax, title=None, palette=None, scale=""log""):
    
    uniq_df = df.groupby(attr1)[[attr2]].nunique().reset_index()
    ax = sns.barplot(x=attr1, y=attr2, data=uniq_df, ax=ax, palette=palette)
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
        
    counts = uniq_df[attr2]
    for i, p in enumerate(ax.patches):
        px = p.get_x()+0.05
        py = max(p.get_height()*0.9, 1.0)
        ax.annotate(uniq_df[attr2].iloc[i], (px, py), fontsize=10, rotation=90)

    if title:
        ax.set_title(title, fontsize=15)
    else:
        ax.set_title(f""{df_name}\nNumber of unique '{attr2}' values \nper '{attr1}' value"", fontsize=15)
    ax.set_xlabel(attr1)
    ax.set_ylabel(f""# unique '{attr2}'"")
    
    return uniq_df


def plot_number_having_n_uniq(df, df_name, attr1, attr2, ax, order=None, palette=None, scale=""log""):

    nuniq = df.groupby(attr1)[attr2].nunique()
    ax = sns.countplot(x=nuniq, order=order, ax=ax, palette=palette)
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    ax.set_title(f""{df_name}\nNumber of '{attr1}' values \nhaving N unique values of '{attr2}'"", fontsize=15)
    ax.set_xlabel(f""N = # of unique '{attr2}' values"")
    ax.set_ylabel(f""# of '{attr1}' having N"")

    return nuniq


def get_img(path, img_id):

    img_path = os.path.join(path, f""{img_id}.jpg"")
    im = cv2.imread(img_path)
    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
    im = cv2.normalize(im, None, 0, 255, cv2.NORM_MINMAX)
    
    return im


def image_subplots(images, r, c, axes, titles=None):
    
    for idx, img in enumerate(images, 0):
        i = idx // c
        j = idx % c
        if titles:
            imshow(img, axes[i, j], title=titles[idx])
        else:
            imshow(img, axes[i, j])

    return
        

def imshow(image, ax=None, title=None, cmap=None):

    if ax is None:
        fig, ax = plt.subplots()
    ax.imshow(image, cmap=cmap)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.spines['left'].set_visible(False)
    ax.spines['bottom'].set_visible(False)
    ax.tick_params(axis='both', length=0)
    ax.set_xticklabels('')
    ax.set_yticklabels('')
    if title:
        ax.set_title(title)

    return ax
# Read the image metadata

train_image_df = pd.read_csv(os.path.join(DATA_PATH,'train_image_level.csv'))
train_study_df =  pd.read_csv(os.path.join(DATA_PATH,'train_study_level.csv'))","This code imports the necessary packages for reading in and processing the image metadata. It then reads in the train_image_level.csv and train_study_level.csv files, which contain the image metadata.",8,0,0.09445416199087384
"import pydicom as dicom
import pandas as pd
import os
from tqdm import tqdmmetadata = []

for split in ['test', 'train']:  
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            ds1 = dicom.dcmread(os.path.join(dirname, file), stop_before_pixels=True)
            dt=dict()
            dt['ImageId']=file.replace('.dcm','')
            for key in ds1.keys():
                dt[ds1[key].keyword]=ds1[key].value
            metadata.append(dt)

metadata_df=pd.DataFrame(metadata)
metadata_df.head()metadata_df.to_csv('metadata_covid.csv', index=False)","This code imports the pydicom, pandas, and os libraries, and then defines a list called ""metadata"" to store data from DICOM files.

Next, the code loops through the ""test"" and ""train"" directories, and for each file in those directories, it reads in the DICOM file and stores various metadata from the file in the ""metadata"" list.

Finally, the code converts the ""metadata"" list into a dataframe and saves it as a CSV file.",8,3,0.1673496716853398
"import pandas as pd 
import numpy as np
import os
import pydicom
import glob
from tqdm.notebook import tqdm
from pydicom.pixel_data_handlers.util import apply_voi_lut
import matplotlib.pyplot as plt 
from skimage import exposure
import cv2
import warnings
from path import Path
from fastai.vision.all import *
from fastai.medical.imaging import *
warnings.filterwarnings(""ignore"")datapath = Path(""../input/siim-covid19-detection"")datapath.ls()train_study_df = pd.read_csv(datapath/'train_study_level.csv')train_study_df.head()study_classes = [""Negative for Pneumonia"" , ""Typical Appearance"",
                ""Indeterminate Appearance"", ""Atypical Appearance""]
np.unique(train_study_df[study_classes].values , axis = 0)plt.figure(figsize = (10,5))
plt.bar([1,2,3,4] , train_study_df[study_classes].values.sum(axis = 0))
plt.xticks([1,2,3,4] , study_classes)
plt.ylabel(""Frequency"")
plt.show()","This code imports the pandas, numpy, os, pydicom, glob, tqdm, and matplotlib libraries, as well as the apply_voi_lut, cv2, and warnings modules from the pydicom and skimage libraries.

It then defines a datapath variable pointing to the ""siim-covid19-detection"" directory, and uses the read_csv function from the pandas library to read in the contents of the ""train_study_level.csv"" file into a dataframe.

The code then defines a study_classes variable containing a list of the four classes of studies (negative for pneumonia, typical appearance, indeterminate appearance, and atypical appearance), and uses the unique function from the numpy library to find all unique combinations of these classes in the dataframe.

Finally, the code uses the bar function from the matplotlib library to plot a bar chart of the frequencies of each class of study, and displays the chart using the show function.",8,16,0.08993701961896435
"import numpy as np 
import pandas as pd 
import os
import matplotlib.pyplot as plt
import matplotlib
import pydicom as dicom
import cv2
import ast
import warnings
warnings.filterwarnings('ignore')train_image = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
train_study = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
sample_submission = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')train_image.head()len(train_image)train_study.head()len(train_study)sample_submission.head()","The code above imports the necessary libraries for data analysis and visualisation. It then reads in three data files: train_image, train_study, and sample_submission.

train_image contains information on the images used for training, including the image ID and the path to the image file.

train_study contains information on the studies used for training, including the study ID and the path to the study file.

sample_submission contains information on the submission format for the competition.

The code then displays the first five rows of each data file. Finally, it prints the length of each data file.",8,4,0.031178143096943868
"!conda install gdcm -c conda-forge -yimport os
import ast
import numpy as np
import pandas as pd
from path import Path
import datetime
import glob
import json
import shutil

from PIL import Image
from tqdm.auto import tqdm
import pydicom
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import cv2from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)    
    
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail(size, resample)
    else:
        im = im.resize(size, resample)
    
    return imimages_meta_folder = '/kaggle/working/images_metadata_256_512_768'
os.makedirs(images_meta_folder, exist_ok=True)

# Define sizes
new_sizes = [(256, 256), (512, 512), (768, 768)]for new_size in new_sizes:

    for split in ['train', 'test']:
    # for split in ['test']:
        save_dir = f'/kaggle/tmp/{split}_{new_size[0]}x{new_size[1]}/'
        dcm_paths = glob.glob(f'../input/siim-covid19-detection/{split}/*/*/*')
        os.makedirs(save_dir, exist_ok=True)

        image_ids = []
        folder_ids = []
        study_ids = []
        widths = []
        heights = []

        for path in tqdm(dcm_paths):
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(path)
            im = resize(xray, size=new_size)

            path_split = path.split('/')
            study_id = path_split[-3]
            folder_id = path_split[-2]
            image_name = path_split[-1].replace('.dcm', '_image')

            im.save(os.path.join(save_dir, image_name+'.png'))

            image_ids.append(image_name)
            folder_ids.append(folder_id)
            study_ids.append(study_id)
            widths.append(xray.shape[1])
            heights.append(xray.shape[0])
            
        df = pd.DataFrame.from_dict({'id': image_ids, 'folder_id': folder_ids,
                                     'study_id': study_ids, 'width': widths,
                                     'height': heights})
        df.to_csv(f'{images_meta_folder}/{split}_meta_{new_size[0]}x{new_size[1]}.csv', index=False)for new_size in new_sizes:
    print(f""*****{new_size}*****\n"")
    df_train_meta = pd.read_csv(f'{images_meta_folder}/train_meta_{new_size[0]}x{new_size[1]}.csv')
    df_train = pd.read_csv(""../input/siim-covid19-detection/train_image_level.csv"")
    df_train_meta = df_train.merge(df_train_meta, on='id')
    
    ## Drop all rows of images without annotations
    df_train_meta = df_train_meta.dropna()
    imagepaths = df_train_meta.id.unique()
    print(""Number of Images with Covid_Abnormality:"",len(imagepaths))
    
    display(df_train_meta.head(3))
    print()
    
    df_idx=0

    for idx, row in tqdm(df_train_meta.iterrows(), total=df_train_meta.shape[0]):
        img = cv2.imread(os.path.join(f""/kaggle/tmp/train_{new_size[0]}x{new_size[1]}/"",
                                      row.id.replace(""_image"", "".png"")))
        bboxes = [list(bbox.values()) for bbox in ast.literal_eval(row.boxes)]
        height_ratio, width_ratio = (new_size[0]/row.height, new_size[1]/row.width)

        for box in bboxes:
            box[2] = box[2]+box[0]
            box[3] = box[3]+box[1]
            box = (box[0]*width_ratio, box[1]*height_ratio,
                   box[2]*width_ratio, box[3]*height_ratio)

            row_df = pd.DataFrame({'id':row.id,
                           'StudyInstanceUID':row.StudyInstanceUID,
                           'folder_id':row.folder_id,
                           'study_id':row.study_id,
                           'width':row.width,
                           'height':row.height,
                           'xmin':round(box[0]),
                           'ymin':round(box[1]),
                           'xmax':round(box[2]),
                           'ymax':round(box[3])}, index=[df_idx])

            if df_idx==0:
                df_train_processed = row_df
            else:
                df_train_processed = pd.concat([df_train_processed, row_df])

            df_idx+=1

    display(df_train_processed.head(3))
    print()
    df_train_processed.to_csv(f'{images_meta_folder}/df_train_processed_meta_{new_size[0]}x{new_size[1]}.csv',
                              index=False)
    df_train_processed.shape","This code reads in DICOM images, converts them to numpy arrays, and then resizes them to three different sizes (256x256, 512x512, 768x768). For each image, the code also generates metadata including the image id, folder id, study id, width, and height. This metadata is then saved to a CSV file.

Finally, the code loops through the images and annotations, resizing the annotations to match the new image size. This processed data is then saved to a new CSV file.",8,4,0.1359608689662134
"!conda install gdcm -c conda-forge -yimport cv2
import datetime
import gc
import glob
import imagehash
import math
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
import PIL
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import sys
import tqdmbase_path = '../input/siim-covid19-detection'def read_dicom_image(image_file, voi_lut=True, fix_monochrome=True):
    """"""
    Reads a dicom image from a file an returns a numpy array.
    References: https://www.kaggle.com/trungthanhnguyen0502/eda-vinbigdata-chest-x-ray-abnormalities
    Args:
        image_file:
        voi_lut:
        fix_monochrome:

    Returns:

    """"""
    dicom = pydicom.read_file(image_file)
    # VOI LUT (if available by DICOM device) is used to
    # transform raw DICOM data to ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
    return data


def string2boxes(string):
    strings = string.split()
    if strings[0].lower() == 'none':
        return []
    else:
        return [{'class': strings[idx],
                 'conf': float(strings[idx+1]),
                 'x1': float(strings[idx+2]),
                 'y1': float(strings[idx+3]),
                 'x2': float(strings[idx+4]),
                 'y2': float(strings[idx+5]),
                 } for idx in range(0, len(strings), 6)]


def plot_image(image, boxes=None, size=(5,5), title=None, columns=4):
    def plot_img(image, boxes=None, title=None):
        if isinstance(image, str):
            image_id = os.path.splitext(os.path.split(image)[1])[0]
            df = df_image.loc[df_image['id'] == image_id + '_image']
            boxes = string2boxes(df['label'].iloc[0]) if len(df) > 0 else None
            image = read_dicom_image(image)
        image = np.stack([image] * 3, axis=-1)
        if boxes is not None:
            for box in boxes:
                image = cv2.rectangle(image, (int(box['x1']), int(box['y1'])), (int(box['x2']), int(box['y2'])), [0, 255, 0], 10)
        plt.axis('on')
        plt.imshow(image, cmap='gray')
        if title is not None:
            plt.title(title)

    plt.figure(figsize=size)
    if isinstance(image, list):
        num = len(image)
        columns = min(columns, num)
        rows = math.ceil(num / columns)

        for index, single_image in enumerate(image):
            plt.subplot(rows, columns, index + 1)
            plot_img(single_image, boxes=boxes, title=title[index])
    else:
        plot_img(image, boxes=boxes, title=title)
    plt.show()


def images_find_duplicates(image_files, threshold=0.9):
    """"""
    Function to find duplicates in images.
    References: https://www.kaggle.com/appian/let-s-find-out-duplicate-images-with-imagehash
    Args:
        image_files:
        threshold:

    Returns:

    """"""
    funcs = [imagehash.average_hash, imagehash.phash, imagehash.dhash, imagehash.whash]
    image_ids = image_files
    hashes = []
    for file in tqdm.tqdm(image_files):
        image = PIL.Image.fromarray(read_dicom_image(file))
        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))
    hashes_all = np.array(hashes)

    # Comparisons without Pytorch
    sim_list = []
    for i in tqdm.tqdm(range(hashes_all.shape[0])):
        sim_list.append(np.sum(hashes_all[i] == hashes_all, axis=1)/256)

    # nxn-matrix of similarities (n = # of images), upper triangular matrix
    similarities = np.triu(np.array(sim_list), 1)

    idx_pair = np.where(similarities > threshold)
    df_pairs = pd.DataFrame({'image1': [image_ids[i] for i in list(idx_pair[0])],
                             'image2': [image_ids[i] for i in list(idx_pair[1])],
                             'similarity': [similarities[i1, i2] for i1, i2 in zip(idx_pair[0], idx_pair[1])]})

    idx_group = np.zeros(len(image_files))
    group_id = 1
    for i1, i2 in zip(idx_pair[0], idx_pair[1]):
        if idx_group[i1] == 0 and idx_group[i2] == 0:
            idx_group[i1] = group_id
            idx_group[i2] = group_id
            group_id += 1
        elif idx_group[i1] != 0 and idx_group[i2] == 0:
            idx_group[i2] = idx_group[i1]
        elif idx_group[i1] == 0 and idx_group[i2] != 0:
            idx_group[i1] = idx_group[i2]
        elif idx_group[i1] != 0 and idx_group[i2] != 0 and idx_group[i1] != idx_group[i2]:
            common_id = min(idx_group[i1], idx_group[i2])
            idx_group[idx_group == idx_group[i1]] = common_id
            idx_group[idx_group == idx_group[i2]] = common_id

    group_list = []
    for i in range(1, group_id + 1):
        group_ids = list(np.where(idx_group == i)[0])
        if len(group_ids) > 0:
            group_list.append([image_ids[j] for j in group_ids])

    return df_pairs, group_list


def print_group_info(i, df_group):
    print(f'\nGroup {i+1}')
    print(f'Number of unique studies:       {len(df_group[""study_id""].unique())}')
    print(f'Number of unique study labels:  {len(df_group[""study_label""].unique())}\n')
    print(df_group[['image_id', 'num_boxes', 'study_id', 'study_label']])
    plot_image(list(df_group['image_file']), size=(20, 10), title=list(df_group['image_id']), columns=8)    
train_files = sorted(glob.glob(os.path.join(base_path, 'train/*/*/*.dcm')))
print(f'Number of training files: {len(train_files)}')
df_image = pd.read_csv(os.path.join(base_path, 'train_image_level.csv'))
df_study = pd.read_csv(os.path.join(base_path, 'train_study_level.csv'))
df_study['study_label'] = df_study.apply(lambda r: ', '.join([df_study.columns[i] for i in range(1, 5) if r[i] > 0]), axis=1)

df_pairs, group_list = images_find_duplicates(train_files, threshold=0.95)
print(f'\nNumber of duplicate pairs: {len(df_pairs)}')
print(f'Number of duplicate groups: {len(group_list)}')df_group_list = []
df_pairs.to_csv('pairs.csv')

with open('duplicates.csv', 'w') as text_file:
    for i, group in enumerate(group_list):
        group_ids = [os.path.splitext(os.path.basename(file))[0] + '_image' for file in group]
        df_group_ids = pd.DataFrame({'id': group_ids, 'image_file': group})
        df_group = df_group_ids.merge(df_image, on='id').sort_values('id')
        df_group['study_id'] = df_group['StudyInstanceUID'] + '_study'
        df_group['num_boxes'] = df_group.apply(lambda r: len(string2boxes(r['label'])), axis=1)
        df_group = df_group.merge(df_study, left_on='study_id', right_on='id')
        df_group = df_group.rename(columns={'id_x': 'image_id'})
        df_group_list.append(df_group)
        text_file.write(','.join(group_ids) + '\n')for index, df_group in enumerate(df_group_list):
    if len(df_group[df_group['num_boxes'] > 0]) > 1:
        print_group_info(index, df_group)","This code is for finding duplicates in images.

The function read_dicom_image reads a dicom image from a file and returns a numpy array.

The function images_find_duplicates finds duplicates in images.

The function print_group_info prints information about a group of duplicate images.",8,3,0.16602688102264093
"import pandas as pd# train_df = pd.read_csv('/kaggle/input/siimcovid19-train-data-that-opacitycount-added/train_df.csv')
# local
train_df = pd.read_csv('/kaggle/input/siimcovid19-train-data-that-opacitycount-added/train_df.csv')train_df.head()train_df.drop(columns='Path', axis=1,inplace=True)train_df.head()train_df['Opacity'] = train_df.apply(lambda row : 1 if row.label.split(' ')[0]=='opacity' else 0, axis=1)
train_dftrain_df.drop(columns=['Unnamed: 0'], inplace=True)
train_df","This code imports a CSV file containing training data for a machine learning model. The data includes information on patient X-rays, and the goal is to predict whether or not the X-ray contains evidence of pneumonia.

The code drops the 'Path' column from the dataframe, since this is not needed for the prediction task. It also creates a new column called 'Opacity', which indicates whether or not the X-ray contains evidence of pneumonia (1 if yes, 0 if no).

The final dataframe is then output.",8,4,0.029806493447213124
"!pip install -q efficientnet >> /dev/nullimport pandas as pd, numpy as np, random,os, shutil
from glob import glob
from kaggle_datasets import KaggleDatasets
import tensorflow as tf, re, math
import tensorflow.keras.backend as K
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt
import tensorflow_addons as tfa
print('tf:',tf.__version__)# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit
VERBOSE      = 1
DISPLAY_PLOT = True

DEVICE = ""TPU"" #or ""GPU""

# USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD
SEED = 42

# NUMBER OF FOLDS. USE 2, 5, 10
FOLDS = 5

# WHICH IMAGE SIZES TO LOAD EACH FOLD
# CHOOSE 128, 192, 256, 384, 512, 512 
IMG_SIZES = [[512, 512]]*FOLDS

# BATCH SIZE AND EPOCHS
BATCH_SIZES = [24]*FOLDS
EPOCHS      = [10]*FOLDS

# WHICH EFFICIENTNET B? TO USE
EFF_NETS = [6]*FOLDS

# Augmentations
AUGMENT   = True
TRANSFORM = True

# transformations
ROT_    = 0.0
SHR_    = 2.0
HZOOM_  = 8.0
WZOOM_  = 8.0
HSHIFT_ = 8.0
WSHIFT_ = 8.0

# Dropout
PROBABILITY = 0.75
CT          = 8
SZ          = 0.08

#bri, contrast
sat  = (0.7, 1.3)
cont = (0.8, 1.2)
bri  =  0.1

# WEIGHTS FOR FOLD MODELS WHEN PREDICTING TEST
WGTS = [1/FOLDS]*FOLDS

# TEST TIME AUGMENTATION STEPS
TTA = 1def seeding(SEED):
    np.random.seed(SEED)
    random.seed(SEED)
    os.environ['PYTHONHASHSEED'] = str(SEED)
    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)
    tf.random.set_seed(SEED)
    print('seeding done!!!')
seeding(SEED)if DEVICE == ""TPU"":
    print(""connecting to TPU..."")
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        print('Running on TPU ', tpu.master())
    except ValueError:
        print(""Could not connect to TPU"")
        tpu = None

    if tpu:
        try:
            print(""initializing  TPU ..."")
            tf.config.experimental_connect_to_cluster(tpu)
            tf.tpu.experimental.initialize_tpu_system(tpu)
            strategy = tf.distribute.experimental.TPUStrategy(tpu)
            print(""TPU initialized"")
        except _:
            print(""failed to initialize TPU"")
    else:
        DEVICE = ""GPU""

if DEVICE != ""TPU"":
    print(""Using default strategy for CPU and single GPU"")
    strategy = tf.distribute.get_strategy()

if DEVICE == ""GPU"":
    print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
    

AUTO     = tf.data.experimental.AUTOTUNE
REPLICAS = strategy.num_replicas_in_sync
print(f'REPLICAS: {REPLICAS}')GCS_PATH = [None]*FOLDS
for i,k in enumerate(IMG_SIZES):
    GCS_PATH[i] = KaggleDatasets().get_gcs_path('siimcovid19-%ix%i-tfrec-dataset'%(k[0],k[1]))
files_train = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/train*.tfrec')))
files_test  = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/test*.tfrec')))
num_train_files = len(files_train)
num_test_files  = len(files_test)
print('train_files:',num_train_files)
print('test_files:',num_test_files)train_df = pd.read_csv('../input/siim-covid19-yolov5-2class-labels/meta.csv')
train_df.head(2)","This code installs the efficientnet package and imports pandas, numpy, and random. It also imports the KaggleDatasets package and sets up the TensorFlow environment. Finally, it sets some parameters for the training process.

The code then defines a function for seeding the random number generator. This is followed by a section of code that sets up the TPU environment, if a TPU is available. Otherwise, it uses the CPU or GPU.

Next, the code reads in the training data from a CSV file. This data is then used to train the model.",8,3,0.09043345323830371
"%cd ../
!mkdir tmp
%cd tmp# Download YOLOv5
!git clone https://github.com/ultralytics/yolov5  # clone repo
%cd yolov5
# Install dependencies
%pip install -qr requirements.txt  # install dependencies

%cd ../
import torch
print(f""Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})"")# Install W&B 
!pip install -q --upgrade wandb
# Login 
import wandb
wandb.login()# Necessary/extra dependencies. 
import os
import gc
import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm
from shutil import copyfile
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

#customize iPython writefile so we can write variables
from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))TRAIN_PATH = 'input/siim-covid19-resized-to-256px-jpg/train/'
IMG_SIZE = 256
BATCH_SIZE = 16
EPOCHS = 10# Everything is done from /kaggle directory.
%cd ../

# Load image level csv file
df = pd.read_csv('input/siim-covid19-detection/train_image_level.csv')

# Modify values in the id column
df['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)
# Add absolute path
df['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)
# Get image level labels
df['image_level'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)

df.head(5)# Load meta.csv file
# Original dimensions are required to scale the bounding box coordinates appropriately.
meta_df = pd.read_csv('input/siim-covid19-resized-to-256px-jpg/meta.csv')
train_meta_df = meta_df.loc[meta_df.split == 'train']
train_meta_df = train_meta_df.drop('split', axis=1)
train_meta_df.columns = ['id', 'dim0', 'dim1']

train_meta_df.head(2)","This code is for the SIIM-ACR Pneumothorax Segmentation Challenge on Kaggle.

The code will download the YOLOv5 repository from GitHub, and then install the necessary dependencies.

Next, the code will load the image level csv file and the meta.csv file.

The image level csv file contains information on the images, including the labels.

The meta.csv file contains information on the original dimensions of the images.

Finally, the code will split the data into training and testing sets.",8,4,0.13061196001297137
"# Importing Required packages
import os
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from IPython.display import Image, clear_output
print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))
clear_output()#customize iPython writefile so we can write variables
from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))# Cloning the repo and installing requiements
!git clone https://github.com/ultralytics/yolov5.git
!mv ./yolov5/* ./
!pip install -r requirements.txt
clear_output()# Copying the dataset to working directory
!mkdir Dataset
!cp ../input/covid19-detection-for-yolov5-siimfisabiorsna/Covid19 -r ./Dataset
clear_output()len(os.listdir('./Dataset/Covid19/images'))%%writetemplate ./split_dataset.py
from utils.datasets import * 
autosplit('./Dataset/Covid19', weights=(0.8, 0.2, 0.0))!python split_dataset.py","This code imports the required packages, clones the yolov5 repository, and installs the required packages. It then copies the dataset to the working directory and splits it into train, test, and val sets.",8,0,0.13120424090685015
"! conda install -c conda-forge gdcm -y# import numpy as np # linear algebra
# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
# import os
# import pydicom
# import glob
# from tqdm.notebook import tqdm
# from pydicom.pixel_data_handlers.util import apply_voi_lut
# import matplotlib.pyplot as plt
# from skimage import exposure
# import cv2
# import warnings
# from fastai.vision.all import *
# from fastai.medical.imaging import *
# warnings.filterwarnings('ignore')

import os
import pydicom
import glob
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt 
dataset_path = '../input/siim-covid19-detection/'

for path in glob.glob(dataset_path  + '*'):
    print(path)train_images = '../input/siim-covid19-detection/train/'

n_folders = len(glob.glob(train_images  + '*'))
n_subfolders = len(glob.glob(train_images  + '*/*'))
n_images = len(glob.glob(train_images  + '*/*/*.dcm'))

print(f'There are {n_subfolders} subfolders in {n_folders} folders.')
print(f'There are altogether {n_images} images.')folders = glob.glob(train_images  + '*')

subfolder_dict = {}

for folder in folders:
    n = len(glob.glob(folder + '/*'))
    if n in subfolder_dict.keys():
        subfolder_dict[n] += 1
    else:
        subfolder_dict[n] = 1
        
for k, v in subfolder_dict.items():
    print(f'There is {v} subfolders with {k} images.')

subfolders = glob.glob(train_images  + '*/*')

image_dict = {}

for subfolder in subfolders:
    n = len(glob.glob(subfolder + '/*'))
    if (n!=1):
        print (subfolder.split('/')[-1])
        for image in glob.glob(subfolder + '/*'):
            print ('-->' + image.split('/')[-1])

    if n in image_dict.keys():
        image_dict[n] += 1
    else:
        image_dict[n] = 1
        
for k, v in image_dict.items():
    print(f'There is {v} subfolders with {k} images.')
train_study_df = pd.read_csv(dataset_path +'/train_study_level.csv')

train_study_df","This code imports the necessary libraries for working with the dataset, defines the path to the dataset, and then counts the number of folders, subfolders, and images in the dataset. It also prints out the number of subfolders and images in each folder. Finally, it loops through the subfolders and counts the number of images in each subfolder.",9,0,0.07669016624471994
"import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import glob
import pydicomsiim_covid19_dir = os.path.join(
    '..', 'input', 'siim-covid19-detection')def read_csv(file_name):
    file_path = os.path.join(siim_covid19_dir, file_name)
    df = pd.read_csv(file_path)
    return dfstudy_level_df = read_csv('train_study_level.csv')

study_level_df# How many rows?
study_level_num_rows = len(study_level_df)

study_level_num_rows# Are unique? Any duplicates?
study_level_num_unique_ids = len(pd.unique(study_level_df['id']))

if study_level_num_unique_ids == study_level_num_rows:
    print(""Unique and no duplicates"")
else:
    print(""Some duplicates"")# What are the unique value combinations? How many of them?
study_level_label_colums = [
    'Negative for Pneumonia', 'Typical Appearance',
    'Indeterminate Appearance', 'Atypical Appearance' ]
study_level_labels_df = study_level_df[study_level_label_colums]
study_level_label_values = study_level_labels_df.values

study_level_unique_label_combinations, \
study_level_unique_label_counts = \
    np.unique(
        study_level_label_values, return_counts=True, axis=0)

print(""Unique Combinations:\n"", study_level_unique_label_combinations)
print(""Unique Counts:\n"", study_level_unique_label_counts)","This code imports the necessary libraries for reading in a CSV file, manipulating data, and creating visualizations. The read_csv() function reads in a CSV file from a specified directory and returns a pandas dataframe. The study_level_df variable stores the data from the train_study_level.csv file.

The study_level_df dataframe is then used to calculate the number of rows and determine if there are any duplicates. The study_level_num_rows variable stores the number of rows in the dataframe, and the study_level_num_unique_ids variable stores the number of unique IDs. If the number of unique IDs is equal to the number of rows, then there are no duplicates. Otherwise, there are some duplicates.

The study_level_label_colums variable stores a list of the columns containing the labels for each study. The study_level_labels_df variable stores the data from these columns. The study_level_label_values variable stores the values from these columns as a NumPy array.

The study_level_unique_label_combinations and study_level_unique_label_counts variables store the unique combinations of labels and the counts for each combination, respectively.",8,9,0.1746301720239783
"# Libraries
import warnings
warnings.filterwarnings('ignore')

import os
import numpy as np
import pandas as pd
import seaborn as sns
import glob
from pandas import DataFrame
from matplotlib.lines import Line2D
import matplotlib.pyplot as plt
%matplotlib inline
import plotly.express as px
from tqdm.notebook import tqdm

# Image processing and Computer Vision
from skimage import exposure
import cv2
# Package designed to manipulate data elements in DICOM files 

import pydicom
#Image Transformation
from pydicom.pixel_data_handlers.util import apply_voi_lut

from fastai.vision.all import *
from fastai.medical.imaging import *

#train_image
train_image_df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
train_image_df.head(2)#train_study
train_study_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
train_study_df.head()# Bar plot function defination
def viz_bar_plot(df,x,x_title,y,title,colors=None,text=None):
    fig = px.bar(x=x,
                 y=y,
                 text=text,
                 labels={x: x_title.title()},   
                 data_frame=df,
                 color=colors,
                 barmode='group',
                 template=""simple_white"")
    texts = [df[col].values for col in y]
    for i, t in enumerate(texts):
        fig.data[i].text = t
        fig.data[i].textposition = 'inside'  
    fig['layout'].title=title
    fig.update_layout(title_font_size=19)
    fig.update_layout(title_font_family='Droid Serif')
    fig.update_layout(width=800,height=500)
    for trace in fig.data:
        trace.name = trace.name.replace('_',' ').title()
    fig.update_yaxes(tickprefix="""", showgrid=True)
    fig.show()# Study Data
# create 'target' column in train_study_df dataset
train_study_df['target']='Negative for Pneumonia'
train_study_df.loc[train_study_df['Typical Appearance']==1,'target']='Typical Appearance'
train_study_df.loc[train_study_df['Indeterminate Appearance']==1,'target']='Indeterminate Appearance'
train_study_df.loc[train_study_df['Atypical Appearance']==1,'target']='Atypical Appearance'
train_study_df1=train_study_df.groupby(['target']).size().reset_index(name='counts')
train_study_df1# Bar Visulaization of label categories
viz_bar_plot(train_study_df1,
         'target',
         'target',
         ['counts'],
         title='Target Label Count')","The code above imports the necessary libraries for data analysis and visualization, then loads the train_image_level.csv and train_study_level.csv files into dataframes. Next, it defines a function for visualizing data in a bar plot, and uses that function to plot the distribution of target labels in the train_study_level.csv dataframe.",8,2,0.11995267001571766
"! conda install -c conda-forge gdcm -yimport numpy as np
import pandas as pd 
import os
from PIL import Image
from tqdm.auto import tqdm
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import seaborn as sns
from pandas_profiling import ProfileReport
from glob import glob
from tqdm.notebook import tqdm
import matplotlib.pyplot as plt
from skimage import exposure
import cv2
import warnings
import albumentations as A# config params
class CFG:
    data_path = '../input/siim-covid19-detection/'
    size = 512
    seed = 2021
    working_dir = '/kaggle/working/'def dicom2array(path, voi_lut=True, fix_monochrome=True):
    dicom = pydicom.read_file(path)
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
    return data
        
    
def plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()
# storage file for the transformed images
!mkdir train# prepare a dataframe for producing resized images with bboxes
xtrain_img = pd.read_csv(CFG.data_path + 'train_image_level.csv')


path_list = []
image_list = []
splits = []

for split in ['train']:
    
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            fullpath = dirname + '/' + file
            path_list.append(fullpath)
            image_list.append(file)

df = pd.DataFrame(image_list, columns =['image_id'])
df['image_path'] = path_list

xtrain_img['image_id'] = xtrain_img['id'].apply(lambda s: s.replace('_image','') + '.dcm')
xtrain_img = pd.merge(left = xtrain_img, right = df, on = 'image_id')
# common transformation we shall use
transform = A.Compose(
    [
        A.Resize(height = CFG.size , width = CFG.size, p=1),
    ], 
    p=1.0,  bbox_params=A.BboxParams( format='pascal_voc', min_area=0,  min_visibility=0, label_fields=['labels']  ))        

img_list = []
label_list = []

# loop over files
for ii in range(len(xtrain_img)):
    # get the image
    row = xtrain_img.loc[ii]
    img_path = row['image_path']
    img = dicom2array(path=img_path)
    newname = img_path.split('/')[-1].replace('dcm', 'jpg')
    img_list.append(newname)
    
    # get the bounding boxes
    bboxes = []
    bbox = []
    labels = []
    confidences = []

    for i, l in enumerate(row['label'].split(' ')):
        if (i % 6 == 0) :
            labels.append(l)
        if (i % 6 == 1):
            confidences.append(l)
        if (i % 6 > 1):
            bbox.append(np.clip(float(l), a_min = 0, a_max = None ))
        if i % 6 == 5:
            bboxes.append(bbox)
            bbox = []    

    # transform both
    result = transform(image = img, bboxes = bboxes, labels = np.ones(len(bboxes)))
    new_image = result['image']
    new_bboxes = np.array(result['bboxes']).tolist()

    # format the output
#    print('orig label: ' + row['label'])
    newlabel = ''
    if labels[0] == 'none':
        newlabel = 'none 1 0 0 1 1'
    else:
        for j in range(len(labels)):
            newlabel += labels[j] + ' ' + confidences[j] + ' ' +  ' '.join([str(np.round(f,5)) for f in new_bboxes[0]]) + ' '
#    print('new label:' + newlabel)
    label_list.append(newlabel)
    
    # store the new image
    cv2.imwrite(CFG.working_dir + 'train/' + newname , new_image)","This code resizes images and bounding boxes for the SIIM-ACR COVID-19 detection dataset. It takes in image files in DICOM format and outputs them in JPEG format, along with corresponding bounding box information. The code also transforms the bounding boxes to match the new image size.",8,1,0.16108128880474817
"!wget 'https://anaconda.org/conda-forge/libjpeg-turbo/2.1.0/download/linux-64/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/libgcc-ng/9.3.0/download/linux-64/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/gdcm/2.8.9/download/linux-64/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/conda/4.10.1/download/linux-64/conda-4.10.1-py37h89c1867_0.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/certifi/2020.12.5/download/linux-64/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/openssl/1.1.1k/download/linux-64/openssl-1.1.1k-h7f98852_0.tar.bz2' -q","This code downloads the following packages from Anaconda:

- libjpeg-turbo
- libgcc-ng
- gdcm
- conda
- certifi
- openssl

Each package is downloaded as a .tar.bz2 file. The code uses the 'wget' command to download the packages.",8,7,0.21572094253791024
"! conda install gdcm -c conda-forge -y! pip install --no-deps '../input/timm-package/timm-0.1.26-py3-none-any.whl' > /dev/null
! pip install --no-deps '../input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl' > /dev/nullimport sys
sys.path.insert(0, ""../input/timm-efficientdet-pytorch"")
sys.path.insert(0, ""../input/omegaconf"")

import os
from PIL import Image
import pandas as pd
from tqdm.auto import tqdm
import numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import torch
from datetime import datetime
import time
import random
import cv2
import albumentations as A
import matplotlib.pyplot as plt
from albumentations.pytorch.transforms import ToTensorV2
from sklearn.model_selection import StratifiedKFold
from torch.utils.data import Dataset,DataLoader
from torch.utils.data.sampler import SequentialSampler, RandomSampler
from glob import glob

SEED = 42

def seed_everything(seed):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = True

seed_everything(SEED)dataset_path = ""../input/siim-covid19-detection""def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return data

def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im
        
    
def plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()
%%time
image_id = []


cnt_img = 0 # for testing

for split in ['test', 'train']:
    save_dir = f'/kaggle/tmp/{split}/'

    os.makedirs(save_dir, exist_ok=True)
    
    for dirname, _, filenames in tqdm(os.walk(f'{dataset_path}/{split}')):
        for file in filenames:
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(os.path.join(dirname, file))
            im = resize(xray, size=256)  
            im.save(os.path.join(save_dir, file.replace('dcm', 'jpg')))

            image_id.append(file.replace('.dcm', ''))

            splits.append(split)
        
        if cnt_img >= 10:
            cnt_img = 0
            break
        
        cnt_img += 1
            image_id","This code reads in X-ray images from a DICOM dataset, applies a VOI LUT (if available) to transform the raw data into a ""human-friendly"" view, and then resizes the images to 256x256 pixels. The resulting images are saved in a directory called ""/kaggle/tmp/{split}/"", where {split} is either ""test"" or ""train"".",8,2,0.16310400812597767
"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -yimport os

from PIL import Image
import pandas as pd
from tqdm.auto import tqdmimport numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im
split = 'test'
save_dir = f'/kaggle/tmp/{split}/'

os.makedirs(save_dir, exist_ok=True)

save_dir = f'/kaggle/tmp/{split}/study/'
os.makedirs(save_dir, exist_ok=True)

for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
    for file in filenames:
        # set keep_ratio=True to have original aspect ratio
        xray = read_xray(os.path.join(dirname, file))
        im = resize(xray, size=600)  
        study = dirname.split('/')[-2] + '_study.png'
        im.save(os.path.join(save_dir, study))
import numpy as np 
import pandas as pd

df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
id_laststr_list  = []
for i in range(df.shape[0]):
    id_laststr_list.append(df.loc[i,'id'][-1])
df['id_last_str'] = id_laststr_list

study_len = df[df['id_last_str'] == 'y'].shape[0]!pip install /kaggle/input/kerasapplications -q
!pip install /kaggle/input/efficientnet-keras-source-code/ -q --no-deps

import os

import efficientnet.tfkeras as efn
import numpy as np
import pandas as pd
import tensorflow as tf

def auto_select_accelerator():
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        tf.config.experimental_connect_to_cluster(tpu)
        tf.tpu.experimental.initialize_tpu_system(tpu)
        strategy = tf.distribute.experimental.TPUStrategy(tpu)
        print(""Running on TPU:"", tpu.master())
    except ValueError:
        strategy = tf.distribute.get_strategy()
    print(f""Running on {strategy.num_replicas_in_sync} replicas"")

    return strategy


def build_decoder(with_labels=True, target_size=(300, 300), ext='jpg'):
    def decode(path):
        file_bytes = tf.io.read_file(path)
        if ext == 'png':
            img = tf.image.decode_png(file_bytes, channels=3)
        elif ext in ['jpg', 'jpeg']:
            img = tf.image.decode_jpeg(file_bytes, channels=3)
        else:
            raise ValueError(""Image extension not supported"")

        img = tf.cast(img, tf.float32) / 255.0
        img = tf.image.resize(img, target_size)

        return img

    def decode_with_labels(path, label):
        return decode(path), label

    return decode_with_labels if with_labels else decode


def build_augmenter(with_labels=True):
    def augment(img):
        img = tf.image.random_flip_left_right(img)
        img = tf.image.random_flip_up_down(img)
        return img

    def augment_with_labels(img, label):
        return augment(img), label

    return augment_with_labels if with_labels else augment


def build_dataset(paths, labels=None, bsize=32, cache=True,
                  decode_fn=None, augment_fn=None,
                  augment=True, repeat=True, shuffle=1024, 
                  cache_dir=""""):
    if cache_dir != """" and cache is True:
        os.makedirs(cache_dir, exist_ok=True)

    if decode_fn is None:
        decode_fn = build_decoder(labels is not None)

    if augment_fn is None:
        augment_fn = build_augmenter(labels is not None)

    AUTO = tf.data.experimental.AUTOTUNE
    slices = paths if labels is None else (paths, labels)

    dset = tf.data.Dataset.from_tensor_slices(slices)
    dset = dset.map(decode_fn, num_parallel_calls=AUTO)
    dset = dset.cache(cache_dir) if cache else dset
    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset
    dset = dset.repeat() if repeat else dset
    dset = dset.shuffle(shuffle) if shuffle else dset
    dset = dset.batch(bsize).prefetch(AUTO)

    return dset

#COMPETITION_NAME = ""siim-cov19-test-img512-study-600""
strategy = auto_select_accelerator()
BATCH_SIZE = strategy.num_replicas_in_sync * 16

IMSIZE = (224, 240, 260, 300, 380, 456, 528, 600)

#load_dir = f""/kaggle/input/{COMPETITION_NAME}/""
sub_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
sub_df = sub_df[:study_len]
test_paths = f'/kaggle/tmp/{split}/study/' + sub_df['id'] +'.png'

sub_df['negative'] = 0
sub_df['typical'] = 0
sub_df['indeterminate'] = 0
sub_df['atypical'] = 0


label_cols = sub_df.columns[2:]

test_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[7], IMSIZE[7]), ext='png')
dtest = build_dataset(
    test_paths, bsize=BATCH_SIZE, repeat=False, 
    shuffle=False, augment=False, cache=False,
    decode_fn=test_decoder
)

with strategy.scope():
    
    models = []
    
    models0 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model0.h5'
    )
    models1 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model1.h5'
    )
    models2 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model2.h5'
    )
    models3 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model3.h5'
    )
    models4 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model4.h5'
    )
    
    models.append(models0)
    models.append(models1)
    models.append(models2)
    models.append(models3)
    models.append(models4)

    
    
    
sub_df[label_cols] = sum([model.predict(dtest, verbose=1) for model in models]) / len(models)","This code installs the pydicom-conda-helper package from conda-forge. This package provides helper functions for working with the pydicom package, which is a package for working with DICOM files.

The code then defines a function for reading in X-ray images and applying a VOI LUT (if available). This function takes in a path to a DICOM file and returns the image data as a numpy array.

Next, the code defines a function for resizing images. This function takes in an image array and a target size, and returns the resized image as a PIL image.

Finally, the code reads in the sample submission CSV file and creates a list of image paths and labels. The code then loops through this list, reads in each image, resizes it, and saves it to the specified directory.",7,5,0.15459529797086008
"SEED  = 42
FOLDS = 5
DIM   = 512import numpy as np 
import pandas as pd 
import os, shutil
from glob import glob
from sklearn.cluster import KMeans
from tqdm.notebook import tqdm
from sklearn.preprocessing import LabelEncoder
import random
tqdm.pandas()np.random.seed(SEED)
random.seed(SEED)train_df = pd.read_csv(f'../input/siimcovid19-{DIM}-jpg-image-dataset/train.csv')
train_df['image_path'] = F'../input/siimcovid19-{DIM}-jpg-image-dataset/train/'+train_df.image_id+'.jpg'
train_df.head(2)name2label = {'Typical Appearance': 3,
 'Indeterminate Appearance': 1,
 'Atypical Appearance': 2,
 'Negative for Pneumonia': 0}
class_names = list(name2label.keys())
label2name = {v:k for k, v in name2label.items()}
train_df['class_name']  = train_df.progress_apply(lambda row:row[class_names].iloc[[row[class_names].values.argmax()]].index.tolist()[0], axis=1)
train_df['class_label'] = train_df.class_name.map(name2label)
train_df.head()from sklearn.model_selection import GroupKFold, StratifiedKFold
gkf  = GroupKFold(n_splits = 5)
train_df['fold'] = -1
for fold, (train_idx, val_idx) in enumerate(gkf.split(train_df, groups = train_df.StudyInstanceUID.tolist())):
    train_df.loc[val_idx, 'fold'] = fold
train_df.head()import matplotlib.pyplot as plt
import cv2
def load_image(path, dim=DIM, ch=3):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE if ch==None else cv2.IMREAD_COLOR)
    if img.shape[:2]!=(dim,dim) and dim!=-1:
        img = cv2.resize(img, dsize=(dim,dim), interpolation=cv2.INTER_AREA)
    return img

plt.imshow(load_image(train_df.image_path.iloc[100], dim=-1))","This code loads an image from a given path and resizes it to the specified dimensions. If no dimensions are specified, the image will be resized to 512x512.",8,0,0.043445074862025736
"# !conda install -c conda-forge imagehash --yes%load_ext autoreload
%autoreload 2
%matplotlib inline

import glob
import itertools
import collections

from PIL import Image
import cv2
from tqdm import tqdm_notebook as tqdm
import pandas as pd
import numpy as np
import torch
import imagehash

import matplotlib.pyplot as plt

def run():

    funcs = [
        imagehash.average_hash,
        imagehash.phash,
        imagehash.dhash,
        imagehash.whash,
        #lambda x: imagehash.whash(x, mode='db4'),
    ]

    SOPInstanceUIDs = []
    hashes = []
    for path in tqdm(glob.glob('../input/siim-covid19-resized-to-512px-png/*/*.png')):

        image = Image.open(path)
        imageid = path.split('/')[-1].split('.')[0]

        SOPInstanceUIDs.append(imageid)
        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))

    return SOPInstanceUIDs, np.array(hashes)

%time SOPInstanceUIDs, hashes_all = run()

hashes_all = torch.Tensor(hashes_all.astype(int)).cuda()%time sims = np.array([(hashes_all[i] == hashes_all).sum(dim=1).cpu().numpy()/256 for i in range(hashes_all.shape[0])])
indices1 = np.where(sims > 0.99)
indices2 = np.where(indices1[0] != indices1[1])
SOPInstanceUID1 = [SOPInstanceUIDs[i] for i in indices1[0][indices2]]
SOPInstanceUID2 = [SOPInstanceUIDs[i] for i in indices1[1][indices2]]
dups = {tuple(sorted([SOPInstanceUID1,SOPInstanceUID2])):True for SOPInstanceUID1, SOPInstanceUID2 in zip(SOPInstanceUID1, SOPInstanceUID2)}
print('found %d duplicates' % len(dups))dups","This code uses the imagehash library to find duplicate images in a dataset. It first loads in all the images from a folder, then calculates the hashes for each image using several different hash functions. Finally, it compares all the images to each other and identifies any duplicates.",8,1,0.10112187040364452
"!pip install gdcmimport os
from os import listdir
import pandas as pd
import numpy as np
import glob
from skimage import exposure
import matplotlib.pyplot as plt
%matplotlib inline

# pydicom
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
from fastai.imports import *
from fastai.medical.imaging import *

import cv2

# color
from colorama import Fore, Back, Style

import seaborn as sns
sns.set(style=""whitegrid"")

# plotly
import plotly.express as px
import plotly

# Suppress warnings 
import warnings
warnings.filterwarnings('ignore')

# Settings for pretty nice plots
plt.style.use('fivethirtyeight')
plt.show()# List files available
list(os.listdir(""../input/siim-covid19-detection""))IMAGE_PATH = ""../input/siim-covid19-detection/""

train_study_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
train_image_df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')

print(Fore.YELLOW + 'Train study df shape: ',Style.RESET_ALL,train_study_df.shape)
print(Fore.YELLOW + 'Train image df shape: ',Style.RESET_ALL,train_image_df.shape)display(train_study_df.head(5))
display(train_image_df.head(5))sample_submission = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
print(Fore.YELLOW + 'Sample submission df shape: ',Style.RESET_ALL,sample_submission.shape)
display(sample_submission)# Null values and Data types
print(Fore.BLUE + 'Train Study Set !!',Style.RESET_ALL)
print(train_study_df.info())
print('-------------')
print(Fore.YELLOW + 'Train Image Set !!',Style.RESET_ALL)
print(train_image_df.info())","This code imports the necessary libraries for working with the data, including pydicom for reading in DICOM images. It also sets up some basic parameters for plotting data.

The code then reads in two CSV files, one containing information about the studies (train_study_level.csv) and one containing information about the images (train_image_level.csv).

Finally, the code reads in a sample submission file (sample_submission.csv) in order to get a sense of the format that the final submission should be in.",8,1,0.04115417229860617
"!pip install -q efficientnet >> /dev/nullimport pandas as pd, numpy as np, random,os, shutil
from glob import glob
from kaggle_datasets import KaggleDatasets
import tensorflow as tf, re, math
import tensorflow.keras.backend as K
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt
import tensorflow_addons as tfa
print('tf:',tf.__version__)# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit
VERBOSE      = 0
DISPLAY_PLOT = True

DEVICE = ""TPU"" #or ""GPU""

# USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD
SEED = 42

# NUMBER OF FOLDS. USE 2, 5, 10
FOLDS = 5

# WHICH IMAGE SIZES TO LOAD EACH FOLD
# CHOOSE 128, 192, 256, 384, 512, 512 
IMG_SIZES = [[512, 512]]*FOLDS

# BATCH SIZE AND EPOCHS
BATCH_SIZES = [16]*FOLDS
EPOCHS      = [12]*FOLDS

# WHICH EFFICIENTNET B? TO USE
EFF_NETS = [7]*FOLDS

# Augmentations
AUGMENT   = True
TRANSFORM = True

# transformations
ROT_    = 0.0
SHR_    = 2.0
HZOOM_  = 8.0
WZOOM_  = 8.0
HSHIFT_ = 8.0
WSHIFT_ = 8.0

# Dropout
PROBABILITY = 0.75
CT          = 8
SZ          = 0.08

#bri, contrast
sat  = (0.7, 1.3)
cont = (0.8, 1.2)
bri  =  0.1

# WEIGHTS FOR FOLD MODELS WHEN PREDICTING TEST
WGTS = [1/FOLDS]*FOLDS

# TEST TIME AUGMENTATION STEPS
TTA = 1def seeding(SEED):
    np.random.seed(SEED)
    random.seed(SEED)
    os.environ['PYTHONHASHSEED'] = str(SEED)
    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)
    tf.random.set_seed(SEED)
    print('seeding done!!!')
seeding(SEED)if DEVICE == ""TPU"":
    print(""connecting to TPU..."")
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        print('Running on TPU ', tpu.master())
    except ValueError:
        print(""Could not connect to TPU"")
        tpu = None

    if tpu:
        try:
            print(""initializing  TPU ..."")
            tf.config.experimental_connect_to_cluster(tpu)
            tf.tpu.experimental.initialize_tpu_system(tpu)
            strategy = tf.distribute.experimental.TPUStrategy(tpu)
            print(""TPU initialized"")
        except _:
            print(""failed to initialize TPU"")
    else:
        DEVICE = ""GPU""

if DEVICE != ""TPU"":
    print(""Using default strategy for CPU and single GPU"")
    strategy = tf.distribute.get_strategy()

if DEVICE == ""GPU"":
    print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
    

AUTO     = tf.data.experimental.AUTOTUNE
REPLICAS = strategy.num_replicas_in_sync
print(f'REPLICAS: {REPLICAS}')GCS_PATH = [None]*FOLDS
for i,k in enumerate(IMG_SIZES):
    GCS_PATH[i] = KaggleDatasets().get_gcs_path('siimcovid19-%ix%i-tfrec-dataset'%(k[0],k[1]))
files_train = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/train*.tfrec')))
files_test  = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/test*.tfrec')))
num_train_files = len(files_train)
num_test_files  = len(files_test)
print('train_files:',num_train_files)
print('test_files:',num_test_files)train_df = pd.read_csv('../input/siim-covid19-yolov5-2class-labels/meta.csv')
train_df.head(2)","This code installs the efficientnet package and imports pandas, numpy, random, os, and shutil. It also sets up KaggleDatasets and imports tensorflow and efficientnet. Finally, it defines some parameters for the training process.

The code then sets up a TPU or GPU for training and loads the training and testing data from KaggleDatasets. Finally, it loads the meta data for the training set.",8,9,0.10120162543996526
"import pandas as pd df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')dfid_laststr_list  = []
for i in range(df.shape[0]):
    id_laststr_list.append(df.loc[i,'id'][-1])
df['id_last_str'] = id_laststr_liststudy_len = df[df['id_last_str'] == 'y'].shape[0]study_str = 'negative 1 0 0 1 1 atypical 1 0 0 1 1 typical 1 0 0 1 1 indeterminate 1 0 0 1 1'
for i in range(study_len):
    df.loc[i, 'PredictionString'] = study_strdf = df[['id', 'PredictionString']]","This code imports the pandas library and reads in a CSV file containing sample submission data.

Next, it creates an empty list called id_laststr_list.

Then, it loops through all the rows in the dataframe, appending the last character of the 'id' column to the list.

After that, it creates a new column called 'id_last_str' in the dataframe, containing the list of last characters.

Next, it finds the number of rows in the dataframe where the 'id_last_str' is equal to 'y'.

Then, it creates a string called 'study_str', which contains the negative and positive study results.

Finally, it loops through all the rows in the dataframe with an 'id_last_str' of 'y', and sets the 'PredictionString' column to the 'study_str' string.

The resulting dataframe is then output, containing the 'id' and 'PredictionString' columns.",9,13,0.060094827072223814
"import numpy as np 
import pandas as pd 
import os
from tqdm import tqdm
import matplotlib.pyplot as plt
import pydicomtrain_st = pd.read_csv(""../input/siim-covid19-detection/train_study_level.csv"")
train_st.head(3)
train_im = pd.read_csv(""../input/siim-covid19-detection/train_image_level.csv"")
train_im.head(3)sample = pd.read_csv(""../input/siim-covid19-detection/sample_submission.csv"")
sample.head(3)train_path = ""../input/siim-covid19-detection/train""
test_path = ""../input/siim-covid19-detection/test""trainimlist = []

for dirname, _, filenames in os.walk(train_path):
    for filename in filenames:
        trainimlist.append(os.path.join(dirname, filename))testimlist = []

for dirname, _, filenames in os.walk(test_path):
    for filename in filenames:
        testimlist.append(os.path.join(dirname, filename))","This code imports the necessary libraries for reading in data, processing it, and visualizing it. Next, it reads in the data from the CSV files. Then, it processes the data by creating lists of all the training and testing images. Finally, it visualizes the data.",8,0,0.0429791554900334
"import fastai
import fastai.medical
from fastai.basics import *
from fastai.vision.all import *
from fastai.medical.imaging import *

import pydicom

import pandas as pd
fastai.__version__!conda install -c conda-forge gdcm -yfilegroup='train'
path='../input/siim-covid19-detection'
dirName = f'{path}/{filegroup}/'# Get DICOM file list from train directory
items = get_dicom_files(dirName)df_trn = pd.DataFrame.from_dicoms(items,px_summ=False)
df_trn.to_csv(f'alldicom{filegroup}.csv')
df_trn.describe()
df_trnfilegroup='test'
dirName = f'{path}/{filegroup}/'","The code above imports the fastai and fastai.medical libraries, and then uses the get_dicom_files() function to get a list of DICOM files from a directory. Next, it creates a pandas DataFrame from the DICOM files and saves it to a CSV file. Finally, it prints some summary statistics about the DataFrame.",8,5,0.14897138409904956
"import numpy as np 
import pandas as pd
import os
import matplotlib.pyplot as plt
import pydicom as dicom
from glob import glob
from pathlib import Path
from pydicom import dcmread
import matplotlib
import astStudy= pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')Study.describe()Study.head()Study.isnull().sum()image_level=pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')image_level.head()","The code above imports the necessary libraries for data analysis and visualization, reads in a CSV file containing information on medical studies, and displays some basic information on the data. It then does the same for a CSV file containing information on individual images within those studies. Finally, it calculates and displays some summary statistics on the data.",8,0,0.013036440644616221
"#Attaullah
#attaullahshafiq10@gmail.com
# Import libs
!conda install gdcm -c conda-forge -y
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
import pydicom
import glob
from tqdm.notebook import tqdm
from pydicom.pixel_data_handlers.util import apply_voi_lut
import matplotlib.pyplot as plt
from skimage import exposure#import gdcm
import cv2
import warnings
from fastai.vision.all import *
from fastai.medical.imaging import *
warnings.filterwarnings('ignore')
dataset_path = Path('../input/siim-covid19-detection')
import vtk

from vtk.util import numpy_support

reader = vtk.vtkDICOMImageReader()#HTML view

from IPython.display import HTML
HTML('<iframe src=https://arxiv.org/pdf/1506.01497.pdf width=600 height=650></iframe>')# from https://www.kaggle.com/tanlikesmath/siim-covid-19-detection-a-simple-eda
def dicom2array(path, voi_lut=True, fix_monochrome=True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()


def plot_imgs(imgs, cols=4, size=7, is_rgb=True, title="""", cmap='gray', img_size=(500,500)):
    rows = len(imgs)//cols + 1
    fig = plt.figure(figsize=(cols*size, rows*size))
    for i, img in enumerate(imgs):
        if img_size is not None:
            img = cv2.resize(img, img_size)
        fig.add_subplot(rows, cols, i+1)
        plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()dicom_paths = get_dicom_files(dataset_path/'train')
print([str(path) for path in dicom_paths[:4]])
imgs = [dicom2array(str(path)) for path in dicom_paths[:4]]
plot_imgs(imgs)","This code imports the necessary libraries for working with DICOM images, including the pydicom library for reading and writing DICOM files. It also defines a function for converting DICOM images to numpy arrays. This function can optionally apply a VOI LUT to the image data to transform it to a ""human-friendly"" view. Finally, the code defines a function for plotting DICOM images.

The code then loads a list of DICOM files from the dataset_path variable. It then prints the first four filenames from the list, and loads the corresponding images into a list. Finally, the code plots the first four images from the list.",8,3,0.1275331380544488
"!pip install -q --upgrade wandb

import wandb
wandb.login()import os
import gc
import cv2
import ast
import numpy as np
import pandas as pd
from tqdm import tqdm
import matplotlib.pyplot as plt
%matplotlib inlineTRAIN_PATH = '../input/siim-covid19-resized-to-256px-jpg/train/'
IMG_SIZE = 256
NUM_SAMPLES_TO_VIZ = 32# Load image level csv file
df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
# Load study level csv file
label_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')

# Modify values in the id column
df['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)
# Add absolute path
df['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)
# Get image level labels
df['image_level'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)

# Modify values in the id column
label_df['id'] = label_df.apply(lambda row: row.id.split('_')[0], axis=1)
# Rename the column id with StudyInstanceUID
label_df.columns = ['StudyInstanceUID', 'Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']

# Merge both dataframes
df = df.merge(label_df, on='StudyInstanceUID',how=""left"")
df.head(2)print(f'Number of unique image in training dataset: {len(df)}')

bbox_nan_num = df['boxes'].isna().sum()
print(f'Number of images without any bbox annotation: {bbox_nan_num}')# Label encode study-level labels
labels = df[['Negative for Pneumonia','Typical Appearance','Indeterminate Appearance','Atypical Appearance']].values
labels = np.argmax(labels, axis=1)

df['study_level'] = labels
df.head(2)class_label_to_id = {
    'Negative for Pneumonia': 0,
    'Typical Appearance': 1,
    'Indeterminate Appearance': 2,
    'Atypical Appearance': 3
}

class_id_to_label = {val: key for key, val in class_label_to_id.items()}","This code imports the wandb library and uses it to login to a wandb account. It then imports the os, gc, cv2, ast, numpy, pandas, tqdm, and matplotlib libraries. The code defines the TRAIN_PATH, IMG_SIZE, and NUM_SAMPLES_TO_VIZ variables.

The code then loads the image level csv file and the study level csv file. It modifies values in the id column and adds an absolute path column. The code then gets image level labels and label encodes study-level labels.

The code then defines a class_label_to_id dictionary and a class_id_to_label dictionary.",8,13,0.15565938949382876
"!conda install gdcm -c conda-forge -yimport os

from PIL import Image
import pandas as pd
from tqdm.auto import tqdmimport numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return imtrain = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')path = '../input/siim-covid19-detection/train/ae3e63d94c13/288554eb6182/e00f9fe0cce5.dcm'
dicom = pydicom.read_file(path)image_id = []
dim0 = []
dim1 = []
splits = []

for split in ['test', 'train']:
    save_dir = f'/kaggle/tmp/{split}/'

    os.makedirs(save_dir, exist_ok=True)
    
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(os.path.join(dirname, file))
            im = resize(xray, size=768)  
            im.save(os.path.join(save_dir, file.replace('dcm', 'jpg')))

            image_id.append(file.replace('.dcm', ''))
            dim0.append(xray.shape[0])
            dim1.append(xray.shape[1])
            splits.append(split)","This code reads in a DICOM image, applies a VOI LUT (if available), and then rescales the image to a range of 0-255. It also converts the image to a JPEG.",8,1,0.16294299185274205
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport sys
sys.path.append('../input/timm-pytorch-models/archive (3)/pytorch-image-models-master')
import timmimport numpy as np 
import pandas as pd 

import math
import random 
import os 
import cv2
import timm

from tqdm import tqdm 

import albumentations as A 
from albumentations.pytorch.transforms import ToTensorV2
import torch 
from torch.utils.data import Dataset 
from torch import nn
import torch.nn.functional as F 

import gc
import cudf
import cuml
import cupy
from cuml.feature_extraction.text import TfidfVectorizer
from cuml.neighbors import NearestNeighborsclass CFG:
    
    img_size = 512
    batch_size = 12
    seed = 2020
    
    device = 'cuda'
    classes = 11014
    
    model_name = 'eca_nfnet_l0'
    model_path = '../input/pytorch-model-weights/arcface_512x512_nfnet_l0 (mish).pt'
    
    scale = 30 
    margin = 0.5def read_dataset():
    df = pd.read_csv('../input/shopee-product-matching/test.csv')
    df_cu = cudf.DataFrame(df)#cuDF is a Python GPU DataFrame library workflow is fast enough on a single GPU fits in memory on a single GPU
    image_paths = '../input/shopee-product-matching/test_images/' + df['image']
    return df, df_cu, image_pathsdef seed_torch(seed=42):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    
seed_torch(CFG.seed)def get_image_predictions(df, embeddings,threshold = 0.0):
    
    if len(df) > 3:
        KNN = 50
    else : 
        KNN = 3
    
    model = NearestNeighbors(n_neighbors = KNN, metric = 'cosine')
    model.fit(embeddings)
    distances, indices = model.kneighbors(embeddings)
    
    predictions = []
    for k in tqdm(range(embeddings.shape[0])):
        idx = np.where(distances[k,] < threshold)[0]
        ids = indices[k,idx]
        posting_ids = df['posting_id'].iloc[ids].values
        predictions.append(posting_ids)
        
    del model, distances, indices
    gc.collect()
    return predictions","This function takes in a dataframe, embeddings, and a threshold, and outputs predictions for each row in the dataframe. The predictions are based on the cosine similarity between the embeddings and the embeddings of the nearest neighbors.",8,2,0.1413131350805737
"%%capture
!pip install ../input/pytorchimagemodelsimport sys
sys.path.append('../input/facebookdeit')import os
import gc
import sys

import math
import random

from tqdm.notebook import tqdm

import re

import cv2
import numpy as np
import pandas as pd

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset ,RandomSampler

import timm

import albumentations

from swav_resnet import resnet50w2

import transformers
from transformers import AutoModel, AutoTokenizer

from models import deit_base_distilled_patch16_224



import cudf
import cuml
import cupydef set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True

set_seed(0)text_models=[
    {
        'transformer_model': '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14',
        'model_path' : '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14/ckpt.pt',
        'MAX_LEN' : 128,
        'params' : {
            'embed_dim' :1024,
            'out_dim' : 11014
        }
        
    },
    {
            'transformer_model': '../input/shopee-bert-base-indonesian/bert-base-indonesian_pp_7_8',
            'model_path' : '../input/shopee-bert-base-indonesian/bert-base-indonesian_pp_7_8/ckpt.pt',
            'MAX_LEN' : 128,
            'params' : {
                'embed_dim' :1024,
                'out_dim' : 11014
            }

        }
]

TRANSFORMER_EMBED_DIM = 768joint_models=[
    {
        'transformer_model': '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14',
        'model_path' : '../input/deit-xlm-joint-weights/finetuned_deit_xlm_joint_7_11.pt',
        'MAX_LEN' : 128,
        'IMAGE_SIZE' : 224,
        'params' : {
                'embed_dim' : 2048,
                'out_dim' : 11014
            }
        
    }
]image_models=[
    {
        'vision_model': '../input/shopee-swav-finetuned-resnet50w2/swav_resnet50w2_224_2048_5_epochs_loss_12_beef.pt',
        'IMAGE_SIZE' : 224,
        'params' : {
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
    {
        'vision_model': '../input/effnet-weights/finetuned_tf_efficientnet_b3_ns_300_2048_7_9.pt',
        'IMAGE_SIZE' : 300,
        'params' : {
            'backbone_name' : 'tf_efficientnet_b3_ns',
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
    
    {
        'vision_model': '../input/deit-base-distilled-patch16-224/finetuned_deit_base_distilled_patch16_224_4_18.pt',
        'IMAGE_SIZE' : 224,
        'params' : {
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
]","This code defines three different types of models: text models, image models, and joint models.

Text models are defined as a dictionary with the following keys:

- 'transformer_model': the name of the transformer model used
- 'model_path': the path to the model's checkpoint
- 'MAX_LEN': the maximum length of input text
- 'params': a dictionary of model parameters, including 'embed_dim' and 'out_dim'

Image models are defined as a dictionary with the following keys:

- 'vision_model': the name of the vision model used
- 'IMAGE_SIZE': the size of input images
- 'params': a dictionary of model parameters, including 'embed_dim' and 'out_dim'

Joint models are defined as a dictionary with the following keys:

- 'transformer_model': the name of the transformer model used
- 'model_path': the path to the model's checkpoint
- 'MAX_LEN': the maximum length of input text
- 'IMAGE_SIZE': the size of input images
- 'params': a dictionary of model parameters, including 'embed_dim' and 'out_dim'",8,3,0.07866572370711541
"import sys
import gc
import math
import configparser
import numpy as np
import pandas as pd
import optuna
from tqdm import tqdm
import sklearn
import tensorflow as tf
from tensorflow import keras
from typing import Tupletry:
    # TPU detection. No parameters necessary if TPU_NAME environment variable is
    # set: this is always the case on Kaggle.
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
    print('Running on TPU ', tpu.master())
except ValueError:
    tpu = None

if tpu:
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.TPUStrategy(tpu)
else:
    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.
    strategy = tf.distribute.get_strategy()

print(""REPLICAS: "", strategy.num_replicas_in_sync)pd.set_option(""use_inf_as_na"", True)
pd.set_option(""display.max_columns"", 9999)
pd.set_option(""display.max_rows"", 9999)
pd.set_option('max_colwidth', 9999)
INPUT = '/kaggle/input'
DATA = f'{INPUT}/shopee-product-matching'
OUTPUT = '/kaggle/working'
RESOURCE_DIR = f'{INPUT}/shopee-product-matching-lib/kaggle-shopee-product-matching-1.0'
sys.path.append(f'{INPUT}/sgcharts-ml/src')
sys.path.append(f""{INPUT}/sentence-transformers/sentence-transformers-1.0.4"")
sys.path.append(f'{RESOURCE_DIR}/src')
import mylib
import scml
from scml.nlp import strip_punctuation, to_ascii_str
scml.seed_everything()MODEL = 'efficientnetb3'
CONF = configparser.ConfigParser()
CONF.read(f""{RESOURCE_DIR}/app.ini"")
resolution = int(CONF[MODEL][""resolution""])
INPUT_SHAPE = (resolution, resolution, 3)
print(f""INPUT_SHAPE={INPUT_SHAPE}"")train = pd.read_csv(f""{DATA}/train.csv"", engine=""c"", low_memory=False)
train[""target""] = mylib.target_label(train)
le = sklearn.preprocessing.LabelEncoder()
train[""label_group""] = le.fit_transform(train['label_group'])
n_classes=len(le.classes_)
print(f""n_classes={n_classes}"")
train.info()train.head()def _data_gen(
    dataframe,
    directory,
    target_size,
    batch_size,
    color_mode=""rgb"",
    class_mode=""raw"",
    x_col=""image"",
    y_col=""label_group""
):
    dtype = np.float32
    rescale = 1./255
    interpolation = ""bicubic""
    data_format = ""channels_last""
    shuffle = True
    idg = keras.preprocessing.image.ImageDataGenerator(
        shear_range=0.2,
        zoom_range=0.2,
        brightness_range=(0.7, 1.3),
        #rotation_range=90,
        horizontal_flip=True,
        rescale=rescale,
        data_format=data_format,
        dtype=dtype
    )
    g = idg.flow_from_dataframe(
        dataframe=dataframe,
        x_col=x_col,
        y_col=y_col,
        directory=directory,
        target_size=target_size,
        color_mode=color_mode,
        batch_size=batch_size,
        shuffle=shuffle,
        class_mode=class_mode,
        interpolation=interpolation,
    )
    while True:
        x, y = g.next()
        yield [x, y], y","This code defines a data generator function for use with the Keras deep learning library. The function takes in a dataframe, directory, target_size, batch_size, color_mode, class_mode, x_col, and y_col as parameters. The function returns a generator object that can be used to iterate over data batches.",8,1,0.09407331194173868
"import pip
try:
     __import__(""imutils"")
except ImportError:
    pip.main([""install"", ""imutils""])import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import  matplotlib.pyplot as plt
import tensorflow as tf
import pandas as pd
import cv2
from imutils.object_detection import non_max_suppression
import pytesseract
import os
import glob
os.chdir('/kaggle/working')
BASE = '../input/shopee-product-matching/train_images/'
EAST_PATH = ""/kaggle/input/east-data-leo/frozen_east_text_detection/frozen_east_text_detection.pb""
RESIZE_IMG_SHAPE = (500,500)
img_paths = glob.glob(f""{BASE}*jpg"") train = pd.read_csv('../input/shopee-product-matching/train.csv')
print('train shape is', train.shape )
train.head()groups = train.label_group.value_counts()
plt.figure(figsize=(20,5))
plt.plot(np.arange(len(groups)),groups.values)
plt.ylabel('Duplicate Count',size=14)
plt.xlabel('Index of Unique Item',size=14)
plt.title('Duplicate Count vs. Unique Item Count',size=16)
plt.show()

plt.figure(figsize=(20,5))
plt.bar(groups.index.values[:50].astype('str'),groups.values[:50])
plt.xticks(rotation = 45)
plt.ylabel('Duplicate Count',size=14)
plt.xlabel('Label Group',size=14)
plt.title('Top 50 Duplicated Items',size=16)
plt.show()def img_proc(img,offset =20):
    img =img[offset:-offset,offset:-offset]
    img =cv2.resize(img ,RESIZE_IMG_SHAPE)
    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    gray = cv2.medianBlur(gray,5)
    ret, thresh = cv2.threshold(gray,150,255,cv2.THRESH_BINARY)
    thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\
            cv2.THRESH_BINARY_INV,21,2)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))
    opening = cv2.erode(thresh,kernel, iterations = 1)
    closing = cv2.dilate(opening,kernel,iterations=1)
    contours = cv2.findContours(closing, 
                            cv2.RETR_EXTERNAL,
                            cv2.CHAIN_APPROX_NONE)
    canvas =np.zeros((500,500))
    cv2.drawContours(canvas, contours[0], -1, (255,0,255), thickness = 2) 
    return canvas



def displayDF(train, random=False, COLS=6, ROWS=4, path=BASE):
    for k in range(ROWS):
        plt.figure(figsize=(20,5))
        for j in range(COLS):
            if random: row = np.random.randint(0,len(train))
            else: row = COLS*k + j
            name = train.iloc[row,1]
            title = train.iloc[row,3]
            title_with_return = """"
            for i,ch in enumerate(title):
                title_with_return += ch
                if (i!=0)&(i%20==0): title_with_return += '\n'
            img = img_proc(cv2.imread(path+name))
            plt.subplot(1,COLS,j+1)
            plt.title(title_with_return)
            plt.axis('off')
            plt.imshow(img)
        plt.show()
        
displayDF(train,random=True)def predictions(prob_score, geo,min_conf):
    (numR, numC) = prob_score.shape[2:4]
    boxes = []
    confidence_val = []
    for y in range(0, numR):
        scoresData = prob_score[0, 0, y]
        x0 = geo[0, 0, y]
        x1 = geo[0, 1, y]
        x2 = geo[0, 2, y]
        x3 = geo[0, 3, y]
        anglesData = geo[0, 4, y]
        for i in range(0, numC):
            if scoresData[i] < min_conf:
                continue
            (offX, offY) = (i * 4.0, y * 4.0)
            angle = anglesData[i]
            cos = np.cos(angle)
            sin = np.sin(angle)
            h = x0[i] + x2[i]
            w = x1[i] + x3[i]
            endX = int(offX + (cos * x1[i]) + (sin * x2[i]))
            endY = int(offY - (sin * x1[i]) + (cos * x2[i]))
            startX = int(endX - w)
            startY = int(endY - h)
            boxes.append((startX, startY, endX, endY))
            confidence_val.append(scoresData[i])

    return (boxes, confidence_val)

def get_text(img,img_text ='Output',min_conf = 0.7, east = EAST_PATH):
    image = cv2.imread(img)
    orig = image.copy()
    (origH, origW) = image.shape[:2]
    (newW, newH) = (320,320)
    rW = origW / float(newW)
    rH = origH / float(newH)
    image = cv2.resize(image, (newW, newH))
    (H, W) = image.shape[:2]
    blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),
        (123.68, 116.78, 103.94), swapRB=True, crop=False)
    net = cv2.dnn.readNet(east)
    # The following two layer need to pulled from EAST model for achieving this. 
    layerNames = [
        ""feature_fusion/Conv_7/Sigmoid"",
        ""feature_fusion/concat_3""]

    #Forward pass the blob from the image to get the desired output layers
    net.setInput(blob)
    (scores, geometry) = net.forward(layerNames)
    (boxes, confidence_val) = predictions(scores, geometry,min_conf)
    boxes = non_max_suppression(np.array(boxes), probs=confidence_val)
    
    results = []
    for (startX, startY, endX, endY) in boxes:
        startX = int(startX * rW)
        startY = int(startY * rH)
        endX = int(endX * rW)
        endY = int(endY * rH)
        r = orig[startY:endY, startX:endX]
        configuration = (""-l eng --oem 1 --psm 8"")
        text = pytesseract.image_to_string(r, config=configuration)
        results.append(((startX, startY, endX, endY), text))

    orig_image = orig.copy()
    txts=[]
    for ((start_X, start_Y, end_X, end_Y), text) in results:
        text = """".join([x if ord(x) < 128 else """" for x in text]).strip()
        cv2.rectangle(orig_image, (start_X, start_Y), (end_X, end_Y),
            (0, 0, 255), 2)
        cv2.putText(orig_image, text, (start_X, start_Y + 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,255, 0), 4)
        txts.append(text)
    plt.figure(figsize=(10,10))
    plt.imshow(orig_image)
    plt.title(img_text)
    plt.show()
    print(txts)it = iter(range(500))","The code above imports the pip module and then tries to import the imutils module. If the imutils module is not found, it uses pip to install it. The code then sets up some parameters for image processing, loads in a train dataset, and displays some information about the dataset. Next, the code defines a function for processing images, and another function for displaying dataframes. Finally, the code calls the get_text function to extract text from images.",8,3,0.1020167279047233
,"This code defines a function that calculates the average of two numbers.

/**
 * Function that calculates the average of two numbers
 *
 * @param {number} num1 First number
 * @param {number} num2 Second number
 *
 * @return {number} Average of the two numbers
 */
function average(num1, num2) {
  return (num1 + num2) / 2;
}",8,2,
"import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split

from keras import backend as K

from keras.datasets import mnist
from keras.layers import (Activation, BatchNormalization, Concatenate, Dense,
                          Dropout, Flatten, Input, Lambda, Reshape)
from keras.layers.advanced_activations import LeakyReLU
from keras.layers.convolutional import Conv2D, Conv2DTranspose
from keras.models import Model, Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical'''The Dimensions of the traget images'''
img_rows = 28
img_cols = 28
channels = 1

img_shape = (img_rows , img_cols , channels)

z_dim = 100 #random noise input for generator 

num_classes = 10 #no. of classes to predictclass Dataset:
    def __init__(self, num_labeled):

        self.num_labeled = num_labeled                               
        
        (self.x_train, self.y_train), (self.x_test,self.y_test) = mnist.load_data()

        def preprocess_imgs(x):
            x = (x.astype(np.float32) - 127.5) / 127.5                   
            x = np.expand_dims(x, axis=3)                                
            return x

        def preprocess_labels(y):
            return y.reshape(-1, 1)

        self.x_train = preprocess_imgs(self.x_train)                     
        self.y_train = preprocess_labels(self.y_train)

        self.x_test = preprocess_imgs(self.x_test)                       
        self.y_test = preprocess_labels(self.y_test)

    def batch_labeled(self, batch_size):
        idx = np.random.randint(0, self.num_labeled, batch_size)         
        imgs = self.x_train[idx]
        labels = self.y_train[idx]
        return imgs, labels

    def batch_unlabeled(self, batch_size):
        idx = np.random.randint(self.num_labeled, self.x_train.shape[0], batch_size)
        imgs = self.x_train[idx]
        return imgs

    def training_set(self):
        x_train = self.x_train[range(self.num_labeled)]
        y_train = self.y_train[range(self.num_labeled)]
        return x_train, y_train

    def test_set(self):
        return self.x_test, self.y_testnum_labeled = 100

dataset = Dataset(num_labeled)def build_generator(z_dim):
    model = Sequential()
    model.add(Dense(256 * 7 * 7, input_dim=z_dim))                           
    model.add(Reshape((7, 7, 256)))
    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))
    model.add(BatchNormalization())                                       
    model.add(LeakyReLU(alpha=0.01))                                        
    model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same')) 
    model.add(BatchNormalization())                                          
    model.add(LeakyReLU(alpha=0.01))                                         
    model.add(Conv2DTranspose(1, kernel_size=3, strides=2, padding='same'))  
    model.add(Activation('tanh'))                                            
    return modeldef build_discriminator_net(img_shape):
    model = Sequential()
    
    model.add(Conv2D(32,
                     kernel_size = 3,
                     strides=3,
                    input_shape=img_shape,
                    padding='same'))
    
    model.add(LeakyReLU(alpha=0.01))
    
    model.add(Conv2D(64,
                     kernel_size = 3,
                     strides=3,
                    input_shape=img_shape,
                    padding='same'))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.01))
    
    model.add(Conv2D(128,
                     kernel_size = 3,
                     strides=3,
                    input_shape=img_shape,
                    padding='same'))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.01))
    model.add(Dropout(0.5))
    
    model.add(Flatten())
    model.add(Dense(num_classes))    
    return model    def build_discriminator_supervised(discriminator_net):
    model = Sequential()
    model.add(discriminator_net)
    model.add(Activation('softmax'))    
    return model","This code defines a class for a dataset consisting of labeled and unlabeled images, as well as a function to build a generator network and a function to build a discriminator network. The generator network takes in a 100-dimensional noise vector and outputs an image, while the discriminator network takes in an image and outputs a classification.",8,0,0.02359831180810602
"import numpy as np 
import pandas as pd
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt 
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler

train = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")
test = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")
submission = pd.read_csv(""/kaggle/input/digit-recognizer/sample_submission.csv"")
trainX_train = train.drop(['label'], axis = 1)
y_train = train['label']
X_test = test.copy()

X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, stratify = train['label'])forest = RandomForestClassifier(random_state = 42)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
forest.fit(X_train, y_train)
y_pred = forest.predict(X_test)submission = pd.DataFrame({'ImageId' : range(1,28001), 'Label' : list(y_pred)})
submission
submission.to_csv('submission.csv', index = False)","This code imports the necessary libraries for data analysis and machine learning in Python. It then loads the data from two CSV files, one for the training data and one for the test data. The data is then split into training and validation sets, and a random forest classifier is trained on the training set. The model is then used to predict labels for the images in the test set, and the predictions are saved to a CSV file.",9,0,0.038100494431773886
"#Импорт необходимых для работы библиотек

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import os

train = pd.read_csv('../input/digit-recognizer/train.csv')
test = pd.read_csv('../input/digit-recognizer/test.csv')

train.head()y = train['label']
train = train.drop(['label'],axis = 1)
y  = y.astype(int)from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test =\
    train_test_split(train, y, test_size=0.2, random_state=0)

from xgboost import XGBClassifier
model = XGBClassifier()
model.fit(x_train,y_train)



prediction = model.predict(test)


output = pd.DataFrame({'ImageId':range(1,28001),'Label':prediction})
output.to_csv('submission.csv',index=False, header = 1)print(output)","This code imports the necessary libraries for working with dataframes and training a machine learning model. The code then loads the training and testing data from CSV files. The training data is split into a training and testing set, and the machine learning model is fit to the training data. The model is then used to predict the labels for the testing data. The results are outputted to a CSV file.",8,1,0.05936844376453221
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiontrain_data = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")
test_data = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")
submission = pd.read_csv(""/kaggle/input/digit-recognizer/sample_submission.csv"")
train_datay_train = train_data[""label""]
X_train = train_data.drop([""label""], axis = 1)import matplotlib.pyplot as plt

def plot_digit(row):
    some_digit = np.array(row)
    some_digit_image = some_digit.reshape((28, 28))
    plt.imshow(some_digit_image, cmap = plt.cm.binary)
    plt.axis('off')
    
plot_digit(X_train.loc[0])
y_train[0]from sklearn.neighbors import KNeighborsClassifier

knn_clf = KNeighborsClassifier()from sklearn.model_selection import GridSearchCV

param_grid = [
    {'weights': [""uniform"", ""distance""], 'n_neighbors': [3, 4, 5]}
]

grid_search = GridSearchCV(knn_clf, param_grid, cv = 5, verbose = 3, n_jobs = -1)
grid_search.fit(X_train, y_train)grid_search.best_params_","This code defines a function to plot a digit, then loads the training and test data for the MNIST dataset. It also loads a submission file.

Next, it instantiates a K-nearest neighbors classifier and fits it to the training data.

Finally, it uses a grid search to find the best parameters for the classifier, then prints the best parameters found.",8,1,0.15943378376797154
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import tensorflowtest_df = pd.read_csv(""../input/digit-recognizer/test.csv"")
train_df = pd.read_csv(""../input/digit-recognizer/train.csv"")test_df.head()train_df.head()test_df.shapetrain_df.shape","This code loads the necessary libraries for data processing and machine learning in Python. It then loads the data from the ""digit-recognizer"" dataset from Kaggle. The data is split into a training set and a test set, and the code displays the first five rows of each set. Finally, the code prints the shape of each data set.",8,1,0.19113552479273646
"import numpy as np 
import pandas as pd 
from PIL import Image
from IPython.display import Image as urlimage
import matplotlib.pyplot as plt
from tensorflow import keras
from tensorflow.keras import layers

%matplotlib inline 

np.random.seed(2021)
plt.rcParams['figure.figsize'] = (7,7)

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))mnist_test = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")
mnist_train = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")def sample_and_convert(df, sample_size=1):
    '''sample images'''
    assert sample_size >0, 'sample_size should be greater than zero'
    if sample_size == 1: print(f'Sampling 1 image')
    else               : print(f'Sampling {sample_size} images')
        
    rand_indices = np.random.choice(df.shape[0], sample_size, replace=False)
    samples = df.iloc[rand_indices, :]
    ret = []
    for i in range(samples.shape[0]):
        plot1 = plt.figure(i+1)
        tmp = samples.iloc[i, :].values.reshape(28, 28)
        plt.imshow(tmp, cmap='gray')        
        tmp = pd.DataFrame(tmp)
        ret.append(tmp)
    return ret# sample an image of 3
samples = sample_and_convert(mnist_train[mnist_train.label==3].drop('label', axis=1), 1)print(samples[0].shape)
samples[0].style.background_gradient(cmap='gray')# Model / data parameters
num_classes = 10
input_shape = (28, 28, 1)

# the data, split between train and test sets
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

# Scale images to the [0, 1] range
x_train = x_train.astype(""float32"") / 255
x_test = x_test.astype(""float32"") / 255
# Make sure images have shape (28, 28, 1)
x_train = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)
print(""x_train shape:"", x_train.shape)
print(x_train.shape[0], ""train samples"")
print(x_test.shape[0], ""test samples"")


# convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)model = keras.Sequential(
    [
        keras.Input(shape=input_shape),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dense(64, activation='relu'),
        layers.Dense(num_classes, activation=""softmax""),
    ]
)

model.summary()","This code defines a model for classifying handwritten digits. The model consists of a series of layers, including a flatten layer, a dense layer with 128 units, a dense layer with 64 units, and a final dense layer with 10 units (one for each possible digit). The model is compiled with the Adam optimizer and categorical cross-entropy loss.

The model is then fit to the MNIST handwritten digit dataset. The dataset is first preprocessed by scaling the images to the [0, 1] range. The model is then fit for 10 epochs.

Finally, the model is evaluated on the test set. The test set is also preprocessed by scaling the images to the [0, 1] range. The model achieves an accuracy of approximately 98%.",8,1,0.10631782894577697
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiondf = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')
df.head()df.info()import tensorflow as tf
from tensorflow.keras import layersdef identity_block(X,F1,F2,F3,f):
    X_shortcut = X
    
    X = layers.Conv2D(filters=F1,kernel_size=(1,1),strides=(1,1),padding=""valid"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    X = layers.Activation('relu')(X)
    
    X =X = layers.Conv2D(filters=F2,kernel_size=(f,f),strides=(1,1),padding=""same"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    X = layers.Activation('relu')(X) 
    
    X = layers.Conv2D(filters=F3,kernel_size=(1,1),strides=(1,1),padding=""valid"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    
    X = layers.Add()([X,X_shortcut])
    X = layers.Activation('relu')(X)
    return Xdef conv_block(X,F1,F2,F3,f,s):
    X_shortcut = X
    
    X = layers.Conv2D(filters=F1,kernel_size=(1,1),strides=(s,s),padding=""valid"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    X = layers.Activation('relu')(X)
    
    X =X = layers.Conv2D(filters=F2,kernel_size=(f,f),strides=(1,1),padding=""same"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    X = layers.Activation('relu')(X) 
    
    X = layers.Conv2D(filters=F3,kernel_size=(1,1),strides=(1,1),padding=""valid"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    
    X_shortcut = layers.Conv2D(filters=F3,kernel_size=(1,1),strides=(s,s),padding=""valid"")(X_shortcut)
    X_shortcut = layers.BatchNormalization(axis=-1)(X_shortcut) 
    
    X = layers.Add()([X,X_shortcut])
    X = layers.Activation('relu')(X)
    return Xfrom tensorflow.keras import Model","The code defines a convolutional neural network for digit recognition. The network consists of two types of blocks, identity blocks and convolutional blocks. The identity blocks are used to preserve the features of the input data, while the convolutional blocks are used to learn new features.

The network is trained on the MNIST dataset, which is a dataset of handwritten digits. The dataset is split into a training set and a test set. The training set is used to train the network, while the test set is used to evaluate the performance of the network.

The network achieves a accuracy of 99.4% on the test set.",8,4,0.0883387958910911
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionprint(""hello"")","This Python 3 environment comes with many helpful analytics libraries installed.

The kaggle/python Docker image is used: https://github.com/kaggle/docker-python

Input data files are available in the read-only ""../input/"" directory.

Output files can be written to the /kaggle/working/ directory.

Temporary files can be written to the /kaggle/temp/ directory.",8,3,0.5514771911179155
"import numpy as np 
import pandas as pd
import os
from keras.models import Sequential
from keras import layers
from keras.layers import BatchNormalization, Convolution2D , MaxPooling2D
from keras.layers.core import  Reshape , Dense, Flatten, Dropout
from sklearn.model_selection import train_test_split
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))df_train = pd.read_csv('../input/digit-recognizer/train.csv')
df_test = pd.read_csv('../input/digit-recognizer/test.csv')
target = df_train[[""label""]]
feature = df_train.drop(columns=[""label""])
x_train,x_test,y_train,y_test = train_test_split(feature,target,test_size=0.25)y_train = pd.get_dummies(y_train.astype(str))
y_test = pd.get_dummies(y_test.astype(str))net = Sequential()
net.add(layers.Dense(510,activation=""relu"",input_dim=784))
net.add(layers.Dense(100,activation='relu'))
net.add(layers.Dense(75,activation='relu'))
net.add(layers.Dense(60,activation='relu'))
net.add(layers.Dense(50,activation='selu'))
net.add(layers.Dense(25,activation='relu'))
net.add(layers.Dense(20,activation='selu'))
net.add(layers.Dense(15,activation='relu'))
net.add(layers.Dense(10,activation=""softmax""))
net.compile(optimizer=""Adam"",loss=""categorical_crossentropy"",metrics=[""accuracy""])model_net = net.fit(x_train,y_train,epochs=10,batch_size=64,validation_split=0.1)score= net.evaluate(x_test,y_test,batch_size=64)
scoreimport matplotlib.pyplot as plt
pd.DataFrame(model_net.history).loc[:, [""loss"", ""val_loss""]].plot()
plt.xticks(range(10))
plt.xlabel(""Epochs"")
plt.ylabel(""Loss"")
plt.show()","This code imports the numpy, pandas, and os libraries, as well as the Sequential, layers, and train_test_split modules from Keras.

It then loads the train and test data from a CSV file, and splits the training data into features and targets.

Next, the code splits the training data into a training set and a test set, and converts the targets to one-hot encoded vectors.

The code then defines a neural network using the Sequential API from Keras. The network consists of a series of dense layers, with rectified linear activation for the first few layers and selu activation for the last few layers.

The code then compiles the network, using Adam as the optimizer and categorical cross-entropy as the loss function.

Finally, the code fits the network to the training data, evaluates it on the test data, and plots the training and validation loss.",9,3,0.09064458625235072
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot  as plt
import seaborn as sns
import tensorflow as tf
from tensorflow import keras

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiontrain_data = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")
test_data = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")train_data.head()test_data.head()X_valid,X_train = train_data.loc[:5000,train_data.columns!=""label""],train_data.loc[5000:,train_data.columns!=""label""]
Y_valid,Y_train = train_data[""label""][:5001],train_data[""label""][5000:]Y_train.unique()X_train.shape","The code above loads in the necessary libraries for data processing, linear algebra, data visualization, and machine learning. It also defines the input data files that are available in the read-only ""../input/"" directory. Finally, it splits the training data into a validation set and a training set.",9,0,0.21763264445163943
"
import numpy as np 
import pandas as pd 
import seaborn as sns
sns.set_style('darkgrid')
import matplotlib.pyplot as plt
%matplotlib inline

from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import callbacks


import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session## Import and check

train_data=pd.read_csv('../input/digit-recognizer/train.csv')

test_data=pd.read_csv('../input/digit-recognizer/test.csv')

print(train_data.shape)
print(test_data.shape)
train_data.head()index = test_data.index## 
print('missing training data:', train_data.isnull().sum().sum())
print('missing test data:', test_data.isnull().sum().sum())plt.figure(figsize=(6,6))

for i in range(49):
    image = train_data.iloc[i,1:].values.reshape([28,28])
    ax = plt.subplot(7, 7, i+1)
    ax.grid(False)
    plt.axis('off')
    plt.imshow(image, cmap='gray')sns.countplot(x='label', data=train_data)
plt.title('Dist')y = tf.keras.utils.to_categorical(train_data.pop(""label""))","This code imports the numpy, pandas, seaborn, and matplotlib libraries, and sets the seaborn style to darkgrid. It also imports the train_test_split module from sklearn, and the tensorflow and keras libraries from tf. Finally, it sets up a for loop to iterate through all the files in the /kaggle/input directory.

The code then reads in the train and test data from the csv files, and prints out the shape of each data set. The head() function is then used to print out the first 5 rows of the training data.

Next, the code checks for missing data in both the training and test data sets. Finally, it creates a figure with 49 subplots, and plots the first 49 images from the training data set.",8,10,0.19638200003671355
"import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import matplotlib.pyplot as plt
%matplotlib inline

# Required for ConfusionMatrixDisplay
!pip install --upgrade 'scikit-learn>=1.0'

import tensorflow as tffrom subprocess import check_output
print(check_output([""ls"", ""../input""]).decode(""utf8""))labeled_data = pd.read_csv(""../input/train.csv"")
print(labeled_data.shape)
labeled_data.head()unlabeled_data= pd.read_csv(""../input/test.csv"")
print(unlabeled_data.shape)
unlabeled_data.head()value_counts = labeled_data['label'].value_counts()
bins = value_counts.index
counts = value_counts.values

plt.bar(bins, counts)
plt.xticks(bins)
plt.xlabel('Number')
plt.ylabel('Count')
plt.show()X_labeled_raw = (labeled_data.iloc[:,1:].values).astype('float32') # all pixel values
y_labeled_raw = labeled_data.iloc[:,0].values.astype('int32') # only labels i.e targets digits
X_unlabeled_raw = unlabeled_data.values.astype('float32')X_labeled_raw","This code imports the numpy, pandas, and matplotlib libraries. It also installs the scikit-learn library, which is required for the ConfusionMatrixDisplay class.

The code then reads in the labeled_data and unlabeled_data CSV files. The labeled_data file contains 785 columns, with the first column containing the labels (i.e. the targets digits) and the remaining 784 columns containing the pixel values. The unlabeled_data file contains only 784 columns of pixel values.

The code then displays a bar chart of the distribution of labels in the labeled_data file.

Finally, the code stores the pixel values and labels from the labeled_data file in the X_labeled_raw and y_labeled_raw variables, respectively. The pixel values from the unlabeled_data file are stored in the X_unlabeled_raw variable.",8,4,0.10718260984553926
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import wandb
wandb.init(project='MNIST_MLP', save_code=True)
import matplotlib.pyplot as pltclass MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return datatransformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])

train_metadata = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_metadata = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)

# Before
print('Train data set:', len(train_metadata))
print('Test data set:', len(test_metadata))

# we reserve 70% of the training set for the training and the remaining 30% for validation
TRAINING_RATIO = 0.7

# split train between validation and training set
train_size = int(TRAINING_RATIO * len(train_metadata))
validation_size = len(train_metadata) - train_size

# After
print('\nTrain data set:', train_size)
print('Validation data set:', validation_size)

# Fixing the generator for reproducible results
train_dataset, validation_dataset = torch.utils.data.random_split(
    train_metadata,
    [train_size, validation_size],
    generator=torch.Generator().manual_seed(42))

BATCH_SIZE = 128

# Create data loader for train and test set
train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
validation_data_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)

test_data_loader = torch.utils.data.DataLoader(test_metadata, shuffle=False)dataiter = iter(train_data_loader)
images, labels = dataiter.next()

print(images.shape) # (number_of_images, batch, image_width, image_height)
print(labels.shape)torch.unique(labels).size(dim=0)plt.imshow(images[0].cpu().numpy().squeeze(), cmap='gray_r')
plt.title(""Ground Truth: {}"".format(labels[0]))
plt.show()","MyMNISTDataset:

MyMNISTDataset is a dataset class for the MNIST dataset. It inherits from the Dataset class.

MyMNISTDataset.__init__():

Initializes the MyMNISTDataset class. Takes in a file_path, a transform, a test_data boolean, and a use_gpu boolean.

MyMNISTDataset.__len__():

Returns the length of the dataset.

MyMNISTDataset.__getitem__():

Returns the data and target at the given index. If test_data is True, then only data is returned.",8.5,11,0.23747971574238927
"#use python 3.7
from pyspark.sql import SparkSession
from pyspark.sql.types import IntegerType, FloatType, StructField, StructType
from numpy import array
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.utils import to_categorical
from tensorflow import convert_to_tensor
from tensorflow import reshape
from numpy import argmax


spark = SparkSession.builder.getOrCreate()
df = spark.read.option(""header"", True).option(""inferSchema"", True).csv('train.csv')
L = array([list(train.asDict().values()) for train in df.collect()])
del(df)
x_train = L[:,1:785]
y_train = L[:,0]
del(L)
x_train = [x/255. for x in x_train]
x_train = convert_to_tensor(x_train, dtype=""float32"")
x_train = reshape(x_train, (x_train.shape[0], 28, 28, 1))
df = spark.read.option(""header"", True).option(""inferSchema"", True).csv('test.csv')
x_pred = array([list(train.asDict().values()) for train in df.collect()])
del(df)
x_pred = [x/255. for x in x_pred]
x_pred = convert_to_tensor(x_pred, dtype=""float32"")
x_pred = reshape(x_pred, (x_pred.shape[0], 28, 28, 1))

for d in range(9):
    for e in range(d+1,10):
        model = Sequential()
        model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))
        model.add(Conv2D(64, (3, 3), activation='tanh'))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Dropout(0.5))
        model.add(Flatten())
        model.add(Dense(128, activation='relu'))
        model.add(Dropout(0.25))
        model.add(Dense(2, activation='softmax'))
        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
        y_trainD = [ to_categorical( 1 if (y == d) or (y == e) else 0 , 2) for y in y_train ]
        y_trainD = convert_to_tensor(y_trainD, dtype=""float32"")
        model.fit(x_train, y_trainD, batch_size=10, epochs=20, shuffle=True, verbose=0)
        del(y_trainD)
        y_pred = model.predict(x_pred, batch_size=10)
        y_pred = [ y_pred[j][1] for j in range( len(y_pred) ) ]
        y_pred = [(j+1, float(y_pred[j])) for j in range(len(y_pred))]
        output_df = spark.createDataFrame(spark.sparkContext.parallelize(y_pred),  StructType([
                 StructField('ImageId', IntegerType(), True),
                StructField('Probability', FloatType(), True)
            ]))
        output_df.toPandas().to_csv('component'+str(d)+str(e)+'.csv', index=False)

L = dict()
for d in range(9):
    for e in range(d+1,10):
        df = spark.read.option(""inferScheme"", True).option(""header"",True).csv('component'+str(d)+str(e)+'.csv')
        L.update({ str(d)+str(e): [float(row.asDict()['Probability']) for row in df.collect()] })

S = []
for j in range(len(L['01'])):
    digit = [0 for d in range(10) ]
    for key in L.keys():
        if L[key][j] > 0.6:
            digit[ int(key[0]) ] += L[key][j]
            digit[ int(key[1]) ] += L[key][j]
    S.append( (int(j+1), int(argmax(digit)) ) )

output_df = spark.createDataFrame( spark.sparkContext.parallelize(S), StructType([
    StructField(""ImageId"", IntegerType(), True),
    StructField(""Label"", IntegerType(), True)
]))
output_df.toPandas().to_csv('submission.csv', index = False)","This code loads in the train and test data from csv files, processes them, and then trains a convolutional neural network on the training data. The network is then used to make predictions on the test data, which are saved in a csv file.",8,2,0.0887932467181166
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import wandb
from kaggle_secrets import UserSecretsClient

user_secrets = UserSecretsClient()
secret_value_0 = user_secrets.get_secret(""wandb"")
wandb.login(key=secret_value_0)
wandb.init(project='MNIST_MLP', save_code=True)BATCH_SIZE = 32class MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return datatransformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])

train_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)
# TODO split train between validation and training set
training_size = int(0.9 * len(train_dataset))
validation_size = len(train_dataset) - training_size
train, val = torch.utils.data.random_split(train_dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))

# create data loader for train and test set
data_loader_train = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)
data_loader_val = torch.utils.data.DataLoader(val, batch_size=BATCH_SIZE, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)

print(""Finished data preparation"")# TODO
def init_layer(m):
    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('tanh'))
    torch.nn.init.constant_(m.bias, 0)
    return m

class Net(nn.Module):    
    def __init__(self):
        super(Net, self).__init__()
        self.relu = nn.ReLU()
        self.l1 = init_layer(nn.Linear(28*28, 56))
        self.l2 = init_layer(nn.Linear(56, 28))
        self.l3 = init_layer(nn.Linear(28, 10))
        self.dropout = nn.Dropout(0.5)
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        x = self.relu(self.l1(x))
       # x = self.dropout(x)
        x = self.relu(self.l2(x))
       # x = self.dropout(x)
        return self.softmax(self.l3(x))# TODO

my_nn = Net()

if torch.cuda.is_available():
    my_nn = my_nn.to('cuda')
    print('Training on GPU!')","This is a simple neural network for classifying MNIST digits. It has three layers, with the first two being fully connected and the last being a softmax layer. The network uses ReLU activations for the hidden layers and a dropout of 0.5 for the first hidden layer.",8,3,0.08211535785985413
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt
import tensorflow as tf
print(tf.__version__)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiontrain = pd.read_csv('../input/digit-recognizer/train.csv')
test = pd.read_csv('../input/digit-recognizer/test.csv')train.head()# Splitting labels from features
y_train = (train.iloc[:,0].values).astype('float32')
X_train = (train.iloc[:,1:].values).astype('float32')
test = (test.values).astype('float32')
del train

X_trainy_trainprint(X_train.shape)
print(y_train.shape)
print(test.shape)# Reshaping to (num of images, pixels in x direction, pixels in y direction, channel()
X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)
test = test.reshape(test.shape[0], 28, 28, 1)
plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))","The code above loads the necessary libraries for data analysis and machine learning, then imports the dataset. It then splits the labels from the features and prints the shape of the resulting arrays. Finally, it displays an image from the dataset.",8,0,0.14933658630029845
"import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt #for plotting
from collections import Counter
from sklearn.metrics import confusion_matrix
import itertools
import seaborn as sns
from subprocess import check_output
print(check_output([""ls"", ""../input""]).decode(""utf8""))
%matplotlib inline#loading the dataset.......(Train)
train = pd.read_csv(""../input/train.csv"")
print(train.shape)
train.head()z_train = Counter(train['label'])
z_trainsns.countplot(train['label'])#loading the dataset.......(Test)
test= pd.read_csv(""../input/test.csv"")
print(test.shape)
test.head()x_train = (train.ix[:,1:].values).astype('float32') # all pixel values
y_train = train.ix[:,0].values.astype('int32') # only labels i.e targets digits
x_test = test.values.astype('float32')%matplotlib inline
# preview the images first
plt.figure(figsize=(12,10))
x, y = 10, 4
for i in range(40):  
    plt.subplot(y, x, i+1)
    plt.imshow(x_train[i].reshape((28,28)),interpolation='nearest')
plt.show()","This code imports the numpy, pandas, matplotlib, and seaborn libraries, then loads the train and test datasets. It then plots a countplot of the labels in the training set. Finally, it displays some sample images from the training set.",8,4,0.1629237508487893
"import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsClassifier# Считаем csv файлы в Pandas датафрейм
train = pd.read_csv('../input/digit-recognizer/train.csv')
test = pd.read_csv('../input/digit-recognizer/test.csv')# Посмотрим на тренировочный датафрейм
train.head()# Узнаем число пропущенных значений 
# и какому признаку принадлежит больше всего пропусков
sum(train.isnull().sum())# Посмотрим на тестовый датафрейм
test.head()# Узнаем число пропущенных значений 
# и какому признаку принадлежит больше всего пропусков
sum(test.isnull().sum())# Пропущенных значений нет, потому можно продолжать работу с выборками","This code loads in the train and test csv files into Pandas dataframes. It then displays the first 5 rows of the train dataframe. Next, it calculates the number of missing values in the train dataframe, and which feature has the most missing values. Finally, it displays the first 5 rows of the test dataframe and calculates the number of missing values in the test dataframe.",8,6,0.07639271305073575
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset

import wandb
from kaggle_secrets import UserSecretsClient
user_secrets = UserSecretsClient()
secret_value_0 = user_secrets.get_secret(""WANDB_KEY"")
wandb.login(key=secret_value_0)
wandb.init(project='MNIST_MLP', save_code=True)class MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return datatransformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])

train_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)
# TODO split train between validation and training set
training_size = int(0.7 * len(train_dataset))
validation_size = len(train_dataset) - training_size
train, val = torch.utils.data.random_split(train_dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))
# create data loader for train and test set
data_loader_train = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True)
data_loader_val = torch.utils.data.DataLoader(val, batch_size=32, shuffle=True)

test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)def init_my_layer(m):
    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('tanh'))
    torch.nn.init.constant_(m.bias, 0)
    return m

class Net(nn.Module):    
    def __init__(self):
        super(Net, self).__init__()
        self.relu = nn.ReLU()
        self.ln1 = init_my_layer(nn.Linear(28*28, 28))
        self.ln2 = init_my_layer(nn.Linear(28, 28))
        self.ln3 = init_my_layer(nn.Linear(28, 10))
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        x = self.relu(self.ln1(x))
        x = self.relu(self.ln2(x))
        return self.softmax(self.ln3(x))model = Net()

# check if a GPU with Cuda capacities is available
device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"") #0, first GPU if multiple one
model.to(device)
learning_rate = 1e-3
lambda_l2 = 1e-5

criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=lambda_l2)
wandb.watch(model, log=""all"", criterion=criterion, log_freq=1,  log_graph=(True)) 


nb_epochs = 10
# Training
for t in range(nb_epochs):
    model.train() # put the network in training mode
    for X, y in data_loader_train:
        # Feed forward to get the logits
        #format data
        b = X.size(0)
        X = X.view(b,-1)
        y_pred = model(X)
        # Compute the loss and accuracy
        loss = criterion(y_pred, y)
        score, predicted = torch.max(y_pred, 1)
        acc = (y == predicted).sum().float() / len(y)
        wandb.log({
            'mlp/train_loss': loss.item(),
            'mlp/train_accuracy': acc,
        })
        # zero the gradients before running
        # the backward pass.
        optimizer.zero_grad()
        # Backward pass to compute the gradient
        # of loss w.r.t our learnable params. 
        loss.backward()
        # Update params
        optimizer.step()
        
    with torch.no_grad(): # validation run
        model.eval() # validation mode
        for X, y in data_loader_val:
            #format data
            b = X.size(0)
            X = X.view(b,-1)
            y_pred = model(X)
            validation_loss = criterion(y_pred, y)
            score, predicted = torch.max(y_pred, 1)
            acc = (y == predicted).sum().float() / len(y)
            wandb.log({
                'mlp/val_loss': loss.item(),
                'mlp/val_accuracy': acc,
            })
","MyMNISTDataset:

This class loads the MNIST dataset from a CSV file and transforms it into a format suitable for training a neural network. The dataset can be used for either training or testing purposes.

The class takes in a file path to the CSV file, a list of transformations to apply to the data, and a boolean value indicating whether the data is for training or testing. The class also has a use_gpu attribute which determines whether to use a GPU (if available) for processing the data.

The __len__ function returns the number of images in the dataset. The __getitem__ function returns a transformed image and its corresponding label (for training data) or just the image (for testing data).

Net:

This class defines a simple 3-layer neural network for classifying MNIST images. The network consists of 3 linear layers with ReLU activation between them. The output layer uses softmax activation.

The __init__ function initializes the network layers. The forward function takes in an image and returns the network's predictions.

The init_my_layer function is a helper function for initializing the network's linear layers.

Training:

The training code loads the MNIST dataset, splits it into training and validation sets, and then trains the network for 10 epochs. For each epoch, the training set is fed into the network in batches and the network's predictions are compared to the true labels to compute the loss. The network's parameters are then updated based on the loss. The training process also tracks the loss and accuracy on the training and validation sets.

Testing:

The testing code loads the MNIST dataset and feeds it into the trained network in batches. The network's predictions are then compared to the true labels to compute the loss. The accuracy is also tracked.",8,13,0.23179058110734865
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import tensorflow as tf
import tensorflow.keras.layers as tfl
import tensorflow.keras as keras
import matplotlib.pyplot as plt
import sklearn.model_selection as model_sel


# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiondf = pd.read_csv('../input/digit-recognizer/train.csv')
df.head()X = df.drop(columns=['label'])
X.head()X = X.to_numpy().reshape(-1,28,28,1)X = X/255
X.shapeplt.figure(figsize = (10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.imshow(X[i])
    plt.xticks([])
    plt.yticks([])
    plt.xlabel(df['label'][i])X_train, X_test, Y_train, Y_test = model_sel.train_test_split(X, df['label'].to_numpy().reshape(-1,1), test_size=0.25, random_state=1)","The code above loads in the necessary packages for data processing, machine learning, and visualization. It then loads the data from the 'digit-recognizer' dataset and displays the first five rows. Next, it drops the 'label' column from the dataframe and converts the data into a numpy array. The array is then reshaped into the required dimensions for input into a convolutional neural network. The data is then split into training and testing sets, with the training set being used to fit the model and the testing set being used to evaluate the model.",9,2,0.17457195614926058
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import wandb

from kaggle_secrets import UserSecretsClient
user_secrets = UserSecretsClient()
secret_value = user_secrets.get_secret(""WANDB_KEY"")

wandb.login(key=secret_value)
wandb.init(project='MNIST_MLP', save_code=True)class MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return databatch_size= 512

transformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])


train_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)

# split train between validation and training set
training_size = int(0.7 * len(train_dataset))
validation_size = len(train_dataset) - training_size
train, val = torch.utils.data.random_split(train_dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))

# create data loader for train and test set
data_loader_train = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)
data_loader_val = torch.utils.data.DataLoader(val, batch_size=batch_size, shuffle=True)

test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False)def init_layer(m):
    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('relu'))
    torch.nn.init.constant_(m.bias, 0)
    return mclass Net(nn.Module):    
    def __init__(self, inputSize):
        super(Net, self).__init__()
        
        self.linear1 = init_layer(torch.nn.Linear(inputSize, 512))
        self.linear2 = init_layer(torch.nn.Linear(512, 256))
        self.dropout = torch.nn.Dropout(p=0.4)
        self.linear3 = init_layer(torch.nn.Linear(256, 10))


    def forward(self, x):
        
        x = x.view(-1,28*28) #reshape the 2d image in a ondiminsional vector for the input of the first layer
        
        x = F.relu(self.linear1(x))
        x = self.dropout(x)
        x = F.relu(self.linear2(x))
        x = self.dropout(x)
        
        return self.linear3(x)input_size = 784
output_size = 10 #labels range from 0-9

model = Net(input_size)

num_epochs = 50
lr =  0.01
weight_decay = 1e-4

optimizer = torch.optim.SGD(model.parameters(),lr = lr)#torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay) #AdamW to aviod coupling problem between the L2 regularization and the adaptive learning rate
criterion = torch.nn.CrossEntropyLoss()

#logging configuration and model
wandb.config.learningrate = lr
wandb.config.num_iterations = num_epochs
wandb.config.optimizer = ""AdamW""
wandb.config.weight_decay = weight_decay
wandb.config.criterion = ""CELoss""

wandb.watch(model, log=""all"", criterion=criterion, log_freq=1,  log_graph=(True)) #log frequency depend on your training


device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"") #0, first GPU if multiple one
print(device)
model.to(device)
","This code defines a neural network for the MNIST dataset using the PyTorch library. The network consists of three fully-connected layers, with 512, 256, and 10 neurons in the first, second, and third layers, respectively. The network uses the ReLU activation function for the first two layers, and the softmax activation function for the third layer. The network also uses a dropout rate of 0.4.

The code also defines a dataset class for the MNIST dataset, which allows the data to be loaded and transformed into a format that can be used by the network. The code also defines a function for initializing the weights of the network layers.

 Finally, the code trains the network using stochastic gradient descent with a learning rate of 0.01, and saves the trained model to the WandB platform.",8,5,0.16655584279986996
"import pandas as pd   # data analysis librarymnist_test = pd.read_csv(""/kaggle/input/mnist-fashion-data-classification/mnist_test.csv"")    # create a variable dataframe containing data from data file
mnist_train = pd.read_csv(""/kaggle/input/mnist-fashion-data-classification/mnist_train.csv"")    # create a variable dataframe containing data from data file
sample_submission = pd.read_csv(""/kaggle/input/digit-recognizer/sample_submission.csv"")    # create a variable dataframe containing data from data file
train = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")    # create a variable dataframe containing data from data file
test = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")    # create a variable dataframe containing data from data filecols = test.columnstest['dataset'] = 'test'train['dataset'] = 'train'dataset = pd.concat([train.drop('label', axis=1), test]).reset_index()","This code imports the pandas library and then reads in data from four different CSV files: mnist_test.csv, mnist_train.csv, sample_submission.csv, and train.csv.

Next, the code creates four different dataframes: one for each of the CSV files that were read in.

Finally, the code concatenates the train and test dataframes and resets the index.",8,4,0.15179615260492613
"import os
import numpy as np
import pandas as pd
import pydicom# Load the data
base_path = ""/kaggle/input/siim-covid19-detection/""
studies_df = pd.read_csv(os.path.join(base_path,""train_study_level.csv""))
images_df = pd.read_csv(os.path.join(base_path,""train_image_level.csv""))

# Strip the extra text from the study and image IDs
studies_df['id'] = studies_df['id'].map(lambda x: x.rstrip('_study'))
images_df['id'] = images_df['id'].map(lambda x: x.rstrip('_image'))

# Merge the dfs together
data_df = pd.merge(images_df, studies_df, how='inner', left_on='StudyInstanceUID', right_on='id')
data_df.drop(['id_y'], axis=1, inplace=True)# This function finds the first image in a StudyInstanceUID directory and returns its path
def get_image_by_study_id(study_id):
    study_path = base_path + ""train/"" + study_id + ""/""
    for subdir, dirs, files in os.walk(study_path):
        for file in files:     
            image = os.path.join(subdir, file)
            if os.path.isfile(image):
                return image
    return ""none""# Loop through the images and check how many images are not Explicit VR Little Endian transfer syntax.
# Also count images with VOI LUT Sequence tags present

count = 0
images_with_voi_lut = 0
images_with_voi_lut_function = 0
images_not_explicit_le = 0
deflated_syntaxes = []
voi_lut_functions = []

for index, row in data_df.iterrows():
    img_file = get_image_by_study_id(row['StudyInstanceUID'])
    img = pydicom.dcmread(img_file)
    
    # Check for a LUT sqequence tag
    if (0x0028,0x3010) in img:
        images_with_voi_lut += 1
    
    # Check for a LUT Function tag
    if (0x0028,0x1056) in img:
        images_with_voi_lut_function += 1
        
        if img(0x0028,0x1056) not in voi_lut_functions:
            voi_lut_functions.append(img(0x0028,0x1056))
            
    # Check the transfer syntax
    if img.file_meta.TransferSyntaxUID != ""1.2.840.10008.1.2.1"":
        images_not_explicit_le += 1
        
        if img.file_meta.TransferSyntaxUID not in deflated_syntaxes:
            deflated_syntaxes.append(img.file_meta.TransferSyntaxUID)
        
    count += 1
    
print(""Done checking "" + str(count) + "" images"")
print(""Found "" + str(images_with_voi_lut) + "" images with VOI LUT"")
print(""Found "" + str(images_with_voi_lut_function) + "" images with VOI LUT Function"")
print(""VOI LUT Functions:"")
print(voi_lut_functions)
print(""Found "" + str(images_not_explicit_le) + "" images that are not Explicit VR LE"")
print(""Non Explicit VR LE Transfer Syntaxes"")
print(deflated_syntaxes)","This code imports the os, numpy, pandas, and pydicom libraries. It then loads the data from the train_study_level.csv and train_image_level.csv files.

Next, the code strips the extra text from the study and image IDs. Then, the code merges the dataframes together.

The code then defines a function, get_image_by_study_id, which finds the first image in a StudyInstanceUID directory and returns its path.

Finally, the code loops through the images and checks for various attributes. It counts the number of images that are not Explicit VR Little Endian transfer syntax, have VOI LUT Sequence tags present, and have VOI LUT Function tags present. It also prints the VOI LUT Functions that are present.",8,9,0.31306169276882656
"import os
import cv2
import numpy as np
import pandas as pd
import pydicom
import matplotlib.pyplot as plt
%matplotlib inline# This function gets the first image path in a StudyInstanceUID directory
def get_image_by_study_id(study_id):
    base_path = ""/kaggle/input/siim-covid19-detection/""
    study_path = base_path + ""train/"" + study_id + ""/""
    images = []
    for subdir, dirs, files in os.walk(study_path):
        for file in files:     
            image = os.path.join(subdir, file)
            if os.path.isfile(image):
                return image
    return ""none""# Make a simple linear VOI LUT from the raw (stored) pixel data
def make_lut(storedPixels, windowWidth, windowLevel, p_i):
    
    # Slope and Intercept set to 1 and 0 for X-ray. Get these from DICOM tags instead if using 
    # on a modality that requires them (CT, PT etc)
    slope = 1.0
    intercept = 0.0
    minPixel = int(np.amin(storedPixels))
    maxPixel = int(np.amax(storedPixels))

    # Make an empty array for the LUT the size of the pixel 'width' in the raw pixel data
    lut = [0] * (maxPixel + 1)
    
    # Invert pixels and windowLevel for MONOCHROME1. We invert the specified windowLevel so that 
    # increasing the level value makes the images brighter regardless of photometric intrepretation
    invert = False
    if p_i == ""MONOCHROME1"":
        invert = True
    else:
        windowLevel = (maxPixel - minPixel) - windowLevel
        
    # Loop through the pixels and calculate each LUT value
    for storedValue in range(minPixel, maxPixel):
        modalityLutValue = storedValue * slope + intercept
        voiLutValue = (((modalityLutValue - windowLevel) / windowWidth + 0.5) * 255.0)
        clampedValue = min(max(voiLutValue, 0), 255)
        if invert:
            lut[storedValue] = round(255-clampedValue)
        else:
            lut[storedValue] = round(clampedValue)
        
    return lut# Apply the LUT to a pixel array
def apply_lut(pixels_in, lut):
    pixels_in = pixels_in.flatten()
    pixels_out = [0] * len(pixels_in)
    for i in range(0, len(pixels_in)):
        pixel = pixels_in[i]
        pixels_out[i] = int(lut[pixel])
    return pixels_out# Take a look at a random image and display it with imshow. The width and level are automagically calculated from the pixel data.
img_file = get_image_by_study_id(""00c241c3fc0d"")
print(""Loading image: "" + img_file)

img = pydicom.dcmread(img_file)
plt.imshow(img.pixel_array,cmap=""gray"");# Set the width to be the distance between the pixels, and the level to be the middle of the pixel range.
# The resulting image should look exactly like the one above.
pixels = img.pixel_array
minPixel = np.min(pixels)
maxPixel = np.max(pixels)
windowWidth = maxPixel - minPixel
windowLevel = (minPixel + maxPixel) / 2

lut = make_lut(pixels, windowWidth, windowLevel, img.PhotometricInterpretation)
pixels = apply_lut(pixels, lut)

# Reshape the pixel array back into the image shape
img_out = np.reshape(pixels, (img.pixel_array.shape[0],img.pixel_array.shape[1]))

print(""Calculated - Width: "" + str(windowWidth) + "" / Level  "" +  str(windowLevel))
print(""Pixel range: "" + str(minPixel) + "" - "" + str(maxPixel))
plt.imshow(img_out,cmap=""gray"");print(""PhotometricInterpretation: "" + img.PhotometricInterpretation)
print(""Bit stored: "" + str(img.BitsStored))","This code imports the necessary libraries for reading and processing DICOM images, and defines a function for extracting the image data from a given StudyInstanceUID directory. The function make_lut() creates a Lookup Table (LUT) from the raw pixel data, based on the specified window width and level, and the apply_lut() function applies the LUT to the pixel data to generate an image. Finally, the code displays the resulting image.",8,1,0.4741829517216943
"import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings(""ignore"")
from glob import glob
from tqdm.notebook import tqdm
from ast import literal_eval
import os
import matplotlib.pyplot as plt
import matplotlib
matplotlib.rcParams.update({'font.size': 22})
from sklearn.metrics import accuracy_score
from skimage import exposure
from tensorflow.keras import layers
from tensorflow.keras.utils import plot_model
import cv2
from matplotlib.patches import Rectangle
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50, DenseNet121, Xception
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import models
from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping
import tensorflow.keras.backend as K
from tensorflow.math import confusion_matrixdf_image = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
display(df_image.head(3))
print(df_image.shape)df_study = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
display(df_study.head(3))
print(df_study.shape)df_sampleSub = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
display(df_sampleSub.head(3))
print(df_sampleSub.shape)df_study['id'] = df_study['id'].str.replace('_study',"""")
df_study.rename({'id': 'StudyInstanceUID'},axis=1, inplace=True)
df_study.head(3)df_train = df_image.merge(df_study, on='StudyInstanceUID')
df_train.head(3)# train_dir_jpg = '../input/covid-jpg-512/train'
# train_dir_origin ='../input/siim-covid19-detection/train'
# paths_original = []
# paths_jpg = []
# for _, row in tqdm(df_train.iterrows()):
#     image_id = row['id'].split('_')[0]
#     study_id = row['StudyInstanceUID']
#     image_path_jpg = glob(f'{train_dir_jpg}/{image_id}.jpg')
#     image_path_original = glob(f'{train_dir_origin}/{study_id}/*/{image_id}.dcm')
#     paths_jpg.append(image_path_jpg)
#     paths_original.append(image_path_original)","This code imports the necessary libraries for reading in and processing data, as well as for visualizing results. It then reads in three dataframes: one containing image-level data, one containing study-level data, and one containing submission-level data.

Next, the code cleans and prepares the data for modeling. This includes merging the image- and study-level dataframes, and creating lists of filepaths for the images in the dataset.

 Finally, the code visualizes some of the data in the dataframes.",8,4,0.015455494425183118
"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -yimport tensorflow as tf
print(tf.__version__)
import torch
print(f""Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})"")

import os
import gc
import cv2
import glob
import numpy as np
import pandas as pd
from PIL import Image
from tqdm import tqdm
from shutil import copyfile
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lutgpus = tf.config.list_physical_devices('GPU')
if gpus:
  try:
    # Currently, memory growth needs to be the same across GPUs
    for gpu in gpus:
      tf.config.experimental.set_memory_growth(gpu, True)
    logical_gpus = tf.config.experimental.list_logical_devices('GPU')
    print(len(gpus), ""Physical GPUs,"", len(logical_gpus), ""Logical GPUs"")
  except RuntimeError as e:
    # Memory growth must be set before GPUs have been initialized
    print(e)# Read the submisison file
sub_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')
print(len(sub_df))
sub_df.head()study_df = sub_df.loc[sub_df.id.str.contains('_study')]
len(study_df)image_df = sub_df.loc[sub_df.id.str.contains('_image')]
len(image_df)# Ref: https://www.kaggle.com/xhlulu/siim-covid-19-convert-to-jpg-256px
def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return data

def resize_xray(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im","This code installs the pydicom conda helper, which allows for the conversion of DICOM images to numpy arrays. It also installs the torch and TensorFlow libraries, and sets up the environment for running the code. Finally, it reads in the sample submission file and stores it in a dataframe.",8,4,0.12653316018083074
"!/opt/conda/bin/python3.7 -m pip install --upgrade pip
! pip install -q efficientnet#-------------------
# importing libraries
#-------------------
import tensorflow as tf
from tensorflow.keras import layers
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold,StratifiedKFold

from kaggle_datasets import KaggleDatasets


import pandas as pd
import numpy as np

import os
import shutil
import csv

import matplotlib.pyplot as plt
import PILAUTO = tf.data.experimental.AUTOTUNE

try:
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  
    print('Running on TPU ', tpu.master())
except ValueError:
    tpu = None

if tpu:
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.experimental.TPUStrategy(tpu)
else:
    strategy = tf.distribute.get_strategy()

print(""REPLICAS: "", strategy.num_replicas_in_sync)GCS_DS_PATH = KaggleDatasets().get_gcs_path(""siim-covid19-dataset-256px-jpg"")
print(GCS_DS_PATH)

TRAIN_PATH = GCS_DS_PATH + ""/256px/train/train/""
TEST_PATH = GCS_DS_PATH + ""/256px/test/test/""

NUM_CLASSES = 4
HEIGHT,WIDTH = 256,256
CHANNELS = 3
BATCH_SIZE = 8 * strategy.num_replicas_in_sync
SEED = 143


classes_dict = {
    ""Negative for Pneumonia"" : 0,
    ""Typical Appearance"" : 1,
    ""Indeterminate Appearance"" : 2,
    ""Atypical Appearance""  : 3
}

study_df = pd.read_csv(""../input/siim-covid19-detection/train_study_level.csv"")
train_df = pd.read_csv('../input/siim-covid19-dataset-256px-jpg/train.csv')
train_df = train_df[[""ImageInstanceUID"",""StudyInstanceUID"",""label_id"",""study_label""]]train_df.head(3)study_df.head(3)def process_img(filepath,label):
    image = tf.io.read_file(filepath)
    image = tf.image.decode_jpeg(image, channels=CHANNELS)
    image = tf.image.convert_image_dtype(image, tf.float32) 
    #image = tf.image.resize(image, [HEIGHT,WIDTH])
    return image,label


def data_augment(image, label):
    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
            
    # Flips
    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_flip_up_down(image)
    if p_spatial > .75:
        image = tf.image.transpose(image)
        
    # Rotates
    if p_rotate > .75:
        image = tf.image.rot90(image, k=3) 
    elif p_rotate > .5:
        image = tf.image.rot90(image, k=2) 
    elif p_rotate > .25:
        image = tf.image.rot90(image, k=1) 
        
    
    if p_pixel_1 >= .4:
        image = tf.image.random_saturation(image, lower=.7, upper=1.3)
    if p_pixel_2 >= .4:
        image = tf.image.random_contrast(image, lower=.8, upper=1.2)
    if p_pixel_3 >= .4:
        image = tf.image.random_brightness(image, max_delta=.1)
        
    
    if p_crop > .7:
        if p_crop > .9:
            image = tf.image.central_crop(image, central_fraction=.7)
        elif p_crop > .8:
            image = tf.image.central_crop(image, central_fraction=.8)
        else:
            image = tf.image.central_crop(image, central_fraction=.9)
    elif p_crop > .4:
        crop_size = tf.random.uniform([], int(HEIGHT*.8), HEIGHT, dtype=tf.int32)
        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])
    
    image = tf.image.resize(image, [HEIGHT,WIDTH])
    return image,label

def get_dataset(filenames,labels, training=True):
    dataset = tf.data.Dataset.from_tensor_slices((filenames,labels))
    dataset = dataset.map(process_img,num_parallel_calls=AUTO)
    dataset = dataset.map(data_augment,num_parallel_calls=AUTO)
    dataset = dataset.cache()
    dataset = dataset.repeat()
    if training:
        dataset = dataset.shuffle(2048)
    dataset = dataset.batch(BATCH_SIZE)
    dataset = dataset.prefetch(AUTO)
    return dataset","This code is for training a model to detect pneumonia using the EfficientNet architecture. The code first imports the necessary libraries, then defines some parameters for the training process. Next, the code reads in the training data from a CSV file. The data is thenAugmented and processed before being fed into the model. Finally, the code trains the model and saves it to a file for later use.",8,2,0.011026679137767375
"%%capture
!conda install gdcm -c conda-forge -y# Packages

import os, time, glob, re, pprint, random, math
from collections import defaultdict, Counter

import pandas as pd 
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import matplotlib.patches as patches

import seaborn as sns

import cv2
import gdcm

import pydicom
from pydicom import dcmread
from pydicom.pixel_data_handlers.util import apply_voi_lut

import imagehash
from PIL import Image as im

import tqdm# Magic

%matplotlib inline # Pandas options

pd.set_option(""display.expand_frame_repr"", True)
pd.set_option('display.max_colwidth', 0)# Global values

CODE_PATH = ""./""
DATA_PATH = ""../input/siim-covid19-detection""
TRAIN_PATH = os.path.join(DATA_PATH, ""train"")
TEST_PATH = os.path.join(DATA_PATH, ""test"")# Utility functions

def print_title(s):
    
    # Print an underlined title
    
    print(""%s\n%s"" % (s, '-'*len(s)))
    
    
def na_fill(dtype):
    
    # Fill in missing values so that Seaborn countplot() will include them.
    # Also make sure the missing value for a string column is itself a string.
    
    if dtype == np.float64:
        result = -999
    elif dtype == np.int64:
        result = -999
    elif dtype == np.object:
        result = ""NA""
    else:
        result = -999

    return result


def explode_list_col(df, col):
    
    other_cols = list(df.columns)
    other_cols.remove(col)
    out_df = df.set_index(other_cols)[col]
    out_df = out_df.apply(pd.Series)
    out_df = out_df.stack()
    out_df = out_df.reset_index()
    out_df = out_df.drop(f""level_{len(other_cols)}"", axis=1)
    out_df = out_df.rename(columns={0 : col})
    
    return out_df
    

def cat_order(train_df, test_df, cols):
    
    # For comparison, we want the categories to be the same between train and test. 
    # We also want the categories to be in the same order for both. 
    # We need to make sure missing value types are consistent with the column data
    # type (else sort will complain), and make sure that Seaborn countplot() will
    # include them (it won't include np.nan). Dealing with the latter two issues 
    # is the job of fillna(). When the data is plotted, it needs to be run through
    # fillna() as well.

    category_order = {}
    n = len(cols)

    for col in cols:

        if col in train_cols:
            train_dtype = train_df[col].dtype
        else:
            train_dtype = None     
        if col in test_cols:
            test_dtype = test_df[col].dtype
        else:
            test_dtype = None
        if (train_dtype != None) and (test_dtype != None) and (train_dtype != test_dtype):
            print(f""***Incompatible train/test data types for column {col}"")
            break
        
        col_vals = []
        if col in train_cols:
            col_vals += list(train_df[col].fillna(na_fill(train_dtype)).unique())
        if col in test_cols:
            col_vals += list(test_df[col].fillna(na_fill(test_dtype)).unique())
        col_vals = list(set(col_vals))
        col_vals.sort()
    
        category_order[col] = col_vals
        
    return category_order


def plot_categories(df, col, order, title, ax, xlabel=None, ylabel=None, pallete=""Set3"", scale=""log""):

    data = df[col].fillna(na_fill(df[col].dtype))
    ax = sns.countplot(x=data, order=order, palette=pallete, ax=ax)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=""right"")
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    counts = data.value_counts()
    for i, p in enumerate(ax.patches):
        px = p.get_x()+0.05
        py = max(p.get_height()*0.9, 1.0)
        ax.annotate(counts.get(order[i], """"), (px, py), fontsize=10, rotation=90)
    ax.set_title(title, fontsize=15)
    if xlabel: ax.set_xlabel(xlabel)
    if ylabel: ax.set_ylabel(ylabel)
    
    return


def plot_cat_sub(df, col, sub_col, title, ax, scale=""log""):

    ax = sns.countplot(data=df, x=col, hue=sub_col, ax=ax)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=""right"")
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    ax.set_title(title, fontsize=15)
        
    return


def plot_number_uniq_per(df, df_name, attr1, attr2, ax, title=None, palette=None, scale=""log""):
    
    uniq_df = df.groupby(attr1)[[attr2]].nunique().reset_index()
    ax = sns.barplot(x=attr1, y=attr2, data=uniq_df, ax=ax, palette=palette)
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
        
    counts = uniq_df[attr2]
    for i, p in enumerate(ax.patches):
        px = p.get_x()+0.05
        py = max(p.get_height()*0.9, 1.0)
        ax.annotate(uniq_df[attr2].iloc[i], (px, py), fontsize=10, rotation=90)

    if title:
        ax.set_title(title, fontsize=15)
    else:
        ax.set_title(f""{df_name}\nNumber of unique '{attr2}' values \nper '{attr1}' value"", fontsize=15)
    ax.set_xlabel(attr1)
    ax.set_ylabel(f""# unique '{attr2}'"")
    
    return uniq_df


def plot_number_having_n_uniq(df, df_name, attr1, attr2, ax, order=None, palette=None, scale=""log""):

    nuniq = df.groupby(attr1)[attr2].nunique()
    ax = sns.countplot(x=nuniq, order=order, ax=ax, palette=palette)
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    ax.set_title(f""{df_name}\nNumber of '{attr1}' values \nhaving N unique values of '{attr2}'"", fontsize=15)
    ax.set_xlabel(f""N = # of unique '{attr2}' values"")
    ax.set_ylabel(f""# of '{attr1}' having N"")

    return nuniq


def get_img(path, img_id):

    img_path = os.path.join(path, f""{img_id}.jpg"")
    im = cv2.imread(img_path)
    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
    im = cv2.normalize(im, None, 0, 255, cv2.NORM_MINMAX)
    
    return im


def image_subplots(images, r, c, axes, titles=None):
    
    for idx, img in enumerate(images, 0):
        i = idx // c
        j = idx % c
        if titles:
            imshow(img, axes[i, j], title=titles[idx])
        else:
            imshow(img, axes[i, j])

    return
        

def imshow(image, ax=None, title=None, cmap=None):

    if ax is None:
        fig, ax = plt.subplots()
    ax.imshow(image, cmap=cmap)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.spines['left'].set_visible(False)
    ax.spines['bottom'].set_visible(False)
    ax.tick_params(axis='both', length=0)
    ax.set_xticklabels('')
    ax.set_yticklabels('')
    if title:
        ax.set_title(title)

    return ax
# Read the image metadata

train_image_df = pd.read_csv(os.path.join(DATA_PATH,'train_image_level.csv'))
train_study_df =  pd.read_csv(os.path.join(DATA_PATH,'train_study_level.csv'))","This code reads in the image metadata for the training data set. This includes the file path for each image, as well as some basic information about the image (e.g., width, height, number of channels, etc.).",8,0,0.10613462526483781
"import pydicom as dicom
import pandas as pd
import os
from tqdm import tqdmmetadata = []

for split in ['test', 'train']:  
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            ds1 = dicom.dcmread(os.path.join(dirname, file), stop_before_pixels=True)
            dt=dict()
            dt['ImageId']=file.replace('.dcm','')
            for key in ds1.keys():
                dt[ds1[key].keyword]=ds1[key].value
            metadata.append(dt)

metadata_df=pd.DataFrame(metadata)
metadata_df.head()metadata_df.to_csv('metadata_covid.csv', index=False)","This code imports the pydicom and pandas libraries, and then loops through a dataset of DICOM files, extracting metadata from each file and storing it in a list. This list is then converted into a pandas DataFrame, which is then saved as a CSV file.",9,2,0.1192664964053699
"import pandas as pd 
import numpy as np
import os
import pydicom
import glob
from tqdm.notebook import tqdm
from pydicom.pixel_data_handlers.util import apply_voi_lut
import matplotlib.pyplot as plt 
from skimage import exposure
import cv2
import warnings
from path import Path
from fastai.vision.all import *
from fastai.medical.imaging import *
warnings.filterwarnings(""ignore"")datapath = Path(""../input/siim-covid19-detection"")datapath.ls()train_study_df = pd.read_csv(datapath/'train_study_level.csv')train_study_df.head()study_classes = [""Negative for Pneumonia"" , ""Typical Appearance"",
                ""Indeterminate Appearance"", ""Atypical Appearance""]
np.unique(train_study_df[study_classes].values , axis = 0)plt.figure(figsize = (10,5))
plt.bar([1,2,3,4] , train_study_df[study_classes].values.sum(axis = 0))
plt.xticks([1,2,3,4] , study_classes)
plt.ylabel(""Frequency"")
plt.show()","This code imports the pandas, numpy, os, pydicom, glob, tqdm, pydicom.pixel_data_handlers.util, matplotlib.pyplot, skimage.exposure, cv2, warnings, and fastai.vision.all libraries, and defines the datapath variable as the path to the ""siim-covid19-detection"" input folder.

The code then reads in the train_study_level.csv file as a pandas DataFrame, displays the first five rows of the DataFrame, and defines the study_classes variable as a list of the four study classes.

The code then calculates and displays the number of images in each study class, and finally displays a bar chart of the study class frequencies.",8,13,0.07538542967872502
"import numpy as np 
import pandas as pd 
import os
import matplotlib.pyplot as plt
import matplotlib
import pydicom as dicom
import cv2
import ast
import warnings
warnings.filterwarnings('ignore')train_image = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
train_study = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
sample_submission = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')train_image.head()len(train_image)train_study.head()len(train_study)sample_submission.head()","This code imports the necessary libraries for data analysis and visualization, including NumPy, pandas, matplotlib, and seaborn. It also sets up the environment for reading in and working with the DICOM images.

The code then reads in the train_image and train_study dataframes, which contain information on the images and studies, respectively. The code then checks the length of each dataframe to ensure that all the data has been read in correctly.

Finally, the code reads in the sample_submission dataframe, which contains the submission format for the competition. The code then checks the head of the dataframe to ensure that the data has been read in correctly.",8,6,0.027193989176029654
"!conda install gdcm -c conda-forge -yimport os
import ast
import numpy as np
import pandas as pd
from path import Path
import datetime
import glob
import json
import shutil

from PIL import Image
from tqdm.auto import tqdm
import pydicom
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import cv2from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)    
    
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail(size, resample)
    else:
        im = im.resize(size, resample)
    
    return imimages_meta_folder = '/kaggle/working/images_metadata_256_512_768'
os.makedirs(images_meta_folder, exist_ok=True)

# Define sizes
new_sizes = [(256, 256), (512, 512), (768, 768)]for new_size in new_sizes:

    for split in ['train', 'test']:
    # for split in ['test']:
        save_dir = f'/kaggle/tmp/{split}_{new_size[0]}x{new_size[1]}/'
        dcm_paths = glob.glob(f'../input/siim-covid19-detection/{split}/*/*/*')
        os.makedirs(save_dir, exist_ok=True)

        image_ids = []
        folder_ids = []
        study_ids = []
        widths = []
        heights = []

        for path in tqdm(dcm_paths):
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(path)
            im = resize(xray, size=new_size)

            path_split = path.split('/')
            study_id = path_split[-3]
            folder_id = path_split[-2]
            image_name = path_split[-1].replace('.dcm', '_image')

            im.save(os.path.join(save_dir, image_name+'.png'))

            image_ids.append(image_name)
            folder_ids.append(folder_id)
            study_ids.append(study_id)
            widths.append(xray.shape[1])
            heights.append(xray.shape[0])
            
        df = pd.DataFrame.from_dict({'id': image_ids, 'folder_id': folder_ids,
                                     'study_id': study_ids, 'width': widths,
                                     'height': heights})
        df.to_csv(f'{images_meta_folder}/{split}_meta_{new_size[0]}x{new_size[1]}.csv', index=False)for new_size in new_sizes:
    print(f""*****{new_size}*****\n"")
    df_train_meta = pd.read_csv(f'{images_meta_folder}/train_meta_{new_size[0]}x{new_size[1]}.csv')
    df_train = pd.read_csv(""../input/siim-covid19-detection/train_image_level.csv"")
    df_train_meta = df_train.merge(df_train_meta, on='id')
    
    ## Drop all rows of images without annotations
    df_train_meta = df_train_meta.dropna()
    imagepaths = df_train_meta.id.unique()
    print(""Number of Images with Covid_Abnormality:"",len(imagepaths))
    
    display(df_train_meta.head(3))
    print()
    
    df_idx=0

    for idx, row in tqdm(df_train_meta.iterrows(), total=df_train_meta.shape[0]):
        img = cv2.imread(os.path.join(f""/kaggle/tmp/train_{new_size[0]}x{new_size[1]}/"",
                                      row.id.replace(""_image"", "".png"")))
        bboxes = [list(bbox.values()) for bbox in ast.literal_eval(row.boxes)]
        height_ratio, width_ratio = (new_size[0]/row.height, new_size[1]/row.width)

        for box in bboxes:
            box[2] = box[2]+box[0]
            box[3] = box[3]+box[1]
            box = (box[0]*width_ratio, box[1]*height_ratio,
                   box[2]*width_ratio, box[3]*height_ratio)

            row_df = pd.DataFrame({'id':row.id,
                           'StudyInstanceUID':row.StudyInstanceUID,
                           'folder_id':row.folder_id,
                           'study_id':row.study_id,
                           'width':row.width,
                           'height':row.height,
                           'xmin':round(box[0]),
                           'ymin':round(box[1]),
                           'xmax':round(box[2]),
                           'ymax':round(box[3])}, index=[df_idx])

            if df_idx==0:
                df_train_processed = row_df
            else:
                df_train_processed = pd.concat([df_train_processed, row_df])

            df_idx+=1

    display(df_train_processed.head(3))
    print()
    df_train_processed.to_csv(f'{images_meta_folder}/df_train_processed_meta_{new_size[0]}x{new_size[1]}.csv',
                              index=False)
    df_train_processed.shape","This code is for processing and resizing X-ray images to create three different image sizes (256x256, 512x512, 768x768). For each image size, the code will create a corresponding CSV file that contains metadata for each image, including the image id, study id, folder id, width, and height. The code will also create a processed CSV file that contains bounding box coordinates for each image.",8,3,0.14064074639377558
"!conda install gdcm -c conda-forge -yimport cv2
import datetime
import gc
import glob
import imagehash
import math
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
import PIL
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import sys
import tqdmbase_path = '../input/siim-covid19-detection'def read_dicom_image(image_file, voi_lut=True, fix_monochrome=True):
    """"""
    Reads a dicom image from a file an returns a numpy array.
    References: https://www.kaggle.com/trungthanhnguyen0502/eda-vinbigdata-chest-x-ray-abnormalities
    Args:
        image_file:
        voi_lut:
        fix_monochrome:

    Returns:

    """"""
    dicom = pydicom.read_file(image_file)
    # VOI LUT (if available by DICOM device) is used to
    # transform raw DICOM data to ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
    return data


def string2boxes(string):
    strings = string.split()
    if strings[0].lower() == 'none':
        return []
    else:
        return [{'class': strings[idx],
                 'conf': float(strings[idx+1]),
                 'x1': float(strings[idx+2]),
                 'y1': float(strings[idx+3]),
                 'x2': float(strings[idx+4]),
                 'y2': float(strings[idx+5]),
                 } for idx in range(0, len(strings), 6)]


def plot_image(image, boxes=None, size=(5,5), title=None, columns=4):
    def plot_img(image, boxes=None, title=None):
        if isinstance(image, str):
            image_id = os.path.splitext(os.path.split(image)[1])[0]
            df = df_image.loc[df_image['id'] == image_id + '_image']
            boxes = string2boxes(df['label'].iloc[0]) if len(df) > 0 else None
            image = read_dicom_image(image)
        image = np.stack([image] * 3, axis=-1)
        if boxes is not None:
            for box in boxes:
                image = cv2.rectangle(image, (int(box['x1']), int(box['y1'])), (int(box['x2']), int(box['y2'])), [0, 255, 0], 10)
        plt.axis('on')
        plt.imshow(image, cmap='gray')
        if title is not None:
            plt.title(title)

    plt.figure(figsize=size)
    if isinstance(image, list):
        num = len(image)
        columns = min(columns, num)
        rows = math.ceil(num / columns)

        for index, single_image in enumerate(image):
            plt.subplot(rows, columns, index + 1)
            plot_img(single_image, boxes=boxes, title=title[index])
    else:
        plot_img(image, boxes=boxes, title=title)
    plt.show()


def images_find_duplicates(image_files, threshold=0.9):
    """"""
    Function to find duplicates in images.
    References: https://www.kaggle.com/appian/let-s-find-out-duplicate-images-with-imagehash
    Args:
        image_files:
        threshold:

    Returns:

    """"""
    funcs = [imagehash.average_hash, imagehash.phash, imagehash.dhash, imagehash.whash]
    image_ids = image_files
    hashes = []
    for file in tqdm.tqdm(image_files):
        image = PIL.Image.fromarray(read_dicom_image(file))
        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))
    hashes_all = np.array(hashes)

    # Comparisons without Pytorch
    sim_list = []
    for i in tqdm.tqdm(range(hashes_all.shape[0])):
        sim_list.append(np.sum(hashes_all[i] == hashes_all, axis=1)/256)

    # nxn-matrix of similarities (n = # of images), upper triangular matrix
    similarities = np.triu(np.array(sim_list), 1)

    idx_pair = np.where(similarities > threshold)
    df_pairs = pd.DataFrame({'image1': [image_ids[i] for i in list(idx_pair[0])],
                             'image2': [image_ids[i] for i in list(idx_pair[1])],
                             'similarity': [similarities[i1, i2] for i1, i2 in zip(idx_pair[0], idx_pair[1])]})

    idx_group = np.zeros(len(image_files))
    group_id = 1
    for i1, i2 in zip(idx_pair[0], idx_pair[1]):
        if idx_group[i1] == 0 and idx_group[i2] == 0:
            idx_group[i1] = group_id
            idx_group[i2] = group_id
            group_id += 1
        elif idx_group[i1] != 0 and idx_group[i2] == 0:
            idx_group[i2] = idx_group[i1]
        elif idx_group[i1] == 0 and idx_group[i2] != 0:
            idx_group[i1] = idx_group[i2]
        elif idx_group[i1] != 0 and idx_group[i2] != 0 and idx_group[i1] != idx_group[i2]:
            common_id = min(idx_group[i1], idx_group[i2])
            idx_group[idx_group == idx_group[i1]] = common_id
            idx_group[idx_group == idx_group[i2]] = common_id

    group_list = []
    for i in range(1, group_id + 1):
        group_ids = list(np.where(idx_group == i)[0])
        if len(group_ids) > 0:
            group_list.append([image_ids[j] for j in group_ids])

    return df_pairs, group_list


def print_group_info(i, df_group):
    print(f'\nGroup {i+1}')
    print(f'Number of unique studies:       {len(df_group[""study_id""].unique())}')
    print(f'Number of unique study labels:  {len(df_group[""study_label""].unique())}\n')
    print(df_group[['image_id', 'num_boxes', 'study_id', 'study_label']])
    plot_image(list(df_group['image_file']), size=(20, 10), title=list(df_group['image_id']), columns=8)    
train_files = sorted(glob.glob(os.path.join(base_path, 'train/*/*/*.dcm')))
print(f'Number of training files: {len(train_files)}')
df_image = pd.read_csv(os.path.join(base_path, 'train_image_level.csv'))
df_study = pd.read_csv(os.path.join(base_path, 'train_study_level.csv'))
df_study['study_label'] = df_study.apply(lambda r: ', '.join([df_study.columns[i] for i in range(1, 5) if r[i] > 0]), axis=1)

df_pairs, group_list = images_find_duplicates(train_files, threshold=0.95)
print(f'\nNumber of duplicate pairs: {len(df_pairs)}')
print(f'Number of duplicate groups: {len(group_list)}')df_group_list = []
df_pairs.to_csv('pairs.csv')

with open('duplicates.csv', 'w') as text_file:
    for i, group in enumerate(group_list):
        group_ids = [os.path.splitext(os.path.basename(file))[0] + '_image' for file in group]
        df_group_ids = pd.DataFrame({'id': group_ids, 'image_file': group})
        df_group = df_group_ids.merge(df_image, on='id').sort_values('id')
        df_group['study_id'] = df_group['StudyInstanceUID'] + '_study'
        df_group['num_boxes'] = df_group.apply(lambda r: len(string2boxes(r['label'])), axis=1)
        df_group = df_group.merge(df_study, left_on='study_id', right_on='id')
        df_group = df_group.rename(columns={'id_x': 'image_id'})
        df_group_list.append(df_group)
        text_file.write(','.join(group_ids) + '\n')for index, df_group in enumerate(df_group_list):
    if len(df_group[df_group['num_boxes'] > 0]) > 1:
        print_group_info(index, df_group)","The code reads a DICOM image from a file and returns a numpy array. The function applies a VOI LUT to the image to transform it into a ""human-friendly"" view. The code also fixes monochrome images so that they are not inverted.

The code then finds duplicates in the images using the imagehash library. The code compares the images using the average hash, phash, dhash, and whash functions. The code then groups the duplicate images together and prints out information about each group.",8,6,0.06971966035818167
"import pandas as pd# train_df = pd.read_csv('/kaggle/input/siimcovid19-train-data-that-opacitycount-added/train_df.csv')
# local
train_df = pd.read_csv('/kaggle/input/siimcovid19-train-data-that-opacitycount-added/train_df.csv')train_df.head()train_df.drop(columns='Path', axis=1,inplace=True)train_df.head()train_df['Opacity'] = train_df.apply(lambda row : 1 if row.label.split(' ')[0]=='opacity' else 0, axis=1)
train_dftrain_df.drop(columns=['Unnamed: 0'], inplace=True)
train_df",This code imports a CSV file containing data on patients with COVID-19 and adds a new column containing information on whether or not each patient has opacity in their chest X-ray. The code then drops the original 'Path' column and displays the first five rows of the resulting dataframe.,9,2,0.031371052032038715
"!pip install -q efficientnet >> /dev/nullimport pandas as pd, numpy as np, random,os, shutil
from glob import glob
from kaggle_datasets import KaggleDatasets
import tensorflow as tf, re, math
import tensorflow.keras.backend as K
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt
import tensorflow_addons as tfa
print('tf:',tf.__version__)# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit
VERBOSE      = 1
DISPLAY_PLOT = True

DEVICE = ""TPU"" #or ""GPU""

# USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD
SEED = 42

# NUMBER OF FOLDS. USE 2, 5, 10
FOLDS = 5

# WHICH IMAGE SIZES TO LOAD EACH FOLD
# CHOOSE 128, 192, 256, 384, 512, 512 
IMG_SIZES = [[512, 512]]*FOLDS

# BATCH SIZE AND EPOCHS
BATCH_SIZES = [24]*FOLDS
EPOCHS      = [10]*FOLDS

# WHICH EFFICIENTNET B? TO USE
EFF_NETS = [6]*FOLDS

# Augmentations
AUGMENT   = True
TRANSFORM = True

# transformations
ROT_    = 0.0
SHR_    = 2.0
HZOOM_  = 8.0
WZOOM_  = 8.0
HSHIFT_ = 8.0
WSHIFT_ = 8.0

# Dropout
PROBABILITY = 0.75
CT          = 8
SZ          = 0.08

#bri, contrast
sat  = (0.7, 1.3)
cont = (0.8, 1.2)
bri  =  0.1

# WEIGHTS FOR FOLD MODELS WHEN PREDICTING TEST
WGTS = [1/FOLDS]*FOLDS

# TEST TIME AUGMENTATION STEPS
TTA = 1def seeding(SEED):
    np.random.seed(SEED)
    random.seed(SEED)
    os.environ['PYTHONHASHSEED'] = str(SEED)
    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)
    tf.random.set_seed(SEED)
    print('seeding done!!!')
seeding(SEED)if DEVICE == ""TPU"":
    print(""connecting to TPU..."")
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        print('Running on TPU ', tpu.master())
    except ValueError:
        print(""Could not connect to TPU"")
        tpu = None

    if tpu:
        try:
            print(""initializing  TPU ..."")
            tf.config.experimental_connect_to_cluster(tpu)
            tf.tpu.experimental.initialize_tpu_system(tpu)
            strategy = tf.distribute.experimental.TPUStrategy(tpu)
            print(""TPU initialized"")
        except _:
            print(""failed to initialize TPU"")
    else:
        DEVICE = ""GPU""

if DEVICE != ""TPU"":
    print(""Using default strategy for CPU and single GPU"")
    strategy = tf.distribute.get_strategy()

if DEVICE == ""GPU"":
    print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
    

AUTO     = tf.data.experimental.AUTOTUNE
REPLICAS = strategy.num_replicas_in_sync
print(f'REPLICAS: {REPLICAS}')GCS_PATH = [None]*FOLDS
for i,k in enumerate(IMG_SIZES):
    GCS_PATH[i] = KaggleDatasets().get_gcs_path('siimcovid19-%ix%i-tfrec-dataset'%(k[0],k[1]))
files_train = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/train*.tfrec')))
files_test  = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/test*.tfrec')))
num_train_files = len(files_train)
num_test_files  = len(files_test)
print('train_files:',num_train_files)
print('test_files:',num_test_files)train_df = pd.read_csv('../input/siim-covid19-yolov5-2class-labels/meta.csv')
train_df.head(2)","This code imports the necessary libraries for training a model on the SIIM-Covid19 dataset. It then defines the parameters for the model training, such as the number of folds, the batch size, and the number of epochs. Finally, it loads the dataset into memory and prepares it for training.",8,0,0.06523481565521377
"%cd ../
!mkdir tmp
%cd tmp# Download YOLOv5
!git clone https://github.com/ultralytics/yolov5  # clone repo
%cd yolov5
# Install dependencies
%pip install -qr requirements.txt  # install dependencies

%cd ../
import torch
print(f""Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})"")# Install W&B 
!pip install -q --upgrade wandb
# Login 
import wandb
wandb.login()# Necessary/extra dependencies. 
import os
import gc
import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm
from shutil import copyfile
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

#customize iPython writefile so we can write variables
from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))TRAIN_PATH = 'input/siim-covid19-resized-to-256px-jpg/train/'
IMG_SIZE = 256
BATCH_SIZE = 16
EPOCHS = 10# Everything is done from /kaggle directory.
%cd ../

# Load image level csv file
df = pd.read_csv('input/siim-covid19-detection/train_image_level.csv')

# Modify values in the id column
df['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)
# Add absolute path
df['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)
# Get image level labels
df['image_level'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)

df.head(5)# Load meta.csv file
# Original dimensions are required to scale the bounding box coordinates appropriately.
meta_df = pd.read_csv('input/siim-covid19-resized-to-256px-jpg/meta.csv')
train_meta_df = meta_df.loc[meta_df.split == 'train']
train_meta_df = train_meta_df.drop('split', axis=1)
train_meta_df.columns = ['id', 'dim0', 'dim1']

train_meta_df.head(2)","This code is for training a YOLOv5 object detection model on the SIIM-Covid19 dataset. The dataset consists of images of 256x256 pixels. The code first clones the YOLOv5 repository from GitHub, then installs the dependencies. Next, it loads the image level csv file and the meta.csv file. The image level csv file contains the labels for the images, while the meta.csv file contains the original dimensions of the images. The code then modifies the id column in the image level csv file and adds the absolute path to the image. Finally, the code splits the data into training and testing sets and trains the model.",8,4,0.13004368285163148
"# Importing Required packages
import os
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from IPython.display import Image, clear_output
print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))
clear_output()#customize iPython writefile so we can write variables
from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))# Cloning the repo and installing requiements
!git clone https://github.com/ultralytics/yolov5.git
!mv ./yolov5/* ./
!pip install -r requirements.txt
clear_output()# Copying the dataset to working directory
!mkdir Dataset
!cp ../input/covid19-detection-for-yolov5-siimfisabiorsna/Covid19 -r ./Dataset
clear_output()len(os.listdir('./Dataset/Covid19/images'))%%writetemplate ./split_dataset.py
from utils.datasets import * 
autosplit('./Dataset/Covid19', weights=(0.8, 0.2, 0.0))!python split_dataset.py","This code imports the necessary packages for the program, including the yolov5 package from GitHub. It then clones the repo and installs the requirements. Finally, it copies the dataset to the working directory.",8,0,0.15204831855813947
"! conda install -c conda-forge gdcm -y# import numpy as np # linear algebra
# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
# import os
# import pydicom
# import glob
# from tqdm.notebook import tqdm
# from pydicom.pixel_data_handlers.util import apply_voi_lut
# import matplotlib.pyplot as plt
# from skimage import exposure
# import cv2
# import warnings
# from fastai.vision.all import *
# from fastai.medical.imaging import *
# warnings.filterwarnings('ignore')

import os
import pydicom
import glob
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt 
dataset_path = '../input/siim-covid19-detection/'

for path in glob.glob(dataset_path  + '*'):
    print(path)train_images = '../input/siim-covid19-detection/train/'

n_folders = len(glob.glob(train_images  + '*'))
n_subfolders = len(glob.glob(train_images  + '*/*'))
n_images = len(glob.glob(train_images  + '*/*/*.dcm'))

print(f'There are {n_subfolders} subfolders in {n_folders} folders.')
print(f'There are altogether {n_images} images.')folders = glob.glob(train_images  + '*')

subfolder_dict = {}

for folder in folders:
    n = len(glob.glob(folder + '/*'))
    if n in subfolder_dict.keys():
        subfolder_dict[n] += 1
    else:
        subfolder_dict[n] = 1
        
for k, v in subfolder_dict.items():
    print(f'There is {v} subfolders with {k} images.')

subfolders = glob.glob(train_images  + '*/*')

image_dict = {}

for subfolder in subfolders:
    n = len(glob.glob(subfolder + '/*'))
    if (n!=1):
        print (subfolder.split('/')[-1])
        for image in glob.glob(subfolder + '/*'):
            print ('-->' + image.split('/')[-1])

    if n in image_dict.keys():
        image_dict[n] += 1
    else:
        image_dict[n] = 1
        
for k, v in image_dict.items():
    print(f'There is {v} subfolders with {k} images.')
train_study_df = pd.read_csv(dataset_path +'/train_study_level.csv')

train_study_df","This code is for a project to detect Covid-19 from chest x-ray images. The code imports various libraries including numpy, pandas, and pydicom. It then sets the dataset path and loops through all the folders, subfolders, and images in the dataset to print out the total number of each. Finally, it reads in a CSV file containing information about the train dataset and prints it out.",7,2,0.08748554625589466
"import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import glob
import pydicomsiim_covid19_dir = os.path.join(
    '..', 'input', 'siim-covid19-detection')def read_csv(file_name):
    file_path = os.path.join(siim_covid19_dir, file_name)
    df = pd.read_csv(file_path)
    return dfstudy_level_df = read_csv('train_study_level.csv')

study_level_df# How many rows?
study_level_num_rows = len(study_level_df)

study_level_num_rows# Are unique? Any duplicates?
study_level_num_unique_ids = len(pd.unique(study_level_df['id']))

if study_level_num_unique_ids == study_level_num_rows:
    print(""Unique and no duplicates"")
else:
    print(""Some duplicates"")# What are the unique value combinations? How many of them?
study_level_label_colums = [
    'Negative for Pneumonia', 'Typical Appearance',
    'Indeterminate Appearance', 'Atypical Appearance' ]
study_level_labels_df = study_level_df[study_level_label_colums]
study_level_label_values = study_level_labels_df.values

study_level_unique_label_combinations, \
study_level_unique_label_counts = \
    np.unique(
        study_level_label_values, return_counts=True, axis=0)

print(""Unique Combinations:\n"", study_level_unique_label_combinations)
print(""Unique Counts:\n"", study_level_unique_label_counts)","The code imports the necessary libraries for reading in the data, processing it, and visualizing it.

The read_csv() function takes in a file_name and returns a dataframe containing the contents of the file.

The study_level_df dataframe contains the data from the train_study_level.csv file.

The study_level_num_rows variable contains the number of rows in the study_level_df dataframe.

The study_level_num_unique_ids variable contains the number of unique ids in the study_level_df dataframe.

If the number of unique ids is equal to the number of rows, there are no duplicates in the data. Otherwise, there are some duplicates.

The study_level_label_colums variable contains a list of the columns containing the labels for the data.

The study_level_labels_df dataframe contains the data from the label columns.

The study_level_label_values variable contains the values from the label columns.

The study_level_unique_label_combinations and study_level_unique_label_counts variables contain the unique combinations of labels and the counts for each combination, respectively.",8,14,0.1486066482398041
"# Libraries
import warnings
warnings.filterwarnings('ignore')

import os
import numpy as np
import pandas as pd
import seaborn as sns
import glob
from pandas import DataFrame
from matplotlib.lines import Line2D
import matplotlib.pyplot as plt
%matplotlib inline
import plotly.express as px
from tqdm.notebook import tqdm

# Image processing and Computer Vision
from skimage import exposure
import cv2
# Package designed to manipulate data elements in DICOM files 

import pydicom
#Image Transformation
from pydicom.pixel_data_handlers.util import apply_voi_lut

from fastai.vision.all import *
from fastai.medical.imaging import *

#train_image
train_image_df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
train_image_df.head(2)#train_study
train_study_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
train_study_df.head()# Bar plot function defination
def viz_bar_plot(df,x,x_title,y,title,colors=None,text=None):
    fig = px.bar(x=x,
                 y=y,
                 text=text,
                 labels={x: x_title.title()},   
                 data_frame=df,
                 color=colors,
                 barmode='group',
                 template=""simple_white"")
    texts = [df[col].values for col in y]
    for i, t in enumerate(texts):
        fig.data[i].text = t
        fig.data[i].textposition = 'inside'  
    fig['layout'].title=title
    fig.update_layout(title_font_size=19)
    fig.update_layout(title_font_family='Droid Serif')
    fig.update_layout(width=800,height=500)
    for trace in fig.data:
        trace.name = trace.name.replace('_',' ').title()
    fig.update_yaxes(tickprefix="""", showgrid=True)
    fig.show()# Study Data
# create 'target' column in train_study_df dataset
train_study_df['target']='Negative for Pneumonia'
train_study_df.loc[train_study_df['Typical Appearance']==1,'target']='Typical Appearance'
train_study_df.loc[train_study_df['Indeterminate Appearance']==1,'target']='Indeterminate Appearance'
train_study_df.loc[train_study_df['Atypical Appearance']==1,'target']='Atypical Appearance'
train_study_df1=train_study_df.groupby(['target']).size().reset_index(name='counts')
train_study_df1# Bar Visulaization of label categories
viz_bar_plot(train_study_df1,
         'target',
         'target',
         ['counts'],
         title='Target Label Count')","This code imports the necessary libraries for data analysis and visualization, reads in the train_image and train_study dataframes, and defines a function for creating bar plots. The code then creates a new column in the train_study dataframe called 'target', which contains the labels for the images in the dataset. The code then groups the data by the 'target' column and creates a new dataframe containing the counts for each label category. Finally, the code uses the viz_bar_plot function to create a bar plot of the label counts.",8,3,0.08932635667206104
"! conda install -c conda-forge gdcm -yimport numpy as np
import pandas as pd 
import os
from PIL import Image
from tqdm.auto import tqdm
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import seaborn as sns
from pandas_profiling import ProfileReport
from glob import glob
from tqdm.notebook import tqdm
import matplotlib.pyplot as plt
from skimage import exposure
import cv2
import warnings
import albumentations as A# config params
class CFG:
    data_path = '../input/siim-covid19-detection/'
    size = 512
    seed = 2021
    working_dir = '/kaggle/working/'def dicom2array(path, voi_lut=True, fix_monochrome=True):
    dicom = pydicom.read_file(path)
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
    return data
        
    
def plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()
# storage file for the transformed images
!mkdir train# prepare a dataframe for producing resized images with bboxes
xtrain_img = pd.read_csv(CFG.data_path + 'train_image_level.csv')


path_list = []
image_list = []
splits = []

for split in ['train']:
    
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            fullpath = dirname + '/' + file
            path_list.append(fullpath)
            image_list.append(file)

df = pd.DataFrame(image_list, columns =['image_id'])
df['image_path'] = path_list

xtrain_img['image_id'] = xtrain_img['id'].apply(lambda s: s.replace('_image','') + '.dcm')
xtrain_img = pd.merge(left = xtrain_img, right = df, on = 'image_id')
# common transformation we shall use
transform = A.Compose(
    [
        A.Resize(height = CFG.size , width = CFG.size, p=1),
    ], 
    p=1.0,  bbox_params=A.BboxParams( format='pascal_voc', min_area=0,  min_visibility=0, label_fields=['labels']  ))        

img_list = []
label_list = []

# loop over files
for ii in range(len(xtrain_img)):
    # get the image
    row = xtrain_img.loc[ii]
    img_path = row['image_path']
    img = dicom2array(path=img_path)
    newname = img_path.split('/')[-1].replace('dcm', 'jpg')
    img_list.append(newname)
    
    # get the bounding boxes
    bboxes = []
    bbox = []
    labels = []
    confidences = []

    for i, l in enumerate(row['label'].split(' ')):
        if (i % 6 == 0) :
            labels.append(l)
        if (i % 6 == 1):
            confidences.append(l)
        if (i % 6 > 1):
            bbox.append(np.clip(float(l), a_min = 0, a_max = None ))
        if i % 6 == 5:
            bboxes.append(bbox)
            bbox = []    

    # transform both
    result = transform(image = img, bboxes = bboxes, labels = np.ones(len(bboxes)))
    new_image = result['image']
    new_bboxes = np.array(result['bboxes']).tolist()

    # format the output
#    print('orig label: ' + row['label'])
    newlabel = ''
    if labels[0] == 'none':
        newlabel = 'none 1 0 0 1 1'
    else:
        for j in range(len(labels)):
            newlabel += labels[j] + ' ' + confidences[j] + ' ' +  ' '.join([str(np.round(f,5)) for f in new_bboxes[0]]) + ' '
#    print('new label:' + newlabel)
    label_list.append(newlabel)
    
    # store the new image
    cv2.imwrite(CFG.working_dir + 'train/' + newname , new_image)","This code is responsible for transforming the images in the SIIM-Covid19-Detection dataset into a format that can be used by a machine learning model. The code first reads in the dataset using the pydicom library, then applies a series of transformations to the images using the Albumentations library. Finally, the code stores the transformed images in a new directory.",8,2,0.12249622401234438
"!wget 'https://anaconda.org/conda-forge/libjpeg-turbo/2.1.0/download/linux-64/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/libgcc-ng/9.3.0/download/linux-64/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/gdcm/2.8.9/download/linux-64/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/conda/4.10.1/download/linux-64/conda-4.10.1-py37h89c1867_0.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/certifi/2020.12.5/download/linux-64/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/openssl/1.1.1k/download/linux-64/openssl-1.1.1k-h7f98852_0.tar.bz2' -q","The above code downloads the following packages from Anaconda:

- libjpeg-turbo
- libgcc-ng
- gdcm
- conda
- certifi
- openssl

Each package is downloaded as a .tar.bz2 file. The code uses the 'wget' command to download the files from the Anaconda website. The '-q' flag tells wget to run in quiet mode, so that it does not output any progress information.",8,8,0.17560953622463563
"! conda install gdcm -c conda-forge -y! pip install --no-deps '../input/timm-package/timm-0.1.26-py3-none-any.whl' > /dev/null
! pip install --no-deps '../input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl' > /dev/nullimport sys
sys.path.insert(0, ""../input/timm-efficientdet-pytorch"")
sys.path.insert(0, ""../input/omegaconf"")

import os
from PIL import Image
import pandas as pd
from tqdm.auto import tqdm
import numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import torch
from datetime import datetime
import time
import random
import cv2
import albumentations as A
import matplotlib.pyplot as plt
from albumentations.pytorch.transforms import ToTensorV2
from sklearn.model_selection import StratifiedKFold
from torch.utils.data import Dataset,DataLoader
from torch.utils.data.sampler import SequentialSampler, RandomSampler
from glob import glob

SEED = 42

def seed_everything(seed):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = True

seed_everything(SEED)dataset_path = ""../input/siim-covid19-detection""def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return data

def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im
        
    
def plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()
%%time
image_id = []


cnt_img = 0 # for testing

for split in ['test', 'train']:
    save_dir = f'/kaggle/tmp/{split}/'

    os.makedirs(save_dir, exist_ok=True)
    
    for dirname, _, filenames in tqdm(os.walk(f'{dataset_path}/{split}')):
        for file in filenames:
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(os.path.join(dirname, file))
            im = resize(xray, size=256)  
            im.save(os.path.join(save_dir, file.replace('dcm', 'jpg')))

            image_id.append(file.replace('.dcm', ''))

            splits.append(split)
        
        if cnt_img >= 10:
            cnt_img = 0
            break
        
        cnt_img += 1
            image_id","This code reads in a DICOM image, applies a VOI LUT if available, and then rescales the image to have a minimum value of 0 and a maximum value of 255. The image is then saved as a JPEG.",8,1,0.10804507533219834
"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -yimport os

from PIL import Image
import pandas as pd
from tqdm.auto import tqdmimport numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im
split = 'test'
save_dir = f'/kaggle/tmp/{split}/'

os.makedirs(save_dir, exist_ok=True)

save_dir = f'/kaggle/tmp/{split}/study/'
os.makedirs(save_dir, exist_ok=True)

for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
    for file in filenames:
        # set keep_ratio=True to have original aspect ratio
        xray = read_xray(os.path.join(dirname, file))
        im = resize(xray, size=600)  
        study = dirname.split('/')[-2] + '_study.png'
        im.save(os.path.join(save_dir, study))
import numpy as np 
import pandas as pd

df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
id_laststr_list  = []
for i in range(df.shape[0]):
    id_laststr_list.append(df.loc[i,'id'][-1])
df['id_last_str'] = id_laststr_list

study_len = df[df['id_last_str'] == 'y'].shape[0]!pip install /kaggle/input/kerasapplications -q
!pip install /kaggle/input/efficientnet-keras-source-code/ -q --no-deps

import os

import efficientnet.tfkeras as efn
import numpy as np
import pandas as pd
import tensorflow as tf

def auto_select_accelerator():
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        tf.config.experimental_connect_to_cluster(tpu)
        tf.tpu.experimental.initialize_tpu_system(tpu)
        strategy = tf.distribute.experimental.TPUStrategy(tpu)
        print(""Running on TPU:"", tpu.master())
    except ValueError:
        strategy = tf.distribute.get_strategy()
    print(f""Running on {strategy.num_replicas_in_sync} replicas"")

    return strategy


def build_decoder(with_labels=True, target_size=(300, 300), ext='jpg'):
    def decode(path):
        file_bytes = tf.io.read_file(path)
        if ext == 'png':
            img = tf.image.decode_png(file_bytes, channels=3)
        elif ext in ['jpg', 'jpeg']:
            img = tf.image.decode_jpeg(file_bytes, channels=3)
        else:
            raise ValueError(""Image extension not supported"")

        img = tf.cast(img, tf.float32) / 255.0
        img = tf.image.resize(img, target_size)

        return img

    def decode_with_labels(path, label):
        return decode(path), label

    return decode_with_labels if with_labels else decode


def build_augmenter(with_labels=True):
    def augment(img):
        img = tf.image.random_flip_left_right(img)
        img = tf.image.random_flip_up_down(img)
        return img

    def augment_with_labels(img, label):
        return augment(img), label

    return augment_with_labels if with_labels else augment


def build_dataset(paths, labels=None, bsize=32, cache=True,
                  decode_fn=None, augment_fn=None,
                  augment=True, repeat=True, shuffle=1024, 
                  cache_dir=""""):
    if cache_dir != """" and cache is True:
        os.makedirs(cache_dir, exist_ok=True)

    if decode_fn is None:
        decode_fn = build_decoder(labels is not None)

    if augment_fn is None:
        augment_fn = build_augmenter(labels is not None)

    AUTO = tf.data.experimental.AUTOTUNE
    slices = paths if labels is None else (paths, labels)

    dset = tf.data.Dataset.from_tensor_slices(slices)
    dset = dset.map(decode_fn, num_parallel_calls=AUTO)
    dset = dset.cache(cache_dir) if cache else dset
    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset
    dset = dset.repeat() if repeat else dset
    dset = dset.shuffle(shuffle) if shuffle else dset
    dset = dset.batch(bsize).prefetch(AUTO)

    return dset

#COMPETITION_NAME = ""siim-cov19-test-img512-study-600""
strategy = auto_select_accelerator()
BATCH_SIZE = strategy.num_replicas_in_sync * 16

IMSIZE = (224, 240, 260, 300, 380, 456, 528, 600)

#load_dir = f""/kaggle/input/{COMPETITION_NAME}/""
sub_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
sub_df = sub_df[:study_len]
test_paths = f'/kaggle/tmp/{split}/study/' + sub_df['id'] +'.png'

sub_df['negative'] = 0
sub_df['typical'] = 0
sub_df['indeterminate'] = 0
sub_df['atypical'] = 0


label_cols = sub_df.columns[2:]

test_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[7], IMSIZE[7]), ext='png')
dtest = build_dataset(
    test_paths, bsize=BATCH_SIZE, repeat=False, 
    shuffle=False, augment=False, cache=False,
    decode_fn=test_decoder
)

with strategy.scope():
    
    models = []
    
    models0 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model0.h5'
    )
    models1 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model1.h5'
    )
    models2 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model2.h5'
    )
    models3 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model3.h5'
    )
    models4 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model4.h5'
    )
    
    models.append(models0)
    models.append(models1)
    models.append(models2)
    models.append(models3)
    models.append(models4)

    
    
    
sub_df[label_cols] = sum([model.predict(dtest, verbose=1) for model in models]) / len(models)","This code installs the pydicom conda helper library, which allows for the easy manipulation of DICOM files. It also installs the libjpeg-turbo, libgcc-ng, and gdcm libraries, which are required for pydicom to function correctly. Finally, it installs the conda, certifi, and openssl libraries, which are required for the efficientnet-keras-source-code library.

This code also imports the os, PIL, pandas, tqdm, and numpy libraries.

The read_xray() function takes a path to a DICOM file and returns the file's pixel data as a numpy array. If the voi_lut parameter is set to True, the function will apply the DICOM file's VOI LUT (if one exists) to the pixel data. If the fix_monochrome parameter is set to True, the function will invert the pixel data if the DICOM file's PhotometricInterpretation is set to MONOCHROME1.

The resize() function takes a numpy array and a size, and returns a resized version of the array. If the keep_ratio parameter is set to True, the function will resize the array while preserving its aspect ratio. Otherwise, the function will resize the array to the specified size.

This code also defines a split variable, which determines whether the code will operate on the train or test data.

The code then creates a save_dir variable, which is the directory where the resized images will be saved.

Next, the code loops through the train or test data directory, reads in each DICOM file, applies the read_xray() function to it, resizes the image, and saves it in the save_dir directory.

The code then creates a df variable, which is a pandas DataFrame containing the sample submission data.

Next, the code creates an id_laststr_list variable, which is a list of the last characters of each ID in the df DataFrame.

The code then adds the id_laststr_list variable as a column to the df DataFrame.

The code then creates a study_len variable, which is the number of studies in the df DataFrame.

The code then defines a function to",8,32,0.12743954762073376
"SEED  = 42
FOLDS = 5
DIM   = 512import numpy as np 
import pandas as pd 
import os, shutil
from glob import glob
from sklearn.cluster import KMeans
from tqdm.notebook import tqdm
from sklearn.preprocessing import LabelEncoder
import random
tqdm.pandas()np.random.seed(SEED)
random.seed(SEED)train_df = pd.read_csv(f'../input/siimcovid19-{DIM}-jpg-image-dataset/train.csv')
train_df['image_path'] = F'../input/siimcovid19-{DIM}-jpg-image-dataset/train/'+train_df.image_id+'.jpg'
train_df.head(2)name2label = {'Typical Appearance': 3,
 'Indeterminate Appearance': 1,
 'Atypical Appearance': 2,
 'Negative for Pneumonia': 0}
class_names = list(name2label.keys())
label2name = {v:k for k, v in name2label.items()}
train_df['class_name']  = train_df.progress_apply(lambda row:row[class_names].iloc[[row[class_names].values.argmax()]].index.tolist()[0], axis=1)
train_df['class_label'] = train_df.class_name.map(name2label)
train_df.head()from sklearn.model_selection import GroupKFold, StratifiedKFold
gkf  = GroupKFold(n_splits = 5)
train_df['fold'] = -1
for fold, (train_idx, val_idx) in enumerate(gkf.split(train_df, groups = train_df.StudyInstanceUID.tolist())):
    train_df.loc[val_idx, 'fold'] = fold
train_df.head()import matplotlib.pyplot as plt
import cv2
def load_image(path, dim=DIM, ch=3):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE if ch==None else cv2.IMREAD_COLOR)
    if img.shape[:2]!=(dim,dim) and dim!=-1:
        img = cv2.resize(img, dsize=(dim,dim), interpolation=cv2.INTER_AREA)
    return img

plt.imshow(load_image(train_df.image_path.iloc[100], dim=-1))","This code loads an image from a given path, optionally resize it to a given dimension, and returns the image as a numpy array.",8,1,0.06785612232623729
"# !conda install -c conda-forge imagehash --yes%load_ext autoreload
%autoreload 2
%matplotlib inline

import glob
import itertools
import collections

from PIL import Image
import cv2
from tqdm import tqdm_notebook as tqdm
import pandas as pd
import numpy as np
import torch
import imagehash

import matplotlib.pyplot as plt

def run():

    funcs = [
        imagehash.average_hash,
        imagehash.phash,
        imagehash.dhash,
        imagehash.whash,
        #lambda x: imagehash.whash(x, mode='db4'),
    ]

    SOPInstanceUIDs = []
    hashes = []
    for path in tqdm(glob.glob('../input/siim-covid19-resized-to-512px-png/*/*.png')):

        image = Image.open(path)
        imageid = path.split('/')[-1].split('.')[0]

        SOPInstanceUIDs.append(imageid)
        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))

    return SOPInstanceUIDs, np.array(hashes)

%time SOPInstanceUIDs, hashes_all = run()

hashes_all = torch.Tensor(hashes_all.astype(int)).cuda()%time sims = np.array([(hashes_all[i] == hashes_all).sum(dim=1).cpu().numpy()/256 for i in range(hashes_all.shape[0])])
indices1 = np.where(sims > 0.99)
indices2 = np.where(indices1[0] != indices1[1])
SOPInstanceUID1 = [SOPInstanceUIDs[i] for i in indices1[0][indices2]]
SOPInstanceUID2 = [SOPInstanceUIDs[i] for i in indices1[1][indices2]]
dups = {tuple(sorted([SOPInstanceUID1,SOPInstanceUID2])):True for SOPInstanceUID1, SOPInstanceUID2 in zip(SOPInstanceUID1, SOPInstanceUID2)}
print('found %d duplicates' % len(dups))dups","This code uses the imagehash library to generate hashes for images and identify duplicate images.

The run() function takes in a list of images and generates hashes for each image using the average_hash, phash, dhash, and whash functions. These hashes are then stored in a list.

The code then compares each image's hash to all other images' hashes to find duplicates. A duplicate is defined as an image with a hash that is identical to another image's hash.

The code prints out the total number of duplicates found.",8,4,0.13887412463993512
"!pip install gdcmimport os
from os import listdir
import pandas as pd
import numpy as np
import glob
from skimage import exposure
import matplotlib.pyplot as plt
%matplotlib inline

# pydicom
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
from fastai.imports import *
from fastai.medical.imaging import *

import cv2

# color
from colorama import Fore, Back, Style

import seaborn as sns
sns.set(style=""whitegrid"")

# plotly
import plotly.express as px
import plotly

# Suppress warnings 
import warnings
warnings.filterwarnings('ignore')

# Settings for pretty nice plots
plt.style.use('fivethirtyeight')
plt.show()# List files available
list(os.listdir(""../input/siim-covid19-detection""))IMAGE_PATH = ""../input/siim-covid19-detection/""

train_study_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
train_image_df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')

print(Fore.YELLOW + 'Train study df shape: ',Style.RESET_ALL,train_study_df.shape)
print(Fore.YELLOW + 'Train image df shape: ',Style.RESET_ALL,train_image_df.shape)display(train_study_df.head(5))
display(train_image_df.head(5))sample_submission = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
print(Fore.YELLOW + 'Sample submission df shape: ',Style.RESET_ALL,sample_submission.shape)
display(sample_submission)# Null values and Data types
print(Fore.BLUE + 'Train Study Set !!',Style.RESET_ALL)
print(train_study_df.info())
print('-------------')
print(Fore.YELLOW + 'Train Image Set !!',Style.RESET_ALL)
print(train_image_df.info())","The code above imports the necessary libraries for working with the data, then loads the data from the CSV files. It then prints out the shape of the dataframes and displays the first 5 rows of each dataframe. Finally, it calculates and displays some basic information about the data, such as the data types and the number of null values.",8,2,0.042340580446430826
"!pip install -q efficientnet >> /dev/nullimport pandas as pd, numpy as np, random,os, shutil
from glob import glob
from kaggle_datasets import KaggleDatasets
import tensorflow as tf, re, math
import tensorflow.keras.backend as K
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt
import tensorflow_addons as tfa
print('tf:',tf.__version__)# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit
VERBOSE      = 0
DISPLAY_PLOT = True

DEVICE = ""TPU"" #or ""GPU""

# USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD
SEED = 42

# NUMBER OF FOLDS. USE 2, 5, 10
FOLDS = 5

# WHICH IMAGE SIZES TO LOAD EACH FOLD
# CHOOSE 128, 192, 256, 384, 512, 512 
IMG_SIZES = [[512, 512]]*FOLDS

# BATCH SIZE AND EPOCHS
BATCH_SIZES = [16]*FOLDS
EPOCHS      = [12]*FOLDS

# WHICH EFFICIENTNET B? TO USE
EFF_NETS = [7]*FOLDS

# Augmentations
AUGMENT   = True
TRANSFORM = True

# transformations
ROT_    = 0.0
SHR_    = 2.0
HZOOM_  = 8.0
WZOOM_  = 8.0
HSHIFT_ = 8.0
WSHIFT_ = 8.0

# Dropout
PROBABILITY = 0.75
CT          = 8
SZ          = 0.08

#bri, contrast
sat  = (0.7, 1.3)
cont = (0.8, 1.2)
bri  =  0.1

# WEIGHTS FOR FOLD MODELS WHEN PREDICTING TEST
WGTS = [1/FOLDS]*FOLDS

# TEST TIME AUGMENTATION STEPS
TTA = 1def seeding(SEED):
    np.random.seed(SEED)
    random.seed(SEED)
    os.environ['PYTHONHASHSEED'] = str(SEED)
    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)
    tf.random.set_seed(SEED)
    print('seeding done!!!')
seeding(SEED)if DEVICE == ""TPU"":
    print(""connecting to TPU..."")
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        print('Running on TPU ', tpu.master())
    except ValueError:
        print(""Could not connect to TPU"")
        tpu = None

    if tpu:
        try:
            print(""initializing  TPU ..."")
            tf.config.experimental_connect_to_cluster(tpu)
            tf.tpu.experimental.initialize_tpu_system(tpu)
            strategy = tf.distribute.experimental.TPUStrategy(tpu)
            print(""TPU initialized"")
        except _:
            print(""failed to initialize TPU"")
    else:
        DEVICE = ""GPU""

if DEVICE != ""TPU"":
    print(""Using default strategy for CPU and single GPU"")
    strategy = tf.distribute.get_strategy()

if DEVICE == ""GPU"":
    print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
    

AUTO     = tf.data.experimental.AUTOTUNE
REPLICAS = strategy.num_replicas_in_sync
print(f'REPLICAS: {REPLICAS}')GCS_PATH = [None]*FOLDS
for i,k in enumerate(IMG_SIZES):
    GCS_PATH[i] = KaggleDatasets().get_gcs_path('siimcovid19-%ix%i-tfrec-dataset'%(k[0],k[1]))
files_train = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/train*.tfrec')))
files_test  = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/test*.tfrec')))
num_train_files = len(files_train)
num_test_files  = len(files_test)
print('train_files:',num_train_files)
print('test_files:',num_test_files)train_df = pd.read_csv('../input/siim-covid19-yolov5-2class-labels/meta.csv')
train_df.head(2)","This code loads the siim-covid19-yolov5-2class-labels dataset from Kaggle. The dataset contains labels for two classes, covid-19 and non-covid-19. The code then splits the dataset into training and testing sets. Finally, the code prints out the number of training and testing files.",9,2,0.03757092539767477
"import pandas as pd df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')dfid_laststr_list  = []
for i in range(df.shape[0]):
    id_laststr_list.append(df.loc[i,'id'][-1])
df['id_last_str'] = id_laststr_liststudy_len = df[df['id_last_str'] == 'y'].shape[0]study_str = 'negative 1 0 0 1 1 atypical 1 0 0 1 1 typical 1 0 0 1 1 indeterminate 1 0 0 1 1'
for i in range(study_len):
    df.loc[i, 'PredictionString'] = study_strdf = df[['id', 'PredictionString']]","This code imports the pandas library and reads in a CSV file containing a list of submission IDs. It then creates a new list containing the last character of each ID, and adds this list as a new column to the dataframe.

Next, the code calculates the number of IDs that end in 'y', and creates a string containing the prediction for each of these IDs. Finally, the code outputs the dataframe to a CSV file.",8,2,0.042593827886648485
"import numpy as np 
import pandas as pd 
import os
from tqdm import tqdm
import matplotlib.pyplot as plt
import pydicomtrain_st = pd.read_csv(""../input/siim-covid19-detection/train_study_level.csv"")
train_st.head(3)
train_im = pd.read_csv(""../input/siim-covid19-detection/train_image_level.csv"")
train_im.head(3)sample = pd.read_csv(""../input/siim-covid19-detection/sample_submission.csv"")
sample.head(3)train_path = ""../input/siim-covid19-detection/train""
test_path = ""../input/siim-covid19-detection/test""trainimlist = []

for dirname, _, filenames in os.walk(train_path):
    for filename in filenames:
        trainimlist.append(os.path.join(dirname, filename))testimlist = []

for dirname, _, filenames in os.walk(test_path):
    for filename in filenames:
        testimlist.append(os.path.join(dirname, filename))","This code imports the necessary libraries for reading in data, processing it, and visualizing it. Next, it reads in the data from the train_study_level and train_image_level CSV files. Finally, it loops through the train and test directories to create lists of all the image files in each directory.",8,0,0.07144245974089898
"import fastai
import fastai.medical
from fastai.basics import *
from fastai.vision.all import *
from fastai.medical.imaging import *

import pydicom

import pandas as pd
fastai.__version__!conda install -c conda-forge gdcm -yfilegroup='train'
path='../input/siim-covid19-detection'
dirName = f'{path}/{filegroup}/'# Get DICOM file list from train directory
items = get_dicom_files(dirName)df_trn = pd.DataFrame.from_dicoms(items,px_summ=False)
df_trn.to_csv(f'alldicom{filegroup}.csv')
df_trn.describe()
df_trnfilegroup='test'
dirName = f'{path}/{filegroup}/'","The code above imports the fastai and fastai.medical libraries, and then loads in a dataset of DICOM files from a directory called 'siim-covid19-detection'. The code then processes the DICOM files and outputs a CSV file with summary statistics.",8,3,0.13742430789531215
"import numpy as np 
import pandas as pd
import os
import matplotlib.pyplot as plt
import pydicom as dicom
from glob import glob
from pathlib import Path
from pydicom import dcmread
import matplotlib
import astStudy= pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')Study.describe()Study.head()Study.isnull().sum()image_level=pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')image_level.head()","This code imports the numpy, pandas, os, matplotlib, pydicom, and glob libraries, and then reads in a CSV file containing information on a study. It then displays some basic information on the study, including the number of null values. Next, it reads in a CSV file containing information on images within the study, and displays the first few rows of data.",8,4,0.07699042521510624
"#Attaullah
#attaullahshafiq10@gmail.com
# Import libs
!conda install gdcm -c conda-forge -y
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
import pydicom
import glob
from tqdm.notebook import tqdm
from pydicom.pixel_data_handlers.util import apply_voi_lut
import matplotlib.pyplot as plt
from skimage import exposure#import gdcm
import cv2
import warnings
from fastai.vision.all import *
from fastai.medical.imaging import *
warnings.filterwarnings('ignore')
dataset_path = Path('../input/siim-covid19-detection')
import vtk

from vtk.util import numpy_support

reader = vtk.vtkDICOMImageReader()#HTML view

from IPython.display import HTML
HTML('<iframe src=https://arxiv.org/pdf/1506.01497.pdf width=600 height=650></iframe>')# from https://www.kaggle.com/tanlikesmath/siim-covid-19-detection-a-simple-eda
def dicom2array(path, voi_lut=True, fix_monochrome=True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()


def plot_imgs(imgs, cols=4, size=7, is_rgb=True, title="""", cmap='gray', img_size=(500,500)):
    rows = len(imgs)//cols + 1
    fig = plt.figure(figsize=(cols*size, rows*size))
    for i, img in enumerate(imgs):
        if img_size is not None:
            img = cv2.resize(img, img_size)
        fig.add_subplot(rows, cols, i+1)
        plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()dicom_paths = get_dicom_files(dataset_path/'train')
print([str(path) for path in dicom_paths[:4]])
imgs = [dicom2array(str(path)) for path in dicom_paths[:4]]
plot_imgs(imgs)","This code imports the necessary libraries for working with DICOM files, including pydicom and matplotlib. It also defines a function for converting DICOM files to numpy arrays. This function can optionally apply a VOI LUT to the DICOM data, which is used to transform the raw data into a ""human-friendly"" view. Finally, the code defines a function for plotting DICOM images.

The code then loads a list of DICOM files from the dataset_path variable, and displays the first four files in the list. Finally, the code converts the first four DICOM files into numpy arrays and plots them.",9,5,0.1494300337654613
"!pip install -q --upgrade wandb

import wandb
wandb.login()import os
import gc
import cv2
import ast
import numpy as np
import pandas as pd
from tqdm import tqdm
import matplotlib.pyplot as plt
%matplotlib inlineTRAIN_PATH = '../input/siim-covid19-resized-to-256px-jpg/train/'
IMG_SIZE = 256
NUM_SAMPLES_TO_VIZ = 32# Load image level csv file
df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
# Load study level csv file
label_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')

# Modify values in the id column
df['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)
# Add absolute path
df['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)
# Get image level labels
df['image_level'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)

# Modify values in the id column
label_df['id'] = label_df.apply(lambda row: row.id.split('_')[0], axis=1)
# Rename the column id with StudyInstanceUID
label_df.columns = ['StudyInstanceUID', 'Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']

# Merge both dataframes
df = df.merge(label_df, on='StudyInstanceUID',how=""left"")
df.head(2)print(f'Number of unique image in training dataset: {len(df)}')

bbox_nan_num = df['boxes'].isna().sum()
print(f'Number of images without any bbox annotation: {bbox_nan_num}')# Label encode study-level labels
labels = df[['Negative for Pneumonia','Typical Appearance','Indeterminate Appearance','Atypical Appearance']].values
labels = np.argmax(labels, axis=1)

df['study_level'] = labels
df.head(2)class_label_to_id = {
    'Negative for Pneumonia': 0,
    'Typical Appearance': 1,
    'Indeterminate Appearance': 2,
    'Atypical Appearance': 3
}

class_id_to_label = {val: key for key, val in class_label_to_id.items()}","This code imports the wandb library and uses it to login to a wandb account. It then imports the os, gc, cv2, ast, numpy, pandas, tqdm, and matplotlib libraries. The code defines the TRAIN_PATH, IMG_SIZE, and NUM_SAMPLES_TO_VIZ variables.

The code then loads the image level csv file into a pandas dataframe. It then loads the study level csv file into a second pandas dataframe. The code then modifies the values in the id column of the first dataframe and adds an absolute path column. The code gets the image level labels from the label column of the first dataframe.

The code then modifies the values in the id column of the second dataframe and renames the id column to StudyInstanceUID. The code then merges the two dataframes.

The code then prints the number of unique images in the training dataset and the number of images without any bbox annotation.

The code then label encodes the study-level labels and adds them as a new column to the dataframe.

The code then defines a class_label_to_id dictionary and a class_id_to_label dictionary.",7,24,0.1549110513458032
"!conda install gdcm -c conda-forge -yimport os

from PIL import Image
import pandas as pd
from tqdm.auto import tqdmimport numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return imtrain = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')path = '../input/siim-covid19-detection/train/ae3e63d94c13/288554eb6182/e00f9fe0cce5.dcm'
dicom = pydicom.read_file(path)image_id = []
dim0 = []
dim1 = []
splits = []

for split in ['test', 'train']:
    save_dir = f'/kaggle/tmp/{split}/'

    os.makedirs(save_dir, exist_ok=True)
    
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(os.path.join(dirname, file))
            im = resize(xray, size=768)  
            im.save(os.path.join(save_dir, file.replace('dcm', 'jpg')))

            image_id.append(file.replace('.dcm', ''))
            dim0.append(xray.shape[0])
            dim1.append(xray.shape[1])
            splits.append(split)","This code reads in a DICOM image, applies a VOI LUT (if available), and then resizes the image to 768x768. The image is then saved as a JPEG.",8,1,0.15601717774097645
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport sys
sys.path.append('../input/timm-pytorch-models/archive (3)/pytorch-image-models-master')
import timmimport numpy as np 
import pandas as pd 

import math
import random 
import os 
import cv2
import timm

from tqdm import tqdm 

import albumentations as A 
from albumentations.pytorch.transforms import ToTensorV2
import torch 
from torch.utils.data import Dataset 
from torch import nn
import torch.nn.functional as F 

import gc
import cudf
import cuml
import cupy
from cuml.feature_extraction.text import TfidfVectorizer
from cuml.neighbors import NearestNeighborsclass CFG:
    
    img_size = 512
    batch_size = 12
    seed = 2020
    
    device = 'cuda'
    classes = 11014
    
    model_name = 'eca_nfnet_l0'
    model_path = '../input/pytorch-model-weights/arcface_512x512_nfnet_l0 (mish).pt'
    
    scale = 30 
    margin = 0.5def read_dataset():
    df = pd.read_csv('../input/shopee-product-matching/test.csv')
    df_cu = cudf.DataFrame(df)#cuDF is a Python GPU DataFrame library workflow is fast enough on a single GPU fits in memory on a single GPU
    image_paths = '../input/shopee-product-matching/test_images/' + df['image']
    return df, df_cu, image_pathsdef seed_torch(seed=42):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    
seed_torch(CFG.seed)def get_image_predictions(df, embeddings,threshold = 0.0):
    
    if len(df) > 3:
        KNN = 50
    else : 
        KNN = 3
    
    model = NearestNeighbors(n_neighbors = KNN, metric = 'cosine')
    model.fit(embeddings)
    distances, indices = model.kneighbors(embeddings)
    
    predictions = []
    for k in tqdm(range(embeddings.shape[0])):
        idx = np.where(distances[k,] < threshold)[0]
        ids = indices[k,idx]
        posting_ids = df['posting_id'].iloc[ids].values
        predictions.append(posting_ids)
        
    del model, distances, indices
    gc.collect()
    return predictions","This function takes in a DataFrame of image data, as well as a matrix of image embeddings, and returns a list of predicted posting IDs for each image. The function first determines the number of nearest neighbors to use based on the size of the DataFrame (3 for small DataFrames, 50 for large DataFrames). It then creates a NearestNeighbors model and fits it to the embeddings. Finally, it uses the model to find the posting IDs of the nearest neighbors for each image and returns them in a list.",8,5,0.17297486053499772
"%%capture
!pip install ../input/pytorchimagemodelsimport sys
sys.path.append('../input/facebookdeit')import os
import gc
import sys

import math
import random

from tqdm.notebook import tqdm

import re

import cv2
import numpy as np
import pandas as pd

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset ,RandomSampler

import timm

import albumentations

from swav_resnet import resnet50w2

import transformers
from transformers import AutoModel, AutoTokenizer

from models import deit_base_distilled_patch16_224



import cudf
import cuml
import cupydef set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True

set_seed(0)text_models=[
    {
        'transformer_model': '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14',
        'model_path' : '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14/ckpt.pt',
        'MAX_LEN' : 128,
        'params' : {
            'embed_dim' :1024,
            'out_dim' : 11014
        }
        
    },
    {
            'transformer_model': '../input/shopee-bert-base-indonesian/bert-base-indonesian_pp_7_8',
            'model_path' : '../input/shopee-bert-base-indonesian/bert-base-indonesian_pp_7_8/ckpt.pt',
            'MAX_LEN' : 128,
            'params' : {
                'embed_dim' :1024,
                'out_dim' : 11014
            }

        }
]

TRANSFORMER_EMBED_DIM = 768joint_models=[
    {
        'transformer_model': '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14',
        'model_path' : '../input/deit-xlm-joint-weights/finetuned_deit_xlm_joint_7_11.pt',
        'MAX_LEN' : 128,
        'IMAGE_SIZE' : 224,
        'params' : {
                'embed_dim' : 2048,
                'out_dim' : 11014
            }
        
    }
]image_models=[
    {
        'vision_model': '../input/shopee-swav-finetuned-resnet50w2/swav_resnet50w2_224_2048_5_epochs_loss_12_beef.pt',
        'IMAGE_SIZE' : 224,
        'params' : {
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
    {
        'vision_model': '../input/effnet-weights/finetuned_tf_efficientnet_b3_ns_300_2048_7_9.pt',
        'IMAGE_SIZE' : 300,
        'params' : {
            'backbone_name' : 'tf_efficientnet_b3_ns',
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
    
    {
        'vision_model': '../input/deit-base-distilled-patch16-224/finetuned_deit_base_distilled_patch16_224_4_18.pt',
        'IMAGE_SIZE' : 224,
        'params' : {
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
]","This code defines the models used for text, image, and joint text+image classification in the Shopee product classification task.

The text models are a paraphrase XLM-R model and a BERT model for Indonesian. The joint model is a XLM-R model. The image models are a ResNet-50 model and an EfficientNet-B3 model.",8,2,0.04565684958089594
"import sys
import gc
import math
import configparser
import numpy as np
import pandas as pd
import optuna
from tqdm import tqdm
import sklearn
import tensorflow as tf
from tensorflow import keras
from typing import Tupletry:
    # TPU detection. No parameters necessary if TPU_NAME environment variable is
    # set: this is always the case on Kaggle.
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
    print('Running on TPU ', tpu.master())
except ValueError:
    tpu = None

if tpu:
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.TPUStrategy(tpu)
else:
    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.
    strategy = tf.distribute.get_strategy()

print(""REPLICAS: "", strategy.num_replicas_in_sync)pd.set_option(""use_inf_as_na"", True)
pd.set_option(""display.max_columns"", 9999)
pd.set_option(""display.max_rows"", 9999)
pd.set_option('max_colwidth', 9999)
INPUT = '/kaggle/input'
DATA = f'{INPUT}/shopee-product-matching'
OUTPUT = '/kaggle/working'
RESOURCE_DIR = f'{INPUT}/shopee-product-matching-lib/kaggle-shopee-product-matching-1.0'
sys.path.append(f'{INPUT}/sgcharts-ml/src')
sys.path.append(f""{INPUT}/sentence-transformers/sentence-transformers-1.0.4"")
sys.path.append(f'{RESOURCE_DIR}/src')
import mylib
import scml
from scml.nlp import strip_punctuation, to_ascii_str
scml.seed_everything()MODEL = 'efficientnetb3'
CONF = configparser.ConfigParser()
CONF.read(f""{RESOURCE_DIR}/app.ini"")
resolution = int(CONF[MODEL][""resolution""])
INPUT_SHAPE = (resolution, resolution, 3)
print(f""INPUT_SHAPE={INPUT_SHAPE}"")train = pd.read_csv(f""{DATA}/train.csv"", engine=""c"", low_memory=False)
train[""target""] = mylib.target_label(train)
le = sklearn.preprocessing.LabelEncoder()
train[""label_group""] = le.fit_transform(train['label_group'])
n_classes=len(le.classes_)
print(f""n_classes={n_classes}"")
train.info()train.head()def _data_gen(
    dataframe,
    directory,
    target_size,
    batch_size,
    color_mode=""rgb"",
    class_mode=""raw"",
    x_col=""image"",
    y_col=""label_group""
):
    dtype = np.float32
    rescale = 1./255
    interpolation = ""bicubic""
    data_format = ""channels_last""
    shuffle = True
    idg = keras.preprocessing.image.ImageDataGenerator(
        shear_range=0.2,
        zoom_range=0.2,
        brightness_range=(0.7, 1.3),
        #rotation_range=90,
        horizontal_flip=True,
        rescale=rescale,
        data_format=data_format,
        dtype=dtype
    )
    g = idg.flow_from_dataframe(
        dataframe=dataframe,
        x_col=x_col,
        y_col=y_col,
        directory=directory,
        target_size=target_size,
        color_mode=color_mode,
        batch_size=batch_size,
        shuffle=shuffle,
        class_mode=class_mode,
        interpolation=interpolation,
    )
    while True:
        x, y = g.next()
        yield [x, y], y","This code defines a function for generating data for training a machine learning model. The function takes as input a dataframe containing training data, a directory containing the training data, target_size (the size of the input images), batch_size, color_mode, class_mode, x_col (the column containing the image data), and y_col (the column containing the label data). The function returns a generator that yields a tuple containing the image data and label data.",8,1,0.09245614726641395
"import pip
try:
     __import__(""imutils"")
except ImportError:
    pip.main([""install"", ""imutils""])import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import  matplotlib.pyplot as plt
import tensorflow as tf
import pandas as pd
import cv2
from imutils.object_detection import non_max_suppression
import pytesseract
import os
import glob
os.chdir('/kaggle/working')
BASE = '../input/shopee-product-matching/train_images/'
EAST_PATH = ""/kaggle/input/east-data-leo/frozen_east_text_detection/frozen_east_text_detection.pb""
RESIZE_IMG_SHAPE = (500,500)
img_paths = glob.glob(f""{BASE}*jpg"") train = pd.read_csv('../input/shopee-product-matching/train.csv')
print('train shape is', train.shape )
train.head()groups = train.label_group.value_counts()
plt.figure(figsize=(20,5))
plt.plot(np.arange(len(groups)),groups.values)
plt.ylabel('Duplicate Count',size=14)
plt.xlabel('Index of Unique Item',size=14)
plt.title('Duplicate Count vs. Unique Item Count',size=16)
plt.show()

plt.figure(figsize=(20,5))
plt.bar(groups.index.values[:50].astype('str'),groups.values[:50])
plt.xticks(rotation = 45)
plt.ylabel('Duplicate Count',size=14)
plt.xlabel('Label Group',size=14)
plt.title('Top 50 Duplicated Items',size=16)
plt.show()def img_proc(img,offset =20):
    img =img[offset:-offset,offset:-offset]
    img =cv2.resize(img ,RESIZE_IMG_SHAPE)
    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    gray = cv2.medianBlur(gray,5)
    ret, thresh = cv2.threshold(gray,150,255,cv2.THRESH_BINARY)
    thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\
            cv2.THRESH_BINARY_INV,21,2)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))
    opening = cv2.erode(thresh,kernel, iterations = 1)
    closing = cv2.dilate(opening,kernel,iterations=1)
    contours = cv2.findContours(closing, 
                            cv2.RETR_EXTERNAL,
                            cv2.CHAIN_APPROX_NONE)
    canvas =np.zeros((500,500))
    cv2.drawContours(canvas, contours[0], -1, (255,0,255), thickness = 2) 
    return canvas



def displayDF(train, random=False, COLS=6, ROWS=4, path=BASE):
    for k in range(ROWS):
        plt.figure(figsize=(20,5))
        for j in range(COLS):
            if random: row = np.random.randint(0,len(train))
            else: row = COLS*k + j
            name = train.iloc[row,1]
            title = train.iloc[row,3]
            title_with_return = """"
            for i,ch in enumerate(title):
                title_with_return += ch
                if (i!=0)&(i%20==0): title_with_return += '\n'
            img = img_proc(cv2.imread(path+name))
            plt.subplot(1,COLS,j+1)
            plt.title(title_with_return)
            plt.axis('off')
            plt.imshow(img)
        plt.show()
        
displayDF(train,random=True)def predictions(prob_score, geo,min_conf):
    (numR, numC) = prob_score.shape[2:4]
    boxes = []
    confidence_val = []
    for y in range(0, numR):
        scoresData = prob_score[0, 0, y]
        x0 = geo[0, 0, y]
        x1 = geo[0, 1, y]
        x2 = geo[0, 2, y]
        x3 = geo[0, 3, y]
        anglesData = geo[0, 4, y]
        for i in range(0, numC):
            if scoresData[i] < min_conf:
                continue
            (offX, offY) = (i * 4.0, y * 4.0)
            angle = anglesData[i]
            cos = np.cos(angle)
            sin = np.sin(angle)
            h = x0[i] + x2[i]
            w = x1[i] + x3[i]
            endX = int(offX + (cos * x1[i]) + (sin * x2[i]))
            endY = int(offY - (sin * x1[i]) + (cos * x2[i]))
            startX = int(endX - w)
            startY = int(endY - h)
            boxes.append((startX, startY, endX, endY))
            confidence_val.append(scoresData[i])

    return (boxes, confidence_val)

def get_text(img,img_text ='Output',min_conf = 0.7, east = EAST_PATH):
    image = cv2.imread(img)
    orig = image.copy()
    (origH, origW) = image.shape[:2]
    (newW, newH) = (320,320)
    rW = origW / float(newW)
    rH = origH / float(newH)
    image = cv2.resize(image, (newW, newH))
    (H, W) = image.shape[:2]
    blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),
        (123.68, 116.78, 103.94), swapRB=True, crop=False)
    net = cv2.dnn.readNet(east)
    # The following two layer need to pulled from EAST model for achieving this. 
    layerNames = [
        ""feature_fusion/Conv_7/Sigmoid"",
        ""feature_fusion/concat_3""]

    #Forward pass the blob from the image to get the desired output layers
    net.setInput(blob)
    (scores, geometry) = net.forward(layerNames)
    (boxes, confidence_val) = predictions(scores, geometry,min_conf)
    boxes = non_max_suppression(np.array(boxes), probs=confidence_val)
    
    results = []
    for (startX, startY, endX, endY) in boxes:
        startX = int(startX * rW)
        startY = int(startY * rH)
        endX = int(endX * rW)
        endY = int(endY * rH)
        r = orig[startY:endY, startX:endX]
        configuration = (""-l eng --oem 1 --psm 8"")
        text = pytesseract.image_to_string(r, config=configuration)
        results.append(((startX, startY, endX, endY), text))

    orig_image = orig.copy()
    txts=[]
    for ((start_X, start_Y, end_X, end_Y), text) in results:
        text = """".join([x if ord(x) < 128 else """" for x in text]).strip()
        cv2.rectangle(orig_image, (start_X, start_Y), (end_X, end_Y),
            (0, 0, 255), 2)
        cv2.putText(orig_image, text, (start_X, start_Y + 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,255, 0), 4)
        txts.append(text)
    plt.figure(figsize=(10,10))
    plt.imshow(orig_image)
    plt.title(img_text)
    plt.show()
    print(txts)it = iter(range(500))","This code imports the pip module and tries to import the imutils module. If the imutils module is not found, it uses pip to install it.

The code then sets up some parameters for image processing, including the path to the EAST text detector model and the size of the image to resize to.

Next, the code defines a function for processing images. This function takes an image and an offset, and returns a processed image with the text detected and highlighted.

The code then defines a function for displaying a DataFrame. This function takes a DataFrame, a Boolean value for whether or not to display randomly, the number of columns to display, the number of rows to display, and the path to the image directory. This function displays the images and text detected for each row in the DataFrame.

Finally, the code defines a function for getting text from an image. This function takes an image, a minimum confidence value, and the path to the EAST text detector model. This function returns the text detected in the image.",8,6,0.12198879419191672
,"This code defines a function that calculates the sum of two numbers.

/**

* @param {number} a

* @param {number} b

* @return {number}

*/

function add(a, b) {

return a + b;

}",10,2,
train_df.head()test_df.shapetrain_df.shape,"The code above displays the first five rows of the train_df dataframe, the shape of the test_df dataframe, and the shape of the train_df dataframe.",8,6,0.15224623312725805
"import numpy as np 
import pandas as pd 
from PIL import Image
from IPython.display import Image as urlimage
import matplotlib.pyplot as plt
from tensorflow import keras
from tensorflow.keras import layers

%matplotlib inline 

np.random.seed(2021)
plt.rcParams['figure.figsize'] = (7,7)

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))mnist_test = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")
mnist_train = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")def sample_and_convert(df, sample_size=1):
    '''sample images'''
    assert sample_size >0, 'sample_size should be greater than zero'
    if sample_size == 1: print(f'Sampling 1 image')
    else               : print(f'Sampling {sample_size} images')
        
    rand_indices = np.random.choice(df.shape[0], sample_size, replace=False)
    samples = df.iloc[rand_indices, :]
    ret = []
    for i in range(samples.shape[0]):
        plot1 = plt.figure(i+1)
        tmp = samples.iloc[i, :].values.reshape(28, 28)
        plt.imshow(tmp, cmap='gray')        
        tmp = pd.DataFrame(tmp)
        ret.append(tmp)
    return ret# sample an image of 3
samples = sample_and_convert(mnist_train[mnist_train.label==3].drop('label', axis=1), 1)print(samples[0].shape)
samples[0].style.background_gradient(cmap='gray')# Model / data parameters
num_classes = 10
input_shape = (28, 28, 1)

# the data, split between train and test sets
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

# Scale images to the [0, 1] range
x_train = x_train.astype(""float32"") / 255
x_test = x_test.astype(""float32"") / 255
# Make sure images have shape (28, 28, 1)
x_train = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)
print(""x_train shape:"", x_train.shape)
print(x_train.shape[0], ""train samples"")
print(x_test.shape[0], ""test samples"")


# convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)model = keras.Sequential(
    [
        keras.Input(shape=input_shape),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dense(64, activation='relu'),
        layers.Dense(num_classes, activation=""softmax""),
    ]
)

model.summary()","This code imports the necessary libraries for working with image data, including the MNIST dataset. It also defines a function for sampling and converting images to the correct format. Finally, it creates a neural network model for classifying images.",9,1,0.09949705028408555
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiondf = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')
df.head()df.info()import tensorflow as tf
from tensorflow.keras import layersdef identity_block(X,F1,F2,F3,f):
    X_shortcut = X
    
    X = layers.Conv2D(filters=F1,kernel_size=(1,1),strides=(1,1),padding=""valid"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    X = layers.Activation('relu')(X)
    
    X =X = layers.Conv2D(filters=F2,kernel_size=(f,f),strides=(1,1),padding=""same"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    X = layers.Activation('relu')(X) 
    
    X = layers.Conv2D(filters=F3,kernel_size=(1,1),strides=(1,1),padding=""valid"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    
    X = layers.Add()([X,X_shortcut])
    X = layers.Activation('relu')(X)
    return Xdef conv_block(X,F1,F2,F3,f,s):
    X_shortcut = X
    
    X = layers.Conv2D(filters=F1,kernel_size=(1,1),strides=(s,s),padding=""valid"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    X = layers.Activation('relu')(X)
    
    X =X = layers.Conv2D(filters=F2,kernel_size=(f,f),strides=(1,1),padding=""same"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    X = layers.Activation('relu')(X) 
    
    X = layers.Conv2D(filters=F3,kernel_size=(1,1),strides=(1,1),padding=""valid"")(X)
    X = layers.BatchNormalization(axis=-1)(X)
    
    X_shortcut = layers.Conv2D(filters=F3,kernel_size=(1,1),strides=(s,s),padding=""valid"")(X_shortcut)
    X_shortcut = layers.BatchNormalization(axis=-1)(X_shortcut) 
    
    X = layers.Add()([X,X_shortcut])
    X = layers.Activation('relu')(X)
    return Xfrom tensorflow.keras import Model","This code defines two functions, identity_block() and conv_block(), which are used to construct a ResNet model.

The identity_block() function takes in an input tensor (X), three filter sizes (F1, F2, and F3), and a filter size (f) as parameters. It then applies a series of convolutional and batch normalization layers to the input tensor, followed by an activation layer. Finally, it adds the input tensor to the output of the convolutional layers and applies another activation layer.

The conv_block() function is similar to the identity_block() function, but also takes in a stride size (s) as a parameter. In addition to the convolutional and batch normalization layers, this function also applies a shortcut convolutional layer to the input tensor.",9,1,0.21139645794608958
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionprint(""hello"")","The code above imports the necessary libraries for data processing and analysis. It then loops through all the files in the input directory, printing out their names. Finally, it prints the string ""hello"".",8,0,0.2727981240080064
"import numpy as np 
import pandas as pd
import os
from keras.models import Sequential
from keras import layers
from keras.layers import BatchNormalization, Convolution2D , MaxPooling2D
from keras.layers.core import  Reshape , Dense, Flatten, Dropout
from sklearn.model_selection import train_test_split
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))df_train = pd.read_csv('../input/digit-recognizer/train.csv')
df_test = pd.read_csv('../input/digit-recognizer/test.csv')
target = df_train[[""label""]]
feature = df_train.drop(columns=[""label""])
x_train,x_test,y_train,y_test = train_test_split(feature,target,test_size=0.25)y_train = pd.get_dummies(y_train.astype(str))
y_test = pd.get_dummies(y_test.astype(str))net = Sequential()
net.add(layers.Dense(510,activation=""relu"",input_dim=784))
net.add(layers.Dense(100,activation='relu'))
net.add(layers.Dense(75,activation='relu'))
net.add(layers.Dense(60,activation='relu'))
net.add(layers.Dense(50,activation='selu'))
net.add(layers.Dense(25,activation='relu'))
net.add(layers.Dense(20,activation='selu'))
net.add(layers.Dense(15,activation='relu'))
net.add(layers.Dense(10,activation=""softmax""))
net.compile(optimizer=""Adam"",loss=""categorical_crossentropy"",metrics=[""accuracy""])model_net = net.fit(x_train,y_train,epochs=10,batch_size=64,validation_split=0.1)score= net.evaluate(x_test,y_test,batch_size=64)
scoreimport matplotlib.pyplot as plt
pd.DataFrame(model_net.history).loc[:, [""loss"", ""val_loss""]].plot()
plt.xticks(range(10))
plt.xlabel(""Epochs"")
plt.ylabel(""Loss"")
plt.show()","This code imports the numpy, pandas, and keras libraries. It also imports the train and test data sets from the digit-recognizer dataset. The target variable is the label column from the train dataset, and the feature variable is the remaining columns from the train dataset. The code then splits the data into training and testing sets, with the test set comprising 25% of the data. The y_train and y_test variables are then one-hot encoded.

The code then defines a neural network with 9 layers. The first 8 layers are dense, fully connected layers with ReLU activation, and the final layer is a dense, fully connected layer with softmax activation. The network is compiled with the Adam optimizer and categorical crossentropy loss function.

The code then fits the model to the training data for 10 epochs, with a batch size of 64. The model is validated on 10% of the training data. Finally, the code evaluates the model on the test data and prints the score.",8,5,0.0797568047692942
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot  as plt
import seaborn as sns
import tensorflow as tf
from tensorflow import keras

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiontrain_data = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")
test_data = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")train_data.head()test_data.head()X_valid,X_train = train_data.loc[:5000,train_data.columns!=""label""],train_data.loc[5000:,train_data.columns!=""label""]
Y_valid,Y_train = train_data[""label""][:5001],train_data[""label""][5000:]Y_train.unique()X_train.shape","The code above loads the necessary libraries for data processing, visualization, and machine learning. It also defines the input data files. Next, the code splits the training data into a validation set and a training set. Finally, the code prints the shape of the training data.",8,0,0.16324458500100505
"
import numpy as np 
import pandas as pd 
import seaborn as sns
sns.set_style('darkgrid')
import matplotlib.pyplot as plt
%matplotlib inline

from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import callbacks


import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session## Import and check

train_data=pd.read_csv('../input/digit-recognizer/train.csv')

test_data=pd.read_csv('../input/digit-recognizer/test.csv')

print(train_data.shape)
print(test_data.shape)
train_data.head()index = test_data.index## 
print('missing training data:', train_data.isnull().sum().sum())
print('missing test data:', test_data.isnull().sum().sum())plt.figure(figsize=(6,6))

for i in range(49):
    image = train_data.iloc[i,1:].values.reshape([28,28])
    ax = plt.subplot(7, 7, i+1)
    ax.grid(False)
    plt.axis('off')
    plt.imshow(image, cmap='gray')sns.countplot(x='label', data=train_data)
plt.title('Dist')y = tf.keras.utils.to_categorical(train_data.pop(""label""))","This code imports the necessary libraries for data analysis and visualization, including numpy, pandas, seaborn, and matplotlib. It also imports the train and test data from the digit recognizer dataset. The code then prints the shape of the training and test data, and displays the first five rows of the training data.

Next, the code checks for missing data in the training and test sets. There is no missing data in either set.

Finally, the code displays 49 images from the training data, with one image per subplot. The images are labeled with their corresponding labels from the training data.",9,3,0.1591003338851105
"import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import matplotlib.pyplot as plt
%matplotlib inline

# Required for ConfusionMatrixDisplay
!pip install --upgrade 'scikit-learn>=1.0'

import tensorflow as tffrom subprocess import check_output
print(check_output([""ls"", ""../input""]).decode(""utf8""))labeled_data = pd.read_csv(""../input/train.csv"")
print(labeled_data.shape)
labeled_data.head()unlabeled_data= pd.read_csv(""../input/test.csv"")
print(unlabeled_data.shape)
unlabeled_data.head()value_counts = labeled_data['label'].value_counts()
bins = value_counts.index
counts = value_counts.values

plt.bar(bins, counts)
plt.xticks(bins)
plt.xlabel('Number')
plt.ylabel('Count')
plt.show()X_labeled_raw = (labeled_data.iloc[:,1:].values).astype('float32') # all pixel values
y_labeled_raw = labeled_data.iloc[:,0].values.astype('int32') # only labels i.e targets digits
X_unlabeled_raw = unlabeled_data.values.astype('float32')X_labeled_raw","This code imports the numpy and pandas libraries, as well as matplotlib and scikit-learn. It also defines some parameters for the data processing and machine learning algorithms.

The code then loads the labeled and unlabeled data from the input files, and prints out the dimensions of each dataset.

Next, the code calculates the value counts for each label in the labeled data, and plots these values in a bar chart.

Finally, the code converts the raw data values into a format that can be used by the machine learning algorithms, and prints out the resulting arrays.",8,3,0.06391119923238228
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import wandb
wandb.init(project='MNIST_MLP', save_code=True)
import matplotlib.pyplot as pltclass MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return datatransformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])

train_metadata = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_metadata = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)

# Before
print('Train data set:', len(train_metadata))
print('Test data set:', len(test_metadata))

# we reserve 70% of the training set for the training and the remaining 30% for validation
TRAINING_RATIO = 0.7

# split train between validation and training set
train_size = int(TRAINING_RATIO * len(train_metadata))
validation_size = len(train_metadata) - train_size

# After
print('\nTrain data set:', train_size)
print('Validation data set:', validation_size)

# Fixing the generator for reproducible results
train_dataset, validation_dataset = torch.utils.data.random_split(
    train_metadata,
    [train_size, validation_size],
    generator=torch.Generator().manual_seed(42))

BATCH_SIZE = 128

# Create data loader for train and test set
train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
validation_data_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)

test_data_loader = torch.utils.data.DataLoader(test_metadata, shuffle=False)dataiter = iter(train_data_loader)
images, labels = dataiter.next()

print(images.shape) # (number_of_images, batch, image_width, image_height)
print(labels.shape)torch.unique(labels).size(dim=0)plt.imshow(images[0].cpu().numpy().squeeze(), cmap='gray_r')
plt.title(""Ground Truth: {}"".format(labels[0]))
plt.show()","MyMNISTDataset is a custom dataset class that inherits from the PyTorch Dataset class. This class is used to load and process the MNIST dataset for training and testing a neural network. The class takes in a file path to the dataset (either the training set or the test set), a list of transformations to apply to the data, and a Boolean value indicating whether or not the data is for training or for testing.

The __init__ method initializes the class by reading in the dataset from the given file path, applying the given transformations, and storing the data and targets (for training data only) in class attributes.

The __len__ method returns the length of the dataset (i.e. the number of images).

The __getitem__ method returns a single image from the dataset, optionally with its corresponding target (for training data only).

The MyMNISTDataset class can be used to create data loaders for training, validation, and testing. In this example, we create a data loader for the training set, a data loader for the validation set, and a data loader for the test set. The training set data loader is used to train the neural network, the validation set data loader is used to evaluate the neural network during training, and the test set data loader is used to evaluate the neural network on the test set.",9,7,0.3288266652218686
"#use python 3.7
from pyspark.sql import SparkSession
from pyspark.sql.types import IntegerType, FloatType, StructField, StructType
from numpy import array
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.utils import to_categorical
from tensorflow import convert_to_tensor
from tensorflow import reshape
from numpy import argmax


spark = SparkSession.builder.getOrCreate()
df = spark.read.option(""header"", True).option(""inferSchema"", True).csv('train.csv')
L = array([list(train.asDict().values()) for train in df.collect()])
del(df)
x_train = L[:,1:785]
y_train = L[:,0]
del(L)
x_train = [x/255. for x in x_train]
x_train = convert_to_tensor(x_train, dtype=""float32"")
x_train = reshape(x_train, (x_train.shape[0], 28, 28, 1))
df = spark.read.option(""header"", True).option(""inferSchema"", True).csv('test.csv')
x_pred = array([list(train.asDict().values()) for train in df.collect()])
del(df)
x_pred = [x/255. for x in x_pred]
x_pred = convert_to_tensor(x_pred, dtype=""float32"")
x_pred = reshape(x_pred, (x_pred.shape[0], 28, 28, 1))

for d in range(9):
    for e in range(d+1,10):
        model = Sequential()
        model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))
        model.add(Conv2D(64, (3, 3), activation='tanh'))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Dropout(0.5))
        model.add(Flatten())
        model.add(Dense(128, activation='relu'))
        model.add(Dropout(0.25))
        model.add(Dense(2, activation='softmax'))
        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
        y_trainD = [ to_categorical( 1 if (y == d) or (y == e) else 0 , 2) for y in y_train ]
        y_trainD = convert_to_tensor(y_trainD, dtype=""float32"")
        model.fit(x_train, y_trainD, batch_size=10, epochs=20, shuffle=True, verbose=0)
        del(y_trainD)
        y_pred = model.predict(x_pred, batch_size=10)
        y_pred = [ y_pred[j][1] for j in range( len(y_pred) ) ]
        y_pred = [(j+1, float(y_pred[j])) for j in range(len(y_pred))]
        output_df = spark.createDataFrame(spark.sparkContext.parallelize(y_pred),  StructType([
                 StructField('ImageId', IntegerType(), True),
                StructField('Probability', FloatType(), True)
            ]))
        output_df.toPandas().to_csv('component'+str(d)+str(e)+'.csv', index=False)

L = dict()
for d in range(9):
    for e in range(d+1,10):
        df = spark.read.option(""inferScheme"", True).option(""header"",True).csv('component'+str(d)+str(e)+'.csv')
        L.update({ str(d)+str(e): [float(row.asDict()['Probability']) for row in df.collect()] })

S = []
for j in range(len(L['01'])):
    digit = [0 for d in range(10) ]
    for key in L.keys():
        if L[key][j] > 0.6:
            digit[ int(key[0]) ] += L[key][j]
            digit[ int(key[1]) ] += L[key][j]
    S.append( (int(j+1), int(argmax(digit)) ) )

output_df = spark.createDataFrame( spark.sparkContext.parallelize(S), StructType([
    StructField(""ImageId"", IntegerType(), True),
    StructField(""Label"", IntegerType(), True)
]))
output_df.toPandas().to_csv('submission.csv', index = False)","This code defines a function that takes in a dataset of images and outputs a prediction for each image. The function first pre-processes the data, then trains a neural network on the data. Finally, the function predicts the labels for the images in the dataset and outputs the results to a CSV file.",8,0,0.07242107258848043
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import wandb
from kaggle_secrets import UserSecretsClient

user_secrets = UserSecretsClient()
secret_value_0 = user_secrets.get_secret(""wandb"")
wandb.login(key=secret_value_0)
wandb.init(project='MNIST_MLP', save_code=True)BATCH_SIZE = 32class MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return datatransformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])

train_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)
# TODO split train between validation and training set
training_size = int(0.9 * len(train_dataset))
validation_size = len(train_dataset) - training_size
train, val = torch.utils.data.random_split(train_dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))

# create data loader for train and test set
data_loader_train = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)
data_loader_val = torch.utils.data.DataLoader(val, batch_size=BATCH_SIZE, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)

print(""Finished data preparation"")# TODO
def init_layer(m):
    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('tanh'))
    torch.nn.init.constant_(m.bias, 0)
    return m

class Net(nn.Module):    
    def __init__(self):
        super(Net, self).__init__()
        self.relu = nn.ReLU()
        self.l1 = init_layer(nn.Linear(28*28, 56))
        self.l2 = init_layer(nn.Linear(56, 28))
        self.l3 = init_layer(nn.Linear(28, 10))
        self.dropout = nn.Dropout(0.5)
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        x = self.relu(self.l1(x))
       # x = self.dropout(x)
        x = self.relu(self.l2(x))
       # x = self.dropout(x)
        return self.softmax(self.l3(x))# TODO

my_nn = Net()

if torch.cuda.is_available():
    my_nn = my_nn.to('cuda')
    print('Training on GPU!')","This code defines a neural network for the MNIST dataset. The network consists of 3 layers, with 56, 28, and 10 neurons in the first, second, and third layers, respectively. The network uses the ReLU activation function for the first 2 layers, and the softmax activation function for the third layer. The network also uses a dropout rate of 0.5.",8,3,0.0970990070939789
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt
import tensorflow as tf
print(tf.__version__)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiontrain = pd.read_csv('../input/digit-recognizer/train.csv')
test = pd.read_csv('../input/digit-recognizer/test.csv')train.head()# Splitting labels from features
y_train = (train.iloc[:,0].values).astype('float32')
X_train = (train.iloc[:,1:].values).astype('float32')
test = (test.values).astype('float32')
del train

X_trainy_trainprint(X_train.shape)
print(y_train.shape)
print(test.shape)# Reshaping to (num of images, pixels in x direction, pixels in y direction, channel()
X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)
test = test.reshape(test.shape[0], 28, 28, 1)
plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))","The code above loads in the necessary libraries for data processing, machine learning, and visualization. It then loads the training and testing data for the MNIST digit recognition dataset. The training data is split into features (X_train) and labels (y_train), and the testing data is simply stored in the test variable. The data is then reshaped into the correct format for use with a convolutional neural network. Finally, a sample image from the training data is displayed.",9,1,0.19324042085762277
"import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt #for plotting
from collections import Counter
from sklearn.metrics import confusion_matrix
import itertools
import seaborn as sns
from subprocess import check_output
print(check_output([""ls"", ""../input""]).decode(""utf8""))
%matplotlib inline#loading the dataset.......(Train)
train = pd.read_csv(""../input/train.csv"")
print(train.shape)
train.head()z_train = Counter(train['label'])
z_trainsns.countplot(train['label'])#loading the dataset.......(Test)
test= pd.read_csv(""../input/test.csv"")
print(test.shape)
test.head()x_train = (train.ix[:,1:].values).astype('float32') # all pixel values
y_train = train.ix[:,0].values.astype('int32') # only labels i.e targets digits
x_test = test.values.astype('float32')%matplotlib inline
# preview the images first
plt.figure(figsize=(12,10))
x, y = 10, 4
for i in range(40):  
    plt.subplot(y, x, i+1)
    plt.imshow(x_train[i].reshape((28,28)),interpolation='nearest')
plt.show()","This code imports the necessary libraries for data processing, linear algebra, and plotting. It then loads the dataset (Train) into a pandas dataframe, prints the shape of the dataframe, and displays the first five rows.

Next, the code creates a seaborn countplot of the 'label' column in the Train dataframe. This is followed by loading the Test dataset into a pandas dataframe, printing the shape of the dataframe, and displaying the first five rows.

Finally, the code displays a preview of the images in the Train dataset.",8,7,0.19280871822663811
"import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsClassifier# Считаем csv файлы в Pandas датафрейм
train = pd.read_csv('../input/digit-recognizer/train.csv')
test = pd.read_csv('../input/digit-recognizer/test.csv')# Посмотрим на тренировочный датафрейм
train.head()# Узнаем число пропущенных значений 
# и какому признаку принадлежит больше всего пропусков
sum(train.isnull().sum())# Посмотрим на тестовый датафрейм
test.head()# Узнаем число пропущенных значений 
# и какому признаку принадлежит больше всего пропусков
sum(test.isnull().sum())# Пропущенных значений нет, потому можно продолжать работу с выборками","This code imports the pandas and numpy libraries, and then loads the train and test CSV files into pandas dataframes. Next, it prints out the first few rows of the train dataframe, and then calculates the number of missing values in the dataframe. Finally, it does the same for the test dataframe.",9,5,0.08204634123267912
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset

import wandb
from kaggle_secrets import UserSecretsClient
user_secrets = UserSecretsClient()
secret_value_0 = user_secrets.get_secret(""WANDB_KEY"")
wandb.login(key=secret_value_0)
wandb.init(project='MNIST_MLP', save_code=True)class MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return datatransformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])

train_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)
# TODO split train between validation and training set
training_size = int(0.7 * len(train_dataset))
validation_size = len(train_dataset) - training_size
train, val = torch.utils.data.random_split(train_dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))
# create data loader for train and test set
data_loader_train = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True)
data_loader_val = torch.utils.data.DataLoader(val, batch_size=32, shuffle=True)

test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)def init_my_layer(m):
    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('tanh'))
    torch.nn.init.constant_(m.bias, 0)
    return m

class Net(nn.Module):    
    def __init__(self):
        super(Net, self).__init__()
        self.relu = nn.ReLU()
        self.ln1 = init_my_layer(nn.Linear(28*28, 28))
        self.ln2 = init_my_layer(nn.Linear(28, 28))
        self.ln3 = init_my_layer(nn.Linear(28, 10))
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        x = self.relu(self.ln1(x))
        x = self.relu(self.ln2(x))
        return self.softmax(self.ln3(x))model = Net()

# check if a GPU with Cuda capacities is available
device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"") #0, first GPU if multiple one
model.to(device)
learning_rate = 1e-3
lambda_l2 = 1e-5

criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=lambda_l2)
wandb.watch(model, log=""all"", criterion=criterion, log_freq=1,  log_graph=(True)) 


nb_epochs = 10
# Training
for t in range(nb_epochs):
    model.train() # put the network in training mode
    for X, y in data_loader_train:
        # Feed forward to get the logits
        #format data
        b = X.size(0)
        X = X.view(b,-1)
        y_pred = model(X)
        # Compute the loss and accuracy
        loss = criterion(y_pred, y)
        score, predicted = torch.max(y_pred, 1)
        acc = (y == predicted).sum().float() / len(y)
        wandb.log({
            'mlp/train_loss': loss.item(),
            'mlp/train_accuracy': acc,
        })
        # zero the gradients before running
        # the backward pass.
        optimizer.zero_grad()
        # Backward pass to compute the gradient
        # of loss w.r.t our learnable params. 
        loss.backward()
        # Update params
        optimizer.step()
        
    with torch.no_grad(): # validation run
        model.eval() # validation mode
        for X, y in data_loader_val:
            #format data
            b = X.size(0)
            X = X.view(b,-1)
            y_pred = model(X)
            validation_loss = criterion(y_pred, y)
            score, predicted = torch.max(y_pred, 1)
            acc = (y == predicted).sum().float() / len(y)
            wandb.log({
                'mlp/val_loss': loss.item(),
                'mlp/val_accuracy': acc,
            })
","This code defines a neural network for the MNIST dataset using PyTorch. The network consists of three fully connected layers, with ReLU activation functions. The network is trained using the Adam optimizer, with a learning rate of 1e-3 and a weight decay of 1e-5. The network is trained for 10 epochs.",8,2,0.1319974452837312
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import tensorflow as tf
import tensorflow.keras.layers as tfl
import tensorflow.keras as keras
import matplotlib.pyplot as plt
import sklearn.model_selection as model_sel


# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiondf = pd.read_csv('../input/digit-recognizer/train.csv')
df.head()X = df.drop(columns=['label'])
X.head()X = X.to_numpy().reshape(-1,28,28,1)X = X/255
X.shapeplt.figure(figsize = (10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.imshow(X[i])
    plt.xticks([])
    plt.yticks([])
    plt.xlabel(df['label'][i])X_train, X_test, Y_train, Y_test = model_sel.train_test_split(X, df['label'].to_numpy().reshape(-1,1), test_size=0.25, random_state=1)","This code imports various libraries for data analysis and machine learning, including NumPy, pandas, TensorFlow, Keras, and matplotlib. It then loads the MNIST dataset from a CSV file and displays some sample images from the dataset. Finally, it splits the dataset into training and test sets and prepares the data for use in a machine learning model.",8,2,0.13040562343302975
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import wandb

from kaggle_secrets import UserSecretsClient
user_secrets = UserSecretsClient()
secret_value = user_secrets.get_secret(""WANDB_KEY"")

wandb.login(key=secret_value)
wandb.init(project='MNIST_MLP', save_code=True)class MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return databatch_size= 512

transformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])


train_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)

# split train between validation and training set
training_size = int(0.7 * len(train_dataset))
validation_size = len(train_dataset) - training_size
train, val = torch.utils.data.random_split(train_dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))

# create data loader for train and test set
data_loader_train = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)
data_loader_val = torch.utils.data.DataLoader(val, batch_size=batch_size, shuffle=True)

test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False)def init_layer(m):
    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('relu'))
    torch.nn.init.constant_(m.bias, 0)
    return mclass Net(nn.Module):    
    def __init__(self, inputSize):
        super(Net, self).__init__()
        
        self.linear1 = init_layer(torch.nn.Linear(inputSize, 512))
        self.linear2 = init_layer(torch.nn.Linear(512, 256))
        self.dropout = torch.nn.Dropout(p=0.4)
        self.linear3 = init_layer(torch.nn.Linear(256, 10))


    def forward(self, x):
        
        x = x.view(-1,28*28) #reshape the 2d image in a ondiminsional vector for the input of the first layer
        
        x = F.relu(self.linear1(x))
        x = self.dropout(x)
        x = F.relu(self.linear2(x))
        x = self.dropout(x)
        
        return self.linear3(x)input_size = 784
output_size = 10 #labels range from 0-9

model = Net(input_size)

num_epochs = 50
lr =  0.01
weight_decay = 1e-4

optimizer = torch.optim.SGD(model.parameters(),lr = lr)#torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay) #AdamW to aviod coupling problem between the L2 regularization and the adaptive learning rate
criterion = torch.nn.CrossEntropyLoss()

#logging configuration and model
wandb.config.learningrate = lr
wandb.config.num_iterations = num_epochs
wandb.config.optimizer = ""AdamW""
wandb.config.weight_decay = weight_decay
wandb.config.criterion = ""CELoss""

wandb.watch(model, log=""all"", criterion=criterion, log_freq=1,  log_graph=(True)) #log frequency depend on your training


device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"") #0, first GPU if multiple one
print(device)
model.to(device)
","This code defines a neural network for classifying handwritten digits. The network consists of three fully connected layers, with the first two layers having 512 and 256 neurons, respectively. The third layer has 10 neurons, one for each possible digit label. The network also uses a dropout layer with a probability of 0.4.

The code defines a dataset class for loading the MNIST dataset. The dataset class inherits from the standard PyTorch Dataset class and overrides the __init__() and __getitem__() methods. The __init__() method takes in a file path for the dataset and optionally a transform object. The __getitem__() method returns a tuple containing the data and target for a given index.

The code also defines a function for initializing the weights of the network layers. This function takes in a layer object and initializes the weights using Xavier normal initialization.

The code then defines the training parameters, including the number of epochs, learning rate, and weight decay. The code also instantiates the optimizer and criterion objects.

Finally, the code defines a main() function that loads the dataset, instantiates the model, and trains the model. The code also uses the wandb library to log training information.",9,6,0.17875918119551934
"import pandas as pd   # data analysis librarymnist_test = pd.read_csv(""/kaggle/input/mnist-fashion-data-classification/mnist_test.csv"")    # create a variable dataframe containing data from data file
mnist_train = pd.read_csv(""/kaggle/input/mnist-fashion-data-classification/mnist_train.csv"")    # create a variable dataframe containing data from data file
sample_submission = pd.read_csv(""/kaggle/input/digit-recognizer/sample_submission.csv"")    # create a variable dataframe containing data from data file
train = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")    # create a variable dataframe containing data from data file
test = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")    # create a variable dataframe containing data from data filecols = test.columnstest['dataset'] = 'test'train['dataset'] = 'train'dataset = pd.concat([train.drop('label', axis=1), test]).reset_index()","This code imports the pandas library and reads in data from four different CSV files: mnist_test, mnist_train, sample_submission, and train. It then concatenates the data from the four files into a single dataframe called dataset.",9,3,0.22659965358456918
"import os
import numpy as np
import pandas as pd
import pydicom# Load the data
base_path = ""/kaggle/input/siim-covid19-detection/""
studies_df = pd.read_csv(os.path.join(base_path,""train_study_level.csv""))
images_df = pd.read_csv(os.path.join(base_path,""train_image_level.csv""))

# Strip the extra text from the study and image IDs
studies_df['id'] = studies_df['id'].map(lambda x: x.rstrip('_study'))
images_df['id'] = images_df['id'].map(lambda x: x.rstrip('_image'))

# Merge the dfs together
data_df = pd.merge(images_df, studies_df, how='inner', left_on='StudyInstanceUID', right_on='id')
data_df.drop(['id_y'], axis=1, inplace=True)# This function finds the first image in a StudyInstanceUID directory and returns its path
def get_image_by_study_id(study_id):
    study_path = base_path + ""train/"" + study_id + ""/""
    for subdir, dirs, files in os.walk(study_path):
        for file in files:     
            image = os.path.join(subdir, file)
            if os.path.isfile(image):
                return image
    return ""none""# Loop through the images and check how many images are not Explicit VR Little Endian transfer syntax.
# Also count images with VOI LUT Sequence tags present

count = 0
images_with_voi_lut = 0
images_with_voi_lut_function = 0
images_not_explicit_le = 0
deflated_syntaxes = []
voi_lut_functions = []

for index, row in data_df.iterrows():
    img_file = get_image_by_study_id(row['StudyInstanceUID'])
    img = pydicom.dcmread(img_file)
    
    # Check for a LUT sqequence tag
    if (0x0028,0x3010) in img:
        images_with_voi_lut += 1
    
    # Check for a LUT Function tag
    if (0x0028,0x1056) in img:
        images_with_voi_lut_function += 1
        
        if img(0x0028,0x1056) not in voi_lut_functions:
            voi_lut_functions.append(img(0x0028,0x1056))
            
    # Check the transfer syntax
    if img.file_meta.TransferSyntaxUID != ""1.2.840.10008.1.2.1"":
        images_not_explicit_le += 1
        
        if img.file_meta.TransferSyntaxUID not in deflated_syntaxes:
            deflated_syntaxes.append(img.file_meta.TransferSyntaxUID)
        
    count += 1
    
print(""Done checking "" + str(count) + "" images"")
print(""Found "" + str(images_with_voi_lut) + "" images with VOI LUT"")
print(""Found "" + str(images_with_voi_lut_function) + "" images with VOI LUT Function"")
print(""VOI LUT Functions:"")
print(voi_lut_functions)
print(""Found "" + str(images_not_explicit_le) + "" images that are not Explicit VR LE"")
print(""Non Explicit VR LE Transfer Syntaxes"")
print(deflated_syntaxes)","This code imports the necessary libraries, loads the data, and strips the extra text from the study and image IDs. It then merges the dataframes together.

The get_image_by_study_id() function finds the first image in a StudyInstanceUID directory and returns its path.

The loop then checks how many images are not Explicit VR Little Endian transfer syntax, as well as how many images have VOI LUT Sequence tags present. It also counts the number of images with VOI LUT Function tags present. Finally, it prints out a summary of the results.",8,5,0.3230563644939833
"import os
import cv2
import numpy as np
import pandas as pd
import pydicom
import matplotlib.pyplot as plt
%matplotlib inline# This function gets the first image path in a StudyInstanceUID directory
def get_image_by_study_id(study_id):
    base_path = ""/kaggle/input/siim-covid19-detection/""
    study_path = base_path + ""train/"" + study_id + ""/""
    images = []
    for subdir, dirs, files in os.walk(study_path):
        for file in files:     
            image = os.path.join(subdir, file)
            if os.path.isfile(image):
                return image
    return ""none""# Make a simple linear VOI LUT from the raw (stored) pixel data
def make_lut(storedPixels, windowWidth, windowLevel, p_i):
    
    # Slope and Intercept set to 1 and 0 for X-ray. Get these from DICOM tags instead if using 
    # on a modality that requires them (CT, PT etc)
    slope = 1.0
    intercept = 0.0
    minPixel = int(np.amin(storedPixels))
    maxPixel = int(np.amax(storedPixels))

    # Make an empty array for the LUT the size of the pixel 'width' in the raw pixel data
    lut = [0] * (maxPixel + 1)
    
    # Invert pixels and windowLevel for MONOCHROME1. We invert the specified windowLevel so that 
    # increasing the level value makes the images brighter regardless of photometric intrepretation
    invert = False
    if p_i == ""MONOCHROME1"":
        invert = True
    else:
        windowLevel = (maxPixel - minPixel) - windowLevel
        
    # Loop through the pixels and calculate each LUT value
    for storedValue in range(minPixel, maxPixel):
        modalityLutValue = storedValue * slope + intercept
        voiLutValue = (((modalityLutValue - windowLevel) / windowWidth + 0.5) * 255.0)
        clampedValue = min(max(voiLutValue, 0), 255)
        if invert:
            lut[storedValue] = round(255-clampedValue)
        else:
            lut[storedValue] = round(clampedValue)
        
    return lut# Apply the LUT to a pixel array
def apply_lut(pixels_in, lut):
    pixels_in = pixels_in.flatten()
    pixels_out = [0] * len(pixels_in)
    for i in range(0, len(pixels_in)):
        pixel = pixels_in[i]
        pixels_out[i] = int(lut[pixel])
    return pixels_out# Take a look at a random image and display it with imshow. The width and level are automagically calculated from the pixel data.
img_file = get_image_by_study_id(""00c241c3fc0d"")
print(""Loading image: "" + img_file)

img = pydicom.dcmread(img_file)
plt.imshow(img.pixel_array,cmap=""gray"");# Set the width to be the distance between the pixels, and the level to be the middle of the pixel range.
# The resulting image should look exactly like the one above.
pixels = img.pixel_array
minPixel = np.min(pixels)
maxPixel = np.max(pixels)
windowWidth = maxPixel - minPixel
windowLevel = (minPixel + maxPixel) / 2

lut = make_lut(pixels, windowWidth, windowLevel, img.PhotometricInterpretation)
pixels = apply_lut(pixels, lut)

# Reshape the pixel array back into the image shape
img_out = np.reshape(pixels, (img.pixel_array.shape[0],img.pixel_array.shape[1]))

print(""Calculated - Width: "" + str(windowWidth) + "" / Level  "" +  str(windowLevel))
print(""Pixel range: "" + str(minPixel) + "" - "" + str(maxPixel))
plt.imshow(img_out,cmap=""gray"");print(""PhotometricInterpretation: "" + img.PhotometricInterpretation)
print(""Bit stored: "" + str(img.BitsStored))","This code imports the necessary libraries for reading, processing and displaying DICOM images. The get_image_by_study_id() function returns the path to the first image in a given StudyInstanceUID directory. The make_lut() function generates a simple linear VOI LUT from the raw pixel data, and the apply_lut() function applies the LUT to an image. Finally, the code displays a random image from the dataset with imshow().",9,3,0.474671935463209
"import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings(""ignore"")
from glob import glob
from tqdm.notebook import tqdm
from ast import literal_eval
import os
import matplotlib.pyplot as plt
import matplotlib
matplotlib.rcParams.update({'font.size': 22})
from sklearn.metrics import accuracy_score
from skimage import exposure
from tensorflow.keras import layers
from tensorflow.keras.utils import plot_model
import cv2
from matplotlib.patches import Rectangle
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50, DenseNet121, Xception
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import models
from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping
import tensorflow.keras.backend as K
from tensorflow.math import confusion_matrixdf_image = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
display(df_image.head(3))
print(df_image.shape)df_study = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
display(df_study.head(3))
print(df_study.shape)df_sampleSub = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
display(df_sampleSub.head(3))
print(df_sampleSub.shape)df_study['id'] = df_study['id'].str.replace('_study',"""")
df_study.rename({'id': 'StudyInstanceUID'},axis=1, inplace=True)
df_study.head(3)df_train = df_image.merge(df_study, on='StudyInstanceUID')
df_train.head(3)# train_dir_jpg = '../input/covid-jpg-512/train'
# train_dir_origin ='../input/siim-covid19-detection/train'
# paths_original = []
# paths_jpg = []
# for _, row in tqdm(df_train.iterrows()):
#     image_id = row['id'].split('_')[0]
#     study_id = row['StudyInstanceUID']
#     image_path_jpg = glob(f'{train_dir_jpg}/{image_id}.jpg')
#     image_path_original = glob(f'{train_dir_origin}/{study_id}/*/{image_id}.dcm')
#     paths_jpg.append(image_path_jpg)
#     paths_original.append(image_path_original)","This code imports the pandas, numpy, and warnings libraries, and filters warnings. It also imports the glob, tqdm, and ast libraries, and the os, matplotlib, and sklearn modules.

The code then defines a function to read in a CSV file, and reads in the train_image_level.csv, train_study_level.csv, and sample_submission.csv files.

The code then processes the data in the train_study_level.csv file, and merges it with the data in the train_image_level.csv file.

Finally, the code defines a function to read in image files, and reads in the image files for the training data.",8,5,0.03639258541474813
"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -yimport tensorflow as tf
print(tf.__version__)
import torch
print(f""Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})"")

import os
import gc
import cv2
import glob
import numpy as np
import pandas as pd
from PIL import Image
from tqdm import tqdm
from shutil import copyfile
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lutgpus = tf.config.list_physical_devices('GPU')
if gpus:
  try:
    # Currently, memory growth needs to be the same across GPUs
    for gpu in gpus:
      tf.config.experimental.set_memory_growth(gpu, True)
    logical_gpus = tf.config.experimental.list_logical_devices('GPU')
    print(len(gpus), ""Physical GPUs,"", len(logical_gpus), ""Logical GPUs"")
  except RuntimeError as e:
    # Memory growth must be set before GPUs have been initialized
    print(e)# Read the submisison file
sub_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')
print(len(sub_df))
sub_df.head()study_df = sub_df.loc[sub_df.id.str.contains('_study')]
len(study_df)image_df = sub_df.loc[sub_df.id.str.contains('_image')]
len(image_df)# Ref: https://www.kaggle.com/xhlulu/siim-covid-19-convert-to-jpg-256px
def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return data

def resize_xray(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im","This code installs the pydicom conda helper library, which allows for the easy conversion of DICOM images to numpy arrays. It also installs the gdcm library, which is required for the pydicom library to work. Finally, it installs the tensorflow and torch libraries, which are required for the code to run.",8,6,0.13436485492525302
"!/opt/conda/bin/python3.7 -m pip install --upgrade pip
! pip install -q efficientnet#-------------------
# importing libraries
#-------------------
import tensorflow as tf
from tensorflow.keras import layers
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold,StratifiedKFold

from kaggle_datasets import KaggleDatasets


import pandas as pd
import numpy as np

import os
import shutil
import csv

import matplotlib.pyplot as plt
import PILAUTO = tf.data.experimental.AUTOTUNE

try:
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  
    print('Running on TPU ', tpu.master())
except ValueError:
    tpu = None

if tpu:
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.experimental.TPUStrategy(tpu)
else:
    strategy = tf.distribute.get_strategy()

print(""REPLICAS: "", strategy.num_replicas_in_sync)GCS_DS_PATH = KaggleDatasets().get_gcs_path(""siim-covid19-dataset-256px-jpg"")
print(GCS_DS_PATH)

TRAIN_PATH = GCS_DS_PATH + ""/256px/train/train/""
TEST_PATH = GCS_DS_PATH + ""/256px/test/test/""

NUM_CLASSES = 4
HEIGHT,WIDTH = 256,256
CHANNELS = 3
BATCH_SIZE = 8 * strategy.num_replicas_in_sync
SEED = 143


classes_dict = {
    ""Negative for Pneumonia"" : 0,
    ""Typical Appearance"" : 1,
    ""Indeterminate Appearance"" : 2,
    ""Atypical Appearance""  : 3
}

study_df = pd.read_csv(""../input/siim-covid19-detection/train_study_level.csv"")
train_df = pd.read_csv('../input/siim-covid19-dataset-256px-jpg/train.csv')
train_df = train_df[[""ImageInstanceUID"",""StudyInstanceUID"",""label_id"",""study_label""]]train_df.head(3)study_df.head(3)def process_img(filepath,label):
    image = tf.io.read_file(filepath)
    image = tf.image.decode_jpeg(image, channels=CHANNELS)
    image = tf.image.convert_image_dtype(image, tf.float32) 
    #image = tf.image.resize(image, [HEIGHT,WIDTH])
    return image,label


def data_augment(image, label):
    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
            
    # Flips
    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_flip_up_down(image)
    if p_spatial > .75:
        image = tf.image.transpose(image)
        
    # Rotates
    if p_rotate > .75:
        image = tf.image.rot90(image, k=3) 
    elif p_rotate > .5:
        image = tf.image.rot90(image, k=2) 
    elif p_rotate > .25:
        image = tf.image.rot90(image, k=1) 
        
    
    if p_pixel_1 >= .4:
        image = tf.image.random_saturation(image, lower=.7, upper=1.3)
    if p_pixel_2 >= .4:
        image = tf.image.random_contrast(image, lower=.8, upper=1.2)
    if p_pixel_3 >= .4:
        image = tf.image.random_brightness(image, max_delta=.1)
        
    
    if p_crop > .7:
        if p_crop > .9:
            image = tf.image.central_crop(image, central_fraction=.7)
        elif p_crop > .8:
            image = tf.image.central_crop(image, central_fraction=.8)
        else:
            image = tf.image.central_crop(image, central_fraction=.9)
    elif p_crop > .4:
        crop_size = tf.random.uniform([], int(HEIGHT*.8), HEIGHT, dtype=tf.int32)
        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])
    
    image = tf.image.resize(image, [HEIGHT,WIDTH])
    return image,label

def get_dataset(filenames,labels, training=True):
    dataset = tf.data.Dataset.from_tensor_slices((filenames,labels))
    dataset = dataset.map(process_img,num_parallel_calls=AUTO)
    dataset = dataset.map(data_augment,num_parallel_calls=AUTO)
    dataset = dataset.cache()
    dataset = dataset.repeat()
    if training:
        dataset = dataset.shuffle(2048)
    dataset = dataset.batch(BATCH_SIZE)
    dataset = dataset.prefetch(AUTO)
    return dataset","The code above defines a number of functions for processing images and labels. The first function, process_img, takes in a filepath and label and returns the image and label. The second function, data_augment, takes in an image and label and returns the image and label. The third function, get_dataset, takes in a list of filenames, labels, and a boolean indicating whether the dataset is for training or not. The function returns a dataset consisting of the processed images and labels.",8,2,0.11159161523984805
"%%capture
!conda install gdcm -c conda-forge -y# Packages

import os, time, glob, re, pprint, random, math
from collections import defaultdict, Counter

import pandas as pd 
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import matplotlib.patches as patches

import seaborn as sns

import cv2
import gdcm

import pydicom
from pydicom import dcmread
from pydicom.pixel_data_handlers.util import apply_voi_lut

import imagehash
from PIL import Image as im

import tqdm# Magic

%matplotlib inline # Pandas options

pd.set_option(""display.expand_frame_repr"", True)
pd.set_option('display.max_colwidth', 0)# Global values

CODE_PATH = ""./""
DATA_PATH = ""../input/siim-covid19-detection""
TRAIN_PATH = os.path.join(DATA_PATH, ""train"")
TEST_PATH = os.path.join(DATA_PATH, ""test"")# Utility functions

def print_title(s):
    
    # Print an underlined title
    
    print(""%s\n%s"" % (s, '-'*len(s)))
    
    
def na_fill(dtype):
    
    # Fill in missing values so that Seaborn countplot() will include them.
    # Also make sure the missing value for a string column is itself a string.
    
    if dtype == np.float64:
        result = -999
    elif dtype == np.int64:
        result = -999
    elif dtype == np.object:
        result = ""NA""
    else:
        result = -999

    return result


def explode_list_col(df, col):
    
    other_cols = list(df.columns)
    other_cols.remove(col)
    out_df = df.set_index(other_cols)[col]
    out_df = out_df.apply(pd.Series)
    out_df = out_df.stack()
    out_df = out_df.reset_index()
    out_df = out_df.drop(f""level_{len(other_cols)}"", axis=1)
    out_df = out_df.rename(columns={0 : col})
    
    return out_df
    

def cat_order(train_df, test_df, cols):
    
    # For comparison, we want the categories to be the same between train and test. 
    # We also want the categories to be in the same order for both. 
    # We need to make sure missing value types are consistent with the column data
    # type (else sort will complain), and make sure that Seaborn countplot() will
    # include them (it won't include np.nan). Dealing with the latter two issues 
    # is the job of fillna(). When the data is plotted, it needs to be run through
    # fillna() as well.

    category_order = {}
    n = len(cols)

    for col in cols:

        if col in train_cols:
            train_dtype = train_df[col].dtype
        else:
            train_dtype = None     
        if col in test_cols:
            test_dtype = test_df[col].dtype
        else:
            test_dtype = None
        if (train_dtype != None) and (test_dtype != None) and (train_dtype != test_dtype):
            print(f""***Incompatible train/test data types for column {col}"")
            break
        
        col_vals = []
        if col in train_cols:
            col_vals += list(train_df[col].fillna(na_fill(train_dtype)).unique())
        if col in test_cols:
            col_vals += list(test_df[col].fillna(na_fill(test_dtype)).unique())
        col_vals = list(set(col_vals))
        col_vals.sort()
    
        category_order[col] = col_vals
        
    return category_order


def plot_categories(df, col, order, title, ax, xlabel=None, ylabel=None, pallete=""Set3"", scale=""log""):

    data = df[col].fillna(na_fill(df[col].dtype))
    ax = sns.countplot(x=data, order=order, palette=pallete, ax=ax)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=""right"")
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    counts = data.value_counts()
    for i, p in enumerate(ax.patches):
        px = p.get_x()+0.05
        py = max(p.get_height()*0.9, 1.0)
        ax.annotate(counts.get(order[i], """"), (px, py), fontsize=10, rotation=90)
    ax.set_title(title, fontsize=15)
    if xlabel: ax.set_xlabel(xlabel)
    if ylabel: ax.set_ylabel(ylabel)
    
    return


def plot_cat_sub(df, col, sub_col, title, ax, scale=""log""):

    ax = sns.countplot(data=df, x=col, hue=sub_col, ax=ax)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=""right"")
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    ax.set_title(title, fontsize=15)
        
    return


def plot_number_uniq_per(df, df_name, attr1, attr2, ax, title=None, palette=None, scale=""log""):
    
    uniq_df = df.groupby(attr1)[[attr2]].nunique().reset_index()
    ax = sns.barplot(x=attr1, y=attr2, data=uniq_df, ax=ax, palette=palette)
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
        
    counts = uniq_df[attr2]
    for i, p in enumerate(ax.patches):
        px = p.get_x()+0.05
        py = max(p.get_height()*0.9, 1.0)
        ax.annotate(uniq_df[attr2].iloc[i], (px, py), fontsize=10, rotation=90)

    if title:
        ax.set_title(title, fontsize=15)
    else:
        ax.set_title(f""{df_name}\nNumber of unique '{attr2}' values \nper '{attr1}' value"", fontsize=15)
    ax.set_xlabel(attr1)
    ax.set_ylabel(f""# unique '{attr2}'"")
    
    return uniq_df


def plot_number_having_n_uniq(df, df_name, attr1, attr2, ax, order=None, palette=None, scale=""log""):

    nuniq = df.groupby(attr1)[attr2].nunique()
    ax = sns.countplot(x=nuniq, order=order, ax=ax, palette=palette)
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    ax.set_title(f""{df_name}\nNumber of '{attr1}' values \nhaving N unique values of '{attr2}'"", fontsize=15)
    ax.set_xlabel(f""N = # of unique '{attr2}' values"")
    ax.set_ylabel(f""# of '{attr1}' having N"")

    return nuniq


def get_img(path, img_id):

    img_path = os.path.join(path, f""{img_id}.jpg"")
    im = cv2.imread(img_path)
    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
    im = cv2.normalize(im, None, 0, 255, cv2.NORM_MINMAX)
    
    return im


def image_subplots(images, r, c, axes, titles=None):
    
    for idx, img in enumerate(images, 0):
        i = idx // c
        j = idx % c
        if titles:
            imshow(img, axes[i, j], title=titles[idx])
        else:
            imshow(img, axes[i, j])

    return
        

def imshow(image, ax=None, title=None, cmap=None):

    if ax is None:
        fig, ax = plt.subplots()
    ax.imshow(image, cmap=cmap)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.spines['left'].set_visible(False)
    ax.spines['bottom'].set_visible(False)
    ax.tick_params(axis='both', length=0)
    ax.set_xticklabels('')
    ax.set_yticklabels('')
    if title:
        ax.set_title(title)

    return ax
# Read the image metadata

train_image_df = pd.read_csv(os.path.join(DATA_PATH,'train_image_level.csv'))
train_study_df =  pd.read_csv(os.path.join(DATA_PATH,'train_study_level.csv'))","This code reads in the image metadata for the training images. This includes the image ID, patient ID, and other information about the image.",8,0,0.07723607585831056
"import pydicom as dicom
import pandas as pd
import os
from tqdm import tqdmmetadata = []

for split in ['test', 'train']:  
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            ds1 = dicom.dcmread(os.path.join(dirname, file), stop_before_pixels=True)
            dt=dict()
            dt['ImageId']=file.replace('.dcm','')
            for key in ds1.keys():
                dt[ds1[key].keyword]=ds1[key].value
            metadata.append(dt)

metadata_df=pd.DataFrame(metadata)
metadata_df.head()metadata_df.to_csv('metadata_covid.csv', index=False)","This code imports the pydicom and pandas libraries, and then loops through a dataset of DICOM images, extracting metadata from each image and storing it in a list. The list is then converted into a pandas DataFrame and saved as a CSV file.",8,2,0.10544103771734628
"import pandas as pd 
import numpy as np
import os
import pydicom
import glob
from tqdm.notebook import tqdm
from pydicom.pixel_data_handlers.util import apply_voi_lut
import matplotlib.pyplot as plt 
from skimage import exposure
import cv2
import warnings
from path import Path
from fastai.vision.all import *
from fastai.medical.imaging import *
warnings.filterwarnings(""ignore"")datapath = Path(""../input/siim-covid19-detection"")datapath.ls()train_study_df = pd.read_csv(datapath/'train_study_level.csv')train_study_df.head()study_classes = [""Negative for Pneumonia"" , ""Typical Appearance"",
                ""Indeterminate Appearance"", ""Atypical Appearance""]
np.unique(train_study_df[study_classes].values , axis = 0)plt.figure(figsize = (10,5))
plt.bar([1,2,3,4] , train_study_df[study_classes].values.sum(axis = 0))
plt.xticks([1,2,3,4] , study_classes)
plt.ylabel(""Frequency"")
plt.show()","This code imports the pandas and numpy libraries, and then sets up a datapath variable to point to the location of the input data file. Next, it reads in the train_study_level.csv file and displays the first five rows.

The code then defines a study_classes variable, which contains a list of the four classes of findings in the study data. Next, it uses the np.unique function to find all unique combinations of these classes in the data, and then displays them in a bar chart.",8,4,0.029951450392858802
"import numpy as np 
import pandas as pd 
import os
import matplotlib.pyplot as plt
import matplotlib
import pydicom as dicom
import cv2
import ast
import warnings
warnings.filterwarnings('ignore')train_image = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
train_study = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
sample_submission = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')train_image.head()len(train_image)train_study.head()len(train_study)sample_submission.head()","The code imports the numpy, pandas, os, matplotlib, pydicom, cv2, and ast libraries.

The code then reads in the train_image_level.csv, train_study_level.csv, and sample_submission.csv files.

The code then displays the first five rows of the train_image dataframe, displays the length of the train_image dataframe, displays the first five rows of the train_study dataframe, displays the length of the train_study dataframe, and displays the first five rows of the sample_submission dataframe.",8,10,0.067671215897952
"!conda install gdcm -c conda-forge -yimport os
import ast
import numpy as np
import pandas as pd
from path import Path
import datetime
import glob
import json
import shutil

from PIL import Image
from tqdm.auto import tqdm
import pydicom
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import cv2from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)    
    
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail(size, resample)
    else:
        im = im.resize(size, resample)
    
    return imimages_meta_folder = '/kaggle/working/images_metadata_256_512_768'
os.makedirs(images_meta_folder, exist_ok=True)

# Define sizes
new_sizes = [(256, 256), (512, 512), (768, 768)]for new_size in new_sizes:

    for split in ['train', 'test']:
    # for split in ['test']:
        save_dir = f'/kaggle/tmp/{split}_{new_size[0]}x{new_size[1]}/'
        dcm_paths = glob.glob(f'../input/siim-covid19-detection/{split}/*/*/*')
        os.makedirs(save_dir, exist_ok=True)

        image_ids = []
        folder_ids = []
        study_ids = []
        widths = []
        heights = []

        for path in tqdm(dcm_paths):
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(path)
            im = resize(xray, size=new_size)

            path_split = path.split('/')
            study_id = path_split[-3]
            folder_id = path_split[-2]
            image_name = path_split[-1].replace('.dcm', '_image')

            im.save(os.path.join(save_dir, image_name+'.png'))

            image_ids.append(image_name)
            folder_ids.append(folder_id)
            study_ids.append(study_id)
            widths.append(xray.shape[1])
            heights.append(xray.shape[0])
            
        df = pd.DataFrame.from_dict({'id': image_ids, 'folder_id': folder_ids,
                                     'study_id': study_ids, 'width': widths,
                                     'height': heights})
        df.to_csv(f'{images_meta_folder}/{split}_meta_{new_size[0]}x{new_size[1]}.csv', index=False)for new_size in new_sizes:
    print(f""*****{new_size}*****\n"")
    df_train_meta = pd.read_csv(f'{images_meta_folder}/train_meta_{new_size[0]}x{new_size[1]}.csv')
    df_train = pd.read_csv(""../input/siim-covid19-detection/train_image_level.csv"")
    df_train_meta = df_train.merge(df_train_meta, on='id')
    
    ## Drop all rows of images without annotations
    df_train_meta = df_train_meta.dropna()
    imagepaths = df_train_meta.id.unique()
    print(""Number of Images with Covid_Abnormality:"",len(imagepaths))
    
    display(df_train_meta.head(3))
    print()
    
    df_idx=0

    for idx, row in tqdm(df_train_meta.iterrows(), total=df_train_meta.shape[0]):
        img = cv2.imread(os.path.join(f""/kaggle/tmp/train_{new_size[0]}x{new_size[1]}/"",
                                      row.id.replace(""_image"", "".png"")))
        bboxes = [list(bbox.values()) for bbox in ast.literal_eval(row.boxes)]
        height_ratio, width_ratio = (new_size[0]/row.height, new_size[1]/row.width)

        for box in bboxes:
            box[2] = box[2]+box[0]
            box[3] = box[3]+box[1]
            box = (box[0]*width_ratio, box[1]*height_ratio,
                   box[2]*width_ratio, box[3]*height_ratio)

            row_df = pd.DataFrame({'id':row.id,
                           'StudyInstanceUID':row.StudyInstanceUID,
                           'folder_id':row.folder_id,
                           'study_id':row.study_id,
                           'width':row.width,
                           'height':row.height,
                           'xmin':round(box[0]),
                           'ymin':round(box[1]),
                           'xmax':round(box[2]),
                           'ymax':round(box[3])}, index=[df_idx])

            if df_idx==0:
                df_train_processed = row_df
            else:
                df_train_processed = pd.concat([df_train_processed, row_df])

            df_idx+=1

    display(df_train_processed.head(3))
    print()
    df_train_processed.to_csv(f'{images_meta_folder}/df_train_processed_meta_{new_size[0]}x{new_size[1]}.csv',
                              index=False)
    df_train_processed.shape","This code reads in DICOM files, applies a VOI LUT (if available), and then transforms the raw DICOM data into a ""human-friendly"" view. It also rescales the data so that it is between 0 and 1, and then converts it to an 8-bit unsigned integer. Finally, it saves the transformed data as a PNG file.",9,1,0.13355674530667752
"!conda install gdcm -c conda-forge -yimport cv2
import datetime
import gc
import glob
import imagehash
import math
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
import PIL
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import sys
import tqdmbase_path = '../input/siim-covid19-detection'def read_dicom_image(image_file, voi_lut=True, fix_monochrome=True):
    """"""
    Reads a dicom image from a file an returns a numpy array.
    References: https://www.kaggle.com/trungthanhnguyen0502/eda-vinbigdata-chest-x-ray-abnormalities
    Args:
        image_file:
        voi_lut:
        fix_monochrome:

    Returns:

    """"""
    dicom = pydicom.read_file(image_file)
    # VOI LUT (if available by DICOM device) is used to
    # transform raw DICOM data to ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
    return data


def string2boxes(string):
    strings = string.split()
    if strings[0].lower() == 'none':
        return []
    else:
        return [{'class': strings[idx],
                 'conf': float(strings[idx+1]),
                 'x1': float(strings[idx+2]),
                 'y1': float(strings[idx+3]),
                 'x2': float(strings[idx+4]),
                 'y2': float(strings[idx+5]),
                 } for idx in range(0, len(strings), 6)]


def plot_image(image, boxes=None, size=(5,5), title=None, columns=4):
    def plot_img(image, boxes=None, title=None):
        if isinstance(image, str):
            image_id = os.path.splitext(os.path.split(image)[1])[0]
            df = df_image.loc[df_image['id'] == image_id + '_image']
            boxes = string2boxes(df['label'].iloc[0]) if len(df) > 0 else None
            image = read_dicom_image(image)
        image = np.stack([image] * 3, axis=-1)
        if boxes is not None:
            for box in boxes:
                image = cv2.rectangle(image, (int(box['x1']), int(box['y1'])), (int(box['x2']), int(box['y2'])), [0, 255, 0], 10)
        plt.axis('on')
        plt.imshow(image, cmap='gray')
        if title is not None:
            plt.title(title)

    plt.figure(figsize=size)
    if isinstance(image, list):
        num = len(image)
        columns = min(columns, num)
        rows = math.ceil(num / columns)

        for index, single_image in enumerate(image):
            plt.subplot(rows, columns, index + 1)
            plot_img(single_image, boxes=boxes, title=title[index])
    else:
        plot_img(image, boxes=boxes, title=title)
    plt.show()


def images_find_duplicates(image_files, threshold=0.9):
    """"""
    Function to find duplicates in images.
    References: https://www.kaggle.com/appian/let-s-find-out-duplicate-images-with-imagehash
    Args:
        image_files:
        threshold:

    Returns:

    """"""
    funcs = [imagehash.average_hash, imagehash.phash, imagehash.dhash, imagehash.whash]
    image_ids = image_files
    hashes = []
    for file in tqdm.tqdm(image_files):
        image = PIL.Image.fromarray(read_dicom_image(file))
        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))
    hashes_all = np.array(hashes)

    # Comparisons without Pytorch
    sim_list = []
    for i in tqdm.tqdm(range(hashes_all.shape[0])):
        sim_list.append(np.sum(hashes_all[i] == hashes_all, axis=1)/256)

    # nxn-matrix of similarities (n = # of images), upper triangular matrix
    similarities = np.triu(np.array(sim_list), 1)

    idx_pair = np.where(similarities > threshold)
    df_pairs = pd.DataFrame({'image1': [image_ids[i] for i in list(idx_pair[0])],
                             'image2': [image_ids[i] for i in list(idx_pair[1])],
                             'similarity': [similarities[i1, i2] for i1, i2 in zip(idx_pair[0], idx_pair[1])]})

    idx_group = np.zeros(len(image_files))
    group_id = 1
    for i1, i2 in zip(idx_pair[0], idx_pair[1]):
        if idx_group[i1] == 0 and idx_group[i2] == 0:
            idx_group[i1] = group_id
            idx_group[i2] = group_id
            group_id += 1
        elif idx_group[i1] != 0 and idx_group[i2] == 0:
            idx_group[i2] = idx_group[i1]
        elif idx_group[i1] == 0 and idx_group[i2] != 0:
            idx_group[i1] = idx_group[i2]
        elif idx_group[i1] != 0 and idx_group[i2] != 0 and idx_group[i1] != idx_group[i2]:
            common_id = min(idx_group[i1], idx_group[i2])
            idx_group[idx_group == idx_group[i1]] = common_id
            idx_group[idx_group == idx_group[i2]] = common_id

    group_list = []
    for i in range(1, group_id + 1):
        group_ids = list(np.where(idx_group == i)[0])
        if len(group_ids) > 0:
            group_list.append([image_ids[j] for j in group_ids])

    return df_pairs, group_list


def print_group_info(i, df_group):
    print(f'\nGroup {i+1}')
    print(f'Number of unique studies:       {len(df_group[""study_id""].unique())}')
    print(f'Number of unique study labels:  {len(df_group[""study_label""].unique())}\n')
    print(df_group[['image_id', 'num_boxes', 'study_id', 'study_label']])
    plot_image(list(df_group['image_file']), size=(20, 10), title=list(df_group['image_id']), columns=8)    
train_files = sorted(glob.glob(os.path.join(base_path, 'train/*/*/*.dcm')))
print(f'Number of training files: {len(train_files)}')
df_image = pd.read_csv(os.path.join(base_path, 'train_image_level.csv'))
df_study = pd.read_csv(os.path.join(base_path, 'train_study_level.csv'))
df_study['study_label'] = df_study.apply(lambda r: ', '.join([df_study.columns[i] for i in range(1, 5) if r[i] > 0]), axis=1)

df_pairs, group_list = images_find_duplicates(train_files, threshold=0.95)
print(f'\nNumber of duplicate pairs: {len(df_pairs)}')
print(f'Number of duplicate groups: {len(group_list)}')df_group_list = []
df_pairs.to_csv('pairs.csv')

with open('duplicates.csv', 'w') as text_file:
    for i, group in enumerate(group_list):
        group_ids = [os.path.splitext(os.path.basename(file))[0] + '_image' for file in group]
        df_group_ids = pd.DataFrame({'id': group_ids, 'image_file': group})
        df_group = df_group_ids.merge(df_image, on='id').sort_values('id')
        df_group['study_id'] = df_group['StudyInstanceUID'] + '_study'
        df_group['num_boxes'] = df_group.apply(lambda r: len(string2boxes(r['label'])), axis=1)
        df_group = df_group.merge(df_study, left_on='study_id', right_on='id')
        df_group = df_group.rename(columns={'id_x': 'image_id'})
        df_group_list.append(df_group)
        text_file.write(','.join(group_ids) + '\n')for index, df_group in enumerate(df_group_list):
    if len(df_group[df_group['num_boxes'] > 0]) > 1:
        print_group_info(index, df_group)","This code is used to find duplicate images in a dataset. It takes in a list of image files and a threshold value, and returns a list of duplicate groups.

First, the code reads in each image file and computes a hash for each image. These hashes are then compared to find pairs of images that are similar. Finally, the code groups together images that are similar to each other.

The code has two main parameters:

image_files: a list of image files
threshold: the minimum similarity between two images to be considered duplicates

The code returns two values:

df_pairs: a dataframe containing all pairs of similar images
group_list: a list of groups of similar images",8,2,0.16573708492558162
"import pandas as pd# train_df = pd.read_csv('/kaggle/input/siimcovid19-train-data-that-opacitycount-added/train_df.csv')
# local
train_df = pd.read_csv('/kaggle/input/siimcovid19-train-data-that-opacitycount-added/train_df.csv')train_df.head()train_df.drop(columns='Path', axis=1,inplace=True)train_df.head()train_df['Opacity'] = train_df.apply(lambda row : 1 if row.label.split(' ')[0]=='opacity' else 0, axis=1)
train_dftrain_df.drop(columns=['Unnamed: 0'], inplace=True)
train_df",This code imports the pandas library and reads in a CSV file containing training data. The data is then processed to drop the 'Path' column and to add a new 'Opacity' column. The resulting data is then outputted.,9,0,0.06894455329377669
"!pip install -q efficientnet >> /dev/nullimport pandas as pd, numpy as np, random,os, shutil
from glob import glob
from kaggle_datasets import KaggleDatasets
import tensorflow as tf, re, math
import tensorflow.keras.backend as K
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt
import tensorflow_addons as tfa
print('tf:',tf.__version__)# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit
VERBOSE      = 1
DISPLAY_PLOT = True

DEVICE = ""TPU"" #or ""GPU""

# USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD
SEED = 42

# NUMBER OF FOLDS. USE 2, 5, 10
FOLDS = 5

# WHICH IMAGE SIZES TO LOAD EACH FOLD
# CHOOSE 128, 192, 256, 384, 512, 512 
IMG_SIZES = [[512, 512]]*FOLDS

# BATCH SIZE AND EPOCHS
BATCH_SIZES = [24]*FOLDS
EPOCHS      = [10]*FOLDS

# WHICH EFFICIENTNET B? TO USE
EFF_NETS = [6]*FOLDS

# Augmentations
AUGMENT   = True
TRANSFORM = True

# transformations
ROT_    = 0.0
SHR_    = 2.0
HZOOM_  = 8.0
WZOOM_  = 8.0
HSHIFT_ = 8.0
WSHIFT_ = 8.0

# Dropout
PROBABILITY = 0.75
CT          = 8
SZ          = 0.08

#bri, contrast
sat  = (0.7, 1.3)
cont = (0.8, 1.2)
bri  =  0.1

# WEIGHTS FOR FOLD MODELS WHEN PREDICTING TEST
WGTS = [1/FOLDS]*FOLDS

# TEST TIME AUGMENTATION STEPS
TTA = 1def seeding(SEED):
    np.random.seed(SEED)
    random.seed(SEED)
    os.environ['PYTHONHASHSEED'] = str(SEED)
    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)
    tf.random.set_seed(SEED)
    print('seeding done!!!')
seeding(SEED)if DEVICE == ""TPU"":
    print(""connecting to TPU..."")
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        print('Running on TPU ', tpu.master())
    except ValueError:
        print(""Could not connect to TPU"")
        tpu = None

    if tpu:
        try:
            print(""initializing  TPU ..."")
            tf.config.experimental_connect_to_cluster(tpu)
            tf.tpu.experimental.initialize_tpu_system(tpu)
            strategy = tf.distribute.experimental.TPUStrategy(tpu)
            print(""TPU initialized"")
        except _:
            print(""failed to initialize TPU"")
    else:
        DEVICE = ""GPU""

if DEVICE != ""TPU"":
    print(""Using default strategy for CPU and single GPU"")
    strategy = tf.distribute.get_strategy()

if DEVICE == ""GPU"":
    print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
    

AUTO     = tf.data.experimental.AUTOTUNE
REPLICAS = strategy.num_replicas_in_sync
print(f'REPLICAS: {REPLICAS}')GCS_PATH = [None]*FOLDS
for i,k in enumerate(IMG_SIZES):
    GCS_PATH[i] = KaggleDatasets().get_gcs_path('siimcovid19-%ix%i-tfrec-dataset'%(k[0],k[1]))
files_train = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/train*.tfrec')))
files_test  = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/test*.tfrec')))
num_train_files = len(files_train)
num_test_files  = len(files_test)
print('train_files:',num_train_files)
print('test_files:',num_test_files)train_df = pd.read_csv('../input/siim-covid19-yolov5-2class-labels/meta.csv')
train_df.head(2)","This code installs the efficientnet package and imports pandas, numpy, random, os, and shutil. It also imports the KaggleDatasets package and tensorflow. The code then sets the verbosity, device, seed, folds, image sizes, batch sizes, and epochs. It also sets the efficientnet model to use, the augmentations, and the transformations. Finally, the code sets the dropout probability, contrast, and brightness.",8,7,0.08271120701688983
"%cd ../
!mkdir tmp
%cd tmp# Download YOLOv5
!git clone https://github.com/ultralytics/yolov5  # clone repo
%cd yolov5
# Install dependencies
%pip install -qr requirements.txt  # install dependencies

%cd ../
import torch
print(f""Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})"")# Install W&B 
!pip install -q --upgrade wandb
# Login 
import wandb
wandb.login()# Necessary/extra dependencies. 
import os
import gc
import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm
from shutil import copyfile
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

#customize iPython writefile so we can write variables
from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))TRAIN_PATH = 'input/siim-covid19-resized-to-256px-jpg/train/'
IMG_SIZE = 256
BATCH_SIZE = 16
EPOCHS = 10# Everything is done from /kaggle directory.
%cd ../

# Load image level csv file
df = pd.read_csv('input/siim-covid19-detection/train_image_level.csv')

# Modify values in the id column
df['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)
# Add absolute path
df['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)
# Get image level labels
df['image_level'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)

df.head(5)# Load meta.csv file
# Original dimensions are required to scale the bounding box coordinates appropriately.
meta_df = pd.read_csv('input/siim-covid19-resized-to-256px-jpg/meta.csv')
train_meta_df = meta_df.loc[meta_df.split == 'train']
train_meta_df = train_meta_df.drop('split', axis=1)
train_meta_df.columns = ['id', 'dim0', 'dim1']

train_meta_df.head(2)","The above code is for training a YOLOv5 model on the SIIM-Covid19 dataset. The code first changes directory to the 'tmp' folder, then clones the YOLOv5 repository. Next, it installs the necessary dependencies and logs in to WandB. Finally, it loads the image level csv file and the meta.csv file.",8,2,0.14050305345610467
"# Importing Required packages
import os
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from IPython.display import Image, clear_output
print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))
clear_output()#customize iPython writefile so we can write variables
from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))# Cloning the repo and installing requiements
!git clone https://github.com/ultralytics/yolov5.git
!mv ./yolov5/* ./
!pip install -r requirements.txt
clear_output()# Copying the dataset to working directory
!mkdir Dataset
!cp ../input/covid19-detection-for-yolov5-siimfisabiorsna/Covid19 -r ./Dataset
clear_output()len(os.listdir('./Dataset/Covid19/images'))%%writetemplate ./split_dataset.py
from utils.datasets import * 
autosplit('./Dataset/Covid19', weights=(0.8, 0.2, 0.0))!python split_dataset.py","This code imports the necessary packages for the project, including torch, numpy, pandas, and matplotlib. It also sets up the environment for using a GPU if one is available. Finally, it registers a line cell magic function for writing template files.

The code then clones the yolov5 repository from GitHub and installs the required packages.

Finally, the code copies the dataset to the working directory and splits it into train, test, and val sets.",8,2,0.16991580767688894
"! conda install -c conda-forge gdcm -y# import numpy as np # linear algebra
# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
# import os
# import pydicom
# import glob
# from tqdm.notebook import tqdm
# from pydicom.pixel_data_handlers.util import apply_voi_lut
# import matplotlib.pyplot as plt
# from skimage import exposure
# import cv2
# import warnings
# from fastai.vision.all import *
# from fastai.medical.imaging import *
# warnings.filterwarnings('ignore')

import os
import pydicom
import glob
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt 
dataset_path = '../input/siim-covid19-detection/'

for path in glob.glob(dataset_path  + '*'):
    print(path)train_images = '../input/siim-covid19-detection/train/'

n_folders = len(glob.glob(train_images  + '*'))
n_subfolders = len(glob.glob(train_images  + '*/*'))
n_images = len(glob.glob(train_images  + '*/*/*.dcm'))

print(f'There are {n_subfolders} subfolders in {n_folders} folders.')
print(f'There are altogether {n_images} images.')folders = glob.glob(train_images  + '*')

subfolder_dict = {}

for folder in folders:
    n = len(glob.glob(folder + '/*'))
    if n in subfolder_dict.keys():
        subfolder_dict[n] += 1
    else:
        subfolder_dict[n] = 1
        
for k, v in subfolder_dict.items():
    print(f'There is {v} subfolders with {k} images.')

subfolders = glob.glob(train_images  + '*/*')

image_dict = {}

for subfolder in subfolders:
    n = len(glob.glob(subfolder + '/*'))
    if (n!=1):
        print (subfolder.split('/')[-1])
        for image in glob.glob(subfolder + '/*'):
            print ('-->' + image.split('/')[-1])

    if n in image_dict.keys():
        image_dict[n] += 1
    else:
        image_dict[n] = 1
        
for k, v in image_dict.items():
    print(f'There is {v} subfolders with {k} images.')
train_study_df = pd.read_csv(dataset_path +'/train_study_level.csv')

train_study_df","This code loads in the dataset path and then counts the number of folders, subfolders, and images in the dataset. It also prints out the number of subfolders and images in each folder. Finally, it creates a dataframe containing information about the studies in the dataset.",9,1,0.08466772492714549
"import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import glob
import pydicomsiim_covid19_dir = os.path.join(
    '..', 'input', 'siim-covid19-detection')def read_csv(file_name):
    file_path = os.path.join(siim_covid19_dir, file_name)
    df = pd.read_csv(file_path)
    return dfstudy_level_df = read_csv('train_study_level.csv')

study_level_df# How many rows?
study_level_num_rows = len(study_level_df)

study_level_num_rows# Are unique? Any duplicates?
study_level_num_unique_ids = len(pd.unique(study_level_df['id']))

if study_level_num_unique_ids == study_level_num_rows:
    print(""Unique and no duplicates"")
else:
    print(""Some duplicates"")# What are the unique value combinations? How many of them?
study_level_label_colums = [
    'Negative for Pneumonia', 'Typical Appearance',
    'Indeterminate Appearance', 'Atypical Appearance' ]
study_level_labels_df = study_level_df[study_level_label_colums]
study_level_label_values = study_level_labels_df.values

study_level_unique_label_combinations, \
study_level_unique_label_counts = \
    np.unique(
        study_level_label_values, return_counts=True, axis=0)

print(""Unique Combinations:\n"", study_level_unique_label_combinations)
print(""Unique Counts:\n"", study_level_unique_label_counts)","This code imports the necessary libraries for reading in data, processing it, and visualizing it. It then defines a function for reading in CSV files. Next, it reads in the study_level.csv file and stores it in a dataframe. It then prints the number of rows in the dataframe, checks for duplicates, and prints the unique combinations of values in the dataframe.",8,3,0.07948382739785154
"# Libraries
import warnings
warnings.filterwarnings('ignore')

import os
import numpy as np
import pandas as pd
import seaborn as sns
import glob
from pandas import DataFrame
from matplotlib.lines import Line2D
import matplotlib.pyplot as plt
%matplotlib inline
import plotly.express as px
from tqdm.notebook import tqdm

# Image processing and Computer Vision
from skimage import exposure
import cv2
# Package designed to manipulate data elements in DICOM files 

import pydicom
#Image Transformation
from pydicom.pixel_data_handlers.util import apply_voi_lut

from fastai.vision.all import *
from fastai.medical.imaging import *

#train_image
train_image_df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
train_image_df.head(2)#train_study
train_study_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
train_study_df.head()# Bar plot function defination
def viz_bar_plot(df,x,x_title,y,title,colors=None,text=None):
    fig = px.bar(x=x,
                 y=y,
                 text=text,
                 labels={x: x_title.title()},   
                 data_frame=df,
                 color=colors,
                 barmode='group',
                 template=""simple_white"")
    texts = [df[col].values for col in y]
    for i, t in enumerate(texts):
        fig.data[i].text = t
        fig.data[i].textposition = 'inside'  
    fig['layout'].title=title
    fig.update_layout(title_font_size=19)
    fig.update_layout(title_font_family='Droid Serif')
    fig.update_layout(width=800,height=500)
    for trace in fig.data:
        trace.name = trace.name.replace('_',' ').title()
    fig.update_yaxes(tickprefix="""", showgrid=True)
    fig.show()# Study Data
# create 'target' column in train_study_df dataset
train_study_df['target']='Negative for Pneumonia'
train_study_df.loc[train_study_df['Typical Appearance']==1,'target']='Typical Appearance'
train_study_df.loc[train_study_df['Indeterminate Appearance']==1,'target']='Indeterminate Appearance'
train_study_df.loc[train_study_df['Atypical Appearance']==1,'target']='Atypical Appearance'
train_study_df1=train_study_df.groupby(['target']).size().reset_index(name='counts')
train_study_df1# Bar Visulaization of label categories
viz_bar_plot(train_study_df1,
         'target',
         'target',
         ['counts'],
         title='Target Label Count')","This code is for generating a bar plot of the label categories in the train_study_df dataset. The x-axis represents the label category, the y-axis represents the number of studies in each category, and the colors represent the counts in each category. The title of the plot is ""Target Label Count"".",8,1,0.08951653793945989
"! conda install -c conda-forge gdcm -yimport numpy as np
import pandas as pd 
import os
from PIL import Image
from tqdm.auto import tqdm
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import seaborn as sns
from pandas_profiling import ProfileReport
from glob import glob
from tqdm.notebook import tqdm
import matplotlib.pyplot as plt
from skimage import exposure
import cv2
import warnings
import albumentations as A# config params
class CFG:
    data_path = '../input/siim-covid19-detection/'
    size = 512
    seed = 2021
    working_dir = '/kaggle/working/'def dicom2array(path, voi_lut=True, fix_monochrome=True):
    dicom = pydicom.read_file(path)
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
    return data
        
    
def plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()
# storage file for the transformed images
!mkdir train# prepare a dataframe for producing resized images with bboxes
xtrain_img = pd.read_csv(CFG.data_path + 'train_image_level.csv')


path_list = []
image_list = []
splits = []

for split in ['train']:
    
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            fullpath = dirname + '/' + file
            path_list.append(fullpath)
            image_list.append(file)

df = pd.DataFrame(image_list, columns =['image_id'])
df['image_path'] = path_list

xtrain_img['image_id'] = xtrain_img['id'].apply(lambda s: s.replace('_image','') + '.dcm')
xtrain_img = pd.merge(left = xtrain_img, right = df, on = 'image_id')
# common transformation we shall use
transform = A.Compose(
    [
        A.Resize(height = CFG.size , width = CFG.size, p=1),
    ], 
    p=1.0,  bbox_params=A.BboxParams( format='pascal_voc', min_area=0,  min_visibility=0, label_fields=['labels']  ))        

img_list = []
label_list = []

# loop over files
for ii in range(len(xtrain_img)):
    # get the image
    row = xtrain_img.loc[ii]
    img_path = row['image_path']
    img = dicom2array(path=img_path)
    newname = img_path.split('/')[-1].replace('dcm', 'jpg')
    img_list.append(newname)
    
    # get the bounding boxes
    bboxes = []
    bbox = []
    labels = []
    confidences = []

    for i, l in enumerate(row['label'].split(' ')):
        if (i % 6 == 0) :
            labels.append(l)
        if (i % 6 == 1):
            confidences.append(l)
        if (i % 6 > 1):
            bbox.append(np.clip(float(l), a_min = 0, a_max = None ))
        if i % 6 == 5:
            bboxes.append(bbox)
            bbox = []    

    # transform both
    result = transform(image = img, bboxes = bboxes, labels = np.ones(len(bboxes)))
    new_image = result['image']
    new_bboxes = np.array(result['bboxes']).tolist()

    # format the output
#    print('orig label: ' + row['label'])
    newlabel = ''
    if labels[0] == 'none':
        newlabel = 'none 1 0 0 1 1'
    else:
        for j in range(len(labels)):
            newlabel += labels[j] + ' ' + confidences[j] + ' ' +  ' '.join([str(np.round(f,5)) for f in new_bboxes[0]]) + ' '
#    print('new label:' + newlabel)
    label_list.append(newlabel)
    
    # store the new image
    cv2.imwrite(CFG.working_dir + 'train/' + newname , new_image)","This code is for preparing training data for a Covid-19 detection model. It takes in a DICOM image, transforms it into a JPEG image, and then stores it in the working directory. The code also generates bounding boxes for each image.",8,0,0.17575205237397312
"!wget 'https://anaconda.org/conda-forge/libjpeg-turbo/2.1.0/download/linux-64/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/libgcc-ng/9.3.0/download/linux-64/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/gdcm/2.8.9/download/linux-64/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/conda/4.10.1/download/linux-64/conda-4.10.1-py37h89c1867_0.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/certifi/2020.12.5/download/linux-64/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/openssl/1.1.1k/download/linux-64/openssl-1.1.1k-h7f98852_0.tar.bz2' -q","The code above downloads the following packages from Anaconda:

- libjpeg-turbo
- libgcc-ng
- gdcm
- conda
- certifi
- openssl

Each package is downloaded as a "".tar.bz2"" file, which is a compressed archive. The ""-q"" option tells the ""wget"" command to run quietly, without printing output to the screen.",8,7,0.1558928143370977
"! conda install gdcm -c conda-forge -y! pip install --no-deps '../input/timm-package/timm-0.1.26-py3-none-any.whl' > /dev/null
! pip install --no-deps '../input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl' > /dev/nullimport sys
sys.path.insert(0, ""../input/timm-efficientdet-pytorch"")
sys.path.insert(0, ""../input/omegaconf"")

import os
from PIL import Image
import pandas as pd
from tqdm.auto import tqdm
import numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import torch
from datetime import datetime
import time
import random
import cv2
import albumentations as A
import matplotlib.pyplot as plt
from albumentations.pytorch.transforms import ToTensorV2
from sklearn.model_selection import StratifiedKFold
from torch.utils.data import Dataset,DataLoader
from torch.utils.data.sampler import SequentialSampler, RandomSampler
from glob import glob

SEED = 42

def seed_everything(seed):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = True

seed_everything(SEED)dataset_path = ""../input/siim-covid19-detection""def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return data

def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im
        
    
def plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()
%%time
image_id = []


cnt_img = 0 # for testing

for split in ['test', 'train']:
    save_dir = f'/kaggle/tmp/{split}/'

    os.makedirs(save_dir, exist_ok=True)
    
    for dirname, _, filenames in tqdm(os.walk(f'{dataset_path}/{split}')):
        for file in filenames:
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(os.path.join(dirname, file))
            im = resize(xray, size=256)  
            im.save(os.path.join(save_dir, file.replace('dcm', 'jpg')))

            image_id.append(file.replace('.dcm', ''))

            splits.append(split)
        
        if cnt_img >= 10:
            cnt_img = 0
            break
        
        cnt_img += 1
            image_id","This code reads in a DICOM image, applies a VOI LUT to it if available, and then resizes it to 256x256. The image is then saved as a JPEG. This process is repeated for all images in the dataset.",8,1,0.1163816209716604
"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -yimport os

from PIL import Image
import pandas as pd
from tqdm.auto import tqdmimport numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im
split = 'test'
save_dir = f'/kaggle/tmp/{split}/'

os.makedirs(save_dir, exist_ok=True)

save_dir = f'/kaggle/tmp/{split}/study/'
os.makedirs(save_dir, exist_ok=True)

for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
    for file in filenames:
        # set keep_ratio=True to have original aspect ratio
        xray = read_xray(os.path.join(dirname, file))
        im = resize(xray, size=600)  
        study = dirname.split('/')[-2] + '_study.png'
        im.save(os.path.join(save_dir, study))
import numpy as np 
import pandas as pd

df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
id_laststr_list  = []
for i in range(df.shape[0]):
    id_laststr_list.append(df.loc[i,'id'][-1])
df['id_last_str'] = id_laststr_list

study_len = df[df['id_last_str'] == 'y'].shape[0]!pip install /kaggle/input/kerasapplications -q
!pip install /kaggle/input/efficientnet-keras-source-code/ -q --no-deps

import os

import efficientnet.tfkeras as efn
import numpy as np
import pandas as pd
import tensorflow as tf

def auto_select_accelerator():
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        tf.config.experimental_connect_to_cluster(tpu)
        tf.tpu.experimental.initialize_tpu_system(tpu)
        strategy = tf.distribute.experimental.TPUStrategy(tpu)
        print(""Running on TPU:"", tpu.master())
    except ValueError:
        strategy = tf.distribute.get_strategy()
    print(f""Running on {strategy.num_replicas_in_sync} replicas"")

    return strategy


def build_decoder(with_labels=True, target_size=(300, 300), ext='jpg'):
    def decode(path):
        file_bytes = tf.io.read_file(path)
        if ext == 'png':
            img = tf.image.decode_png(file_bytes, channels=3)
        elif ext in ['jpg', 'jpeg']:
            img = tf.image.decode_jpeg(file_bytes, channels=3)
        else:
            raise ValueError(""Image extension not supported"")

        img = tf.cast(img, tf.float32) / 255.0
        img = tf.image.resize(img, target_size)

        return img

    def decode_with_labels(path, label):
        return decode(path), label

    return decode_with_labels if with_labels else decode


def build_augmenter(with_labels=True):
    def augment(img):
        img = tf.image.random_flip_left_right(img)
        img = tf.image.random_flip_up_down(img)
        return img

    def augment_with_labels(img, label):
        return augment(img), label

    return augment_with_labels if with_labels else augment


def build_dataset(paths, labels=None, bsize=32, cache=True,
                  decode_fn=None, augment_fn=None,
                  augment=True, repeat=True, shuffle=1024, 
                  cache_dir=""""):
    if cache_dir != """" and cache is True:
        os.makedirs(cache_dir, exist_ok=True)

    if decode_fn is None:
        decode_fn = build_decoder(labels is not None)

    if augment_fn is None:
        augment_fn = build_augmenter(labels is not None)

    AUTO = tf.data.experimental.AUTOTUNE
    slices = paths if labels is None else (paths, labels)

    dset = tf.data.Dataset.from_tensor_slices(slices)
    dset = dset.map(decode_fn, num_parallel_calls=AUTO)
    dset = dset.cache(cache_dir) if cache else dset
    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset
    dset = dset.repeat() if repeat else dset
    dset = dset.shuffle(shuffle) if shuffle else dset
    dset = dset.batch(bsize).prefetch(AUTO)

    return dset

#COMPETITION_NAME = ""siim-cov19-test-img512-study-600""
strategy = auto_select_accelerator()
BATCH_SIZE = strategy.num_replicas_in_sync * 16

IMSIZE = (224, 240, 260, 300, 380, 456, 528, 600)

#load_dir = f""/kaggle/input/{COMPETITION_NAME}/""
sub_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
sub_df = sub_df[:study_len]
test_paths = f'/kaggle/tmp/{split}/study/' + sub_df['id'] +'.png'

sub_df['negative'] = 0
sub_df['typical'] = 0
sub_df['indeterminate'] = 0
sub_df['atypical'] = 0


label_cols = sub_df.columns[2:]

test_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[7], IMSIZE[7]), ext='png')
dtest = build_dataset(
    test_paths, bsize=BATCH_SIZE, repeat=False, 
    shuffle=False, augment=False, cache=False,
    decode_fn=test_decoder
)

with strategy.scope():
    
    models = []
    
    models0 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model0.h5'
    )
    models1 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model1.h5'
    )
    models2 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model2.h5'
    )
    models3 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model3.h5'
    )
    models4 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model4.h5'
    )
    
    models.append(models0)
    models.append(models1)
    models.append(models2)
    models.append(models3)
    models.append(models4)

    
    
    
sub_df[label_cols] = sum([model.predict(dtest, verbose=1) for model in models]) / len(models)","This code installs the pydicom conda helper package, which allows for the reading of DICOM files. It then reads in a DICOM file, applies a VOI LUT if available, and transforms the raw data into a ""human-friendly"" view. Finally, it resizes the image to a desired size.",8,3,0.1451628615701429
"SEED  = 42
FOLDS = 5
DIM   = 512import numpy as np 
import pandas as pd 
import os, shutil
from glob import glob
from sklearn.cluster import KMeans
from tqdm.notebook import tqdm
from sklearn.preprocessing import LabelEncoder
import random
tqdm.pandas()np.random.seed(SEED)
random.seed(SEED)train_df = pd.read_csv(f'../input/siimcovid19-{DIM}-jpg-image-dataset/train.csv')
train_df['image_path'] = F'../input/siimcovid19-{DIM}-jpg-image-dataset/train/'+train_df.image_id+'.jpg'
train_df.head(2)name2label = {'Typical Appearance': 3,
 'Indeterminate Appearance': 1,
 'Atypical Appearance': 2,
 'Negative for Pneumonia': 0}
class_names = list(name2label.keys())
label2name = {v:k for k, v in name2label.items()}
train_df['class_name']  = train_df.progress_apply(lambda row:row[class_names].iloc[[row[class_names].values.argmax()]].index.tolist()[0], axis=1)
train_df['class_label'] = train_df.class_name.map(name2label)
train_df.head()from sklearn.model_selection import GroupKFold, StratifiedKFold
gkf  = GroupKFold(n_splits = 5)
train_df['fold'] = -1
for fold, (train_idx, val_idx) in enumerate(gkf.split(train_df, groups = train_df.StudyInstanceUID.tolist())):
    train_df.loc[val_idx, 'fold'] = fold
train_df.head()import matplotlib.pyplot as plt
import cv2
def load_image(path, dim=DIM, ch=3):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE if ch==None else cv2.IMREAD_COLOR)
    if img.shape[:2]!=(dim,dim) and dim!=-1:
        img = cv2.resize(img, dsize=(dim,dim), interpolation=cv2.INTER_AREA)
    return img

plt.imshow(load_image(train_df.image_path.iloc[100], dim=-1))","This code loads an image from a given path, with the option to resize it to a specified dimension.",8,0,0.04318398601502013
"# !conda install -c conda-forge imagehash --yes%load_ext autoreload
%autoreload 2
%matplotlib inline

import glob
import itertools
import collections

from PIL import Image
import cv2
from tqdm import tqdm_notebook as tqdm
import pandas as pd
import numpy as np
import torch
import imagehash

import matplotlib.pyplot as plt

def run():

    funcs = [
        imagehash.average_hash,
        imagehash.phash,
        imagehash.dhash,
        imagehash.whash,
        #lambda x: imagehash.whash(x, mode='db4'),
    ]

    SOPInstanceUIDs = []
    hashes = []
    for path in tqdm(glob.glob('../input/siim-covid19-resized-to-512px-png/*/*.png')):

        image = Image.open(path)
        imageid = path.split('/')[-1].split('.')[0]

        SOPInstanceUIDs.append(imageid)
        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))

    return SOPInstanceUIDs, np.array(hashes)

%time SOPInstanceUIDs, hashes_all = run()

hashes_all = torch.Tensor(hashes_all.astype(int)).cuda()%time sims = np.array([(hashes_all[i] == hashes_all).sum(dim=1).cpu().numpy()/256 for i in range(hashes_all.shape[0])])
indices1 = np.where(sims > 0.99)
indices2 = np.where(indices1[0] != indices1[1])
SOPInstanceUID1 = [SOPInstanceUIDs[i] for i in indices1[0][indices2]]
SOPInstanceUID2 = [SOPInstanceUIDs[i] for i in indices1[1][indices2]]
dups = {tuple(sorted([SOPInstanceUID1,SOPInstanceUID2])):True for SOPInstanceUID1, SOPInstanceUID2 in zip(SOPInstanceUID1, SOPInstanceUID2)}
print('found %d duplicates' % len(dups))dups","This code uses the imagehash library to find duplicates in a dataset of images. First, the code defines a list of functions to be used for hashing. Next, the code loops through all of the images in the dataset, calculates the hashes for each image, and stores the results in a list. Finally, the code compares the hashes of all images to find duplicates.",8,2,0.08560977755937241
"!pip install gdcmimport os
from os import listdir
import pandas as pd
import numpy as np
import glob
from skimage import exposure
import matplotlib.pyplot as plt
%matplotlib inline

# pydicom
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
from fastai.imports import *
from fastai.medical.imaging import *

import cv2

# color
from colorama import Fore, Back, Style

import seaborn as sns
sns.set(style=""whitegrid"")

# plotly
import plotly.express as px
import plotly

# Suppress warnings 
import warnings
warnings.filterwarnings('ignore')

# Settings for pretty nice plots
plt.style.use('fivethirtyeight')
plt.show()# List files available
list(os.listdir(""../input/siim-covid19-detection""))IMAGE_PATH = ""../input/siim-covid19-detection/""

train_study_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
train_image_df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')

print(Fore.YELLOW + 'Train study df shape: ',Style.RESET_ALL,train_study_df.shape)
print(Fore.YELLOW + 'Train image df shape: ',Style.RESET_ALL,train_image_df.shape)display(train_study_df.head(5))
display(train_image_df.head(5))sample_submission = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
print(Fore.YELLOW + 'Sample submission df shape: ',Style.RESET_ALL,sample_submission.shape)
display(sample_submission)# Null values and Data types
print(Fore.BLUE + 'Train Study Set !!',Style.RESET_ALL)
print(train_study_df.info())
print('-------------')
print(Fore.YELLOW + 'Train Image Set !!',Style.RESET_ALL)
print(train_image_df.info())","1. The code above imports the necessary libraries for data analysis and visualization.

2. It then loads the train_study_level.csv and train_image_level.csv files into pandas dataframes.

3. Next, it prints the shape of the dataframes.

4. Finally, it displays the first 5 rows of each dataframe.",8,3,0.040395547012541666
"!pip install -q efficientnet >> /dev/nullimport pandas as pd, numpy as np, random,os, shutil
from glob import glob
from kaggle_datasets import KaggleDatasets
import tensorflow as tf, re, math
import tensorflow.keras.backend as K
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt
import tensorflow_addons as tfa
print('tf:',tf.__version__)# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit
VERBOSE      = 0
DISPLAY_PLOT = True

DEVICE = ""TPU"" #or ""GPU""

# USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD
SEED = 42

# NUMBER OF FOLDS. USE 2, 5, 10
FOLDS = 5

# WHICH IMAGE SIZES TO LOAD EACH FOLD
# CHOOSE 128, 192, 256, 384, 512, 512 
IMG_SIZES = [[512, 512]]*FOLDS

# BATCH SIZE AND EPOCHS
BATCH_SIZES = [16]*FOLDS
EPOCHS      = [12]*FOLDS

# WHICH EFFICIENTNET B? TO USE
EFF_NETS = [7]*FOLDS

# Augmentations
AUGMENT   = True
TRANSFORM = True

# transformations
ROT_    = 0.0
SHR_    = 2.0
HZOOM_  = 8.0
WZOOM_  = 8.0
HSHIFT_ = 8.0
WSHIFT_ = 8.0

# Dropout
PROBABILITY = 0.75
CT          = 8
SZ          = 0.08

#bri, contrast
sat  = (0.7, 1.3)
cont = (0.8, 1.2)
bri  =  0.1

# WEIGHTS FOR FOLD MODELS WHEN PREDICTING TEST
WGTS = [1/FOLDS]*FOLDS

# TEST TIME AUGMENTATION STEPS
TTA = 1def seeding(SEED):
    np.random.seed(SEED)
    random.seed(SEED)
    os.environ['PYTHONHASHSEED'] = str(SEED)
    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)
    tf.random.set_seed(SEED)
    print('seeding done!!!')
seeding(SEED)if DEVICE == ""TPU"":
    print(""connecting to TPU..."")
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        print('Running on TPU ', tpu.master())
    except ValueError:
        print(""Could not connect to TPU"")
        tpu = None

    if tpu:
        try:
            print(""initializing  TPU ..."")
            tf.config.experimental_connect_to_cluster(tpu)
            tf.tpu.experimental.initialize_tpu_system(tpu)
            strategy = tf.distribute.experimental.TPUStrategy(tpu)
            print(""TPU initialized"")
        except _:
            print(""failed to initialize TPU"")
    else:
        DEVICE = ""GPU""

if DEVICE != ""TPU"":
    print(""Using default strategy for CPU and single GPU"")
    strategy = tf.distribute.get_strategy()

if DEVICE == ""GPU"":
    print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
    

AUTO     = tf.data.experimental.AUTOTUNE
REPLICAS = strategy.num_replicas_in_sync
print(f'REPLICAS: {REPLICAS}')GCS_PATH = [None]*FOLDS
for i,k in enumerate(IMG_SIZES):
    GCS_PATH[i] = KaggleDatasets().get_gcs_path('siimcovid19-%ix%i-tfrec-dataset'%(k[0],k[1]))
files_train = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/train*.tfrec')))
files_test  = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/test*.tfrec')))
num_train_files = len(files_train)
num_test_files  = len(files_test)
print('train_files:',num_train_files)
print('test_files:',num_test_files)train_df = pd.read_csv('../input/siim-covid19-yolov5-2class-labels/meta.csv')
train_df.head(2)","This code imports the necessary libraries for the project, sets up the TPU for training, and loads the training and testing data. The code also defines the parameters for training, such as the batch size, number of epochs, and image size. Finally, the code sets up the data augmentation parameters.",9,0,0.07108363651092386
"import pandas as pd df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')dfid_laststr_list  = []
for i in range(df.shape[0]):
    id_laststr_list.append(df.loc[i,'id'][-1])
df['id_last_str'] = id_laststr_liststudy_len = df[df['id_last_str'] == 'y'].shape[0]study_str = 'negative 1 0 0 1 1 atypical 1 0 0 1 1 typical 1 0 0 1 1 indeterminate 1 0 0 1 1'
for i in range(study_len):
    df.loc[i, 'PredictionString'] = study_strdf = df[['id', 'PredictionString']]","The code imports the pandas library and reads in a CSV file containing data on Covid-19 patients. It then creates a new column called 'id_last_str' which contains the last character of each patient's ID. The code then calculates the number of patients in the study who have a 'y' as their last character ('study_len'), and creates a string ('study_str') containing the prediction for each of these patients. Finally, the code outputs a new CSV file containing the patient IDs and predictions.",8,3,0.05578108536635429
"import numpy as np 
import pandas as pd 
import os
from tqdm import tqdm
import matplotlib.pyplot as plt
import pydicomtrain_st = pd.read_csv(""../input/siim-covid19-detection/train_study_level.csv"")
train_st.head(3)
train_im = pd.read_csv(""../input/siim-covid19-detection/train_image_level.csv"")
train_im.head(3)sample = pd.read_csv(""../input/siim-covid19-detection/sample_submission.csv"")
sample.head(3)train_path = ""../input/siim-covid19-detection/train""
test_path = ""../input/siim-covid19-detection/test""trainimlist = []

for dirname, _, filenames in os.walk(train_path):
    for filename in filenames:
        trainimlist.append(os.path.join(dirname, filename))testimlist = []

for dirname, _, filenames in os.walk(test_path):
    for filename in filenames:
        testimlist.append(os.path.join(dirname, filename))","This code imports the necessary libraries for the project, reads in the training and testing data, and creates lists of all the training and testing images.",8,0,0.03226200490005314
"import fastai
import fastai.medical
from fastai.basics import *
from fastai.vision.all import *
from fastai.medical.imaging import *

import pydicom

import pandas as pd
fastai.__version__!conda install -c conda-forge gdcm -yfilegroup='train'
path='../input/siim-covid19-detection'
dirName = f'{path}/{filegroup}/'# Get DICOM file list from train directory
items = get_dicom_files(dirName)df_trn = pd.DataFrame.from_dicoms(items,px_summ=False)
df_trn.to_csv(f'alldicom{filegroup}.csv')
df_trn.describe()
df_trnfilegroup='test'
dirName = f'{path}/{filegroup}/'","1. The fastai library is imported for use in the code.

2. The medical module from fastai is imported.

3. The basics module from fastai is imported.

4. The vision module from fastai is imported.

5. The imaging module from fastai is imported.

6. The pydicom library is imported.

7. The pandas library is imported.

8. The filegroup 'train' is selected from the input path.

9. The get_dicom_files() function is used to retrieve a list of DICOM files from the selected filegroup.

10. The retrieved files are then converted into a pandas dataframe.

11. The dataframe is then saved as a CSV file.

12. Finally, the filegroup 'test' is selected and the same process is repeated.",8,13,0.15353042127109967
"import numpy as np 
import pandas as pd
import os
import matplotlib.pyplot as plt
import pydicom as dicom
from glob import glob
from pathlib import Path
from pydicom import dcmread
import matplotlib
import astStudy= pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')Study.describe()Study.head()Study.isnull().sum()image_level=pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')image_level.head()","This code imports the numpy, pandas, os, matplotlib, pydicom, and glob libraries, and then reads in a CSV file containing information about medical studies. It then displays some basic information about the data, checks for null values, and reads in another CSV file containing information about individual images.",8,4,0.054957963469600205
"#Attaullah
#attaullahshafiq10@gmail.com
# Import libs
!conda install gdcm -c conda-forge -y
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
import pydicom
import glob
from tqdm.notebook import tqdm
from pydicom.pixel_data_handlers.util import apply_voi_lut
import matplotlib.pyplot as plt
from skimage import exposure#import gdcm
import cv2
import warnings
from fastai.vision.all import *
from fastai.medical.imaging import *
warnings.filterwarnings('ignore')
dataset_path = Path('../input/siim-covid19-detection')
import vtk

from vtk.util import numpy_support

reader = vtk.vtkDICOMImageReader()#HTML view

from IPython.display import HTML
HTML('<iframe src=https://arxiv.org/pdf/1506.01497.pdf width=600 height=650></iframe>')# from https://www.kaggle.com/tanlikesmath/siim-covid-19-detection-a-simple-eda
def dicom2array(path, voi_lut=True, fix_monochrome=True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()


def plot_imgs(imgs, cols=4, size=7, is_rgb=True, title="""", cmap='gray', img_size=(500,500)):
    rows = len(imgs)//cols + 1
    fig = plt.figure(figsize=(cols*size, rows*size))
    for i, img in enumerate(imgs):
        if img_size is not None:
            img = cv2.resize(img, img_size)
        fig.add_subplot(rows, cols, i+1)
        plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()dicom_paths = get_dicom_files(dataset_path/'train')
print([str(path) for path in dicom_paths[:4]])
imgs = [dicom2array(str(path)) for path in dicom_paths[:4]]
plot_imgs(imgs)","This code imports the necessary libraries for working with DICOM files, then defines a function for converting DICOM files to numpy arrays. The code then reads in a list of DICOM files from a given directory, converts them to numpy arrays, and plots the resulting images.",8,2,0.10291647483394922
"!pip install -q --upgrade wandb

import wandb
wandb.login()import os
import gc
import cv2
import ast
import numpy as np
import pandas as pd
from tqdm import tqdm
import matplotlib.pyplot as plt
%matplotlib inlineTRAIN_PATH = '../input/siim-covid19-resized-to-256px-jpg/train/'
IMG_SIZE = 256
NUM_SAMPLES_TO_VIZ = 32# Load image level csv file
df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
# Load study level csv file
label_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')

# Modify values in the id column
df['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)
# Add absolute path
df['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)
# Get image level labels
df['image_level'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)

# Modify values in the id column
label_df['id'] = label_df.apply(lambda row: row.id.split('_')[0], axis=1)
# Rename the column id with StudyInstanceUID
label_df.columns = ['StudyInstanceUID', 'Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']

# Merge both dataframes
df = df.merge(label_df, on='StudyInstanceUID',how=""left"")
df.head(2)print(f'Number of unique image in training dataset: {len(df)}')

bbox_nan_num = df['boxes'].isna().sum()
print(f'Number of images without any bbox annotation: {bbox_nan_num}')# Label encode study-level labels
labels = df[['Negative for Pneumonia','Typical Appearance','Indeterminate Appearance','Atypical Appearance']].values
labels = np.argmax(labels, axis=1)

df['study_level'] = labels
df.head(2)class_label_to_id = {
    'Negative for Pneumonia': 0,
    'Typical Appearance': 1,
    'Indeterminate Appearance': 2,
    'Atypical Appearance': 3
}

class_id_to_label = {val: key for key, val in class_label_to_id.items()}","This code installs the wandb library and imports it. It also sets up some constants for use later in the code.

Next, the code loads in two CSV files - one containing image-level labels, and one containing study-level labels. The image-level labels are processed to extract the image ID and the label, and the study-level labels are processed to extract the study ID and the label.

The code then merges the two dataframes, so that each row in the resulting dataframe contains both an image ID and a study ID. Finally, the study-level labels are encoded as integers.",8,3,0.19787153515044845
"!conda install gdcm -c conda-forge -yimport os

from PIL import Image
import pandas as pd
from tqdm.auto import tqdmimport numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return imtrain = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')path = '../input/siim-covid19-detection/train/ae3e63d94c13/288554eb6182/e00f9fe0cce5.dcm'
dicom = pydicom.read_file(path)image_id = []
dim0 = []
dim1 = []
splits = []

for split in ['test', 'train']:
    save_dir = f'/kaggle/tmp/{split}/'

    os.makedirs(save_dir, exist_ok=True)
    
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(os.path.join(dirname, file))
            im = resize(xray, size=768)  
            im.save(os.path.join(save_dir, file.replace('dcm', 'jpg')))

            image_id.append(file.replace('.dcm', ''))
            dim0.append(xray.shape[0])
            dim1.append(xray.shape[1])
            splits.append(split)","This code reads in a DICOM file, applies a VOI LUT (if available), and then transforms the raw data into a ""human-friendly"" view. It also resizes the image to a specified size. Finally, it saves the image as a JPEG file.",8,1,0.2317144003058128
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport sys
sys.path.append('../input/timm-pytorch-models/archive (3)/pytorch-image-models-master')
import timmimport numpy as np 
import pandas as pd 

import math
import random 
import os 
import cv2
import timm

from tqdm import tqdm 

import albumentations as A 
from albumentations.pytorch.transforms import ToTensorV2
import torch 
from torch.utils.data import Dataset 
from torch import nn
import torch.nn.functional as F 

import gc
import cudf
import cuml
import cupy
from cuml.feature_extraction.text import TfidfVectorizer
from cuml.neighbors import NearestNeighborsclass CFG:
    
    img_size = 512
    batch_size = 12
    seed = 2020
    
    device = 'cuda'
    classes = 11014
    
    model_name = 'eca_nfnet_l0'
    model_path = '../input/pytorch-model-weights/arcface_512x512_nfnet_l0 (mish).pt'
    
    scale = 30 
    margin = 0.5def read_dataset():
    df = pd.read_csv('../input/shopee-product-matching/test.csv')
    df_cu = cudf.DataFrame(df)#cuDF is a Python GPU DataFrame library workflow is fast enough on a single GPU fits in memory on a single GPU
    image_paths = '../input/shopee-product-matching/test_images/' + df['image']
    return df, df_cu, image_pathsdef seed_torch(seed=42):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    
seed_torch(CFG.seed)def get_image_predictions(df, embeddings,threshold = 0.0):
    
    if len(df) > 3:
        KNN = 50
    else : 
        KNN = 3
    
    model = NearestNeighbors(n_neighbors = KNN, metric = 'cosine')
    model.fit(embeddings)
    distances, indices = model.kneighbors(embeddings)
    
    predictions = []
    for k in tqdm(range(embeddings.shape[0])):
        idx = np.where(distances[k,] < threshold)[0]
        ids = indices[k,idx]
        posting_ids = df['posting_id'].iloc[ids].values
        predictions.append(posting_ids)
        
    del model, distances, indices
    gc.collect()
    return predictions","This function takes in a dataframe, embeddings, and a threshold, and outputs predictions for each row in the dataframe. The predictions are based on the cosine similarity between the embeddings, and the threshold determines how similar the embeddings must be in order to be considered a match.",8,2,0.14614549694325918
"%%capture
!pip install ../input/pytorchimagemodelsimport sys
sys.path.append('../input/facebookdeit')import os
import gc
import sys

import math
import random

from tqdm.notebook import tqdm

import re

import cv2
import numpy as np
import pandas as pd

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset ,RandomSampler

import timm

import albumentations

from swav_resnet import resnet50w2

import transformers
from transformers import AutoModel, AutoTokenizer

from models import deit_base_distilled_patch16_224



import cudf
import cuml
import cupydef set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True

set_seed(0)text_models=[
    {
        'transformer_model': '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14',
        'model_path' : '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14/ckpt.pt',
        'MAX_LEN' : 128,
        'params' : {
            'embed_dim' :1024,
            'out_dim' : 11014
        }
        
    },
    {
            'transformer_model': '../input/shopee-bert-base-indonesian/bert-base-indonesian_pp_7_8',
            'model_path' : '../input/shopee-bert-base-indonesian/bert-base-indonesian_pp_7_8/ckpt.pt',
            'MAX_LEN' : 128,
            'params' : {
                'embed_dim' :1024,
                'out_dim' : 11014
            }

        }
]

TRANSFORMER_EMBED_DIM = 768joint_models=[
    {
        'transformer_model': '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14',
        'model_path' : '../input/deit-xlm-joint-weights/finetuned_deit_xlm_joint_7_11.pt',
        'MAX_LEN' : 128,
        'IMAGE_SIZE' : 224,
        'params' : {
                'embed_dim' : 2048,
                'out_dim' : 11014
            }
        
    }
]image_models=[
    {
        'vision_model': '../input/shopee-swav-finetuned-resnet50w2/swav_resnet50w2_224_2048_5_epochs_loss_12_beef.pt',
        'IMAGE_SIZE' : 224,
        'params' : {
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
    {
        'vision_model': '../input/effnet-weights/finetuned_tf_efficientnet_b3_ns_300_2048_7_9.pt',
        'IMAGE_SIZE' : 300,
        'params' : {
            'backbone_name' : 'tf_efficientnet_b3_ns',
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
    
    {
        'vision_model': '../input/deit-base-distilled-patch16-224/finetuned_deit_base_distilled_patch16_224_4_18.pt',
        'IMAGE_SIZE' : 224,
        'params' : {
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
]","This code defines three types of models: text, image, and joint.

The text models are Paraphrase-XLMR and BERT-Indonesian.

The image models are SWAV-ResNet50W2 and DEIT-Base-Distilled-Patch16-224.

The joint model is Paraphrase-XLMR.

Each model has a corresponding model path, MAX_LEN, and params.

The params for the text models are:

-embed_dim: The dimension of the embedding layer.

-out_dim: The dimension of the output layer.

The params for the image models are:

-embed_dim: The dimension of the embedding layer.

-out_dim: The dimension of the output layer.

The params for the joint model are:

-embed_dim: The dimension of the embedding layer.

-out_dim: The dimension of the output layer.

-IMAGE_SIZE: The size of the input image.",8,6,0.06005827451399398
"import sys
import gc
import math
import configparser
import numpy as np
import pandas as pd
import optuna
from tqdm import tqdm
import sklearn
import tensorflow as tf
from tensorflow import keras
from typing import Tupletry:
    # TPU detection. No parameters necessary if TPU_NAME environment variable is
    # set: this is always the case on Kaggle.
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
    print('Running on TPU ', tpu.master())
except ValueError:
    tpu = None

if tpu:
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.TPUStrategy(tpu)
else:
    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.
    strategy = tf.distribute.get_strategy()

print(""REPLICAS: "", strategy.num_replicas_in_sync)pd.set_option(""use_inf_as_na"", True)
pd.set_option(""display.max_columns"", 9999)
pd.set_option(""display.max_rows"", 9999)
pd.set_option('max_colwidth', 9999)
INPUT = '/kaggle/input'
DATA = f'{INPUT}/shopee-product-matching'
OUTPUT = '/kaggle/working'
RESOURCE_DIR = f'{INPUT}/shopee-product-matching-lib/kaggle-shopee-product-matching-1.0'
sys.path.append(f'{INPUT}/sgcharts-ml/src')
sys.path.append(f""{INPUT}/sentence-transformers/sentence-transformers-1.0.4"")
sys.path.append(f'{RESOURCE_DIR}/src')
import mylib
import scml
from scml.nlp import strip_punctuation, to_ascii_str
scml.seed_everything()MODEL = 'efficientnetb3'
CONF = configparser.ConfigParser()
CONF.read(f""{RESOURCE_DIR}/app.ini"")
resolution = int(CONF[MODEL][""resolution""])
INPUT_SHAPE = (resolution, resolution, 3)
print(f""INPUT_SHAPE={INPUT_SHAPE}"")train = pd.read_csv(f""{DATA}/train.csv"", engine=""c"", low_memory=False)
train[""target""] = mylib.target_label(train)
le = sklearn.preprocessing.LabelEncoder()
train[""label_group""] = le.fit_transform(train['label_group'])
n_classes=len(le.classes_)
print(f""n_classes={n_classes}"")
train.info()train.head()def _data_gen(
    dataframe,
    directory,
    target_size,
    batch_size,
    color_mode=""rgb"",
    class_mode=""raw"",
    x_col=""image"",
    y_col=""label_group""
):
    dtype = np.float32
    rescale = 1./255
    interpolation = ""bicubic""
    data_format = ""channels_last""
    shuffle = True
    idg = keras.preprocessing.image.ImageDataGenerator(
        shear_range=0.2,
        zoom_range=0.2,
        brightness_range=(0.7, 1.3),
        #rotation_range=90,
        horizontal_flip=True,
        rescale=rescale,
        data_format=data_format,
        dtype=dtype
    )
    g = idg.flow_from_dataframe(
        dataframe=dataframe,
        x_col=x_col,
        y_col=y_col,
        directory=directory,
        target_size=target_size,
        color_mode=color_mode,
        batch_size=batch_size,
        shuffle=shuffle,
        class_mode=class_mode,
        interpolation=interpolation,
    )
    while True:
        x, y = g.next()
        yield [x, y], y","This code defines a function for generating data for training a machine learning model. The function takes in a dataframe, directory, target_size, batch_size, color_mode, class_mode, x_col, and y_col as parameters. The function returns a generator that yields a tuple of two elements, x and y. The x element is a numpy array containing the input data, and the y element is a numpy array containing the target labels.",8,3,0.10583227239073247
"import pip
try:
     __import__(""imutils"")
except ImportError:
    pip.main([""install"", ""imutils""])import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import  matplotlib.pyplot as plt
import tensorflow as tf
import pandas as pd
import cv2
from imutils.object_detection import non_max_suppression
import pytesseract
import os
import glob
os.chdir('/kaggle/working')
BASE = '../input/shopee-product-matching/train_images/'
EAST_PATH = ""/kaggle/input/east-data-leo/frozen_east_text_detection/frozen_east_text_detection.pb""
RESIZE_IMG_SHAPE = (500,500)
img_paths = glob.glob(f""{BASE}*jpg"") train = pd.read_csv('../input/shopee-product-matching/train.csv')
print('train shape is', train.shape )
train.head()groups = train.label_group.value_counts()
plt.figure(figsize=(20,5))
plt.plot(np.arange(len(groups)),groups.values)
plt.ylabel('Duplicate Count',size=14)
plt.xlabel('Index of Unique Item',size=14)
plt.title('Duplicate Count vs. Unique Item Count',size=16)
plt.show()

plt.figure(figsize=(20,5))
plt.bar(groups.index.values[:50].astype('str'),groups.values[:50])
plt.xticks(rotation = 45)
plt.ylabel('Duplicate Count',size=14)
plt.xlabel('Label Group',size=14)
plt.title('Top 50 Duplicated Items',size=16)
plt.show()def img_proc(img,offset =20):
    img =img[offset:-offset,offset:-offset]
    img =cv2.resize(img ,RESIZE_IMG_SHAPE)
    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    gray = cv2.medianBlur(gray,5)
    ret, thresh = cv2.threshold(gray,150,255,cv2.THRESH_BINARY)
    thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\
            cv2.THRESH_BINARY_INV,21,2)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))
    opening = cv2.erode(thresh,kernel, iterations = 1)
    closing = cv2.dilate(opening,kernel,iterations=1)
    contours = cv2.findContours(closing, 
                            cv2.RETR_EXTERNAL,
                            cv2.CHAIN_APPROX_NONE)
    canvas =np.zeros((500,500))
    cv2.drawContours(canvas, contours[0], -1, (255,0,255), thickness = 2) 
    return canvas



def displayDF(train, random=False, COLS=6, ROWS=4, path=BASE):
    for k in range(ROWS):
        plt.figure(figsize=(20,5))
        for j in range(COLS):
            if random: row = np.random.randint(0,len(train))
            else: row = COLS*k + j
            name = train.iloc[row,1]
            title = train.iloc[row,3]
            title_with_return = """"
            for i,ch in enumerate(title):
                title_with_return += ch
                if (i!=0)&(i%20==0): title_with_return += '\n'
            img = img_proc(cv2.imread(path+name))
            plt.subplot(1,COLS,j+1)
            plt.title(title_with_return)
            plt.axis('off')
            plt.imshow(img)
        plt.show()
        
displayDF(train,random=True)def predictions(prob_score, geo,min_conf):
    (numR, numC) = prob_score.shape[2:4]
    boxes = []
    confidence_val = []
    for y in range(0, numR):
        scoresData = prob_score[0, 0, y]
        x0 = geo[0, 0, y]
        x1 = geo[0, 1, y]
        x2 = geo[0, 2, y]
        x3 = geo[0, 3, y]
        anglesData = geo[0, 4, y]
        for i in range(0, numC):
            if scoresData[i] < min_conf:
                continue
            (offX, offY) = (i * 4.0, y * 4.0)
            angle = anglesData[i]
            cos = np.cos(angle)
            sin = np.sin(angle)
            h = x0[i] + x2[i]
            w = x1[i] + x3[i]
            endX = int(offX + (cos * x1[i]) + (sin * x2[i]))
            endY = int(offY - (sin * x1[i]) + (cos * x2[i]))
            startX = int(endX - w)
            startY = int(endY - h)
            boxes.append((startX, startY, endX, endY))
            confidence_val.append(scoresData[i])

    return (boxes, confidence_val)

def get_text(img,img_text ='Output',min_conf = 0.7, east = EAST_PATH):
    image = cv2.imread(img)
    orig = image.copy()
    (origH, origW) = image.shape[:2]
    (newW, newH) = (320,320)
    rW = origW / float(newW)
    rH = origH / float(newH)
    image = cv2.resize(image, (newW, newH))
    (H, W) = image.shape[:2]
    blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),
        (123.68, 116.78, 103.94), swapRB=True, crop=False)
    net = cv2.dnn.readNet(east)
    # The following two layer need to pulled from EAST model for achieving this. 
    layerNames = [
        ""feature_fusion/Conv_7/Sigmoid"",
        ""feature_fusion/concat_3""]

    #Forward pass the blob from the image to get the desired output layers
    net.setInput(blob)
    (scores, geometry) = net.forward(layerNames)
    (boxes, confidence_val) = predictions(scores, geometry,min_conf)
    boxes = non_max_suppression(np.array(boxes), probs=confidence_val)
    
    results = []
    for (startX, startY, endX, endY) in boxes:
        startX = int(startX * rW)
        startY = int(startY * rH)
        endX = int(endX * rW)
        endY = int(endY * rH)
        r = orig[startY:endY, startX:endX]
        configuration = (""-l eng --oem 1 --psm 8"")
        text = pytesseract.image_to_string(r, config=configuration)
        results.append(((startX, startY, endX, endY), text))

    orig_image = orig.copy()
    txts=[]
    for ((start_X, start_Y, end_X, end_Y), text) in results:
        text = """".join([x if ord(x) < 128 else """" for x in text]).strip()
        cv2.rectangle(orig_image, (start_X, start_Y), (end_X, end_Y),
            (0, 0, 255), 2)
        cv2.putText(orig_image, text, (start_X, start_Y + 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,255, 0), 4)
        txts.append(text)
    plt.figure(figsize=(10,10))
    plt.imshow(orig_image)
    plt.title(img_text)
    plt.show()
    print(txts)it = iter(range(500))","This code imports the pip module and tries to import the imutils module. If the imutils module is not found, the code uses pip to install it. The code then imports the numpy, pandas, matplotlib, and tensorflow modules.

The code defines a function to process images. The function takes an image and an offset as input and returns a processed image. The function first crops the image by the offset and then resize it. The function then converts the image to grayscale and applies a median blur. The function then threshold the image and finds the contours. The contours are drawn on a canvas and the canvas is returned.

The code defines a function to display dataframes. The function takes a dataframe, a Boolean value for whether to display randomly, the number of columns, the number of rows, and the path to the image directory. The function then loops through the dataframe and displays the images in the dataframe.

The code defines a function to get text from an image. The function takes an image, a minimum confidence value, and the path to the EAST text detector. The function then loads the image and resize it. The function then creates a blob from the image and passes it through the EAST text detector. The function then gets the predictions and applies non-max suppression. The function then loops through the predictions and draws the bounding boxes and text on the image. The function then returns the text.

The code then iterates through 500 images.",8,10,0.08990118867311646
,This code creates a function that calculates the sum of two numbers.,8,0,
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot  as plt
import seaborn as sns
import tensorflow as tf
from tensorflow import keras

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiontrain_data = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")
test_data = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")train_data.head()test_data.head()X_valid,X_train = train_data.loc[:5000,train_data.columns!=""label""],train_data.loc[5000:,train_data.columns!=""label""]
Y_valid,Y_train = train_data[""label""][:5001],train_data[""label""][5000:]Y_train.unique()X_train.shape","The code above loads the necessary libraries for data analysis and visualization, then loads the data from the CSV files. Next, it splits the data into training and validation sets, then displays some information about the data. Finally, it trains a neural network on the training data and evaluates it on the validation data.",9,0,0.1441950824017797
"
import numpy as np 
import pandas as pd 
import seaborn as sns
sns.set_style('darkgrid')
import matplotlib.pyplot as plt
%matplotlib inline

from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import callbacks


import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session## Import and check

train_data=pd.read_csv('../input/digit-recognizer/train.csv')

test_data=pd.read_csv('../input/digit-recognizer/test.csv')

print(train_data.shape)
print(test_data.shape)
train_data.head()index = test_data.index## 
print('missing training data:', train_data.isnull().sum().sum())
print('missing test data:', test_data.isnull().sum().sum())plt.figure(figsize=(6,6))

for i in range(49):
    image = train_data.iloc[i,1:].values.reshape([28,28])
    ax = plt.subplot(7, 7, i+1)
    ax.grid(False)
    plt.axis('off')
    plt.imshow(image, cmap='gray')sns.countplot(x='label', data=train_data)
plt.title('Dist')y = tf.keras.utils.to_categorical(train_data.pop(""label""))","This code imports the necessary libraries for data manipulation, visualization, and machine learning. It then loads the training and test data from a CSV file. The shape of the training and test data is printed, followed by the first five rows of the training data. The code then checks for missing values in the training and test data. Finally, it displays 49 images from the training data, with each image being 28x28 pixels.",9,0,0.1490752655602965
"import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import matplotlib.pyplot as plt
%matplotlib inline

# Required for ConfusionMatrixDisplay
!pip install --upgrade 'scikit-learn>=1.0'

import tensorflow as tffrom subprocess import check_output
print(check_output([""ls"", ""../input""]).decode(""utf8""))labeled_data = pd.read_csv(""../input/train.csv"")
print(labeled_data.shape)
labeled_data.head()unlabeled_data= pd.read_csv(""../input/test.csv"")
print(unlabeled_data.shape)
unlabeled_data.head()value_counts = labeled_data['label'].value_counts()
bins = value_counts.index
counts = value_counts.values

plt.bar(bins, counts)
plt.xticks(bins)
plt.xlabel('Number')
plt.ylabel('Count')
plt.show()X_labeled_raw = (labeled_data.iloc[:,1:].values).astype('float32') # all pixel values
y_labeled_raw = labeled_data.iloc[:,0].values.astype('int32') # only labels i.e targets digits
X_unlabeled_raw = unlabeled_data.values.astype('float32')X_labeled_raw","This code imports the numpy and pandas libraries, as well as matplotlib, for data visualization. It also installs and upgrades scikit-learn, a machine learning library. Finally, it imports the tensorflow library.

The code then loads the labeled data from the train.csv file, and prints the shape of the dataframe. The head() function is then used to print the first 5 rows of the dataframe.

The code then does the same for the unlabeled data in the test.csv file.

The code then creates a bar chart of the counts of each number in the labeled data.",8,6,0.06153959948660961
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import wandb
wandb.init(project='MNIST_MLP', save_code=True)
import matplotlib.pyplot as pltclass MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return datatransformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])

train_metadata = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_metadata = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)

# Before
print('Train data set:', len(train_metadata))
print('Test data set:', len(test_metadata))

# we reserve 70% of the training set for the training and the remaining 30% for validation
TRAINING_RATIO = 0.7

# split train between validation and training set
train_size = int(TRAINING_RATIO * len(train_metadata))
validation_size = len(train_metadata) - train_size

# After
print('\nTrain data set:', train_size)
print('Validation data set:', validation_size)

# Fixing the generator for reproducible results
train_dataset, validation_dataset = torch.utils.data.random_split(
    train_metadata,
    [train_size, validation_size],
    generator=torch.Generator().manual_seed(42))

BATCH_SIZE = 128

# Create data loader for train and test set
train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
validation_data_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)

test_data_loader = torch.utils.data.DataLoader(test_metadata, shuffle=False)dataiter = iter(train_data_loader)
images, labels = dataiter.next()

print(images.shape) # (number_of_images, batch, image_width, image_height)
print(labels.shape)torch.unique(labels).size(dim=0)plt.imshow(images[0].cpu().numpy().squeeze(), cmap='gray_r')
plt.title(""Ground Truth: {}"".format(labels[0]))
plt.show()","The code defines a custom dataset class for loading and processing the MNIST dataset. The dataset is split into a training set and a test set, with the training set further split into a training set and a validation set. A data loader is created for each of the three sets of data.

The code also defines a transformation to be applied to the data, which includes converting the data to a Tensor, normalizing the data, and converting it to a PIL image.

Finally, the code displays a sample image from the training set, along with its label.",8,1,0.29137396085710676
"#use python 3.7
from pyspark.sql import SparkSession
from pyspark.sql.types import IntegerType, FloatType, StructField, StructType
from numpy import array
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.utils import to_categorical
from tensorflow import convert_to_tensor
from tensorflow import reshape
from numpy import argmax


spark = SparkSession.builder.getOrCreate()
df = spark.read.option(""header"", True).option(""inferSchema"", True).csv('train.csv')
L = array([list(train.asDict().values()) for train in df.collect()])
del(df)
x_train = L[:,1:785]
y_train = L[:,0]
del(L)
x_train = [x/255. for x in x_train]
x_train = convert_to_tensor(x_train, dtype=""float32"")
x_train = reshape(x_train, (x_train.shape[0], 28, 28, 1))
df = spark.read.option(""header"", True).option(""inferSchema"", True).csv('test.csv')
x_pred = array([list(train.asDict().values()) for train in df.collect()])
del(df)
x_pred = [x/255. for x in x_pred]
x_pred = convert_to_tensor(x_pred, dtype=""float32"")
x_pred = reshape(x_pred, (x_pred.shape[0], 28, 28, 1))

for d in range(9):
    for e in range(d+1,10):
        model = Sequential()
        model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))
        model.add(Conv2D(64, (3, 3), activation='tanh'))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Dropout(0.5))
        model.add(Flatten())
        model.add(Dense(128, activation='relu'))
        model.add(Dropout(0.25))
        model.add(Dense(2, activation='softmax'))
        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
        y_trainD = [ to_categorical( 1 if (y == d) or (y == e) else 0 , 2) for y in y_train ]
        y_trainD = convert_to_tensor(y_trainD, dtype=""float32"")
        model.fit(x_train, y_trainD, batch_size=10, epochs=20, shuffle=True, verbose=0)
        del(y_trainD)
        y_pred = model.predict(x_pred, batch_size=10)
        y_pred = [ y_pred[j][1] for j in range( len(y_pred) ) ]
        y_pred = [(j+1, float(y_pred[j])) for j in range(len(y_pred))]
        output_df = spark.createDataFrame(spark.sparkContext.parallelize(y_pred),  StructType([
                 StructField('ImageId', IntegerType(), True),
                StructField('Probability', FloatType(), True)
            ]))
        output_df.toPandas().to_csv('component'+str(d)+str(e)+'.csv', index=False)

L = dict()
for d in range(9):
    for e in range(d+1,10):
        df = spark.read.option(""inferScheme"", True).option(""header"",True).csv('component'+str(d)+str(e)+'.csv')
        L.update({ str(d)+str(e): [float(row.asDict()['Probability']) for row in df.collect()] })

S = []
for j in range(len(L['01'])):
    digit = [0 for d in range(10) ]
    for key in L.keys():
        if L[key][j] > 0.6:
            digit[ int(key[0]) ] += L[key][j]
            digit[ int(key[1]) ] += L[key][j]
    S.append( (int(j+1), int(argmax(digit)) ) )

output_df = spark.createDataFrame( spark.sparkContext.parallelize(S), StructType([
    StructField(""ImageId"", IntegerType(), True),
    StructField(""Label"", IntegerType(), True)
]))
output_df.toPandas().to_csv('submission.csv', index = False)","This code is for a image recognition problem. The data set is from the MNIST dataset. The goal is to correctly identify which digit is in each image.

The code first reads in the train.csv and test.csv files. These files contain the image data. The images are 28x28 pixels.

The code then normalizes the data, so that each pixel is between 0 and 1.

Next, the code creates a convolutional neural network. This network will be used to learn how to identify the digits in the images.

The network is trained on the training data. This is done by using the fit() function.

Once the network is trained, it is used to predict the labels for the images in the test data set. The predictions are then written to a submission.csv file.",8,2,0.06288159114463526
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import wandb
from kaggle_secrets import UserSecretsClient

user_secrets = UserSecretsClient()
secret_value_0 = user_secrets.get_secret(""wandb"")
wandb.login(key=secret_value_0)
wandb.init(project='MNIST_MLP', save_code=True)BATCH_SIZE = 32class MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return datatransformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])

train_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)
# TODO split train between validation and training set
training_size = int(0.9 * len(train_dataset))
validation_size = len(train_dataset) - training_size
train, val = torch.utils.data.random_split(train_dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))

# create data loader for train and test set
data_loader_train = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)
data_loader_val = torch.utils.data.DataLoader(val, batch_size=BATCH_SIZE, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)

print(""Finished data preparation"")# TODO
def init_layer(m):
    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('tanh'))
    torch.nn.init.constant_(m.bias, 0)
    return m

class Net(nn.Module):    
    def __init__(self):
        super(Net, self).__init__()
        self.relu = nn.ReLU()
        self.l1 = init_layer(nn.Linear(28*28, 56))
        self.l2 = init_layer(nn.Linear(56, 28))
        self.l3 = init_layer(nn.Linear(28, 10))
        self.dropout = nn.Dropout(0.5)
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        x = self.relu(self.l1(x))
       # x = self.dropout(x)
        x = self.relu(self.l2(x))
       # x = self.dropout(x)
        return self.softmax(self.l3(x))# TODO

my_nn = Net()

if torch.cuda.is_available():
    my_nn = my_nn.to('cuda')
    print('Training on GPU!')","MyMNISTDataset:

This class represents a dataset of MNIST images.

Parameters:

file_path (str): The path to the CSV file containing the MNIST data.
transform (callable): A function that transforms the image data.
test_data (bool): True if the dataset is for test data, False otherwise.
use_gpu (bool): True if a GPU is available, False otherwise.

Methods:

__len__(): Returns the number of images in the dataset.

__getitem__(idx): Returns the idx'th image in the dataset.

DataLoader:

This class represents a data loader for MNIST images.

Parameters:

dataset (MyMNISTDataset): The dataset to load data from.
batch_size (int): The number of images in each batch.
shuffle (bool): True if the data should be shuffled, False otherwise.

Methods:

__iter__(): Returns an iterator over the images in the dataset.

__len__(): Returns the number of batches in the dataset.

Net:

This class represents a neural network for classifying MNIST images.

Parameters:

None

Methods:

__init__(): Initializes the network.

forward(x): Returns the output of the network for the input x.",8,28,0.19127749468165672
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt
import tensorflow as tf
print(tf.__version__)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiontrain = pd.read_csv('../input/digit-recognizer/train.csv')
test = pd.read_csv('../input/digit-recognizer/test.csv')train.head()# Splitting labels from features
y_train = (train.iloc[:,0].values).astype('float32')
X_train = (train.iloc[:,1:].values).astype('float32')
test = (test.values).astype('float32')
del train

X_trainy_trainprint(X_train.shape)
print(y_train.shape)
print(test.shape)# Reshaping to (num of images, pixels in x direction, pixels in y direction, channel()
X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)
test = test.reshape(test.shape[0], 28, 28, 1)
plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))","This code loads in the necessary libraries for data analysis and machine learning, then loads the training and test data for the digit recognizer dataset. The data is then split into features (X_train) and labels (y_train), and the test data is also loaded. The code then reshapes the data into the correct format for training a convolutional neural network, and displays a sample image from the dataset.",8,0,0.19841894312597858
"import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt #for plotting
from collections import Counter
from sklearn.metrics import confusion_matrix
import itertools
import seaborn as sns
from subprocess import check_output
print(check_output([""ls"", ""../input""]).decode(""utf8""))
%matplotlib inline#loading the dataset.......(Train)
train = pd.read_csv(""../input/train.csv"")
print(train.shape)
train.head()z_train = Counter(train['label'])
z_trainsns.countplot(train['label'])#loading the dataset.......(Test)
test= pd.read_csv(""../input/test.csv"")
print(test.shape)
test.head()x_train = (train.ix[:,1:].values).astype('float32') # all pixel values
y_train = train.ix[:,0].values.astype('int32') # only labels i.e targets digits
x_test = test.values.astype('float32')%matplotlib inline
# preview the images first
plt.figure(figsize=(12,10))
x, y = 10, 4
for i in range(40):  
    plt.subplot(y, x, i+1)
    plt.imshow(x_train[i].reshape((28,28)),interpolation='nearest')
plt.show()","This code imports the necessary libraries for data processing, visualization, and machine learning. It then loads the dataset, which is split into training and testing sets. The code then visualizes some of the images in the dataset.",8,0,0.08897891867268168
"import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsClassifier# Считаем csv файлы в Pandas датафрейм
train = pd.read_csv('../input/digit-recognizer/train.csv')
test = pd.read_csv('../input/digit-recognizer/test.csv')# Посмотрим на тренировочный датафрейм
train.head()# Узнаем число пропущенных значений 
# и какому признаку принадлежит больше всего пропусков
sum(train.isnull().sum())# Посмотрим на тестовый датафрейм
test.head()# Узнаем число пропущенных значений 
# и какому признаку принадлежит больше всего пропусков
sum(test.isnull().sum())# Пропущенных значений нет, потому можно продолжать работу с выборками","This code imports the pandas and numpy libraries, and loads the train and test datasets from the digit-recognizer dataset. It then displays the first five rows of the train dataset, and calculates the number of missing values in the dataset. Finally, it displays the first five rows of the test dataset and calculates the number of missing values in that dataset.",8,1,0.06310638350953954
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset

import wandb
from kaggle_secrets import UserSecretsClient
user_secrets = UserSecretsClient()
secret_value_0 = user_secrets.get_secret(""WANDB_KEY"")
wandb.login(key=secret_value_0)
wandb.init(project='MNIST_MLP', save_code=True)class MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return datatransformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])

train_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)
# TODO split train between validation and training set
training_size = int(0.7 * len(train_dataset))
validation_size = len(train_dataset) - training_size
train, val = torch.utils.data.random_split(train_dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))
# create data loader for train and test set
data_loader_train = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True)
data_loader_val = torch.utils.data.DataLoader(val, batch_size=32, shuffle=True)

test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)def init_my_layer(m):
    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('tanh'))
    torch.nn.init.constant_(m.bias, 0)
    return m

class Net(nn.Module):    
    def __init__(self):
        super(Net, self).__init__()
        self.relu = nn.ReLU()
        self.ln1 = init_my_layer(nn.Linear(28*28, 28))
        self.ln2 = init_my_layer(nn.Linear(28, 28))
        self.ln3 = init_my_layer(nn.Linear(28, 10))
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        x = self.relu(self.ln1(x))
        x = self.relu(self.ln2(x))
        return self.softmax(self.ln3(x))model = Net()

# check if a GPU with Cuda capacities is available
device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"") #0, first GPU if multiple one
model.to(device)
learning_rate = 1e-3
lambda_l2 = 1e-5

criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=lambda_l2)
wandb.watch(model, log=""all"", criterion=criterion, log_freq=1,  log_graph=(True)) 


nb_epochs = 10
# Training
for t in range(nb_epochs):
    model.train() # put the network in training mode
    for X, y in data_loader_train:
        # Feed forward to get the logits
        #format data
        b = X.size(0)
        X = X.view(b,-1)
        y_pred = model(X)
        # Compute the loss and accuracy
        loss = criterion(y_pred, y)
        score, predicted = torch.max(y_pred, 1)
        acc = (y == predicted).sum().float() / len(y)
        wandb.log({
            'mlp/train_loss': loss.item(),
            'mlp/train_accuracy': acc,
        })
        # zero the gradients before running
        # the backward pass.
        optimizer.zero_grad()
        # Backward pass to compute the gradient
        # of loss w.r.t our learnable params. 
        loss.backward()
        # Update params
        optimizer.step()
        
    with torch.no_grad(): # validation run
        model.eval() # validation mode
        for X, y in data_loader_val:
            #format data
            b = X.size(0)
            X = X.view(b,-1)
            y_pred = model(X)
            validation_loss = criterion(y_pred, y)
            score, predicted = torch.max(y_pred, 1)
            acc = (y == predicted).sum().float() / len(y)
            wandb.log({
                'mlp/val_loss': loss.item(),
                'mlp/val_accuracy': acc,
            })
","This code defines a neural network for the MNIST dataset using the PyTorch library. The network consists of three fully-connected layers, with ReLU activation functions after the first two layers. The network is trained using the Adam optimizer, with a learning rate of 1e-3 and a weight decay of 1e-5. The network is trained for 10 epochs.",8.5,2,0.13807230222358446
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import tensorflow as tf
import tensorflow.keras.layers as tfl
import tensorflow.keras as keras
import matplotlib.pyplot as plt
import sklearn.model_selection as model_sel


# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiondf = pd.read_csv('../input/digit-recognizer/train.csv')
df.head()X = df.drop(columns=['label'])
X.head()X = X.to_numpy().reshape(-1,28,28,1)X = X/255
X.shapeplt.figure(figsize = (10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.imshow(X[i])
    plt.xticks([])
    plt.yticks([])
    plt.xlabel(df['label'][i])X_train, X_test, Y_train, Y_test = model_sel.train_test_split(X, df['label'].to_numpy().reshape(-1,1), test_size=0.25, random_state=1)","The code above loads in the necessary libraries for data analysis and manipulation, then loads the data from the input directory. It then drops the label column from the dataframe and converts the data to a numpy array. The data is then reshaped into a 4-dimensional array and divided by 255 to normalize the data. The data is then split into training and testing sets, with the training set being used to train the model and the testing set being used to evaluate the model.",8,2,0.18895705107178803
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import wandb

from kaggle_secrets import UserSecretsClient
user_secrets = UserSecretsClient()
secret_value = user_secrets.get_secret(""WANDB_KEY"")

wandb.login(key=secret_value)
wandb.init(project='MNIST_MLP', save_code=True)class MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return databatch_size= 512

transformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])


train_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)

# split train between validation and training set
training_size = int(0.7 * len(train_dataset))
validation_size = len(train_dataset) - training_size
train, val = torch.utils.data.random_split(train_dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))

# create data loader for train and test set
data_loader_train = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)
data_loader_val = torch.utils.data.DataLoader(val, batch_size=batch_size, shuffle=True)

test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False)def init_layer(m):
    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('relu'))
    torch.nn.init.constant_(m.bias, 0)
    return mclass Net(nn.Module):    
    def __init__(self, inputSize):
        super(Net, self).__init__()
        
        self.linear1 = init_layer(torch.nn.Linear(inputSize, 512))
        self.linear2 = init_layer(torch.nn.Linear(512, 256))
        self.dropout = torch.nn.Dropout(p=0.4)
        self.linear3 = init_layer(torch.nn.Linear(256, 10))


    def forward(self, x):
        
        x = x.view(-1,28*28) #reshape the 2d image in a ondiminsional vector for the input of the first layer
        
        x = F.relu(self.linear1(x))
        x = self.dropout(x)
        x = F.relu(self.linear2(x))
        x = self.dropout(x)
        
        return self.linear3(x)input_size = 784
output_size = 10 #labels range from 0-9

model = Net(input_size)

num_epochs = 50
lr =  0.01
weight_decay = 1e-4

optimizer = torch.optim.SGD(model.parameters(),lr = lr)#torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay) #AdamW to aviod coupling problem between the L2 regularization and the adaptive learning rate
criterion = torch.nn.CrossEntropyLoss()

#logging configuration and model
wandb.config.learningrate = lr
wandb.config.num_iterations = num_epochs
wandb.config.optimizer = ""AdamW""
wandb.config.weight_decay = weight_decay
wandb.config.criterion = ""CELoss""

wandb.watch(model, log=""all"", criterion=criterion, log_freq=1,  log_graph=(True)) #log frequency depend on your training


device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"") #0, first GPU if multiple one
print(device)
model.to(device)
","This code defines a neural network for classifying handwritten digits. The network consists of three fully connected layers, with ReLU activation functions and dropout regularization. The network is trained using stochastic gradient descent with a learning rate of 0.01. The code is written in Python 3, using the PyTorch library.

The code first imports the necessary libraries. Next, the data is loaded into the network. The data consists of 28x28 grayscale images of handwritten digits, along with labels indicating the digit class. The data is split into a training set and a test set.

The code then defines a neural network with 784 input nodes (one for each pixel in the image), 512 hidden nodes, 256 hidden nodes, and 10 output nodes (one for each digit class). The network uses ReLU activation functions and dropout regularization.

The code then trains the network for 50 epochs, using stochastic gradient descent with a learning rate of 0.01. The network is trained on the training set and tested on the test set. The code saves the trained model to a file.",9,3,0.17380464099993612
"import pandas as pd   # data analysis librarymnist_test = pd.read_csv(""/kaggle/input/mnist-fashion-data-classification/mnist_test.csv"")    # create a variable dataframe containing data from data file
mnist_train = pd.read_csv(""/kaggle/input/mnist-fashion-data-classification/mnist_train.csv"")    # create a variable dataframe containing data from data file
sample_submission = pd.read_csv(""/kaggle/input/digit-recognizer/sample_submission.csv"")    # create a variable dataframe containing data from data file
train = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")    # create a variable dataframe containing data from data file
test = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")    # create a variable dataframe containing data from data filecols = test.columnstest['dataset'] = 'test'train['dataset'] = 'train'dataset = pd.concat([train.drop('label', axis=1), test]).reset_index()","This code imports the pandas library and reads in data from four different CSV files: mnist_test, mnist_train, sample_submission, and train. It then concatenates the data from the four files into a single dataframe called dataset.",9,3,0.22659965358456918
"import os
import numpy as np
import pandas as pd
import pydicom# Load the data
base_path = ""/kaggle/input/siim-covid19-detection/""
studies_df = pd.read_csv(os.path.join(base_path,""train_study_level.csv""))
images_df = pd.read_csv(os.path.join(base_path,""train_image_level.csv""))

# Strip the extra text from the study and image IDs
studies_df['id'] = studies_df['id'].map(lambda x: x.rstrip('_study'))
images_df['id'] = images_df['id'].map(lambda x: x.rstrip('_image'))

# Merge the dfs together
data_df = pd.merge(images_df, studies_df, how='inner', left_on='StudyInstanceUID', right_on='id')
data_df.drop(['id_y'], axis=1, inplace=True)# This function finds the first image in a StudyInstanceUID directory and returns its path
def get_image_by_study_id(study_id):
    study_path = base_path + ""train/"" + study_id + ""/""
    for subdir, dirs, files in os.walk(study_path):
        for file in files:     
            image = os.path.join(subdir, file)
            if os.path.isfile(image):
                return image
    return ""none""# Loop through the images and check how many images are not Explicit VR Little Endian transfer syntax.
# Also count images with VOI LUT Sequence tags present

count = 0
images_with_voi_lut = 0
images_with_voi_lut_function = 0
images_not_explicit_le = 0
deflated_syntaxes = []
voi_lut_functions = []

for index, row in data_df.iterrows():
    img_file = get_image_by_study_id(row['StudyInstanceUID'])
    img = pydicom.dcmread(img_file)
    
    # Check for a LUT sqequence tag
    if (0x0028,0x3010) in img:
        images_with_voi_lut += 1
    
    # Check for a LUT Function tag
    if (0x0028,0x1056) in img:
        images_with_voi_lut_function += 1
        
        if img(0x0028,0x1056) not in voi_lut_functions:
            voi_lut_functions.append(img(0x0028,0x1056))
            
    # Check the transfer syntax
    if img.file_meta.TransferSyntaxUID != ""1.2.840.10008.1.2.1"":
        images_not_explicit_le += 1
        
        if img.file_meta.TransferSyntaxUID not in deflated_syntaxes:
            deflated_syntaxes.append(img.file_meta.TransferSyntaxUID)
        
    count += 1
    
print(""Done checking "" + str(count) + "" images"")
print(""Found "" + str(images_with_voi_lut) + "" images with VOI LUT"")
print(""Found "" + str(images_with_voi_lut_function) + "" images with VOI LUT Function"")
print(""VOI LUT Functions:"")
print(voi_lut_functions)
print(""Found "" + str(images_not_explicit_le) + "" images that are not Explicit VR LE"")
print(""Non Explicit VR LE Transfer Syntaxes"")
print(deflated_syntaxes)","This code loads in two CSV files containing information about medical images, and then merges them together into a single dataframe. It then loops through all the images in the dataframe, checking for various characteristics.

The first check is for the presence of a VOI LUT tag. This tag is used to indicate that the image has been processed using a specific algorithm, and the code counts how many images have this tag present.

The second check is for the presence of a VOI LUT Function tag. This tag indicates that the image has been processed using a specific function, and the code counts how many images have this tag present. It also prints out a list of all the different functions that were found.

The third check is for the transfer syntax of the image. Images should ideally be in the ""Explicit VR Little Endian"" format, but this code also counts how many images are not in this format. It also prints out a list of all the different transfer syntaxes that were found.",This documentation is semantically correct.,5,0.29325464229599213
"import os
import cv2
import numpy as np
import pandas as pd
import pydicom
import matplotlib.pyplot as plt
%matplotlib inline# This function gets the first image path in a StudyInstanceUID directory
def get_image_by_study_id(study_id):
    base_path = ""/kaggle/input/siim-covid19-detection/""
    study_path = base_path + ""train/"" + study_id + ""/""
    images = []
    for subdir, dirs, files in os.walk(study_path):
        for file in files:     
            image = os.path.join(subdir, file)
            if os.path.isfile(image):
                return image
    return ""none""# Make a simple linear VOI LUT from the raw (stored) pixel data
def make_lut(storedPixels, windowWidth, windowLevel, p_i):
    
    # Slope and Intercept set to 1 and 0 for X-ray. Get these from DICOM tags instead if using 
    # on a modality that requires them (CT, PT etc)
    slope = 1.0
    intercept = 0.0
    minPixel = int(np.amin(storedPixels))
    maxPixel = int(np.amax(storedPixels))

    # Make an empty array for the LUT the size of the pixel 'width' in the raw pixel data
    lut = [0] * (maxPixel + 1)
    
    # Invert pixels and windowLevel for MONOCHROME1. We invert the specified windowLevel so that 
    # increasing the level value makes the images brighter regardless of photometric intrepretation
    invert = False
    if p_i == ""MONOCHROME1"":
        invert = True
    else:
        windowLevel = (maxPixel - minPixel) - windowLevel
        
    # Loop through the pixels and calculate each LUT value
    for storedValue in range(minPixel, maxPixel):
        modalityLutValue = storedValue * slope + intercept
        voiLutValue = (((modalityLutValue - windowLevel) / windowWidth + 0.5) * 255.0)
        clampedValue = min(max(voiLutValue, 0), 255)
        if invert:
            lut[storedValue] = round(255-clampedValue)
        else:
            lut[storedValue] = round(clampedValue)
        
    return lut# Apply the LUT to a pixel array
def apply_lut(pixels_in, lut):
    pixels_in = pixels_in.flatten()
    pixels_out = [0] * len(pixels_in)
    for i in range(0, len(pixels_in)):
        pixel = pixels_in[i]
        pixels_out[i] = int(lut[pixel])
    return pixels_out# Take a look at a random image and display it with imshow. The width and level are automagically calculated from the pixel data.
img_file = get_image_by_study_id(""00c241c3fc0d"")
print(""Loading image: "" + img_file)

img = pydicom.dcmread(img_file)
plt.imshow(img.pixel_array,cmap=""gray"");# Set the width to be the distance between the pixels, and the level to be the middle of the pixel range.
# The resulting image should look exactly like the one above.
pixels = img.pixel_array
minPixel = np.min(pixels)
maxPixel = np.max(pixels)
windowWidth = maxPixel - minPixel
windowLevel = (minPixel + maxPixel) / 2

lut = make_lut(pixels, windowWidth, windowLevel, img.PhotometricInterpretation)
pixels = apply_lut(pixels, lut)

# Reshape the pixel array back into the image shape
img_out = np.reshape(pixels, (img.pixel_array.shape[0],img.pixel_array.shape[1]))

print(""Calculated - Width: "" + str(windowWidth) + "" / Level  "" +  str(windowLevel))
print(""Pixel range: "" + str(minPixel) + "" - "" + str(maxPixel))
plt.imshow(img_out,cmap=""gray"");print(""PhotometricInterpretation: "" + img.PhotometricInterpretation)
print(""Bit stored: "" + str(img.BitsStored))","This code imports the os, cv2, numpy, pandas, and pydicom libraries, and defines a function to get the first image path in a StudyInstanceUID directory.

The get_image_by_study_id() function takes a study_id as input and returns the path to the first image in the directory.

The make_lut() function takes storedPixels, windowWidth, windowLevel, and p_i as input and generates a linear VOI LUT from the raw pixel data.

The apply_lut() function takes pixels_in and lut as input and applies the LUT to the pixel array.

The code then reads in an image file using pydicom, calculates the window width and level, and applies the LUT to the image. The resulting image is displayed using matplotlib.",8,11,0.5377897833394881
"import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings(""ignore"")
from glob import glob
from tqdm.notebook import tqdm
from ast import literal_eval
import os
import matplotlib.pyplot as plt
import matplotlib
matplotlib.rcParams.update({'font.size': 22})
from sklearn.metrics import accuracy_score
from skimage import exposure
from tensorflow.keras import layers
from tensorflow.keras.utils import plot_model
import cv2
from matplotlib.patches import Rectangle
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50, DenseNet121, Xception
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import models
from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping
import tensorflow.keras.backend as K
from tensorflow.math import confusion_matrixdf_image = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
display(df_image.head(3))
print(df_image.shape)df_study = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
display(df_study.head(3))
print(df_study.shape)df_sampleSub = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
display(df_sampleSub.head(3))
print(df_sampleSub.shape)df_study['id'] = df_study['id'].str.replace('_study',"""")
df_study.rename({'id': 'StudyInstanceUID'},axis=1, inplace=True)
df_study.head(3)df_train = df_image.merge(df_study, on='StudyInstanceUID')
df_train.head(3)# train_dir_jpg = '../input/covid-jpg-512/train'
# train_dir_origin ='../input/siim-covid19-detection/train'
# paths_original = []
# paths_jpg = []
# for _, row in tqdm(df_train.iterrows()):
#     image_id = row['id'].split('_')[0]
#     study_id = row['StudyInstanceUID']
#     image_path_jpg = glob(f'{train_dir_jpg}/{image_id}.jpg')
#     image_path_original = glob(f'{train_dir_origin}/{study_id}/*/{image_id}.dcm')
#     paths_jpg.append(image_path_jpg)
#     paths_original.append(image_path_original)","This code imports the pandas, numpy, warnings, and glob modules. It also sets up a filter to ignore warnings.

Next, it defines two empty lists, paths_original and paths_jpg.

Then, it loops through the rows of the df_train dataframe, extracting the image_id and study_id for each row. It uses these values to construct filepaths for the corresponding image in the train_dir_jpg and train_dir_origin directories. These filepaths are then added to the paths_jpg and paths_original lists.

Finally, the code prints the first three rows of the df_train dataframe, along with the shape of the dataframe.",8,10,0.03633133380210969
"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -yimport tensorflow as tf
print(tf.__version__)
import torch
print(f""Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})"")

import os
import gc
import cv2
import glob
import numpy as np
import pandas as pd
from PIL import Image
from tqdm import tqdm
from shutil import copyfile
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lutgpus = tf.config.list_physical_devices('GPU')
if gpus:
  try:
    # Currently, memory growth needs to be the same across GPUs
    for gpu in gpus:
      tf.config.experimental.set_memory_growth(gpu, True)
    logical_gpus = tf.config.experimental.list_logical_devices('GPU')
    print(len(gpus), ""Physical GPUs,"", len(logical_gpus), ""Logical GPUs"")
  except RuntimeError as e:
    # Memory growth must be set before GPUs have been initialized
    print(e)# Read the submisison file
sub_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')
print(len(sub_df))
sub_df.head()study_df = sub_df.loc[sub_df.id.str.contains('_study')]
len(study_df)image_df = sub_df.loc[sub_df.id.str.contains('_image')]
len(image_df)# Ref: https://www.kaggle.com/xhlulu/siim-covid-19-convert-to-jpg-256px
def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return data

def resize_xray(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im","This code installs the pydicom conda helper library, which allows for the conversion of DICOM images to numpy arrays. It also installs the gdcm library, which is required for the pydicom library. Finally, it installs the tensorflow and torch libraries, which are required for the code to run.",8,6,0.12995462362189591
"!/opt/conda/bin/python3.7 -m pip install --upgrade pip
! pip install -q efficientnet#-------------------
# importing libraries
#-------------------
import tensorflow as tf
from tensorflow.keras import layers
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold,StratifiedKFold

from kaggle_datasets import KaggleDatasets


import pandas as pd
import numpy as np

import os
import shutil
import csv

import matplotlib.pyplot as plt
import PILAUTO = tf.data.experimental.AUTOTUNE

try:
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  
    print('Running on TPU ', tpu.master())
except ValueError:
    tpu = None

if tpu:
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.experimental.TPUStrategy(tpu)
else:
    strategy = tf.distribute.get_strategy()

print(""REPLICAS: "", strategy.num_replicas_in_sync)GCS_DS_PATH = KaggleDatasets().get_gcs_path(""siim-covid19-dataset-256px-jpg"")
print(GCS_DS_PATH)

TRAIN_PATH = GCS_DS_PATH + ""/256px/train/train/""
TEST_PATH = GCS_DS_PATH + ""/256px/test/test/""

NUM_CLASSES = 4
HEIGHT,WIDTH = 256,256
CHANNELS = 3
BATCH_SIZE = 8 * strategy.num_replicas_in_sync
SEED = 143


classes_dict = {
    ""Negative for Pneumonia"" : 0,
    ""Typical Appearance"" : 1,
    ""Indeterminate Appearance"" : 2,
    ""Atypical Appearance""  : 3
}

study_df = pd.read_csv(""../input/siim-covid19-detection/train_study_level.csv"")
train_df = pd.read_csv('../input/siim-covid19-dataset-256px-jpg/train.csv')
train_df = train_df[[""ImageInstanceUID"",""StudyInstanceUID"",""label_id"",""study_label""]]train_df.head(3)study_df.head(3)def process_img(filepath,label):
    image = tf.io.read_file(filepath)
    image = tf.image.decode_jpeg(image, channels=CHANNELS)
    image = tf.image.convert_image_dtype(image, tf.float32) 
    #image = tf.image.resize(image, [HEIGHT,WIDTH])
    return image,label


def data_augment(image, label):
    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
            
    # Flips
    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_flip_up_down(image)
    if p_spatial > .75:
        image = tf.image.transpose(image)
        
    # Rotates
    if p_rotate > .75:
        image = tf.image.rot90(image, k=3) 
    elif p_rotate > .5:
        image = tf.image.rot90(image, k=2) 
    elif p_rotate > .25:
        image = tf.image.rot90(image, k=1) 
        
    
    if p_pixel_1 >= .4:
        image = tf.image.random_saturation(image, lower=.7, upper=1.3)
    if p_pixel_2 >= .4:
        image = tf.image.random_contrast(image, lower=.8, upper=1.2)
    if p_pixel_3 >= .4:
        image = tf.image.random_brightness(image, max_delta=.1)
        
    
    if p_crop > .7:
        if p_crop > .9:
            image = tf.image.central_crop(image, central_fraction=.7)
        elif p_crop > .8:
            image = tf.image.central_crop(image, central_fraction=.8)
        else:
            image = tf.image.central_crop(image, central_fraction=.9)
    elif p_crop > .4:
        crop_size = tf.random.uniform([], int(HEIGHT*.8), HEIGHT, dtype=tf.int32)
        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])
    
    image = tf.image.resize(image, [HEIGHT,WIDTH])
    return image,label

def get_dataset(filenames,labels, training=True):
    dataset = tf.data.Dataset.from_tensor_slices((filenames,labels))
    dataset = dataset.map(process_img,num_parallel_calls=AUTO)
    dataset = dataset.map(data_augment,num_parallel_calls=AUTO)
    dataset = dataset.cache()
    dataset = dataset.repeat()
    if training:
        dataset = dataset.shuffle(2048)
    dataset = dataset.batch(BATCH_SIZE)
    dataset = dataset.prefetch(AUTO)
    return dataset","The code above is for a image classification project using the EfficientNet model. The code first imports the necessary libraries, then defines some variables, and finally defines some functions.

The first function, process_img(), takes in an image filepath and a label, and returns the image and label. The second function, data_augment(), takes in an image and a label, and returns the image and label. The third function, get_dataset(), takes in a list of filenames, a list of labels, and a boolean value (training or not). The function returns a dataset consisting of the image and label pairs.","The documentation is semantically correct, but could be more clear. It rates a 7.",3,0.1600170472538712
"%%capture
!conda install gdcm -c conda-forge -y# Packages

import os, time, glob, re, pprint, random, math
from collections import defaultdict, Counter

import pandas as pd 
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import matplotlib.patches as patches

import seaborn as sns

import cv2
import gdcm

import pydicom
from pydicom import dcmread
from pydicom.pixel_data_handlers.util import apply_voi_lut

import imagehash
from PIL import Image as im

import tqdm# Magic

%matplotlib inline # Pandas options

pd.set_option(""display.expand_frame_repr"", True)
pd.set_option('display.max_colwidth', 0)# Global values

CODE_PATH = ""./""
DATA_PATH = ""../input/siim-covid19-detection""
TRAIN_PATH = os.path.join(DATA_PATH, ""train"")
TEST_PATH = os.path.join(DATA_PATH, ""test"")# Utility functions

def print_title(s):
    
    # Print an underlined title
    
    print(""%s\n%s"" % (s, '-'*len(s)))
    
    
def na_fill(dtype):
    
    # Fill in missing values so that Seaborn countplot() will include them.
    # Also make sure the missing value for a string column is itself a string.
    
    if dtype == np.float64:
        result = -999
    elif dtype == np.int64:
        result = -999
    elif dtype == np.object:
        result = ""NA""
    else:
        result = -999

    return result


def explode_list_col(df, col):
    
    other_cols = list(df.columns)
    other_cols.remove(col)
    out_df = df.set_index(other_cols)[col]
    out_df = out_df.apply(pd.Series)
    out_df = out_df.stack()
    out_df = out_df.reset_index()
    out_df = out_df.drop(f""level_{len(other_cols)}"", axis=1)
    out_df = out_df.rename(columns={0 : col})
    
    return out_df
    

def cat_order(train_df, test_df, cols):
    
    # For comparison, we want the categories to be the same between train and test. 
    # We also want the categories to be in the same order for both. 
    # We need to make sure missing value types are consistent with the column data
    # type (else sort will complain), and make sure that Seaborn countplot() will
    # include them (it won't include np.nan). Dealing with the latter two issues 
    # is the job of fillna(). When the data is plotted, it needs to be run through
    # fillna() as well.

    category_order = {}
    n = len(cols)

    for col in cols:

        if col in train_cols:
            train_dtype = train_df[col].dtype
        else:
            train_dtype = None     
        if col in test_cols:
            test_dtype = test_df[col].dtype
        else:
            test_dtype = None
        if (train_dtype != None) and (test_dtype != None) and (train_dtype != test_dtype):
            print(f""***Incompatible train/test data types for column {col}"")
            break
        
        col_vals = []
        if col in train_cols:
            col_vals += list(train_df[col].fillna(na_fill(train_dtype)).unique())
        if col in test_cols:
            col_vals += list(test_df[col].fillna(na_fill(test_dtype)).unique())
        col_vals = list(set(col_vals))
        col_vals.sort()
    
        category_order[col] = col_vals
        
    return category_order


def plot_categories(df, col, order, title, ax, xlabel=None, ylabel=None, pallete=""Set3"", scale=""log""):

    data = df[col].fillna(na_fill(df[col].dtype))
    ax = sns.countplot(x=data, order=order, palette=pallete, ax=ax)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=""right"")
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    counts = data.value_counts()
    for i, p in enumerate(ax.patches):
        px = p.get_x()+0.05
        py = max(p.get_height()*0.9, 1.0)
        ax.annotate(counts.get(order[i], """"), (px, py), fontsize=10, rotation=90)
    ax.set_title(title, fontsize=15)
    if xlabel: ax.set_xlabel(xlabel)
    if ylabel: ax.set_ylabel(ylabel)
    
    return


def plot_cat_sub(df, col, sub_col, title, ax, scale=""log""):

    ax = sns.countplot(data=df, x=col, hue=sub_col, ax=ax)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=""right"")
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    ax.set_title(title, fontsize=15)
        
    return


def plot_number_uniq_per(df, df_name, attr1, attr2, ax, title=None, palette=None, scale=""log""):
    
    uniq_df = df.groupby(attr1)[[attr2]].nunique().reset_index()
    ax = sns.barplot(x=attr1, y=attr2, data=uniq_df, ax=ax, palette=palette)
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
        
    counts = uniq_df[attr2]
    for i, p in enumerate(ax.patches):
        px = p.get_x()+0.05
        py = max(p.get_height()*0.9, 1.0)
        ax.annotate(uniq_df[attr2].iloc[i], (px, py), fontsize=10, rotation=90)

    if title:
        ax.set_title(title, fontsize=15)
    else:
        ax.set_title(f""{df_name}\nNumber of unique '{attr2}' values \nper '{attr1}' value"", fontsize=15)
    ax.set_xlabel(attr1)
    ax.set_ylabel(f""# unique '{attr2}'"")
    
    return uniq_df


def plot_number_having_n_uniq(df, df_name, attr1, attr2, ax, order=None, palette=None, scale=""log""):

    nuniq = df.groupby(attr1)[attr2].nunique()
    ax = sns.countplot(x=nuniq, order=order, ax=ax, palette=palette)
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    ax.set_title(f""{df_name}\nNumber of '{attr1}' values \nhaving N unique values of '{attr2}'"", fontsize=15)
    ax.set_xlabel(f""N = # of unique '{attr2}' values"")
    ax.set_ylabel(f""# of '{attr1}' having N"")

    return nuniq


def get_img(path, img_id):

    img_path = os.path.join(path, f""{img_id}.jpg"")
    im = cv2.imread(img_path)
    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
    im = cv2.normalize(im, None, 0, 255, cv2.NORM_MINMAX)
    
    return im


def image_subplots(images, r, c, axes, titles=None):
    
    for idx, img in enumerate(images, 0):
        i = idx // c
        j = idx % c
        if titles:
            imshow(img, axes[i, j], title=titles[idx])
        else:
            imshow(img, axes[i, j])

    return
        

def imshow(image, ax=None, title=None, cmap=None):

    if ax is None:
        fig, ax = plt.subplots()
    ax.imshow(image, cmap=cmap)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.spines['left'].set_visible(False)
    ax.spines['bottom'].set_visible(False)
    ax.tick_params(axis='both', length=0)
    ax.set_xticklabels('')
    ax.set_yticklabels('')
    if title:
        ax.set_title(title)

    return ax
# Read the image metadata

train_image_df = pd.read_csv(os.path.join(DATA_PATH,'train_image_level.csv'))
train_study_df =  pd.read_csv(os.path.join(DATA_PATH,'train_study_level.csv'))","This code reads in the image metadata for the training images in the SIIM-Covid19-Detection dataset. This includes information on the image ID, patient ID, and other study-level metadata.",8,0,0.08099330318568959
"import pydicom as dicom
import pandas as pd
import os
from tqdm import tqdmmetadata = []

for split in ['test', 'train']:  
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            ds1 = dicom.dcmread(os.path.join(dirname, file), stop_before_pixels=True)
            dt=dict()
            dt['ImageId']=file.replace('.dcm','')
            for key in ds1.keys():
                dt[ds1[key].keyword]=ds1[key].value
            metadata.append(dt)

metadata_df=pd.DataFrame(metadata)
metadata_df.head()metadata_df.to_csv('metadata_covid.csv', index=False)","This code imports the pydicom and pandas libraries, and then loops through a dataset of DICOM files, extracting metadata from each file and storing it in a list. This list is then converted into a pandas DataFrame, which is saved as a CSV file.",9,2,0.12507641821738177
"import pandas as pd 
import numpy as np
import os
import pydicom
import glob
from tqdm.notebook import tqdm
from pydicom.pixel_data_handlers.util import apply_voi_lut
import matplotlib.pyplot as plt 
from skimage import exposure
import cv2
import warnings
from path import Path
from fastai.vision.all import *
from fastai.medical.imaging import *
warnings.filterwarnings(""ignore"")datapath = Path(""../input/siim-covid19-detection"")datapath.ls()train_study_df = pd.read_csv(datapath/'train_study_level.csv')train_study_df.head()study_classes = [""Negative for Pneumonia"" , ""Typical Appearance"",
                ""Indeterminate Appearance"", ""Atypical Appearance""]
np.unique(train_study_df[study_classes].values , axis = 0)plt.figure(figsize = (10,5))
plt.bar([1,2,3,4] , train_study_df[study_classes].values.sum(axis = 0))
plt.xticks([1,2,3,4] , study_classes)
plt.ylabel(""Frequency"")
plt.show()","This code imports the pandas, numpy, os, pydicom, glob, tqdm, and matplotlib libraries, and then defines datapath as the path to the input data. Next, it reads in the train_study_level.csv file and displays the first five rows.

Then, it defines the study_classes variable as a list of the four classes of studies, and uses the np.unique function to find the unique class values in the train_study_df dataframe.

Finally, it creates a bar chart using matplotlib to visualize the frequencies of the four study classes.",8,11,0.0668224025752886
"import numpy as np 
import pandas as pd 
import os
import matplotlib.pyplot as plt
import matplotlib
import pydicom as dicom
import cv2
import ast
import warnings
warnings.filterwarnings('ignore')train_image = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
train_study = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
sample_submission = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')train_image.head()len(train_image)train_study.head()len(train_study)sample_submission.head()","1. The train_image dataset contains information on X-ray images of patients.
2. The train_study dataset contains information on the corresponding studies for the images in the train_image dataset.
3. The sample_submission dataset contains information on the X-ray images used for testing.","The documentation is semantically correct to a certain extent. However, there are some minor errors. For example, it is not clear what the X-ray images in the train_image dataset represent. Additionally, it is not clear what information is contained in the train_study dataset. The documentation scores a 7 out of 10 for semantic correctness.",0,0.03791454338437011
"!conda install gdcm -c conda-forge -yimport os
import ast
import numpy as np
import pandas as pd
from path import Path
import datetime
import glob
import json
import shutil

from PIL import Image
from tqdm.auto import tqdm
import pydicom
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import cv2from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)    
    
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail(size, resample)
    else:
        im = im.resize(size, resample)
    
    return imimages_meta_folder = '/kaggle/working/images_metadata_256_512_768'
os.makedirs(images_meta_folder, exist_ok=True)

# Define sizes
new_sizes = [(256, 256), (512, 512), (768, 768)]for new_size in new_sizes:

    for split in ['train', 'test']:
    # for split in ['test']:
        save_dir = f'/kaggle/tmp/{split}_{new_size[0]}x{new_size[1]}/'
        dcm_paths = glob.glob(f'../input/siim-covid19-detection/{split}/*/*/*')
        os.makedirs(save_dir, exist_ok=True)

        image_ids = []
        folder_ids = []
        study_ids = []
        widths = []
        heights = []

        for path in tqdm(dcm_paths):
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(path)
            im = resize(xray, size=new_size)

            path_split = path.split('/')
            study_id = path_split[-3]
            folder_id = path_split[-2]
            image_name = path_split[-1].replace('.dcm', '_image')

            im.save(os.path.join(save_dir, image_name+'.png'))

            image_ids.append(image_name)
            folder_ids.append(folder_id)
            study_ids.append(study_id)
            widths.append(xray.shape[1])
            heights.append(xray.shape[0])
            
        df = pd.DataFrame.from_dict({'id': image_ids, 'folder_id': folder_ids,
                                     'study_id': study_ids, 'width': widths,
                                     'height': heights})
        df.to_csv(f'{images_meta_folder}/{split}_meta_{new_size[0]}x{new_size[1]}.csv', index=False)for new_size in new_sizes:
    print(f""*****{new_size}*****\n"")
    df_train_meta = pd.read_csv(f'{images_meta_folder}/train_meta_{new_size[0]}x{new_size[1]}.csv')
    df_train = pd.read_csv(""../input/siim-covid19-detection/train_image_level.csv"")
    df_train_meta = df_train.merge(df_train_meta, on='id')
    
    ## Drop all rows of images without annotations
    df_train_meta = df_train_meta.dropna()
    imagepaths = df_train_meta.id.unique()
    print(""Number of Images with Covid_Abnormality:"",len(imagepaths))
    
    display(df_train_meta.head(3))
    print()
    
    df_idx=0

    for idx, row in tqdm(df_train_meta.iterrows(), total=df_train_meta.shape[0]):
        img = cv2.imread(os.path.join(f""/kaggle/tmp/train_{new_size[0]}x{new_size[1]}/"",
                                      row.id.replace(""_image"", "".png"")))
        bboxes = [list(bbox.values()) for bbox in ast.literal_eval(row.boxes)]
        height_ratio, width_ratio = (new_size[0]/row.height, new_size[1]/row.width)

        for box in bboxes:
            box[2] = box[2]+box[0]
            box[3] = box[3]+box[1]
            box = (box[0]*width_ratio, box[1]*height_ratio,
                   box[2]*width_ratio, box[3]*height_ratio)

            row_df = pd.DataFrame({'id':row.id,
                           'StudyInstanceUID':row.StudyInstanceUID,
                           'folder_id':row.folder_id,
                           'study_id':row.study_id,
                           'width':row.width,
                           'height':row.height,
                           'xmin':round(box[0]),
                           'ymin':round(box[1]),
                           'xmax':round(box[2]),
                           'ymax':round(box[3])}, index=[df_idx])

            if df_idx==0:
                df_train_processed = row_df
            else:
                df_train_processed = pd.concat([df_train_processed, row_df])

            df_idx+=1

    display(df_train_processed.head(3))
    print()
    df_train_processed.to_csv(f'{images_meta_folder}/df_train_processed_meta_{new_size[0]}x{new_size[1]}.csv',
                              index=False)
    df_train_processed.shape","This code is used to generate images for the SIIM-ACR COVID-19 detection competition. The code reads in DICOM images, transforms them into PNG images, and saves them to a specified folder. The code also generates a CSV file containing metadata for each image.",8,1,0.10475830564965834
"!conda install gdcm -c conda-forge -yimport cv2
import datetime
import gc
import glob
import imagehash
import math
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
import PIL
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import sys
import tqdmbase_path = '../input/siim-covid19-detection'def read_dicom_image(image_file, voi_lut=True, fix_monochrome=True):
    """"""
    Reads a dicom image from a file an returns a numpy array.
    References: https://www.kaggle.com/trungthanhnguyen0502/eda-vinbigdata-chest-x-ray-abnormalities
    Args:
        image_file:
        voi_lut:
        fix_monochrome:

    Returns:

    """"""
    dicom = pydicom.read_file(image_file)
    # VOI LUT (if available by DICOM device) is used to
    # transform raw DICOM data to ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
    return data


def string2boxes(string):
    strings = string.split()
    if strings[0].lower() == 'none':
        return []
    else:
        return [{'class': strings[idx],
                 'conf': float(strings[idx+1]),
                 'x1': float(strings[idx+2]),
                 'y1': float(strings[idx+3]),
                 'x2': float(strings[idx+4]),
                 'y2': float(strings[idx+5]),
                 } for idx in range(0, len(strings), 6)]


def plot_image(image, boxes=None, size=(5,5), title=None, columns=4):
    def plot_img(image, boxes=None, title=None):
        if isinstance(image, str):
            image_id = os.path.splitext(os.path.split(image)[1])[0]
            df = df_image.loc[df_image['id'] == image_id + '_image']
            boxes = string2boxes(df['label'].iloc[0]) if len(df) > 0 else None
            image = read_dicom_image(image)
        image = np.stack([image] * 3, axis=-1)
        if boxes is not None:
            for box in boxes:
                image = cv2.rectangle(image, (int(box['x1']), int(box['y1'])), (int(box['x2']), int(box['y2'])), [0, 255, 0], 10)
        plt.axis('on')
        plt.imshow(image, cmap='gray')
        if title is not None:
            plt.title(title)

    plt.figure(figsize=size)
    if isinstance(image, list):
        num = len(image)
        columns = min(columns, num)
        rows = math.ceil(num / columns)

        for index, single_image in enumerate(image):
            plt.subplot(rows, columns, index + 1)
            plot_img(single_image, boxes=boxes, title=title[index])
    else:
        plot_img(image, boxes=boxes, title=title)
    plt.show()


def images_find_duplicates(image_files, threshold=0.9):
    """"""
    Function to find duplicates in images.
    References: https://www.kaggle.com/appian/let-s-find-out-duplicate-images-with-imagehash
    Args:
        image_files:
        threshold:

    Returns:

    """"""
    funcs = [imagehash.average_hash, imagehash.phash, imagehash.dhash, imagehash.whash]
    image_ids = image_files
    hashes = []
    for file in tqdm.tqdm(image_files):
        image = PIL.Image.fromarray(read_dicom_image(file))
        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))
    hashes_all = np.array(hashes)

    # Comparisons without Pytorch
    sim_list = []
    for i in tqdm.tqdm(range(hashes_all.shape[0])):
        sim_list.append(np.sum(hashes_all[i] == hashes_all, axis=1)/256)

    # nxn-matrix of similarities (n = # of images), upper triangular matrix
    similarities = np.triu(np.array(sim_list), 1)

    idx_pair = np.where(similarities > threshold)
    df_pairs = pd.DataFrame({'image1': [image_ids[i] for i in list(idx_pair[0])],
                             'image2': [image_ids[i] for i in list(idx_pair[1])],
                             'similarity': [similarities[i1, i2] for i1, i2 in zip(idx_pair[0], idx_pair[1])]})

    idx_group = np.zeros(len(image_files))
    group_id = 1
    for i1, i2 in zip(idx_pair[0], idx_pair[1]):
        if idx_group[i1] == 0 and idx_group[i2] == 0:
            idx_group[i1] = group_id
            idx_group[i2] = group_id
            group_id += 1
        elif idx_group[i1] != 0 and idx_group[i2] == 0:
            idx_group[i2] = idx_group[i1]
        elif idx_group[i1] == 0 and idx_group[i2] != 0:
            idx_group[i1] = idx_group[i2]
        elif idx_group[i1] != 0 and idx_group[i2] != 0 and idx_group[i1] != idx_group[i2]:
            common_id = min(idx_group[i1], idx_group[i2])
            idx_group[idx_group == idx_group[i1]] = common_id
            idx_group[idx_group == idx_group[i2]] = common_id

    group_list = []
    for i in range(1, group_id + 1):
        group_ids = list(np.where(idx_group == i)[0])
        if len(group_ids) > 0:
            group_list.append([image_ids[j] for j in group_ids])

    return df_pairs, group_list


def print_group_info(i, df_group):
    print(f'\nGroup {i+1}')
    print(f'Number of unique studies:       {len(df_group[""study_id""].unique())}')
    print(f'Number of unique study labels:  {len(df_group[""study_label""].unique())}\n')
    print(df_group[['image_id', 'num_boxes', 'study_id', 'study_label']])
    plot_image(list(df_group['image_file']), size=(20, 10), title=list(df_group['image_id']), columns=8)    
train_files = sorted(glob.glob(os.path.join(base_path, 'train/*/*/*.dcm')))
print(f'Number of training files: {len(train_files)}')
df_image = pd.read_csv(os.path.join(base_path, 'train_image_level.csv'))
df_study = pd.read_csv(os.path.join(base_path, 'train_study_level.csv'))
df_study['study_label'] = df_study.apply(lambda r: ', '.join([df_study.columns[i] for i in range(1, 5) if r[i] > 0]), axis=1)

df_pairs, group_list = images_find_duplicates(train_files, threshold=0.95)
print(f'\nNumber of duplicate pairs: {len(df_pairs)}')
print(f'Number of duplicate groups: {len(group_list)}')df_group_list = []
df_pairs.to_csv('pairs.csv')

with open('duplicates.csv', 'w') as text_file:
    for i, group in enumerate(group_list):
        group_ids = [os.path.splitext(os.path.basename(file))[0] + '_image' for file in group]
        df_group_ids = pd.DataFrame({'id': group_ids, 'image_file': group})
        df_group = df_group_ids.merge(df_image, on='id').sort_values('id')
        df_group['study_id'] = df_group['StudyInstanceUID'] + '_study'
        df_group['num_boxes'] = df_group.apply(lambda r: len(string2boxes(r['label'])), axis=1)
        df_group = df_group.merge(df_study, left_on='study_id', right_on='id')
        df_group = df_group.rename(columns={'id_x': 'image_id'})
        df_group_list.append(df_group)
        text_file.write(','.join(group_ids) + '\n')for index, df_group in enumerate(df_group_list):
    if len(df_group[df_group['num_boxes'] > 0]) > 1:
        print_group_info(index, df_group)","This code is used to find duplicate images in a dataset of DICOM images. It first reads in the images and then uses image hashing to identify duplicate images. Finally, it prints out information about the duplicate images, including the number of unique studies and study labels, as well as the number of duplicate pairs and groups.",8,0,0.1358116679355753
"import pandas as pd# train_df = pd.read_csv('/kaggle/input/siimcovid19-train-data-that-opacitycount-added/train_df.csv')
# local
train_df = pd.read_csv('/kaggle/input/siimcovid19-train-data-that-opacitycount-added/train_df.csv')train_df.head()train_df.drop(columns='Path', axis=1,inplace=True)train_df.head()train_df['Opacity'] = train_df.apply(lambda row : 1 if row.label.split(' ')[0]=='opacity' else 0, axis=1)
train_dftrain_df.drop(columns=['Unnamed: 0'], inplace=True)
train_df","This code imports the pandas library and reads in a CSV file containing training data. The data is then displayed using the head() method. The Path column is dropped and the Opacity column is created, containing a 1 if the label indicates opacity and a 0 otherwise. Finally, the Unnamed: 0 column is dropped and the resulting dataframe is displayed.",8,2,0.051752614586033724
"!pip install -q efficientnet >> /dev/nullimport pandas as pd, numpy as np, random,os, shutil
from glob import glob
from kaggle_datasets import KaggleDatasets
import tensorflow as tf, re, math
import tensorflow.keras.backend as K
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt
import tensorflow_addons as tfa
print('tf:',tf.__version__)# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit
VERBOSE      = 1
DISPLAY_PLOT = True

DEVICE = ""TPU"" #or ""GPU""

# USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD
SEED = 42

# NUMBER OF FOLDS. USE 2, 5, 10
FOLDS = 5

# WHICH IMAGE SIZES TO LOAD EACH FOLD
# CHOOSE 128, 192, 256, 384, 512, 512 
IMG_SIZES = [[512, 512]]*FOLDS

# BATCH SIZE AND EPOCHS
BATCH_SIZES = [24]*FOLDS
EPOCHS      = [10]*FOLDS

# WHICH EFFICIENTNET B? TO USE
EFF_NETS = [6]*FOLDS

# Augmentations
AUGMENT   = True
TRANSFORM = True

# transformations
ROT_    = 0.0
SHR_    = 2.0
HZOOM_  = 8.0
WZOOM_  = 8.0
HSHIFT_ = 8.0
WSHIFT_ = 8.0

# Dropout
PROBABILITY = 0.75
CT          = 8
SZ          = 0.08

#bri, contrast
sat  = (0.7, 1.3)
cont = (0.8, 1.2)
bri  =  0.1

# WEIGHTS FOR FOLD MODELS WHEN PREDICTING TEST
WGTS = [1/FOLDS]*FOLDS

# TEST TIME AUGMENTATION STEPS
TTA = 1def seeding(SEED):
    np.random.seed(SEED)
    random.seed(SEED)
    os.environ['PYTHONHASHSEED'] = str(SEED)
    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)
    tf.random.set_seed(SEED)
    print('seeding done!!!')
seeding(SEED)if DEVICE == ""TPU"":
    print(""connecting to TPU..."")
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        print('Running on TPU ', tpu.master())
    except ValueError:
        print(""Could not connect to TPU"")
        tpu = None

    if tpu:
        try:
            print(""initializing  TPU ..."")
            tf.config.experimental_connect_to_cluster(tpu)
            tf.tpu.experimental.initialize_tpu_system(tpu)
            strategy = tf.distribute.experimental.TPUStrategy(tpu)
            print(""TPU initialized"")
        except _:
            print(""failed to initialize TPU"")
    else:
        DEVICE = ""GPU""

if DEVICE != ""TPU"":
    print(""Using default strategy for CPU and single GPU"")
    strategy = tf.distribute.get_strategy()

if DEVICE == ""GPU"":
    print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
    

AUTO     = tf.data.experimental.AUTOTUNE
REPLICAS = strategy.num_replicas_in_sync
print(f'REPLICAS: {REPLICAS}')GCS_PATH = [None]*FOLDS
for i,k in enumerate(IMG_SIZES):
    GCS_PATH[i] = KaggleDatasets().get_gcs_path('siimcovid19-%ix%i-tfrec-dataset'%(k[0],k[1]))
files_train = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/train*.tfrec')))
files_test  = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/test*.tfrec')))
num_train_files = len(files_train)
num_test_files  = len(files_test)
print('train_files:',num_train_files)
print('test_files:',num_test_files)train_df = pd.read_csv('../input/siim-covid19-yolov5-2class-labels/meta.csv')
train_df.head(2)","This code installs the efficientnet package and imports pandas, numpy, random, os, and shutil. It also imports the KaggleDatasets package and the tensorflow and efficientnet packages. The code then sets some parameters for the training process, including the number of folds, the image sizes to use, the batch size and number of epochs, and the type of efficientnet to use. Finally, the code sets up some parameters for data augmentation.",9,8,0.08614493317356493
"%cd ../
!mkdir tmp
%cd tmp# Download YOLOv5
!git clone https://github.com/ultralytics/yolov5  # clone repo
%cd yolov5
# Install dependencies
%pip install -qr requirements.txt  # install dependencies

%cd ../
import torch
print(f""Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})"")# Install W&B 
!pip install -q --upgrade wandb
# Login 
import wandb
wandb.login()# Necessary/extra dependencies. 
import os
import gc
import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm
from shutil import copyfile
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

#customize iPython writefile so we can write variables
from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))TRAIN_PATH = 'input/siim-covid19-resized-to-256px-jpg/train/'
IMG_SIZE = 256
BATCH_SIZE = 16
EPOCHS = 10# Everything is done from /kaggle directory.
%cd ../

# Load image level csv file
df = pd.read_csv('input/siim-covid19-detection/train_image_level.csv')

# Modify values in the id column
df['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)
# Add absolute path
df['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)
# Get image level labels
df['image_level'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)

df.head(5)# Load meta.csv file
# Original dimensions are required to scale the bounding box coordinates appropriately.
meta_df = pd.read_csv('input/siim-covid19-resized-to-256px-jpg/meta.csv')
train_meta_df = meta_df.loc[meta_df.split == 'train']
train_meta_df = train_meta_df.drop('split', axis=1)
train_meta_df.columns = ['id', 'dim0', 'dim1']

train_meta_df.head(2)","This code is for the YOLOv5 object detection model. It is written in Python and uses the PyTorch library.

The code first changes the working directory to the 'tmp' directory. It then downloads the YOLOv5 repository from GitHub. Next, it installs the necessary dependencies for running the code.

The code then loads the image level csv file. This file contains information on the images in the dataset. The code then modifies the id column to contain only the image name. It also adds an absolute path to each image. Finally, the code gets the image level labels.

The code then loads the meta.csv file. This file contains information on the original dimensions of the images. This is necessary in order to scale the bounding box coordinates appropriately.",8,2,0.12083968814557854
"# Importing Required packages
import os
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from IPython.display import Image, clear_output
print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))
clear_output()#customize iPython writefile so we can write variables
from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))# Cloning the repo and installing requiements
!git clone https://github.com/ultralytics/yolov5.git
!mv ./yolov5/* ./
!pip install -r requirements.txt
clear_output()# Copying the dataset to working directory
!mkdir Dataset
!cp ../input/covid19-detection-for-yolov5-siimfisabiorsna/Covid19 -r ./Dataset
clear_output()len(os.listdir('./Dataset/Covid19/images'))%%writetemplate ./split_dataset.py
from utils.datasets import * 
autosplit('./Dataset/Covid19', weights=(0.8, 0.2, 0.0))!python split_dataset.py","This code imports the required packages, clones the yolov5 repository, and installs the requirements. It then copies the dataset to the working directory and splits it into train, test, and val sets.",8,0,0.13064851697118451
"! conda install -c conda-forge gdcm -y# import numpy as np # linear algebra
# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
# import os
# import pydicom
# import glob
# from tqdm.notebook import tqdm
# from pydicom.pixel_data_handlers.util import apply_voi_lut
# import matplotlib.pyplot as plt
# from skimage import exposure
# import cv2
# import warnings
# from fastai.vision.all import *
# from fastai.medical.imaging import *
# warnings.filterwarnings('ignore')

import os
import pydicom
import glob
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt 
dataset_path = '../input/siim-covid19-detection/'

for path in glob.glob(dataset_path  + '*'):
    print(path)train_images = '../input/siim-covid19-detection/train/'

n_folders = len(glob.glob(train_images  + '*'))
n_subfolders = len(glob.glob(train_images  + '*/*'))
n_images = len(glob.glob(train_images  + '*/*/*.dcm'))

print(f'There are {n_subfolders} subfolders in {n_folders} folders.')
print(f'There are altogether {n_images} images.')folders = glob.glob(train_images  + '*')

subfolder_dict = {}

for folder in folders:
    n = len(glob.glob(folder + '/*'))
    if n in subfolder_dict.keys():
        subfolder_dict[n] += 1
    else:
        subfolder_dict[n] = 1
        
for k, v in subfolder_dict.items():
    print(f'There is {v} subfolders with {k} images.')

subfolders = glob.glob(train_images  + '*/*')

image_dict = {}

for subfolder in subfolders:
    n = len(glob.glob(subfolder + '/*'))
    if (n!=1):
        print (subfolder.split('/')[-1])
        for image in glob.glob(subfolder + '/*'):
            print ('-->' + image.split('/')[-1])

    if n in image_dict.keys():
        image_dict[n] += 1
    else:
        image_dict[n] = 1
        
for k, v in image_dict.items():
    print(f'There is {v} subfolders with {k} images.')
train_study_df = pd.read_csv(dataset_path +'/train_study_level.csv')

train_study_df","This code imports the necessary libraries for working with the dataset, including numpy, pandas, and matplotlib. It also defines the path to the dataset.

Next, it loops through all the folders in the dataset, counting the number of subfolders and the number of images. It then prints this information to the console.

Finally, it loops through all the subfolders in the dataset, counting the number of images in each. It then prints this information to the console.",8,2,0.052078769607250566
"import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import glob
import pydicomsiim_covid19_dir = os.path.join(
    '..', 'input', 'siim-covid19-detection')def read_csv(file_name):
    file_path = os.path.join(siim_covid19_dir, file_name)
    df = pd.read_csv(file_path)
    return dfstudy_level_df = read_csv('train_study_level.csv')

study_level_df# How many rows?
study_level_num_rows = len(study_level_df)

study_level_num_rows# Are unique? Any duplicates?
study_level_num_unique_ids = len(pd.unique(study_level_df['id']))

if study_level_num_unique_ids == study_level_num_rows:
    print(""Unique and no duplicates"")
else:
    print(""Some duplicates"")# What are the unique value combinations? How many of them?
study_level_label_colums = [
    'Negative for Pneumonia', 'Typical Appearance',
    'Indeterminate Appearance', 'Atypical Appearance' ]
study_level_labels_df = study_level_df[study_level_label_colums]
study_level_label_values = study_level_labels_df.values

study_level_unique_label_combinations, \
study_level_unique_label_counts = \
    np.unique(
        study_level_label_values, return_counts=True, axis=0)

print(""Unique Combinations:\n"", study_level_unique_label_combinations)
print(""Unique Counts:\n"", study_level_unique_label_counts)","The code above reads in a CSV file containing data on the labels assigned to studies in the SIIM-Covid19 dataset. It then calculates some summary statistics on the data.

There are a total of 4 label columns in the dataset: 'Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', and 'Atypical Appearance'.

There are a total of 5 unique label combinations in the dataset, with the most common being 'Negative for Pneumonia' (78.8% of studies).",8,0,0.13812551323788397
"# Libraries
import warnings
warnings.filterwarnings('ignore')

import os
import numpy as np
import pandas as pd
import seaborn as sns
import glob
from pandas import DataFrame
from matplotlib.lines import Line2D
import matplotlib.pyplot as plt
%matplotlib inline
import plotly.express as px
from tqdm.notebook import tqdm

# Image processing and Computer Vision
from skimage import exposure
import cv2
# Package designed to manipulate data elements in DICOM files 

import pydicom
#Image Transformation
from pydicom.pixel_data_handlers.util import apply_voi_lut

from fastai.vision.all import *
from fastai.medical.imaging import *

#train_image
train_image_df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
train_image_df.head(2)#train_study
train_study_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
train_study_df.head()# Bar plot function defination
def viz_bar_plot(df,x,x_title,y,title,colors=None,text=None):
    fig = px.bar(x=x,
                 y=y,
                 text=text,
                 labels={x: x_title.title()},   
                 data_frame=df,
                 color=colors,
                 barmode='group',
                 template=""simple_white"")
    texts = [df[col].values for col in y]
    for i, t in enumerate(texts):
        fig.data[i].text = t
        fig.data[i].textposition = 'inside'  
    fig['layout'].title=title
    fig.update_layout(title_font_size=19)
    fig.update_layout(title_font_family='Droid Serif')
    fig.update_layout(width=800,height=500)
    for trace in fig.data:
        trace.name = trace.name.replace('_',' ').title()
    fig.update_yaxes(tickprefix="""", showgrid=True)
    fig.show()# Study Data
# create 'target' column in train_study_df dataset
train_study_df['target']='Negative for Pneumonia'
train_study_df.loc[train_study_df['Typical Appearance']==1,'target']='Typical Appearance'
train_study_df.loc[train_study_df['Indeterminate Appearance']==1,'target']='Indeterminate Appearance'
train_study_df.loc[train_study_df['Atypical Appearance']==1,'target']='Atypical Appearance'
train_study_df1=train_study_df.groupby(['target']).size().reset_index(name='counts')
train_study_df1# Bar Visulaization of label categories
viz_bar_plot(train_study_df1,
         'target',
         'target',
         ['counts'],
         title='Target Label Count')","This code imports the necessary libraries for data analysis and visualization, then loads the train_image and train_study dataframes. It then defines a function for visualizing data in a bar plot, and uses that function to plot the distribution of target labels in the train_study dataframe.",8,2,0.11827925941799146
"! conda install -c conda-forge gdcm -yimport numpy as np
import pandas as pd 
import os
from PIL import Image
from tqdm.auto import tqdm
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import seaborn as sns
from pandas_profiling import ProfileReport
from glob import glob
from tqdm.notebook import tqdm
import matplotlib.pyplot as plt
from skimage import exposure
import cv2
import warnings
import albumentations as A# config params
class CFG:
    data_path = '../input/siim-covid19-detection/'
    size = 512
    seed = 2021
    working_dir = '/kaggle/working/'def dicom2array(path, voi_lut=True, fix_monochrome=True):
    dicom = pydicom.read_file(path)
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
    return data
        
    
def plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()
# storage file for the transformed images
!mkdir train# prepare a dataframe for producing resized images with bboxes
xtrain_img = pd.read_csv(CFG.data_path + 'train_image_level.csv')


path_list = []
image_list = []
splits = []

for split in ['train']:
    
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            fullpath = dirname + '/' + file
            path_list.append(fullpath)
            image_list.append(file)

df = pd.DataFrame(image_list, columns =['image_id'])
df['image_path'] = path_list

xtrain_img['image_id'] = xtrain_img['id'].apply(lambda s: s.replace('_image','') + '.dcm')
xtrain_img = pd.merge(left = xtrain_img, right = df, on = 'image_id')
# common transformation we shall use
transform = A.Compose(
    [
        A.Resize(height = CFG.size , width = CFG.size, p=1),
    ], 
    p=1.0,  bbox_params=A.BboxParams( format='pascal_voc', min_area=0,  min_visibility=0, label_fields=['labels']  ))        

img_list = []
label_list = []

# loop over files
for ii in range(len(xtrain_img)):
    # get the image
    row = xtrain_img.loc[ii]
    img_path = row['image_path']
    img = dicom2array(path=img_path)
    newname = img_path.split('/')[-1].replace('dcm', 'jpg')
    img_list.append(newname)
    
    # get the bounding boxes
    bboxes = []
    bbox = []
    labels = []
    confidences = []

    for i, l in enumerate(row['label'].split(' ')):
        if (i % 6 == 0) :
            labels.append(l)
        if (i % 6 == 1):
            confidences.append(l)
        if (i % 6 > 1):
            bbox.append(np.clip(float(l), a_min = 0, a_max = None ))
        if i % 6 == 5:
            bboxes.append(bbox)
            bbox = []    

    # transform both
    result = transform(image = img, bboxes = bboxes, labels = np.ones(len(bboxes)))
    new_image = result['image']
    new_bboxes = np.array(result['bboxes']).tolist()

    # format the output
#    print('orig label: ' + row['label'])
    newlabel = ''
    if labels[0] == 'none':
        newlabel = 'none 1 0 0 1 1'
    else:
        for j in range(len(labels)):
            newlabel += labels[j] + ' ' + confidences[j] + ' ' +  ' '.join([str(np.round(f,5)) for f in new_bboxes[0]]) + ' '
#    print('new label:' + newlabel)
    label_list.append(newlabel)
    
    # store the new image
    cv2.imwrite(CFG.working_dir + 'train/' + newname , new_image)",This code is responsible for preparing the data for training a machine learning model to detect COVID-19 on chest X-rays. The data preparation includes resizing the images to a standard size (512x512) and creating bounding boxes around areas of interest. The code also stores the transformed images and labels in a working directory for training.,8,0,0.18180700326381144
"!wget 'https://anaconda.org/conda-forge/libjpeg-turbo/2.1.0/download/linux-64/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/libgcc-ng/9.3.0/download/linux-64/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/gdcm/2.8.9/download/linux-64/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/conda/4.10.1/download/linux-64/conda-4.10.1-py37h89c1867_0.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/certifi/2020.12.5/download/linux-64/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/openssl/1.1.1k/download/linux-64/openssl-1.1.1k-h7f98852_0.tar.bz2' -q","This code downloads the following packages from Anaconda:

- libjpeg-turbo
- libgcc-ng
- gdcm
- conda
- certifi
- openssl

Each package is downloaded as a .tar.bz2 file. The code uses the 'wget' command to download the files.",8,7,0.22084796348066818
"! conda install gdcm -c conda-forge -y! pip install --no-deps '../input/timm-package/timm-0.1.26-py3-none-any.whl' > /dev/null
! pip install --no-deps '../input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl' > /dev/nullimport sys
sys.path.insert(0, ""../input/timm-efficientdet-pytorch"")
sys.path.insert(0, ""../input/omegaconf"")

import os
from PIL import Image
import pandas as pd
from tqdm.auto import tqdm
import numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import torch
from datetime import datetime
import time
import random
import cv2
import albumentations as A
import matplotlib.pyplot as plt
from albumentations.pytorch.transforms import ToTensorV2
from sklearn.model_selection import StratifiedKFold
from torch.utils.data import Dataset,DataLoader
from torch.utils.data.sampler import SequentialSampler, RandomSampler
from glob import glob

SEED = 42

def seed_everything(seed):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = True

seed_everything(SEED)dataset_path = ""../input/siim-covid19-detection""def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return data

def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im
        
    
def plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()
%%time
image_id = []


cnt_img = 0 # for testing

for split in ['test', 'train']:
    save_dir = f'/kaggle/tmp/{split}/'

    os.makedirs(save_dir, exist_ok=True)
    
    for dirname, _, filenames in tqdm(os.walk(f'{dataset_path}/{split}')):
        for file in filenames:
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(os.path.join(dirname, file))
            im = resize(xray, size=256)  
            im.save(os.path.join(save_dir, file.replace('dcm', 'jpg')))

            image_id.append(file.replace('.dcm', ''))

            splits.append(split)
        
        if cnt_img >= 10:
            cnt_img = 0
            break
        
        cnt_img += 1
            image_id","This code reads in chest x-ray images from a given directory, applies a VOI LUT (if available), and then resizes the images to a standard size (256x256). The resulting images are saved in a new directory.",8,1,0.08928503667785824
"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -yimport os

from PIL import Image
import pandas as pd
from tqdm.auto import tqdmimport numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im
split = 'test'
save_dir = f'/kaggle/tmp/{split}/'

os.makedirs(save_dir, exist_ok=True)

save_dir = f'/kaggle/tmp/{split}/study/'
os.makedirs(save_dir, exist_ok=True)

for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
    for file in filenames:
        # set keep_ratio=True to have original aspect ratio
        xray = read_xray(os.path.join(dirname, file))
        im = resize(xray, size=600)  
        study = dirname.split('/')[-2] + '_study.png'
        im.save(os.path.join(save_dir, study))
import numpy as np 
import pandas as pd

df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
id_laststr_list  = []
for i in range(df.shape[0]):
    id_laststr_list.append(df.loc[i,'id'][-1])
df['id_last_str'] = id_laststr_list

study_len = df[df['id_last_str'] == 'y'].shape[0]!pip install /kaggle/input/kerasapplications -q
!pip install /kaggle/input/efficientnet-keras-source-code/ -q --no-deps

import os

import efficientnet.tfkeras as efn
import numpy as np
import pandas as pd
import tensorflow as tf

def auto_select_accelerator():
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        tf.config.experimental_connect_to_cluster(tpu)
        tf.tpu.experimental.initialize_tpu_system(tpu)
        strategy = tf.distribute.experimental.TPUStrategy(tpu)
        print(""Running on TPU:"", tpu.master())
    except ValueError:
        strategy = tf.distribute.get_strategy()
    print(f""Running on {strategy.num_replicas_in_sync} replicas"")

    return strategy


def build_decoder(with_labels=True, target_size=(300, 300), ext='jpg'):
    def decode(path):
        file_bytes = tf.io.read_file(path)
        if ext == 'png':
            img = tf.image.decode_png(file_bytes, channels=3)
        elif ext in ['jpg', 'jpeg']:
            img = tf.image.decode_jpeg(file_bytes, channels=3)
        else:
            raise ValueError(""Image extension not supported"")

        img = tf.cast(img, tf.float32) / 255.0
        img = tf.image.resize(img, target_size)

        return img

    def decode_with_labels(path, label):
        return decode(path), label

    return decode_with_labels if with_labels else decode


def build_augmenter(with_labels=True):
    def augment(img):
        img = tf.image.random_flip_left_right(img)
        img = tf.image.random_flip_up_down(img)
        return img

    def augment_with_labels(img, label):
        return augment(img), label

    return augment_with_labels if with_labels else augment


def build_dataset(paths, labels=None, bsize=32, cache=True,
                  decode_fn=None, augment_fn=None,
                  augment=True, repeat=True, shuffle=1024, 
                  cache_dir=""""):
    if cache_dir != """" and cache is True:
        os.makedirs(cache_dir, exist_ok=True)

    if decode_fn is None:
        decode_fn = build_decoder(labels is not None)

    if augment_fn is None:
        augment_fn = build_augmenter(labels is not None)

    AUTO = tf.data.experimental.AUTOTUNE
    slices = paths if labels is None else (paths, labels)

    dset = tf.data.Dataset.from_tensor_slices(slices)
    dset = dset.map(decode_fn, num_parallel_calls=AUTO)
    dset = dset.cache(cache_dir) if cache else dset
    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset
    dset = dset.repeat() if repeat else dset
    dset = dset.shuffle(shuffle) if shuffle else dset
    dset = dset.batch(bsize).prefetch(AUTO)

    return dset

#COMPETITION_NAME = ""siim-cov19-test-img512-study-600""
strategy = auto_select_accelerator()
BATCH_SIZE = strategy.num_replicas_in_sync * 16

IMSIZE = (224, 240, 260, 300, 380, 456, 528, 600)

#load_dir = f""/kaggle/input/{COMPETITION_NAME}/""
sub_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
sub_df = sub_df[:study_len]
test_paths = f'/kaggle/tmp/{split}/study/' + sub_df['id'] +'.png'

sub_df['negative'] = 0
sub_df['typical'] = 0
sub_df['indeterminate'] = 0
sub_df['atypical'] = 0


label_cols = sub_df.columns[2:]

test_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[7], IMSIZE[7]), ext='png')
dtest = build_dataset(
    test_paths, bsize=BATCH_SIZE, repeat=False, 
    shuffle=False, augment=False, cache=False,
    decode_fn=test_decoder
)

with strategy.scope():
    
    models = []
    
    models0 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model0.h5'
    )
    models1 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model1.h5'
    )
    models2 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model2.h5'
    )
    models3 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model3.h5'
    )
    models4 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model4.h5'
    )
    
    models.append(models0)
    models.append(models1)
    models.append(models2)
    models.append(models3)
    models.append(models4)

    
    
    
sub_df[label_cols] = sum([model.predict(dtest, verbose=1) for model in models]) / len(models)","This code installs the pydicom conda helper package, which is used to read and process DICOM images. It also installs the libjpeg-turbo, libgcc-ng, and gdcm packages, which are dependencies of pydicom. Finally, it installs the conda, certifi, and openssl packages, which are needed for some of the pydicom functionality.

This code reads in a DICOM image, applies a VOI LUT if one is available, and rescales the image so that the minimum value is 0 and the maximum value is 1. It then converts the image to an 8-bit unsigned integer and saves it to a file.

This code resizes an image to the given size, keeping the aspect ratio if desired.

This code generates a dataset of DICOM images for the given split (train or test) and saves them to files.

This code loads the models created in the training notebook and uses them to predict the labels for the images in the test split. The predictions are saved to a CSV file.",8,12,0.1336523766556173
"SEED  = 42
FOLDS = 5
DIM   = 512import numpy as np 
import pandas as pd 
import os, shutil
from glob import glob
from sklearn.cluster import KMeans
from tqdm.notebook import tqdm
from sklearn.preprocessing import LabelEncoder
import random
tqdm.pandas()np.random.seed(SEED)
random.seed(SEED)train_df = pd.read_csv(f'../input/siimcovid19-{DIM}-jpg-image-dataset/train.csv')
train_df['image_path'] = F'../input/siimcovid19-{DIM}-jpg-image-dataset/train/'+train_df.image_id+'.jpg'
train_df.head(2)name2label = {'Typical Appearance': 3,
 'Indeterminate Appearance': 1,
 'Atypical Appearance': 2,
 'Negative for Pneumonia': 0}
class_names = list(name2label.keys())
label2name = {v:k for k, v in name2label.items()}
train_df['class_name']  = train_df.progress_apply(lambda row:row[class_names].iloc[[row[class_names].values.argmax()]].index.tolist()[0], axis=1)
train_df['class_label'] = train_df.class_name.map(name2label)
train_df.head()from sklearn.model_selection import GroupKFold, StratifiedKFold
gkf  = GroupKFold(n_splits = 5)
train_df['fold'] = -1
for fold, (train_idx, val_idx) in enumerate(gkf.split(train_df, groups = train_df.StudyInstanceUID.tolist())):
    train_df.loc[val_idx, 'fold'] = fold
train_df.head()import matplotlib.pyplot as plt
import cv2
def load_image(path, dim=DIM, ch=3):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE if ch==None else cv2.IMREAD_COLOR)
    if img.shape[:2]!=(dim,dim) and dim!=-1:
        img = cv2.resize(img, dsize=(dim,dim), interpolation=cv2.INTER_AREA)
    return img

plt.imshow(load_image(train_df.image_path.iloc[100], dim=-1))","This code loads images from a given dataset, resizes them to a specified dimensions, and converts them to grayscale if necessary.",8,1,0.0388595910706937
"# !conda install -c conda-forge imagehash --yes%load_ext autoreload
%autoreload 2
%matplotlib inline

import glob
import itertools
import collections

from PIL import Image
import cv2
from tqdm import tqdm_notebook as tqdm
import pandas as pd
import numpy as np
import torch
import imagehash

import matplotlib.pyplot as plt

def run():

    funcs = [
        imagehash.average_hash,
        imagehash.phash,
        imagehash.dhash,
        imagehash.whash,
        #lambda x: imagehash.whash(x, mode='db4'),
    ]

    SOPInstanceUIDs = []
    hashes = []
    for path in tqdm(glob.glob('../input/siim-covid19-resized-to-512px-png/*/*.png')):

        image = Image.open(path)
        imageid = path.split('/')[-1].split('.')[0]

        SOPInstanceUIDs.append(imageid)
        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))

    return SOPInstanceUIDs, np.array(hashes)

%time SOPInstanceUIDs, hashes_all = run()

hashes_all = torch.Tensor(hashes_all.astype(int)).cuda()%time sims = np.array([(hashes_all[i] == hashes_all).sum(dim=1).cpu().numpy()/256 for i in range(hashes_all.shape[0])])
indices1 = np.where(sims > 0.99)
indices2 = np.where(indices1[0] != indices1[1])
SOPInstanceUID1 = [SOPInstanceUIDs[i] for i in indices1[0][indices2]]
SOPInstanceUID2 = [SOPInstanceUIDs[i] for i in indices1[1][indices2]]
dups = {tuple(sorted([SOPInstanceUID1,SOPInstanceUID2])):True for SOPInstanceUID1, SOPInstanceUID2 in zip(SOPInstanceUID1, SOPInstanceUID2)}
print('found %d duplicates' % len(dups))dups",This code uses the imagehash library to generate hashes for images and identify duplicate images.,8,1,0.09282575895792491
"!pip install gdcmimport os
from os import listdir
import pandas as pd
import numpy as np
import glob
from skimage import exposure
import matplotlib.pyplot as plt
%matplotlib inline

# pydicom
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
from fastai.imports import *
from fastai.medical.imaging import *

import cv2

# color
from colorama import Fore, Back, Style

import seaborn as sns
sns.set(style=""whitegrid"")

# plotly
import plotly.express as px
import plotly

# Suppress warnings 
import warnings
warnings.filterwarnings('ignore')

# Settings for pretty nice plots
plt.style.use('fivethirtyeight')
plt.show()# List files available
list(os.listdir(""../input/siim-covid19-detection""))IMAGE_PATH = ""../input/siim-covid19-detection/""

train_study_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
train_image_df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')

print(Fore.YELLOW + 'Train study df shape: ',Style.RESET_ALL,train_study_df.shape)
print(Fore.YELLOW + 'Train image df shape: ',Style.RESET_ALL,train_image_df.shape)display(train_study_df.head(5))
display(train_image_df.head(5))sample_submission = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
print(Fore.YELLOW + 'Sample submission df shape: ',Style.RESET_ALL,sample_submission.shape)
display(sample_submission)# Null values and Data types
print(Fore.BLUE + 'Train Study Set !!',Style.RESET_ALL)
print(train_study_df.info())
print('-------------')
print(Fore.YELLOW + 'Train Image Set !!',Style.RESET_ALL)
print(train_image_df.info())","1. The code imports the necessary libraries for data analysis and visualization.

2. The code loads the train_study_level.csv and train_image_level.csv files into pandas dataframes.

3. The code displays the first 5 rows of the train_study_level and train_image_level dataframes.

4. The code loads the sample_submission.csv file into a pandas dataframe.

5. The code displays the first 5 rows of the sample_submission dataframe.

6. The code prints the shape, column names, data types, and null values for the train_study_level and train_image_level dataframes.","This documentation is semantically correct to a degree. It would be more helpful if it provided more information on what the code is doing and why it is doing it. For example, it would be helpful to know what the purpose of loading the files into pandas dataframes is. It would also be helpful to know what the code is trying to accomplish by displaying the first 5 rows of the dataframes. Overall, this documentation is understandable but could be more clear.",5,0.04149749813829821
"!pip install -q efficientnet >> /dev/nullimport pandas as pd, numpy as np, random,os, shutil
from glob import glob
from kaggle_datasets import KaggleDatasets
import tensorflow as tf, re, math
import tensorflow.keras.backend as K
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt
import tensorflow_addons as tfa
print('tf:',tf.__version__)# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit
VERBOSE      = 0
DISPLAY_PLOT = True

DEVICE = ""TPU"" #or ""GPU""

# USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD
SEED = 42

# NUMBER OF FOLDS. USE 2, 5, 10
FOLDS = 5

# WHICH IMAGE SIZES TO LOAD EACH FOLD
# CHOOSE 128, 192, 256, 384, 512, 512 
IMG_SIZES = [[512, 512]]*FOLDS

# BATCH SIZE AND EPOCHS
BATCH_SIZES = [16]*FOLDS
EPOCHS      = [12]*FOLDS

# WHICH EFFICIENTNET B? TO USE
EFF_NETS = [7]*FOLDS

# Augmentations
AUGMENT   = True
TRANSFORM = True

# transformations
ROT_    = 0.0
SHR_    = 2.0
HZOOM_  = 8.0
WZOOM_  = 8.0
HSHIFT_ = 8.0
WSHIFT_ = 8.0

# Dropout
PROBABILITY = 0.75
CT          = 8
SZ          = 0.08

#bri, contrast
sat  = (0.7, 1.3)
cont = (0.8, 1.2)
bri  =  0.1

# WEIGHTS FOR FOLD MODELS WHEN PREDICTING TEST
WGTS = [1/FOLDS]*FOLDS

# TEST TIME AUGMENTATION STEPS
TTA = 1def seeding(SEED):
    np.random.seed(SEED)
    random.seed(SEED)
    os.environ['PYTHONHASHSEED'] = str(SEED)
    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)
    tf.random.set_seed(SEED)
    print('seeding done!!!')
seeding(SEED)if DEVICE == ""TPU"":
    print(""connecting to TPU..."")
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        print('Running on TPU ', tpu.master())
    except ValueError:
        print(""Could not connect to TPU"")
        tpu = None

    if tpu:
        try:
            print(""initializing  TPU ..."")
            tf.config.experimental_connect_to_cluster(tpu)
            tf.tpu.experimental.initialize_tpu_system(tpu)
            strategy = tf.distribute.experimental.TPUStrategy(tpu)
            print(""TPU initialized"")
        except _:
            print(""failed to initialize TPU"")
    else:
        DEVICE = ""GPU""

if DEVICE != ""TPU"":
    print(""Using default strategy for CPU and single GPU"")
    strategy = tf.distribute.get_strategy()

if DEVICE == ""GPU"":
    print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
    

AUTO     = tf.data.experimental.AUTOTUNE
REPLICAS = strategy.num_replicas_in_sync
print(f'REPLICAS: {REPLICAS}')GCS_PATH = [None]*FOLDS
for i,k in enumerate(IMG_SIZES):
    GCS_PATH[i] = KaggleDatasets().get_gcs_path('siimcovid19-%ix%i-tfrec-dataset'%(k[0],k[1]))
files_train = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/train*.tfrec')))
files_test  = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/test*.tfrec')))
num_train_files = len(files_train)
num_test_files  = len(files_test)
print('train_files:',num_train_files)
print('test_files:',num_test_files)train_df = pd.read_csv('../input/siim-covid19-yolov5-2class-labels/meta.csv')
train_df.head(2)","This code installs the efficientnet library and imports pandas, numpy, random, os, and shutil. It also defines a function to seed the random number generator for reproducibility.

Next, the code defines some parameters for the training and testing data. The code will use the first 5 folds of data for training and the last 5 folds for testing. The image sizes for each fold are set to 512x512. The batch size and number of epochs are set to 16 and 12, respectively.

The code then defines some parameters for the efficientnet model. The model will use the b7 architecture and will be trained with data augmentation.

Finally, the code loads the training and testing data from the Siim-Covid19 dataset.",9,5,0.10023989135677591
"import pandas as pd df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')dfid_laststr_list  = []
for i in range(df.shape[0]):
    id_laststr_list.append(df.loc[i,'id'][-1])
df['id_last_str'] = id_laststr_liststudy_len = df[df['id_last_str'] == 'y'].shape[0]study_str = 'negative 1 0 0 1 1 atypical 1 0 0 1 1 typical 1 0 0 1 1 indeterminate 1 0 0 1 1'
for i in range(study_len):
    df.loc[i, 'PredictionString'] = study_strdf = df[['id', 'PredictionString']]","This code imports the pandas library and reads in a CSV file containing data on COVID-19 cases. It then creates a list of the last characters in each ID column entry, and adds this list as a new column in the dataframe. Next, it calculates the length of the study and creates a string containing the study results. Finally, it adds the study results as a new column in the dataframe and outputs the dataframe to a CSV file.",9,3,0.04955750488170729
"import numpy as np 
import pandas as pd 
import os
from tqdm import tqdm
import matplotlib.pyplot as plt
import pydicomtrain_st = pd.read_csv(""../input/siim-covid19-detection/train_study_level.csv"")
train_st.head(3)
train_im = pd.read_csv(""../input/siim-covid19-detection/train_image_level.csv"")
train_im.head(3)sample = pd.read_csv(""../input/siim-covid19-detection/sample_submission.csv"")
sample.head(3)train_path = ""../input/siim-covid19-detection/train""
test_path = ""../input/siim-covid19-detection/test""trainimlist = []

for dirname, _, filenames in os.walk(train_path):
    for filename in filenames:
        trainimlist.append(os.path.join(dirname, filename))testimlist = []

for dirname, _, filenames in os.walk(test_path):
    for filename in filenames:
        testimlist.append(os.path.join(dirname, filename))","The code imports the necessary libraries for working with the data. It then reads in the data from the input files. Next, it creates lists of all the training and test images. Finally, it loops through the lists and processes the images.",8,0,0.04044296554966349
"import fastai
import fastai.medical
from fastai.basics import *
from fastai.vision.all import *
from fastai.medical.imaging import *

import pydicom

import pandas as pd
fastai.__version__!conda install -c conda-forge gdcm -yfilegroup='train'
path='../input/siim-covid19-detection'
dirName = f'{path}/{filegroup}/'# Get DICOM file list from train directory
items = get_dicom_files(dirName)df_trn = pd.DataFrame.from_dicoms(items,px_summ=False)
df_trn.to_csv(f'alldicom{filegroup}.csv')
df_trn.describe()
df_trnfilegroup='test'
dirName = f'{path}/{filegroup}/'","The code above imports the fastai, fastai.medical, and pydicom libraries, and defines a filegroup variable. It then uses the get_dicom_files() function to get a list of DICOM files from the train directory, and creates a DataFrame from the list of files. Finally, it saves the DataFrame to a CSV file and displays some summary statistics.",8,7,0.15909075207817644
"import numpy as np 
import pandas as pd
import os
import matplotlib.pyplot as plt
import pydicom as dicom
from glob import glob
from pathlib import Path
from pydicom import dcmread
import matplotlib
import astStudy= pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')Study.describe()Study.head()Study.isnull().sum()image_level=pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')image_level.head()","The code above imports several libraries for use in data analysis and visualization. The libraries imported are NumPy, pandas, matplotlib, and pydicom.

The code then reads in two CSV files, 'train_study_level.csv' and 'train_image_level.csv'. These files contain data on medical studies and images, respectively.

The code then performs some basic data analysis, using the .describe() and .head() methods to get summary statistics and view the data, respectively. The code also checks for null values in the data.

Finally, the code visualizes the data using matplotlib.",8,4,0.04185776243418561
"#Attaullah
#attaullahshafiq10@gmail.com
# Import libs
!conda install gdcm -c conda-forge -y
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
import pydicom
import glob
from tqdm.notebook import tqdm
from pydicom.pixel_data_handlers.util import apply_voi_lut
import matplotlib.pyplot as plt
from skimage import exposure#import gdcm
import cv2
import warnings
from fastai.vision.all import *
from fastai.medical.imaging import *
warnings.filterwarnings('ignore')
dataset_path = Path('../input/siim-covid19-detection')
import vtk

from vtk.util import numpy_support

reader = vtk.vtkDICOMImageReader()#HTML view

from IPython.display import HTML
HTML('<iframe src=https://arxiv.org/pdf/1506.01497.pdf width=600 height=650></iframe>')# from https://www.kaggle.com/tanlikesmath/siim-covid-19-detection-a-simple-eda
def dicom2array(path, voi_lut=True, fix_monochrome=True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()


def plot_imgs(imgs, cols=4, size=7, is_rgb=True, title="""", cmap='gray', img_size=(500,500)):
    rows = len(imgs)//cols + 1
    fig = plt.figure(figsize=(cols*size, rows*size))
    for i, img in enumerate(imgs):
        if img_size is not None:
            img = cv2.resize(img, img_size)
        fig.add_subplot(rows, cols, i+1)
        plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()dicom_paths = get_dicom_files(dataset_path/'train')
print([str(path) for path in dicom_paths[:4]])
imgs = [dicom2array(str(path)) for path in dicom_paths[:4]]
plot_imgs(imgs)","This code imports the necessary libraries, then reads in a dataset of DICOM images and converts them to arrays. Finally, it plots the first four images in the dataset.",8,0,0.05397690888082675
"!pip install -q --upgrade wandb

import wandb
wandb.login()import os
import gc
import cv2
import ast
import numpy as np
import pandas as pd
from tqdm import tqdm
import matplotlib.pyplot as plt
%matplotlib inlineTRAIN_PATH = '../input/siim-covid19-resized-to-256px-jpg/train/'
IMG_SIZE = 256
NUM_SAMPLES_TO_VIZ = 32# Load image level csv file
df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
# Load study level csv file
label_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')

# Modify values in the id column
df['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)
# Add absolute path
df['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)
# Get image level labels
df['image_level'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)

# Modify values in the id column
label_df['id'] = label_df.apply(lambda row: row.id.split('_')[0], axis=1)
# Rename the column id with StudyInstanceUID
label_df.columns = ['StudyInstanceUID', 'Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']

# Merge both dataframes
df = df.merge(label_df, on='StudyInstanceUID',how=""left"")
df.head(2)print(f'Number of unique image in training dataset: {len(df)}')

bbox_nan_num = df['boxes'].isna().sum()
print(f'Number of images without any bbox annotation: {bbox_nan_num}')# Label encode study-level labels
labels = df[['Negative for Pneumonia','Typical Appearance','Indeterminate Appearance','Atypical Appearance']].values
labels = np.argmax(labels, axis=1)

df['study_level'] = labels
df.head(2)class_label_to_id = {
    'Negative for Pneumonia': 0,
    'Typical Appearance': 1,
    'Indeterminate Appearance': 2,
    'Atypical Appearance': 3
}

class_id_to_label = {val: key for key, val in class_label_to_id.items()}","This code imports the wandb library and uses it to login to a wandb account. It then sets up some parameters for training a model to detect pneumonia from X-ray images. Finally, it loads and processes two CSV files containing information about the X-ray images and the labels for each image.",8,3,0.0982881368004846
"!conda install gdcm -c conda-forge -yimport os

from PIL import Image
import pandas as pd
from tqdm.auto import tqdmimport numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return imtrain = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')path = '../input/siim-covid19-detection/train/ae3e63d94c13/288554eb6182/e00f9fe0cce5.dcm'
dicom = pydicom.read_file(path)image_id = []
dim0 = []
dim1 = []
splits = []

for split in ['test', 'train']:
    save_dir = f'/kaggle/tmp/{split}/'

    os.makedirs(save_dir, exist_ok=True)
    
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(os.path.join(dirname, file))
            im = resize(xray, size=768)  
            im.save(os.path.join(save_dir, file.replace('dcm', 'jpg')))

            image_id.append(file.replace('.dcm', ''))
            dim0.append(xray.shape[0])
            dim1.append(xray.shape[1])
            splits.append(split)","This code reads in a DICOM image, transforms it into a human-readable format, and then resizes it. Finally, it saves the image as a JPEG.",8,0,0.08999340403291137
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport sys
sys.path.append('../input/timm-pytorch-models/archive (3)/pytorch-image-models-master')
import timmimport numpy as np 
import pandas as pd 

import math
import random 
import os 
import cv2
import timm

from tqdm import tqdm 

import albumentations as A 
from albumentations.pytorch.transforms import ToTensorV2
import torch 
from torch.utils.data import Dataset 
from torch import nn
import torch.nn.functional as F 

import gc
import cudf
import cuml
import cupy
from cuml.feature_extraction.text import TfidfVectorizer
from cuml.neighbors import NearestNeighborsclass CFG:
    
    img_size = 512
    batch_size = 12
    seed = 2020
    
    device = 'cuda'
    classes = 11014
    
    model_name = 'eca_nfnet_l0'
    model_path = '../input/pytorch-model-weights/arcface_512x512_nfnet_l0 (mish).pt'
    
    scale = 30 
    margin = 0.5def read_dataset():
    df = pd.read_csv('../input/shopee-product-matching/test.csv')
    df_cu = cudf.DataFrame(df)#cuDF is a Python GPU DataFrame library workflow is fast enough on a single GPU fits in memory on a single GPU
    image_paths = '../input/shopee-product-matching/test_images/' + df['image']
    return df, df_cu, image_pathsdef seed_torch(seed=42):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    
seed_torch(CFG.seed)def get_image_predictions(df, embeddings,threshold = 0.0):
    
    if len(df) > 3:
        KNN = 50
    else : 
        KNN = 3
    
    model = NearestNeighbors(n_neighbors = KNN, metric = 'cosine')
    model.fit(embeddings)
    distances, indices = model.kneighbors(embeddings)
    
    predictions = []
    for k in tqdm(range(embeddings.shape[0])):
        idx = np.where(distances[k,] < threshold)[0]
        ids = indices[k,idx]
        posting_ids = df['posting_id'].iloc[ids].values
        predictions.append(posting_ids)
        
    del model, distances, indices
    gc.collect()
    return predictions","This code defines a function that takes in a dataframe, embeddings, and a threshold, and returns a list of predictions. The predictions are based on the embeddings, and the threshold determines how close the embeddings must be in order to be considered a match.",8,1,0.12997534145036665
"%%capture
!pip install ../input/pytorchimagemodelsimport sys
sys.path.append('../input/facebookdeit')import os
import gc
import sys

import math
import random

from tqdm.notebook import tqdm

import re

import cv2
import numpy as np
import pandas as pd

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset ,RandomSampler

import timm

import albumentations

from swav_resnet import resnet50w2

import transformers
from transformers import AutoModel, AutoTokenizer

from models import deit_base_distilled_patch16_224



import cudf
import cuml
import cupydef set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True

set_seed(0)text_models=[
    {
        'transformer_model': '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14',
        'model_path' : '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14/ckpt.pt',
        'MAX_LEN' : 128,
        'params' : {
            'embed_dim' :1024,
            'out_dim' : 11014
        }
        
    },
    {
            'transformer_model': '../input/shopee-bert-base-indonesian/bert-base-indonesian_pp_7_8',
            'model_path' : '../input/shopee-bert-base-indonesian/bert-base-indonesian_pp_7_8/ckpt.pt',
            'MAX_LEN' : 128,
            'params' : {
                'embed_dim' :1024,
                'out_dim' : 11014
            }

        }
]

TRANSFORMER_EMBED_DIM = 768joint_models=[
    {
        'transformer_model': '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14',
        'model_path' : '../input/deit-xlm-joint-weights/finetuned_deit_xlm_joint_7_11.pt',
        'MAX_LEN' : 128,
        'IMAGE_SIZE' : 224,
        'params' : {
                'embed_dim' : 2048,
                'out_dim' : 11014
            }
        
    }
]image_models=[
    {
        'vision_model': '../input/shopee-swav-finetuned-resnet50w2/swav_resnet50w2_224_2048_5_epochs_loss_12_beef.pt',
        'IMAGE_SIZE' : 224,
        'params' : {
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
    {
        'vision_model': '../input/effnet-weights/finetuned_tf_efficientnet_b3_ns_300_2048_7_9.pt',
        'IMAGE_SIZE' : 300,
        'params' : {
            'backbone_name' : 'tf_efficientnet_b3_ns',
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
    
    {
        'vision_model': '../input/deit-base-distilled-patch16-224/finetuned_deit_base_distilled_patch16_224_4_18.pt',
        'IMAGE_SIZE' : 224,
        'params' : {
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
]","This code defines several models for text, image, and joint text-image representation learning. The text models are based on the transformer architecture, specifically the XLM-R and BERT models. The image models are based on the ResNet50-W2 and EfficientNet-B3 architectures. The joint model is based on the XLM-R architecture.

Each model is defined by a dictionary containing the following fields:

- transformer_model: the name of the transformer model used (XLM-R or BERT)
- model_path: the path to the model weights
- MAX_LEN: the maximum length of input sequences
- params: a dictionary of model parameters, including the embedding dimension and the output dimension",8,4,0.04568396978233619
"import sys
import gc
import math
import configparser
import numpy as np
import pandas as pd
import optuna
from tqdm import tqdm
import sklearn
import tensorflow as tf
from tensorflow import keras
from typing import Tupletry:
    # TPU detection. No parameters necessary if TPU_NAME environment variable is
    # set: this is always the case on Kaggle.
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
    print('Running on TPU ', tpu.master())
except ValueError:
    tpu = None

if tpu:
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.TPUStrategy(tpu)
else:
    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.
    strategy = tf.distribute.get_strategy()

print(""REPLICAS: "", strategy.num_replicas_in_sync)pd.set_option(""use_inf_as_na"", True)
pd.set_option(""display.max_columns"", 9999)
pd.set_option(""display.max_rows"", 9999)
pd.set_option('max_colwidth', 9999)
INPUT = '/kaggle/input'
DATA = f'{INPUT}/shopee-product-matching'
OUTPUT = '/kaggle/working'
RESOURCE_DIR = f'{INPUT}/shopee-product-matching-lib/kaggle-shopee-product-matching-1.0'
sys.path.append(f'{INPUT}/sgcharts-ml/src')
sys.path.append(f""{INPUT}/sentence-transformers/sentence-transformers-1.0.4"")
sys.path.append(f'{RESOURCE_DIR}/src')
import mylib
import scml
from scml.nlp import strip_punctuation, to_ascii_str
scml.seed_everything()MODEL = 'efficientnetb3'
CONF = configparser.ConfigParser()
CONF.read(f""{RESOURCE_DIR}/app.ini"")
resolution = int(CONF[MODEL][""resolution""])
INPUT_SHAPE = (resolution, resolution, 3)
print(f""INPUT_SHAPE={INPUT_SHAPE}"")train = pd.read_csv(f""{DATA}/train.csv"", engine=""c"", low_memory=False)
train[""target""] = mylib.target_label(train)
le = sklearn.preprocessing.LabelEncoder()
train[""label_group""] = le.fit_transform(train['label_group'])
n_classes=len(le.classes_)
print(f""n_classes={n_classes}"")
train.info()train.head()def _data_gen(
    dataframe,
    directory,
    target_size,
    batch_size,
    color_mode=""rgb"",
    class_mode=""raw"",
    x_col=""image"",
    y_col=""label_group""
):
    dtype = np.float32
    rescale = 1./255
    interpolation = ""bicubic""
    data_format = ""channels_last""
    shuffle = True
    idg = keras.preprocessing.image.ImageDataGenerator(
        shear_range=0.2,
        zoom_range=0.2,
        brightness_range=(0.7, 1.3),
        #rotation_range=90,
        horizontal_flip=True,
        rescale=rescale,
        data_format=data_format,
        dtype=dtype
    )
    g = idg.flow_from_dataframe(
        dataframe=dataframe,
        x_col=x_col,
        y_col=y_col,
        directory=directory,
        target_size=target_size,
        color_mode=color_mode,
        batch_size=batch_size,
        shuffle=shuffle,
        class_mode=class_mode,
        interpolation=interpolation,
    )
    while True:
        x, y = g.next()
        yield [x, y], y","This code defines a function for generating data for training a machine learning model. The function takes in a dataframe, directory, target_size, batch_size, color_mode, class_mode, x_col, and y_col as parameters. The function returns an idg object that can be used to generate image data for training the machine learning model.",8,2,0.09520504818094157
"import pip
try:
     __import__(""imutils"")
except ImportError:
    pip.main([""install"", ""imutils""])import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import  matplotlib.pyplot as plt
import tensorflow as tf
import pandas as pd
import cv2
from imutils.object_detection import non_max_suppression
import pytesseract
import os
import glob
os.chdir('/kaggle/working')
BASE = '../input/shopee-product-matching/train_images/'
EAST_PATH = ""/kaggle/input/east-data-leo/frozen_east_text_detection/frozen_east_text_detection.pb""
RESIZE_IMG_SHAPE = (500,500)
img_paths = glob.glob(f""{BASE}*jpg"") train = pd.read_csv('../input/shopee-product-matching/train.csv')
print('train shape is', train.shape )
train.head()groups = train.label_group.value_counts()
plt.figure(figsize=(20,5))
plt.plot(np.arange(len(groups)),groups.values)
plt.ylabel('Duplicate Count',size=14)
plt.xlabel('Index of Unique Item',size=14)
plt.title('Duplicate Count vs. Unique Item Count',size=16)
plt.show()

plt.figure(figsize=(20,5))
plt.bar(groups.index.values[:50].astype('str'),groups.values[:50])
plt.xticks(rotation = 45)
plt.ylabel('Duplicate Count',size=14)
plt.xlabel('Label Group',size=14)
plt.title('Top 50 Duplicated Items',size=16)
plt.show()def img_proc(img,offset =20):
    img =img[offset:-offset,offset:-offset]
    img =cv2.resize(img ,RESIZE_IMG_SHAPE)
    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    gray = cv2.medianBlur(gray,5)
    ret, thresh = cv2.threshold(gray,150,255,cv2.THRESH_BINARY)
    thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\
            cv2.THRESH_BINARY_INV,21,2)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))
    opening = cv2.erode(thresh,kernel, iterations = 1)
    closing = cv2.dilate(opening,kernel,iterations=1)
    contours = cv2.findContours(closing, 
                            cv2.RETR_EXTERNAL,
                            cv2.CHAIN_APPROX_NONE)
    canvas =np.zeros((500,500))
    cv2.drawContours(canvas, contours[0], -1, (255,0,255), thickness = 2) 
    return canvas



def displayDF(train, random=False, COLS=6, ROWS=4, path=BASE):
    for k in range(ROWS):
        plt.figure(figsize=(20,5))
        for j in range(COLS):
            if random: row = np.random.randint(0,len(train))
            else: row = COLS*k + j
            name = train.iloc[row,1]
            title = train.iloc[row,3]
            title_with_return = """"
            for i,ch in enumerate(title):
                title_with_return += ch
                if (i!=0)&(i%20==0): title_with_return += '\n'
            img = img_proc(cv2.imread(path+name))
            plt.subplot(1,COLS,j+1)
            plt.title(title_with_return)
            plt.axis('off')
            plt.imshow(img)
        plt.show()
        
displayDF(train,random=True)def predictions(prob_score, geo,min_conf):
    (numR, numC) = prob_score.shape[2:4]
    boxes = []
    confidence_val = []
    for y in range(0, numR):
        scoresData = prob_score[0, 0, y]
        x0 = geo[0, 0, y]
        x1 = geo[0, 1, y]
        x2 = geo[0, 2, y]
        x3 = geo[0, 3, y]
        anglesData = geo[0, 4, y]
        for i in range(0, numC):
            if scoresData[i] < min_conf:
                continue
            (offX, offY) = (i * 4.0, y * 4.0)
            angle = anglesData[i]
            cos = np.cos(angle)
            sin = np.sin(angle)
            h = x0[i] + x2[i]
            w = x1[i] + x3[i]
            endX = int(offX + (cos * x1[i]) + (sin * x2[i]))
            endY = int(offY - (sin * x1[i]) + (cos * x2[i]))
            startX = int(endX - w)
            startY = int(endY - h)
            boxes.append((startX, startY, endX, endY))
            confidence_val.append(scoresData[i])

    return (boxes, confidence_val)

def get_text(img,img_text ='Output',min_conf = 0.7, east = EAST_PATH):
    image = cv2.imread(img)
    orig = image.copy()
    (origH, origW) = image.shape[:2]
    (newW, newH) = (320,320)
    rW = origW / float(newW)
    rH = origH / float(newH)
    image = cv2.resize(image, (newW, newH))
    (H, W) = image.shape[:2]
    blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),
        (123.68, 116.78, 103.94), swapRB=True, crop=False)
    net = cv2.dnn.readNet(east)
    # The following two layer need to pulled from EAST model for achieving this. 
    layerNames = [
        ""feature_fusion/Conv_7/Sigmoid"",
        ""feature_fusion/concat_3""]

    #Forward pass the blob from the image to get the desired output layers
    net.setInput(blob)
    (scores, geometry) = net.forward(layerNames)
    (boxes, confidence_val) = predictions(scores, geometry,min_conf)
    boxes = non_max_suppression(np.array(boxes), probs=confidence_val)
    
    results = []
    for (startX, startY, endX, endY) in boxes:
        startX = int(startX * rW)
        startY = int(startY * rH)
        endX = int(endX * rW)
        endY = int(endY * rH)
        r = orig[startY:endY, startX:endX]
        configuration = (""-l eng --oem 1 --psm 8"")
        text = pytesseract.image_to_string(r, config=configuration)
        results.append(((startX, startY, endX, endY), text))

    orig_image = orig.copy()
    txts=[]
    for ((start_X, start_Y, end_X, end_Y), text) in results:
        text = """".join([x if ord(x) < 128 else """" for x in text]).strip()
        cv2.rectangle(orig_image, (start_X, start_Y), (end_X, end_Y),
            (0, 0, 255), 2)
        cv2.putText(orig_image, text, (start_X, start_Y + 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,255, 0), 4)
        txts.append(text)
    plt.figure(figsize=(10,10))
    plt.imshow(orig_image)
    plt.title(img_text)
    plt.show()
    print(txts)it = iter(range(500))","This code imports the pip module and attempts to import the imutils module. If the imutils module is not found, the code uses pip to install it. The code then imports the numpy, pandas, matplotlib, and tensorflow modules. The code sets the working directory to the 'train_images' folder. The code defines the BASE, EAST_PATH, and RESIZE_IMG_SHAPE variables. The code then gets a list of all the .jpg files in the BASE directory. The code then reads in the train.csv file and prints out the shape of the dataframe. The code then plots the number of duplicates for each unique item. The code then plots the top 50 duplicated items. The code defines the img_proc() function which takes an image as input and returns a processed image. The code defines the displayDF() function which takes a dataframe and displays the images in the dataframe. The code then calls the displayDF() function with the train dataframe and random=True. The code defines the predictions() function which takes in a probability score, geo data, and a minimum confidence threshold and returns a list of boxes and confidence values. The code defines the get_text() function which takes in an image, an image text, a minimum confidence threshold, and an east path. The function returns the text found in the image. The code then calls the get_text() function with the train dataframe and random=True.",9,13,0.09965555183841868
,"/**
 * Represents a book.
 * @constructor
 * @param {string} title - The title of the book.
 * @param {string} author - The author of the book.
 */
function Book(title, author) {
  this.title = title;
  this.author = author;
}

/**
 * Gets the title of the book.
 * @returns {string}
 */
Book.prototype.getTitle = function() {
  return this.title;
};

/**
 * Gets the author of the book.
 * @returns {string}
 */
Book.prototype.getAuthor = function() {
  return this.author;
};

/**
 * Creates a new instance of Book.
 * @param {string} title - The title of the book.
 * @param {string} author - The author of the book.
 * @returns {Book}
 */
Book.create = function(title, author) {
  return new Book(title, author);
};",8,10,
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import wandb
wandb.init(project='MNIST_MLP', save_code=True)
import matplotlib.pyplot as pltclass MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return datatransformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])

train_metadata = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_metadata = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)

# Before
print('Train data set:', len(train_metadata))
print('Test data set:', len(test_metadata))

# we reserve 70% of the training set for the training and the remaining 30% for validation
TRAINING_RATIO = 0.7

# split train between validation and training set
train_size = int(TRAINING_RATIO * len(train_metadata))
validation_size = len(train_metadata) - train_size

# After
print('\nTrain data set:', train_size)
print('Validation data set:', validation_size)

# Fixing the generator for reproducible results
train_dataset, validation_dataset = torch.utils.data.random_split(
    train_metadata,
    [train_size, validation_size],
    generator=torch.Generator().manual_seed(42))

BATCH_SIZE = 128

# Create data loader for train and test set
train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
validation_data_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)

test_data_loader = torch.utils.data.DataLoader(test_metadata, shuffle=False)dataiter = iter(train_data_loader)
images, labels = dataiter.next()

print(images.shape) # (number_of_images, batch, image_width, image_height)
print(labels.shape)torch.unique(labels).size(dim=0)plt.imshow(images[0].cpu().numpy().squeeze(), cmap='gray_r')
plt.title(""Ground Truth: {}"".format(labels[0]))
plt.show()","MyMNISTDataset:

This class inherits from the Dataset class and is used to load and transform the MNIST data.

__init__:

This function initializes the MyMNISTDataset class. It takes in a file_path, which is the path to the MNIST data file, a transform, which is a function that transforms the data, and a test_data boolean that indicates whether the data is for training or testing.

__len__:

This function returns the length of the dataset.

__getitem__:

This function returns the data at the given index. If the data is for training, it also returns the target.

transformations:

This is a function that transforms the data. It converts the data to a PyTorch Tensor and normalizes it.

train_metadata:

This is an instance of the MyMNISTDataset class that is used to load the training data.

test_metadata:

This is an instance of the MyMNISTDataset class that is used to load the test data.

TRAINING_RATIO:

This is the ratio of the training set that is used for training. The remaining data is used for validation.

train_size:

This is the size of the training set.

validation_size:

This is the size of the validation set.

train_dataset:

This is the training set.

validation_dataset:

This is the validation set.

BATCH_SIZE:

This is the batch size.

train_data_loader:

This is a DataLoader for the training set.

validation_data_loader:

This is a DataLoader for the validation set.

test_data_loader:

This is a DataLoader for the test set.",8,22,0.3168753351992559
"#use python 3.7
from pyspark.sql import SparkSession
from pyspark.sql.types import IntegerType, FloatType, StructField, StructType
from numpy import array
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.utils import to_categorical
from tensorflow import convert_to_tensor
from tensorflow import reshape
from numpy import argmax


spark = SparkSession.builder.getOrCreate()
df = spark.read.option(""header"", True).option(""inferSchema"", True).csv('train.csv')
L = array([list(train.asDict().values()) for train in df.collect()])
del(df)
x_train = L[:,1:785]
y_train = L[:,0]
del(L)
x_train = [x/255. for x in x_train]
x_train = convert_to_tensor(x_train, dtype=""float32"")
x_train = reshape(x_train, (x_train.shape[0], 28, 28, 1))
df = spark.read.option(""header"", True).option(""inferSchema"", True).csv('test.csv')
x_pred = array([list(train.asDict().values()) for train in df.collect()])
del(df)
x_pred = [x/255. for x in x_pred]
x_pred = convert_to_tensor(x_pred, dtype=""float32"")
x_pred = reshape(x_pred, (x_pred.shape[0], 28, 28, 1))

for d in range(9):
    for e in range(d+1,10):
        model = Sequential()
        model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(28,28,1)))
        model.add(Conv2D(64, (3, 3), activation='tanh'))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Dropout(0.5))
        model.add(Flatten())
        model.add(Dense(128, activation='relu'))
        model.add(Dropout(0.25))
        model.add(Dense(2, activation='softmax'))
        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
        y_trainD = [ to_categorical( 1 if (y == d) or (y == e) else 0 , 2) for y in y_train ]
        y_trainD = convert_to_tensor(y_trainD, dtype=""float32"")
        model.fit(x_train, y_trainD, batch_size=10, epochs=20, shuffle=True, verbose=0)
        del(y_trainD)
        y_pred = model.predict(x_pred, batch_size=10)
        y_pred = [ y_pred[j][1] for j in range( len(y_pred) ) ]
        y_pred = [(j+1, float(y_pred[j])) for j in range(len(y_pred))]
        output_df = spark.createDataFrame(spark.sparkContext.parallelize(y_pred),  StructType([
                 StructField('ImageId', IntegerType(), True),
                StructField('Probability', FloatType(), True)
            ]))
        output_df.toPandas().to_csv('component'+str(d)+str(e)+'.csv', index=False)

L = dict()
for d in range(9):
    for e in range(d+1,10):
        df = spark.read.option(""inferScheme"", True).option(""header"",True).csv('component'+str(d)+str(e)+'.csv')
        L.update({ str(d)+str(e): [float(row.asDict()['Probability']) for row in df.collect()] })

S = []
for j in range(len(L['01'])):
    digit = [0 for d in range(10) ]
    for key in L.keys():
        if L[key][j] > 0.6:
            digit[ int(key[0]) ] += L[key][j]
            digit[ int(key[1]) ] += L[key][j]
    S.append( (int(j+1), int(argmax(digit)) ) )

output_df = spark.createDataFrame( spark.sparkContext.parallelize(S), StructType([
    StructField(""ImageId"", IntegerType(), True),
    StructField(""Label"", IntegerType(), True)
]))
output_df.toPandas().to_csv('submission.csv', index = False)","The code above is for a machine learning project that predicts the digits in handwritten images. The project is done in Python, using the Spark and Keras libraries.

The first part of the code reads in the training data from a CSV file. This data is then converted into a numpy array, which is used to train the machine learning model. The model is a convolutional neural network, which is a type of neural network that is particularly well suited for image recognition tasks.

The second part of the code reads in the test data from a CSV file. This data is then converted into a numpy array, which is used to test the machine learning model. The model is then used to predict the digits in the images in the test data.

The final part of the code outputs the predictions to a CSV file.",8,2,0.11009817724294815
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import wandb
from kaggle_secrets import UserSecretsClient

user_secrets = UserSecretsClient()
secret_value_0 = user_secrets.get_secret(""wandb"")
wandb.login(key=secret_value_0)
wandb.init(project='MNIST_MLP', save_code=True)BATCH_SIZE = 32class MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return datatransformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])

train_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)
# TODO split train between validation and training set
training_size = int(0.9 * len(train_dataset))
validation_size = len(train_dataset) - training_size
train, val = torch.utils.data.random_split(train_dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))

# create data loader for train and test set
data_loader_train = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)
data_loader_val = torch.utils.data.DataLoader(val, batch_size=BATCH_SIZE, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)

print(""Finished data preparation"")# TODO
def init_layer(m):
    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('tanh'))
    torch.nn.init.constant_(m.bias, 0)
    return m

class Net(nn.Module):    
    def __init__(self):
        super(Net, self).__init__()
        self.relu = nn.ReLU()
        self.l1 = init_layer(nn.Linear(28*28, 56))
        self.l2 = init_layer(nn.Linear(56, 28))
        self.l3 = init_layer(nn.Linear(28, 10))
        self.dropout = nn.Dropout(0.5)
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        x = self.relu(self.l1(x))
       # x = self.dropout(x)
        x = self.relu(self.l2(x))
       # x = self.dropout(x)
        return self.softmax(self.l3(x))# TODO

my_nn = Net()

if torch.cuda.is_available():
    my_nn = my_nn.to('cuda')
    print('Training on GPU!')","This code defines a neural network for the MNIST dataset using the PyTorch library. The network consists of 3 fully connected layers, with ReLU activation functions and a softmax output layer. The network is trained using stochastic gradient descent with a learning rate of 0.001.",9,3,0.06927848162266452
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt
import tensorflow as tf
print(tf.__version__)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiontrain = pd.read_csv('../input/digit-recognizer/train.csv')
test = pd.read_csv('../input/digit-recognizer/test.csv')train.head()# Splitting labels from features
y_train = (train.iloc[:,0].values).astype('float32')
X_train = (train.iloc[:,1:].values).astype('float32')
test = (test.values).astype('float32')
del train

X_trainy_trainprint(X_train.shape)
print(y_train.shape)
print(test.shape)# Reshaping to (num of images, pixels in x direction, pixels in y direction, channel()
X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)
test = test.reshape(test.shape[0], 28, 28, 1)
plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))","This code loads in the necessary libraries for data analysis, including numpy, pandas, matplotlib, and tensorflow. It also sets up the input data files from the /kaggle/input directory.

Next, the code splits the labels from the features in the training data, and also converts the data to the 'float32' data type. The test data is also converted to 'float32'.

The code then reshapes the training and test data into 4-dimensional arrays, in preparation for use with a convolutional neural network. Finally, a sample image from the training data is displayed.",9,4,0.27578883560363515
"import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt #for plotting
from collections import Counter
from sklearn.metrics import confusion_matrix
import itertools
import seaborn as sns
from subprocess import check_output
print(check_output([""ls"", ""../input""]).decode(""utf8""))
%matplotlib inline#loading the dataset.......(Train)
train = pd.read_csv(""../input/train.csv"")
print(train.shape)
train.head()z_train = Counter(train['label'])
z_trainsns.countplot(train['label'])#loading the dataset.......(Test)
test= pd.read_csv(""../input/test.csv"")
print(test.shape)
test.head()x_train = (train.ix[:,1:].values).astype('float32') # all pixel values
y_train = train.ix[:,0].values.astype('int32') # only labels i.e targets digits
x_test = test.values.astype('float32')%matplotlib inline
# preview the images first
plt.figure(figsize=(12,10))
x, y = 10, 4
for i in range(40):  
    plt.subplot(y, x, i+1)
    plt.imshow(x_train[i].reshape((28,28)),interpolation='nearest')
plt.show()","This code imports the necessary libraries for data processing, visualization, and machine learning. The dataset is loaded into a pandas dataframe, and the shape of the data is printed. The first five rows of the data are then displayed. The code then creates a seaborn countplot to visualize the distribution of the labels in the training data. The features and labels are then extracted from the dataframe and converted to numpy arrays. The code then displays some sample images from the training data.",9,5,0.11775316896230487
"import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsClassifier# Считаем csv файлы в Pandas датафрейм
train = pd.read_csv('../input/digit-recognizer/train.csv')
test = pd.read_csv('../input/digit-recognizer/test.csv')# Посмотрим на тренировочный датафрейм
train.head()# Узнаем число пропущенных значений 
# и какому признаку принадлежит больше всего пропусков
sum(train.isnull().sum())# Посмотрим на тестовый датафрейм
test.head()# Узнаем число пропущенных значений 
# и какому признаку принадлежит больше всего пропусков
sum(test.isnull().sum())# Пропущенных значений нет, потому можно продолжать работу с выборками","This code imports the pandas and numpy libraries, and loads the data from the digit-recognizer dataset. It then displays the first five rows of the training dataframe, and prints the number of missing values in the training and test sets. Finally, it trains a K-nearest neighbors classifier on the training data and predicts the labels for the test set.",8,2,0.048795994481610074
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset

import wandb
from kaggle_secrets import UserSecretsClient
user_secrets = UserSecretsClient()
secret_value_0 = user_secrets.get_secret(""WANDB_KEY"")
wandb.login(key=secret_value_0)
wandb.init(project='MNIST_MLP', save_code=True)class MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return datatransformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])

train_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)
# TODO split train between validation and training set
training_size = int(0.7 * len(train_dataset))
validation_size = len(train_dataset) - training_size
train, val = torch.utils.data.random_split(train_dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))
# create data loader for train and test set
data_loader_train = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True)
data_loader_val = torch.utils.data.DataLoader(val, batch_size=32, shuffle=True)

test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)def init_my_layer(m):
    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('tanh'))
    torch.nn.init.constant_(m.bias, 0)
    return m

class Net(nn.Module):    
    def __init__(self):
        super(Net, self).__init__()
        self.relu = nn.ReLU()
        self.ln1 = init_my_layer(nn.Linear(28*28, 28))
        self.ln2 = init_my_layer(nn.Linear(28, 28))
        self.ln3 = init_my_layer(nn.Linear(28, 10))
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        x = self.relu(self.ln1(x))
        x = self.relu(self.ln2(x))
        return self.softmax(self.ln3(x))model = Net()

# check if a GPU with Cuda capacities is available
device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"") #0, first GPU if multiple one
model.to(device)
learning_rate = 1e-3
lambda_l2 = 1e-5

criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=lambda_l2)
wandb.watch(model, log=""all"", criterion=criterion, log_freq=1,  log_graph=(True)) 


nb_epochs = 10
# Training
for t in range(nb_epochs):
    model.train() # put the network in training mode
    for X, y in data_loader_train:
        # Feed forward to get the logits
        #format data
        b = X.size(0)
        X = X.view(b,-1)
        y_pred = model(X)
        # Compute the loss and accuracy
        loss = criterion(y_pred, y)
        score, predicted = torch.max(y_pred, 1)
        acc = (y == predicted).sum().float() / len(y)
        wandb.log({
            'mlp/train_loss': loss.item(),
            'mlp/train_accuracy': acc,
        })
        # zero the gradients before running
        # the backward pass.
        optimizer.zero_grad()
        # Backward pass to compute the gradient
        # of loss w.r.t our learnable params. 
        loss.backward()
        # Update params
        optimizer.step()
        
    with torch.no_grad(): # validation run
        model.eval() # validation mode
        for X, y in data_loader_val:
            #format data
            b = X.size(0)
            X = X.view(b,-1)
            y_pred = model(X)
            validation_loss = criterion(y_pred, y)
            score, predicted = torch.max(y_pred, 1)
            acc = (y == predicted).sum().float() / len(y)
            wandb.log({
                'mlp/val_loss': loss.item(),
                'mlp/val_accuracy': acc,
            })
","MyMNISTDataset:

This class inherits from the Dataset class in PyTorch. It is used to load and process data for the MNIST dataset. The constructor takes in a file path, a transform object, and a boolean value indicating whether the data is for the training set or the test set. The class defines two methods: __len__() and __getitem__(). The __len__() method returns the length of the dataset, and the __getitem__() method returns a single item from the dataset at the given index.

Net:

This class inherits from the nn.Module class in PyTorch. It defines a simple neural network for classifying MNIST digits. The network consists of three linear layers, with ReLU activation between the first two layers. The output layer uses softmax activation. The __init__() method defines the layers of the network, and the forward() method defines the forward pass through the network.

DataLoader:

This class inherits from the DataLoader class in PyTorch. It is used to load data in batches for training or testing. The constructor takes in a dataset object, a batch size, and a boolean value indicating whether the data should be shuffled. The class defines two methods: __len__() and __getitem__(). The __len__() method returns the length of the dataset, and the __getitem__() method returns a single batch of data from the dataset.

Criterion:

This class inherits from the Criterion class in PyTorch. It is used to define the loss function for training the neural network. The constructor takes in a loss function object. The class defines the method forward(), which takes in the output of the neural network and the ground truth labels and computes the loss.

Optimizer:

This class inherits from the Optimizer class in PyTorch. It is used to define the optimizer for training the neural network. The constructor takes in an Optimizer object and a learning rate. The class defines the method step(), which takes in the gradient of the loss with respect to the parameters of the neural network and updates the parameters.",8,18,0.2149630629472637
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import tensorflow as tf
import tensorflow.keras.layers as tfl
import tensorflow.keras as keras
import matplotlib.pyplot as plt
import sklearn.model_selection as model_sel


# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiondf = pd.read_csv('../input/digit-recognizer/train.csv')
df.head()X = df.drop(columns=['label'])
X.head()X = X.to_numpy().reshape(-1,28,28,1)X = X/255
X.shapeplt.figure(figsize = (10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.imshow(X[i])
    plt.xticks([])
    plt.yticks([])
    plt.xlabel(df['label'][i])X_train, X_test, Y_train, Y_test = model_sel.train_test_split(X, df['label'].to_numpy().reshape(-1,1), test_size=0.25, random_state=1)","The code above loads in the necessary libraries for data processing, machine learning, and visualization. It then imports the data from the 'digit-recognizer' dataset and displays the first five rows.

Next, the code defines the features (X) and labels (Y) for the machine learning model. The features are the pixel values from the images and the labels are the digits that the images represent.

The code then splits the data into training and testing sets. The training set is used to train the machine learning model and the testing set is used to evaluate the model.

Finally, the code visualizes the first 25 images from the training set.",8,1,0.16259628752158953
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import wandb

from kaggle_secrets import UserSecretsClient
user_secrets = UserSecretsClient()
secret_value = user_secrets.get_secret(""WANDB_KEY"")

wandb.login(key=secret_value)
wandb.init(project='MNIST_MLP', save_code=True)class MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return databatch_size= 512

transformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])


train_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)

# split train between validation and training set
training_size = int(0.7 * len(train_dataset))
validation_size = len(train_dataset) - training_size
train, val = torch.utils.data.random_split(train_dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))

# create data loader for train and test set
data_loader_train = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)
data_loader_val = torch.utils.data.DataLoader(val, batch_size=batch_size, shuffle=True)

test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False)def init_layer(m):
    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('relu'))
    torch.nn.init.constant_(m.bias, 0)
    return mclass Net(nn.Module):    
    def __init__(self, inputSize):
        super(Net, self).__init__()
        
        self.linear1 = init_layer(torch.nn.Linear(inputSize, 512))
        self.linear2 = init_layer(torch.nn.Linear(512, 256))
        self.dropout = torch.nn.Dropout(p=0.4)
        self.linear3 = init_layer(torch.nn.Linear(256, 10))


    def forward(self, x):
        
        x = x.view(-1,28*28) #reshape the 2d image in a ondiminsional vector for the input of the first layer
        
        x = F.relu(self.linear1(x))
        x = self.dropout(x)
        x = F.relu(self.linear2(x))
        x = self.dropout(x)
        
        return self.linear3(x)input_size = 784
output_size = 10 #labels range from 0-9

model = Net(input_size)

num_epochs = 50
lr =  0.01
weight_decay = 1e-4

optimizer = torch.optim.SGD(model.parameters(),lr = lr)#torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay) #AdamW to aviod coupling problem between the L2 regularization and the adaptive learning rate
criterion = torch.nn.CrossEntropyLoss()

#logging configuration and model
wandb.config.learningrate = lr
wandb.config.num_iterations = num_epochs
wandb.config.optimizer = ""AdamW""
wandb.config.weight_decay = weight_decay
wandb.config.criterion = ""CELoss""

wandb.watch(model, log=""all"", criterion=criterion, log_freq=1,  log_graph=(True)) #log frequency depend on your training


device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"") #0, first GPU if multiple one
print(device)
model.to(device)
","This code defines a neural network for the MNIST dataset using the PyTorch library. The network consists of three fully-connected layers, with 512, 256, and 10 neurons in the first, second, and third layers, respectively. The network uses the ReLU activation function for the first two layers, and the softmax activation function for the final layer. The network also uses a dropout layer with a probability of 0.4.

The code defines a dataset class for the MNIST dataset, which includes the ability to transform the data into PyTorch tensors and load the data into a PyTorch DataLoader. The code also defines a function for initializing the weights of the neural network layers.

The code then trains the neural network using stochastic gradient descent with a learning rate of 0.01 and a weight decay of 1e-4. The code also uses the AdamW optimizer to avoid coupling problems between the L2 regularization and the adaptive learning rate. The code uses the cross entropy loss function.

The code logs the training process using the Wandb library. The code also saves the trained model to the current directory.",8,7,0.1746541583055602
"import pandas as pd   # data analysis librarymnist_test = pd.read_csv(""/kaggle/input/mnist-fashion-data-classification/mnist_test.csv"")    # create a variable dataframe containing data from data file
mnist_train = pd.read_csv(""/kaggle/input/mnist-fashion-data-classification/mnist_train.csv"")    # create a variable dataframe containing data from data file
sample_submission = pd.read_csv(""/kaggle/input/digit-recognizer/sample_submission.csv"")    # create a variable dataframe containing data from data file
train = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")    # create a variable dataframe containing data from data file
test = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")    # create a variable dataframe containing data from data filecols = test.columnstest['dataset'] = 'test'train['dataset'] = 'train'dataset = pd.concat([train.drop('label', axis=1), test]).reset_index()","This code imports the pandas library and reads in data from four different CSV files: mnist_test, mnist_train, sample_submission, and train. It then concatenates the data from these files into a single dataframe called dataset.",8,3,0.24816859989396067
"import os
import numpy as np
import pandas as pd
import pydicom# Load the data
base_path = ""/kaggle/input/siim-covid19-detection/""
studies_df = pd.read_csv(os.path.join(base_path,""train_study_level.csv""))
images_df = pd.read_csv(os.path.join(base_path,""train_image_level.csv""))

# Strip the extra text from the study and image IDs
studies_df['id'] = studies_df['id'].map(lambda x: x.rstrip('_study'))
images_df['id'] = images_df['id'].map(lambda x: x.rstrip('_image'))

# Merge the dfs together
data_df = pd.merge(images_df, studies_df, how='inner', left_on='StudyInstanceUID', right_on='id')
data_df.drop(['id_y'], axis=1, inplace=True)# This function finds the first image in a StudyInstanceUID directory and returns its path
def get_image_by_study_id(study_id):
    study_path = base_path + ""train/"" + study_id + ""/""
    for subdir, dirs, files in os.walk(study_path):
        for file in files:     
            image = os.path.join(subdir, file)
            if os.path.isfile(image):
                return image
    return ""none""# Loop through the images and check how many images are not Explicit VR Little Endian transfer syntax.
# Also count images with VOI LUT Sequence tags present

count = 0
images_with_voi_lut = 0
images_with_voi_lut_function = 0
images_not_explicit_le = 0
deflated_syntaxes = []
voi_lut_functions = []

for index, row in data_df.iterrows():
    img_file = get_image_by_study_id(row['StudyInstanceUID'])
    img = pydicom.dcmread(img_file)
    
    # Check for a LUT sqequence tag
    if (0x0028,0x3010) in img:
        images_with_voi_lut += 1
    
    # Check for a LUT Function tag
    if (0x0028,0x1056) in img:
        images_with_voi_lut_function += 1
        
        if img(0x0028,0x1056) not in voi_lut_functions:
            voi_lut_functions.append(img(0x0028,0x1056))
            
    # Check the transfer syntax
    if img.file_meta.TransferSyntaxUID != ""1.2.840.10008.1.2.1"":
        images_not_explicit_le += 1
        
        if img.file_meta.TransferSyntaxUID not in deflated_syntaxes:
            deflated_syntaxes.append(img.file_meta.TransferSyntaxUID)
        
    count += 1
    
print(""Done checking "" + str(count) + "" images"")
print(""Found "" + str(images_with_voi_lut) + "" images with VOI LUT"")
print(""Found "" + str(images_with_voi_lut_function) + "" images with VOI LUT Function"")
print(""VOI LUT Functions:"")
print(voi_lut_functions)
print(""Found "" + str(images_not_explicit_le) + "" images that are not Explicit VR LE"")
print(""Non Explicit VR LE Transfer Syntaxes"")
print(deflated_syntaxes)","This code imports the necessary libraries, loads the data, and strips the extra text from the study and image IDs. It then merges the dataframes together.

The get_image_by_study_id() function finds the first image in a StudyInstanceUID directory and returns its path.

The code then loops through the images and checks for various tags. It counts the number of images with VOI LUT Sequence tags present, as well as the number of images with VOI LUT Function tags. It also checks the transfer syntax of the images and counts the number of images that are not Explicit VR Little Endian. Finally, it prints the results.",8,5,0.30284822229406566
"import os
import cv2
import numpy as np
import pandas as pd
import pydicom
import matplotlib.pyplot as plt
%matplotlib inline# This function gets the first image path in a StudyInstanceUID directory
def get_image_by_study_id(study_id):
    base_path = ""/kaggle/input/siim-covid19-detection/""
    study_path = base_path + ""train/"" + study_id + ""/""
    images = []
    for subdir, dirs, files in os.walk(study_path):
        for file in files:     
            image = os.path.join(subdir, file)
            if os.path.isfile(image):
                return image
    return ""none""# Make a simple linear VOI LUT from the raw (stored) pixel data
def make_lut(storedPixels, windowWidth, windowLevel, p_i):
    
    # Slope and Intercept set to 1 and 0 for X-ray. Get these from DICOM tags instead if using 
    # on a modality that requires them (CT, PT etc)
    slope = 1.0
    intercept = 0.0
    minPixel = int(np.amin(storedPixels))
    maxPixel = int(np.amax(storedPixels))

    # Make an empty array for the LUT the size of the pixel 'width' in the raw pixel data
    lut = [0] * (maxPixel + 1)
    
    # Invert pixels and windowLevel for MONOCHROME1. We invert the specified windowLevel so that 
    # increasing the level value makes the images brighter regardless of photometric intrepretation
    invert = False
    if p_i == ""MONOCHROME1"":
        invert = True
    else:
        windowLevel = (maxPixel - minPixel) - windowLevel
        
    # Loop through the pixels and calculate each LUT value
    for storedValue in range(minPixel, maxPixel):
        modalityLutValue = storedValue * slope + intercept
        voiLutValue = (((modalityLutValue - windowLevel) / windowWidth + 0.5) * 255.0)
        clampedValue = min(max(voiLutValue, 0), 255)
        if invert:
            lut[storedValue] = round(255-clampedValue)
        else:
            lut[storedValue] = round(clampedValue)
        
    return lut# Apply the LUT to a pixel array
def apply_lut(pixels_in, lut):
    pixels_in = pixels_in.flatten()
    pixels_out = [0] * len(pixels_in)
    for i in range(0, len(pixels_in)):
        pixel = pixels_in[i]
        pixels_out[i] = int(lut[pixel])
    return pixels_out# Take a look at a random image and display it with imshow. The width and level are automagically calculated from the pixel data.
img_file = get_image_by_study_id(""00c241c3fc0d"")
print(""Loading image: "" + img_file)

img = pydicom.dcmread(img_file)
plt.imshow(img.pixel_array,cmap=""gray"");# Set the width to be the distance between the pixels, and the level to be the middle of the pixel range.
# The resulting image should look exactly like the one above.
pixels = img.pixel_array
minPixel = np.min(pixels)
maxPixel = np.max(pixels)
windowWidth = maxPixel - minPixel
windowLevel = (minPixel + maxPixel) / 2

lut = make_lut(pixels, windowWidth, windowLevel, img.PhotometricInterpretation)
pixels = apply_lut(pixels, lut)

# Reshape the pixel array back into the image shape
img_out = np.reshape(pixels, (img.pixel_array.shape[0],img.pixel_array.shape[1]))

print(""Calculated - Width: "" + str(windowWidth) + "" / Level  "" +  str(windowLevel))
print(""Pixel range: "" + str(minPixel) + "" - "" + str(maxPixel))
plt.imshow(img_out,cmap=""gray"");print(""PhotometricInterpretation: "" + img.PhotometricInterpretation)
print(""Bit stored: "" + str(img.BitsStored))","This code imports the necessary libraries, then defines a function to get the first image path in a StudyInstanceUID directory.

Next, a function is defined to make a simple linear VOI LUT from the raw (stored) pixel data. This function takes the stored pixel data, the window width, the window level, and the photometric interpretation (p_i) as input.

The code then defines a function to apply the LUT to a pixel array. This function takes the pixel array and the LUT as input, and returns the pixel array with the LUT applied.

Finally, the code displays a random image, then calculates and displays the width and level of the image.",9,2,0.4935425065001222
"import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings(""ignore"")
from glob import glob
from tqdm.notebook import tqdm
from ast import literal_eval
import os
import matplotlib.pyplot as plt
import matplotlib
matplotlib.rcParams.update({'font.size': 22})
from sklearn.metrics import accuracy_score
from skimage import exposure
from tensorflow.keras import layers
from tensorflow.keras.utils import plot_model
import cv2
from matplotlib.patches import Rectangle
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50, DenseNet121, Xception
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import models
from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping
import tensorflow.keras.backend as K
from tensorflow.math import confusion_matrixdf_image = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
display(df_image.head(3))
print(df_image.shape)df_study = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
display(df_study.head(3))
print(df_study.shape)df_sampleSub = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
display(df_sampleSub.head(3))
print(df_sampleSub.shape)df_study['id'] = df_study['id'].str.replace('_study',"""")
df_study.rename({'id': 'StudyInstanceUID'},axis=1, inplace=True)
df_study.head(3)df_train = df_image.merge(df_study, on='StudyInstanceUID')
df_train.head(3)# train_dir_jpg = '../input/covid-jpg-512/train'
# train_dir_origin ='../input/siim-covid19-detection/train'
# paths_original = []
# paths_jpg = []
# for _, row in tqdm(df_train.iterrows()):
#     image_id = row['id'].split('_')[0]
#     study_id = row['StudyInstanceUID']
#     image_path_jpg = glob(f'{train_dir_jpg}/{image_id}.jpg')
#     image_path_original = glob(f'{train_dir_origin}/{study_id}/*/{image_id}.dcm')
#     paths_jpg.append(image_path_jpg)
#     paths_original.append(image_path_original)","This code imports the pandas and numpy libraries, and sets up a filter to ignore warnings. It then defines a function to read in CSV files containing image and study data, and merge them into a single dataframe. Finally, it defines a function to read in a sample submission file.",8,2,0.01994772786557592
"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -yimport tensorflow as tf
print(tf.__version__)
import torch
print(f""Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})"")

import os
import gc
import cv2
import glob
import numpy as np
import pandas as pd
from PIL import Image
from tqdm import tqdm
from shutil import copyfile
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lutgpus = tf.config.list_physical_devices('GPU')
if gpus:
  try:
    # Currently, memory growth needs to be the same across GPUs
    for gpu in gpus:
      tf.config.experimental.set_memory_growth(gpu, True)
    logical_gpus = tf.config.experimental.list_logical_devices('GPU')
    print(len(gpus), ""Physical GPUs,"", len(logical_gpus), ""Logical GPUs"")
  except RuntimeError as e:
    # Memory growth must be set before GPUs have been initialized
    print(e)# Read the submisison file
sub_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')
print(len(sub_df))
sub_df.head()study_df = sub_df.loc[sub_df.id.str.contains('_study')]
len(study_df)image_df = sub_df.loc[sub_df.id.str.contains('_image')]
len(image_df)# Ref: https://www.kaggle.com/xhlulu/siim-covid-19-convert-to-jpg-256px
def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return data

def resize_xray(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im","This code installs the pydicom conda helper package, which allows for the reading and manipulation of DICOM images. It also installs the TensorFlow and PyTorch packages, and imports the required modules for reading, processing, and resizing DICOM images. Finally, it reads in the sample submission file and splits it into two dataframes: one for the study images and one for the image data.",8,3,0.13066740388682338
"!/opt/conda/bin/python3.7 -m pip install --upgrade pip
! pip install -q efficientnet#-------------------
# importing libraries
#-------------------
import tensorflow as tf
from tensorflow.keras import layers
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold,StratifiedKFold

from kaggle_datasets import KaggleDatasets


import pandas as pd
import numpy as np

import os
import shutil
import csv

import matplotlib.pyplot as plt
import PILAUTO = tf.data.experimental.AUTOTUNE

try:
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  
    print('Running on TPU ', tpu.master())
except ValueError:
    tpu = None

if tpu:
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.experimental.TPUStrategy(tpu)
else:
    strategy = tf.distribute.get_strategy()

print(""REPLICAS: "", strategy.num_replicas_in_sync)GCS_DS_PATH = KaggleDatasets().get_gcs_path(""siim-covid19-dataset-256px-jpg"")
print(GCS_DS_PATH)

TRAIN_PATH = GCS_DS_PATH + ""/256px/train/train/""
TEST_PATH = GCS_DS_PATH + ""/256px/test/test/""

NUM_CLASSES = 4
HEIGHT,WIDTH = 256,256
CHANNELS = 3
BATCH_SIZE = 8 * strategy.num_replicas_in_sync
SEED = 143


classes_dict = {
    ""Negative for Pneumonia"" : 0,
    ""Typical Appearance"" : 1,
    ""Indeterminate Appearance"" : 2,
    ""Atypical Appearance""  : 3
}

study_df = pd.read_csv(""../input/siim-covid19-detection/train_study_level.csv"")
train_df = pd.read_csv('../input/siim-covid19-dataset-256px-jpg/train.csv')
train_df = train_df[[""ImageInstanceUID"",""StudyInstanceUID"",""label_id"",""study_label""]]train_df.head(3)study_df.head(3)def process_img(filepath,label):
    image = tf.io.read_file(filepath)
    image = tf.image.decode_jpeg(image, channels=CHANNELS)
    image = tf.image.convert_image_dtype(image, tf.float32) 
    #image = tf.image.resize(image, [HEIGHT,WIDTH])
    return image,label


def data_augment(image, label):
    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
            
    # Flips
    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_flip_up_down(image)
    if p_spatial > .75:
        image = tf.image.transpose(image)
        
    # Rotates
    if p_rotate > .75:
        image = tf.image.rot90(image, k=3) 
    elif p_rotate > .5:
        image = tf.image.rot90(image, k=2) 
    elif p_rotate > .25:
        image = tf.image.rot90(image, k=1) 
        
    
    if p_pixel_1 >= .4:
        image = tf.image.random_saturation(image, lower=.7, upper=1.3)
    if p_pixel_2 >= .4:
        image = tf.image.random_contrast(image, lower=.8, upper=1.2)
    if p_pixel_3 >= .4:
        image = tf.image.random_brightness(image, max_delta=.1)
        
    
    if p_crop > .7:
        if p_crop > .9:
            image = tf.image.central_crop(image, central_fraction=.7)
        elif p_crop > .8:
            image = tf.image.central_crop(image, central_fraction=.8)
        else:
            image = tf.image.central_crop(image, central_fraction=.9)
    elif p_crop > .4:
        crop_size = tf.random.uniform([], int(HEIGHT*.8), HEIGHT, dtype=tf.int32)
        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])
    
    image = tf.image.resize(image, [HEIGHT,WIDTH])
    return image,label

def get_dataset(filenames,labels, training=True):
    dataset = tf.data.Dataset.from_tensor_slices((filenames,labels))
    dataset = dataset.map(process_img,num_parallel_calls=AUTO)
    dataset = dataset.map(data_augment,num_parallel_calls=AUTO)
    dataset = dataset.cache()
    dataset = dataset.repeat()
    if training:
        dataset = dataset.shuffle(2048)
    dataset = dataset.batch(BATCH_SIZE)
    dataset = dataset.prefetch(AUTO)
    return dataset","This code imports the necessary libraries for training a machine learning model to detect pneumonia from X-ray images. The libraries used are TensorFlow, Keras, Scikit-Learn, and Pandas.

The code defines a function to process images. This function takes an image filepath and a label as input, and outputs a processed image and label. The image is read from the filepath, decoded, and converted to float32 format. The label is unchanged.

The code also defines a function to augment data. This function takes an image and a label as input, and outputs an augmented image and label. The image is randomly flipped left-right and up-down, and may also be rotated, cropped, or have its saturation, contrast, or brightness changed.

Finally, the code defines a function to get a dataset. This function takes a list of filenames and labels as input, and outputs a dataset. The dataset is processed using the process_img() function and data_augment() function, and is cached, repeated, shuffled (if training), and batched.",9,3,0.1432901690484685
"%%capture
!conda install gdcm -c conda-forge -y# Packages

import os, time, glob, re, pprint, random, math
from collections import defaultdict, Counter

import pandas as pd 
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import matplotlib.patches as patches

import seaborn as sns

import cv2
import gdcm

import pydicom
from pydicom import dcmread
from pydicom.pixel_data_handlers.util import apply_voi_lut

import imagehash
from PIL import Image as im

import tqdm# Magic

%matplotlib inline # Pandas options

pd.set_option(""display.expand_frame_repr"", True)
pd.set_option('display.max_colwidth', 0)# Global values

CODE_PATH = ""./""
DATA_PATH = ""../input/siim-covid19-detection""
TRAIN_PATH = os.path.join(DATA_PATH, ""train"")
TEST_PATH = os.path.join(DATA_PATH, ""test"")# Utility functions

def print_title(s):
    
    # Print an underlined title
    
    print(""%s\n%s"" % (s, '-'*len(s)))
    
    
def na_fill(dtype):
    
    # Fill in missing values so that Seaborn countplot() will include them.
    # Also make sure the missing value for a string column is itself a string.
    
    if dtype == np.float64:
        result = -999
    elif dtype == np.int64:
        result = -999
    elif dtype == np.object:
        result = ""NA""
    else:
        result = -999

    return result


def explode_list_col(df, col):
    
    other_cols = list(df.columns)
    other_cols.remove(col)
    out_df = df.set_index(other_cols)[col]
    out_df = out_df.apply(pd.Series)
    out_df = out_df.stack()
    out_df = out_df.reset_index()
    out_df = out_df.drop(f""level_{len(other_cols)}"", axis=1)
    out_df = out_df.rename(columns={0 : col})
    
    return out_df
    

def cat_order(train_df, test_df, cols):
    
    # For comparison, we want the categories to be the same between train and test. 
    # We also want the categories to be in the same order for both. 
    # We need to make sure missing value types are consistent with the column data
    # type (else sort will complain), and make sure that Seaborn countplot() will
    # include them (it won't include np.nan). Dealing with the latter two issues 
    # is the job of fillna(). When the data is plotted, it needs to be run through
    # fillna() as well.

    category_order = {}
    n = len(cols)

    for col in cols:

        if col in train_cols:
            train_dtype = train_df[col].dtype
        else:
            train_dtype = None     
        if col in test_cols:
            test_dtype = test_df[col].dtype
        else:
            test_dtype = None
        if (train_dtype != None) and (test_dtype != None) and (train_dtype != test_dtype):
            print(f""***Incompatible train/test data types for column {col}"")
            break
        
        col_vals = []
        if col in train_cols:
            col_vals += list(train_df[col].fillna(na_fill(train_dtype)).unique())
        if col in test_cols:
            col_vals += list(test_df[col].fillna(na_fill(test_dtype)).unique())
        col_vals = list(set(col_vals))
        col_vals.sort()
    
        category_order[col] = col_vals
        
    return category_order


def plot_categories(df, col, order, title, ax, xlabel=None, ylabel=None, pallete=""Set3"", scale=""log""):

    data = df[col].fillna(na_fill(df[col].dtype))
    ax = sns.countplot(x=data, order=order, palette=pallete, ax=ax)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=""right"")
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    counts = data.value_counts()
    for i, p in enumerate(ax.patches):
        px = p.get_x()+0.05
        py = max(p.get_height()*0.9, 1.0)
        ax.annotate(counts.get(order[i], """"), (px, py), fontsize=10, rotation=90)
    ax.set_title(title, fontsize=15)
    if xlabel: ax.set_xlabel(xlabel)
    if ylabel: ax.set_ylabel(ylabel)
    
    return


def plot_cat_sub(df, col, sub_col, title, ax, scale=""log""):

    ax = sns.countplot(data=df, x=col, hue=sub_col, ax=ax)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=""right"")
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    ax.set_title(title, fontsize=15)
        
    return


def plot_number_uniq_per(df, df_name, attr1, attr2, ax, title=None, palette=None, scale=""log""):
    
    uniq_df = df.groupby(attr1)[[attr2]].nunique().reset_index()
    ax = sns.barplot(x=attr1, y=attr2, data=uniq_df, ax=ax, palette=palette)
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
        
    counts = uniq_df[attr2]
    for i, p in enumerate(ax.patches):
        px = p.get_x()+0.05
        py = max(p.get_height()*0.9, 1.0)
        ax.annotate(uniq_df[attr2].iloc[i], (px, py), fontsize=10, rotation=90)

    if title:
        ax.set_title(title, fontsize=15)
    else:
        ax.set_title(f""{df_name}\nNumber of unique '{attr2}' values \nper '{attr1}' value"", fontsize=15)
    ax.set_xlabel(attr1)
    ax.set_ylabel(f""# unique '{attr2}'"")
    
    return uniq_df


def plot_number_having_n_uniq(df, df_name, attr1, attr2, ax, order=None, palette=None, scale=""log""):

    nuniq = df.groupby(attr1)[attr2].nunique()
    ax = sns.countplot(x=nuniq, order=order, ax=ax, palette=palette)
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    ax.set_title(f""{df_name}\nNumber of '{attr1}' values \nhaving N unique values of '{attr2}'"", fontsize=15)
    ax.set_xlabel(f""N = # of unique '{attr2}' values"")
    ax.set_ylabel(f""# of '{attr1}' having N"")

    return nuniq


def get_img(path, img_id):

    img_path = os.path.join(path, f""{img_id}.jpg"")
    im = cv2.imread(img_path)
    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
    im = cv2.normalize(im, None, 0, 255, cv2.NORM_MINMAX)
    
    return im


def image_subplots(images, r, c, axes, titles=None):
    
    for idx, img in enumerate(images, 0):
        i = idx // c
        j = idx % c
        if titles:
            imshow(img, axes[i, j], title=titles[idx])
        else:
            imshow(img, axes[i, j])

    return
        

def imshow(image, ax=None, title=None, cmap=None):

    if ax is None:
        fig, ax = plt.subplots()
    ax.imshow(image, cmap=cmap)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.spines['left'].set_visible(False)
    ax.spines['bottom'].set_visible(False)
    ax.tick_params(axis='both', length=0)
    ax.set_xticklabels('')
    ax.set_yticklabels('')
    if title:
        ax.set_title(title)

    return ax
# Read the image metadata

train_image_df = pd.read_csv(os.path.join(DATA_PATH,'train_image_level.csv'))
train_study_df =  pd.read_csv(os.path.join(DATA_PATH,'train_study_level.csv'))","This code reads in the image metadata for the training data set. This includes the file path for each image, as well as some basic information about the image (e.g., dimensions, modality, etc.).",8,0,0.10400244502735231
"import pydicom as dicom
import pandas as pd
import os
from tqdm import tqdmmetadata = []

for split in ['test', 'train']:  
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            ds1 = dicom.dcmread(os.path.join(dirname, file), stop_before_pixels=True)
            dt=dict()
            dt['ImageId']=file.replace('.dcm','')
            for key in ds1.keys():
                dt[ds1[key].keyword]=ds1[key].value
            metadata.append(dt)

metadata_df=pd.DataFrame(metadata)
metadata_df.head()metadata_df.to_csv('metadata_covid.csv', index=False)","This code imports the pydicom and pandas libraries, and then loops through a dataset of DICOM files, extracting metadata from each file and storing it in a list. This list is then converted into a pandas DataFrame and saved to a CSV file.",9,2,0.1092575311423896
"import pandas as pd 
import numpy as np
import os
import pydicom
import glob
from tqdm.notebook import tqdm
from pydicom.pixel_data_handlers.util import apply_voi_lut
import matplotlib.pyplot as plt 
from skimage import exposure
import cv2
import warnings
from path import Path
from fastai.vision.all import *
from fastai.medical.imaging import *
warnings.filterwarnings(""ignore"")datapath = Path(""../input/siim-covid19-detection"")datapath.ls()train_study_df = pd.read_csv(datapath/'train_study_level.csv')train_study_df.head()study_classes = [""Negative for Pneumonia"" , ""Typical Appearance"",
                ""Indeterminate Appearance"", ""Atypical Appearance""]
np.unique(train_study_df[study_classes].values , axis = 0)plt.figure(figsize = (10,5))
plt.bar([1,2,3,4] , train_study_df[study_classes].values.sum(axis = 0))
plt.xticks([1,2,3,4] , study_classes)
plt.ylabel(""Frequency"")
plt.show()","This code imports the pandas, numpy, os, pydicom, glob, tqdm, and matplotlib libraries. It also imports the apply_voi_lut, exposure, and cv2 modules from the pydicom, skimage, and fastai libraries, respectively.

The code then defines a datapath variable that points to the input data directory. Next, it reads in the train_study_level.csv file and displays the first five rows of the dataframe.

The code then defines a study_classes variable that contains a list of the four classes of findings in the study data. Next, the code displays the unique class values in the study data and plots a bar chart of the class frequencies.",8,12,0.0503420889698054
"import numpy as np 
import pandas as pd 
import os
import matplotlib.pyplot as plt
import matplotlib
import pydicom as dicom
import cv2
import ast
import warnings
warnings.filterwarnings('ignore')train_image = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
train_study = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
sample_submission = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')train_image.head()len(train_image)train_study.head()len(train_study)sample_submission.head()","This code imports the necessary libraries for working with the data, including NumPy, pandas, matplotlib, and cv2. It then loads the train_image, train_study, and sample_submission dataframes from the input files. Finally, it displays the first five rows of the train_image dataframe.",9,3,0.08303066222954547
"!conda install gdcm -c conda-forge -yimport os
import ast
import numpy as np
import pandas as pd
from path import Path
import datetime
import glob
import json
import shutil

from PIL import Image
from tqdm.auto import tqdm
import pydicom
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import cv2from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)    
    
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail(size, resample)
    else:
        im = im.resize(size, resample)
    
    return imimages_meta_folder = '/kaggle/working/images_metadata_256_512_768'
os.makedirs(images_meta_folder, exist_ok=True)

# Define sizes
new_sizes = [(256, 256), (512, 512), (768, 768)]for new_size in new_sizes:

    for split in ['train', 'test']:
    # for split in ['test']:
        save_dir = f'/kaggle/tmp/{split}_{new_size[0]}x{new_size[1]}/'
        dcm_paths = glob.glob(f'../input/siim-covid19-detection/{split}/*/*/*')
        os.makedirs(save_dir, exist_ok=True)

        image_ids = []
        folder_ids = []
        study_ids = []
        widths = []
        heights = []

        for path in tqdm(dcm_paths):
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(path)
            im = resize(xray, size=new_size)

            path_split = path.split('/')
            study_id = path_split[-3]
            folder_id = path_split[-2]
            image_name = path_split[-1].replace('.dcm', '_image')

            im.save(os.path.join(save_dir, image_name+'.png'))

            image_ids.append(image_name)
            folder_ids.append(folder_id)
            study_ids.append(study_id)
            widths.append(xray.shape[1])
            heights.append(xray.shape[0])
            
        df = pd.DataFrame.from_dict({'id': image_ids, 'folder_id': folder_ids,
                                     'study_id': study_ids, 'width': widths,
                                     'height': heights})
        df.to_csv(f'{images_meta_folder}/{split}_meta_{new_size[0]}x{new_size[1]}.csv', index=False)for new_size in new_sizes:
    print(f""*****{new_size}*****\n"")
    df_train_meta = pd.read_csv(f'{images_meta_folder}/train_meta_{new_size[0]}x{new_size[1]}.csv')
    df_train = pd.read_csv(""../input/siim-covid19-detection/train_image_level.csv"")
    df_train_meta = df_train.merge(df_train_meta, on='id')
    
    ## Drop all rows of images without annotations
    df_train_meta = df_train_meta.dropna()
    imagepaths = df_train_meta.id.unique()
    print(""Number of Images with Covid_Abnormality:"",len(imagepaths))
    
    display(df_train_meta.head(3))
    print()
    
    df_idx=0

    for idx, row in tqdm(df_train_meta.iterrows(), total=df_train_meta.shape[0]):
        img = cv2.imread(os.path.join(f""/kaggle/tmp/train_{new_size[0]}x{new_size[1]}/"",
                                      row.id.replace(""_image"", "".png"")))
        bboxes = [list(bbox.values()) for bbox in ast.literal_eval(row.boxes)]
        height_ratio, width_ratio = (new_size[0]/row.height, new_size[1]/row.width)

        for box in bboxes:
            box[2] = box[2]+box[0]
            box[3] = box[3]+box[1]
            box = (box[0]*width_ratio, box[1]*height_ratio,
                   box[2]*width_ratio, box[3]*height_ratio)

            row_df = pd.DataFrame({'id':row.id,
                           'StudyInstanceUID':row.StudyInstanceUID,
                           'folder_id':row.folder_id,
                           'study_id':row.study_id,
                           'width':row.width,
                           'height':row.height,
                           'xmin':round(box[0]),
                           'ymin':round(box[1]),
                           'xmax':round(box[2]),
                           'ymax':round(box[3])}, index=[df_idx])

            if df_idx==0:
                df_train_processed = row_df
            else:
                df_train_processed = pd.concat([df_train_processed, row_df])

            df_idx+=1

    display(df_train_processed.head(3))
    print()
    df_train_processed.to_csv(f'{images_meta_folder}/df_train_processed_meta_{new_size[0]}x{new_size[1]}.csv',
                              index=False)
    df_train_processed.shape","This code is used to resize images and generate metadata for those images. The new sizes are defined as tuples in a list. The code then loops through all of the images in a given folder, resizes them to the new dimensions, and saves them in a new folder. Finally, it generates a metadata file for the new images.",8,1,0.09257279514433348
"!conda install gdcm -c conda-forge -yimport cv2
import datetime
import gc
import glob
import imagehash
import math
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
import PIL
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import sys
import tqdmbase_path = '../input/siim-covid19-detection'def read_dicom_image(image_file, voi_lut=True, fix_monochrome=True):
    """"""
    Reads a dicom image from a file an returns a numpy array.
    References: https://www.kaggle.com/trungthanhnguyen0502/eda-vinbigdata-chest-x-ray-abnormalities
    Args:
        image_file:
        voi_lut:
        fix_monochrome:

    Returns:

    """"""
    dicom = pydicom.read_file(image_file)
    # VOI LUT (if available by DICOM device) is used to
    # transform raw DICOM data to ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
    return data


def string2boxes(string):
    strings = string.split()
    if strings[0].lower() == 'none':
        return []
    else:
        return [{'class': strings[idx],
                 'conf': float(strings[idx+1]),
                 'x1': float(strings[idx+2]),
                 'y1': float(strings[idx+3]),
                 'x2': float(strings[idx+4]),
                 'y2': float(strings[idx+5]),
                 } for idx in range(0, len(strings), 6)]


def plot_image(image, boxes=None, size=(5,5), title=None, columns=4):
    def plot_img(image, boxes=None, title=None):
        if isinstance(image, str):
            image_id = os.path.splitext(os.path.split(image)[1])[0]
            df = df_image.loc[df_image['id'] == image_id + '_image']
            boxes = string2boxes(df['label'].iloc[0]) if len(df) > 0 else None
            image = read_dicom_image(image)
        image = np.stack([image] * 3, axis=-1)
        if boxes is not None:
            for box in boxes:
                image = cv2.rectangle(image, (int(box['x1']), int(box['y1'])), (int(box['x2']), int(box['y2'])), [0, 255, 0], 10)
        plt.axis('on')
        plt.imshow(image, cmap='gray')
        if title is not None:
            plt.title(title)

    plt.figure(figsize=size)
    if isinstance(image, list):
        num = len(image)
        columns = min(columns, num)
        rows = math.ceil(num / columns)

        for index, single_image in enumerate(image):
            plt.subplot(rows, columns, index + 1)
            plot_img(single_image, boxes=boxes, title=title[index])
    else:
        plot_img(image, boxes=boxes, title=title)
    plt.show()


def images_find_duplicates(image_files, threshold=0.9):
    """"""
    Function to find duplicates in images.
    References: https://www.kaggle.com/appian/let-s-find-out-duplicate-images-with-imagehash
    Args:
        image_files:
        threshold:

    Returns:

    """"""
    funcs = [imagehash.average_hash, imagehash.phash, imagehash.dhash, imagehash.whash]
    image_ids = image_files
    hashes = []
    for file in tqdm.tqdm(image_files):
        image = PIL.Image.fromarray(read_dicom_image(file))
        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))
    hashes_all = np.array(hashes)

    # Comparisons without Pytorch
    sim_list = []
    for i in tqdm.tqdm(range(hashes_all.shape[0])):
        sim_list.append(np.sum(hashes_all[i] == hashes_all, axis=1)/256)

    # nxn-matrix of similarities (n = # of images), upper triangular matrix
    similarities = np.triu(np.array(sim_list), 1)

    idx_pair = np.where(similarities > threshold)
    df_pairs = pd.DataFrame({'image1': [image_ids[i] for i in list(idx_pair[0])],
                             'image2': [image_ids[i] for i in list(idx_pair[1])],
                             'similarity': [similarities[i1, i2] for i1, i2 in zip(idx_pair[0], idx_pair[1])]})

    idx_group = np.zeros(len(image_files))
    group_id = 1
    for i1, i2 in zip(idx_pair[0], idx_pair[1]):
        if idx_group[i1] == 0 and idx_group[i2] == 0:
            idx_group[i1] = group_id
            idx_group[i2] = group_id
            group_id += 1
        elif idx_group[i1] != 0 and idx_group[i2] == 0:
            idx_group[i2] = idx_group[i1]
        elif idx_group[i1] == 0 and idx_group[i2] != 0:
            idx_group[i1] = idx_group[i2]
        elif idx_group[i1] != 0 and idx_group[i2] != 0 and idx_group[i1] != idx_group[i2]:
            common_id = min(idx_group[i1], idx_group[i2])
            idx_group[idx_group == idx_group[i1]] = common_id
            idx_group[idx_group == idx_group[i2]] = common_id

    group_list = []
    for i in range(1, group_id + 1):
        group_ids = list(np.where(idx_group == i)[0])
        if len(group_ids) > 0:
            group_list.append([image_ids[j] for j in group_ids])

    return df_pairs, group_list


def print_group_info(i, df_group):
    print(f'\nGroup {i+1}')
    print(f'Number of unique studies:       {len(df_group[""study_id""].unique())}')
    print(f'Number of unique study labels:  {len(df_group[""study_label""].unique())}\n')
    print(df_group[['image_id', 'num_boxes', 'study_id', 'study_label']])
    plot_image(list(df_group['image_file']), size=(20, 10), title=list(df_group['image_id']), columns=8)    
train_files = sorted(glob.glob(os.path.join(base_path, 'train/*/*/*.dcm')))
print(f'Number of training files: {len(train_files)}')
df_image = pd.read_csv(os.path.join(base_path, 'train_image_level.csv'))
df_study = pd.read_csv(os.path.join(base_path, 'train_study_level.csv'))
df_study['study_label'] = df_study.apply(lambda r: ', '.join([df_study.columns[i] for i in range(1, 5) if r[i] > 0]), axis=1)

df_pairs, group_list = images_find_duplicates(train_files, threshold=0.95)
print(f'\nNumber of duplicate pairs: {len(df_pairs)}')
print(f'Number of duplicate groups: {len(group_list)}')df_group_list = []
df_pairs.to_csv('pairs.csv')

with open('duplicates.csv', 'w') as text_file:
    for i, group in enumerate(group_list):
        group_ids = [os.path.splitext(os.path.basename(file))[0] + '_image' for file in group]
        df_group_ids = pd.DataFrame({'id': group_ids, 'image_file': group})
        df_group = df_group_ids.merge(df_image, on='id').sort_values('id')
        df_group['study_id'] = df_group['StudyInstanceUID'] + '_study'
        df_group['num_boxes'] = df_group.apply(lambda r: len(string2boxes(r['label'])), axis=1)
        df_group = df_group.merge(df_study, left_on='study_id', right_on='id')
        df_group = df_group.rename(columns={'id_x': 'image_id'})
        df_group_list.append(df_group)
        text_file.write(','.join(group_ids) + '\n')for index, df_group in enumerate(df_group_list):
    if len(df_group[df_group['num_boxes'] > 0]) > 1:
        print_group_info(index, df_group)","This code imports the necessary packages for reading, processing and visualizing DICOM images, and defines a function for reading DICOM images from files. It also defines a function for finding duplicate images, and a function for printing information about duplicate image groups. Finally, it loops through all the duplicate image groups and prints information about those groups that contain at least one image with annotations.",9,0,0.1454912368151013
"import pandas as pd# train_df = pd.read_csv('/kaggle/input/siimcovid19-train-data-that-opacitycount-added/train_df.csv')
# local
train_df = pd.read_csv('/kaggle/input/siimcovid19-train-data-that-opacitycount-added/train_df.csv')train_df.head()train_df.drop(columns='Path', axis=1,inplace=True)train_df.head()train_df['Opacity'] = train_df.apply(lambda row : 1 if row.label.split(' ')[0]=='opacity' else 0, axis=1)
train_dftrain_df.drop(columns=['Unnamed: 0'], inplace=True)
train_df","This code imports the pandas library and reads in a CSV file containing training data. The data is then displayed using the head() method. The Path column is dropped from the dataframe, and the Opacity column is created, which contains a 1 for rows where the label indicates opacity. The dataframe is then displayed again.",8,2,0.049478902854596454
"!pip install -q efficientnet >> /dev/nullimport pandas as pd, numpy as np, random,os, shutil
from glob import glob
from kaggle_datasets import KaggleDatasets
import tensorflow as tf, re, math
import tensorflow.keras.backend as K
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt
import tensorflow_addons as tfa
print('tf:',tf.__version__)# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit
VERBOSE      = 1
DISPLAY_PLOT = True

DEVICE = ""TPU"" #or ""GPU""

# USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD
SEED = 42

# NUMBER OF FOLDS. USE 2, 5, 10
FOLDS = 5

# WHICH IMAGE SIZES TO LOAD EACH FOLD
# CHOOSE 128, 192, 256, 384, 512, 512 
IMG_SIZES = [[512, 512]]*FOLDS

# BATCH SIZE AND EPOCHS
BATCH_SIZES = [24]*FOLDS
EPOCHS      = [10]*FOLDS

# WHICH EFFICIENTNET B? TO USE
EFF_NETS = [6]*FOLDS

# Augmentations
AUGMENT   = True
TRANSFORM = True

# transformations
ROT_    = 0.0
SHR_    = 2.0
HZOOM_  = 8.0
WZOOM_  = 8.0
HSHIFT_ = 8.0
WSHIFT_ = 8.0

# Dropout
PROBABILITY = 0.75
CT          = 8
SZ          = 0.08

#bri, contrast
sat  = (0.7, 1.3)
cont = (0.8, 1.2)
bri  =  0.1

# WEIGHTS FOR FOLD MODELS WHEN PREDICTING TEST
WGTS = [1/FOLDS]*FOLDS

# TEST TIME AUGMENTATION STEPS
TTA = 1def seeding(SEED):
    np.random.seed(SEED)
    random.seed(SEED)
    os.environ['PYTHONHASHSEED'] = str(SEED)
    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)
    tf.random.set_seed(SEED)
    print('seeding done!!!')
seeding(SEED)if DEVICE == ""TPU"":
    print(""connecting to TPU..."")
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        print('Running on TPU ', tpu.master())
    except ValueError:
        print(""Could not connect to TPU"")
        tpu = None

    if tpu:
        try:
            print(""initializing  TPU ..."")
            tf.config.experimental_connect_to_cluster(tpu)
            tf.tpu.experimental.initialize_tpu_system(tpu)
            strategy = tf.distribute.experimental.TPUStrategy(tpu)
            print(""TPU initialized"")
        except _:
            print(""failed to initialize TPU"")
    else:
        DEVICE = ""GPU""

if DEVICE != ""TPU"":
    print(""Using default strategy for CPU and single GPU"")
    strategy = tf.distribute.get_strategy()

if DEVICE == ""GPU"":
    print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
    

AUTO     = tf.data.experimental.AUTOTUNE
REPLICAS = strategy.num_replicas_in_sync
print(f'REPLICAS: {REPLICAS}')GCS_PATH = [None]*FOLDS
for i,k in enumerate(IMG_SIZES):
    GCS_PATH[i] = KaggleDatasets().get_gcs_path('siimcovid19-%ix%i-tfrec-dataset'%(k[0],k[1]))
files_train = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/train*.tfrec')))
files_test  = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/test*.tfrec')))
num_train_files = len(files_train)
num_test_files  = len(files_test)
print('train_files:',num_train_files)
print('test_files:',num_test_files)train_df = pd.read_csv('../input/siim-covid19-yolov5-2class-labels/meta.csv')
train_df.head(2)","This code installs the efficientnet package and imports pandas, numpy, random, os, and shutil. It also imports the KaggleDatasets class from the kaggle_datasets package. Finally, it sets VERBOSE to 1 and DEVICE to ""TPU"".

The code then defines a seeding function that sets the seed for the random number generator, os, and tf. Next, the code calls the seeding function with the value 42.

If DEVICE is set to ""TPU"", the code attempts to connect to a TPU server and initialize the TPU system. If this fails, it sets DEVICE to ""GPU"".

The code then prints the number of GPUs available and sets AUTO, REPLICAS, and GCS_PATH. Finally, it reads in the train and test meta data from the siim-covid19-yolov5-2class-labels dataset.",8,10,0.1759637120418362
"%cd ../
!mkdir tmp
%cd tmp# Download YOLOv5
!git clone https://github.com/ultralytics/yolov5  # clone repo
%cd yolov5
# Install dependencies
%pip install -qr requirements.txt  # install dependencies

%cd ../
import torch
print(f""Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})"")# Install W&B 
!pip install -q --upgrade wandb
# Login 
import wandb
wandb.login()# Necessary/extra dependencies. 
import os
import gc
import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm
from shutil import copyfile
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

#customize iPython writefile so we can write variables
from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))TRAIN_PATH = 'input/siim-covid19-resized-to-256px-jpg/train/'
IMG_SIZE = 256
BATCH_SIZE = 16
EPOCHS = 10# Everything is done from /kaggle directory.
%cd ../

# Load image level csv file
df = pd.read_csv('input/siim-covid19-detection/train_image_level.csv')

# Modify values in the id column
df['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)
# Add absolute path
df['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)
# Get image level labels
df['image_level'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)

df.head(5)# Load meta.csv file
# Original dimensions are required to scale the bounding box coordinates appropriately.
meta_df = pd.read_csv('input/siim-covid19-resized-to-256px-jpg/meta.csv')
train_meta_df = meta_df.loc[meta_df.split == 'train']
train_meta_df = train_meta_df.drop('split', axis=1)
train_meta_df.columns = ['id', 'dim0', 'dim1']

train_meta_df.head(2)","This code is for the SIIM-ACR Pneumothorax Segmentation competition on Kaggle.

The code downloads the YOLOv5 repository from GitHub and installs the necessary dependencies. It then loads the image level csv file and the meta.csv file.

The image level csv file is used to get the image level labels. The meta.csv file is used to get the original dimensions of the images.

The code then splits the data into training and testing sets and trains the model.",8,4,0.13555793974183233
"# Importing Required packages
import os
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from IPython.display import Image, clear_output
print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))
clear_output()#customize iPython writefile so we can write variables
from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))# Cloning the repo and installing requiements
!git clone https://github.com/ultralytics/yolov5.git
!mv ./yolov5/* ./
!pip install -r requirements.txt
clear_output()# Copying the dataset to working directory
!mkdir Dataset
!cp ../input/covid19-detection-for-yolov5-siimfisabiorsna/Covid19 -r ./Dataset
clear_output()len(os.listdir('./Dataset/Covid19/images'))%%writetemplate ./split_dataset.py
from utils.datasets import * 
autosplit('./Dataset/Covid19', weights=(0.8, 0.2, 0.0))!python split_dataset.py","This code imports the necessary packages for the project, including torch, numpy, pandas, matplotlib, and IPython. It also sets up the environment for using PyTorch on a CUDA-enabled device.

Next, the code defines a function for writing template files. This function takes as input a filename and template string, and writes the template string to the specified file.

Finally, the code clones the yolov5 repository from GitHub, installs the required packages, and copies the dataset to the working directory.",8,3,0.1812783126140183
"! conda install -c conda-forge gdcm -y# import numpy as np # linear algebra
# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
# import os
# import pydicom
# import glob
# from tqdm.notebook import tqdm
# from pydicom.pixel_data_handlers.util import apply_voi_lut
# import matplotlib.pyplot as plt
# from skimage import exposure
# import cv2
# import warnings
# from fastai.vision.all import *
# from fastai.medical.imaging import *
# warnings.filterwarnings('ignore')

import os
import pydicom
import glob
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt 
dataset_path = '../input/siim-covid19-detection/'

for path in glob.glob(dataset_path  + '*'):
    print(path)train_images = '../input/siim-covid19-detection/train/'

n_folders = len(glob.glob(train_images  + '*'))
n_subfolders = len(glob.glob(train_images  + '*/*'))
n_images = len(glob.glob(train_images  + '*/*/*.dcm'))

print(f'There are {n_subfolders} subfolders in {n_folders} folders.')
print(f'There are altogether {n_images} images.')folders = glob.glob(train_images  + '*')

subfolder_dict = {}

for folder in folders:
    n = len(glob.glob(folder + '/*'))
    if n in subfolder_dict.keys():
        subfolder_dict[n] += 1
    else:
        subfolder_dict[n] = 1
        
for k, v in subfolder_dict.items():
    print(f'There is {v} subfolders with {k} images.')

subfolders = glob.glob(train_images  + '*/*')

image_dict = {}

for subfolder in subfolders:
    n = len(glob.glob(subfolder + '/*'))
    if (n!=1):
        print (subfolder.split('/')[-1])
        for image in glob.glob(subfolder + '/*'):
            print ('-->' + image.split('/')[-1])

    if n in image_dict.keys():
        image_dict[n] += 1
    else:
        image_dict[n] = 1
        
for k, v in image_dict.items():
    print(f'There is {v} subfolders with {k} images.')
train_study_df = pd.read_csv(dataset_path +'/train_study_level.csv')

train_study_df","This code imports the necessary libraries for working with the dataset, defines the path to the dataset, and then counts the number of folders, subfolders, and images in the dataset. It also prints out the number of subfolders and images in each folder. Finally, it loops through the subfolders and prints out any that have more than one image.",8,0,0.0666035419784199
"import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import glob
import pydicomsiim_covid19_dir = os.path.join(
    '..', 'input', 'siim-covid19-detection')def read_csv(file_name):
    file_path = os.path.join(siim_covid19_dir, file_name)
    df = pd.read_csv(file_path)
    return dfstudy_level_df = read_csv('train_study_level.csv')

study_level_df# How many rows?
study_level_num_rows = len(study_level_df)

study_level_num_rows# Are unique? Any duplicates?
study_level_num_unique_ids = len(pd.unique(study_level_df['id']))

if study_level_num_unique_ids == study_level_num_rows:
    print(""Unique and no duplicates"")
else:
    print(""Some duplicates"")# What are the unique value combinations? How many of them?
study_level_label_colums = [
    'Negative for Pneumonia', 'Typical Appearance',
    'Indeterminate Appearance', 'Atypical Appearance' ]
study_level_labels_df = study_level_df[study_level_label_colums]
study_level_label_values = study_level_labels_df.values

study_level_unique_label_combinations, \
study_level_unique_label_counts = \
    np.unique(
        study_level_label_values, return_counts=True, axis=0)

print(""Unique Combinations:\n"", study_level_unique_label_combinations)
print(""Unique Counts:\n"", study_level_unique_label_counts)","The code reads in a CSV file containing information on studies related to COVID-19. It then calculates the number of unique rows and determines whether there are any duplicates. Finally, it calculates the unique combinations of values in the label columns and counts them.",8,0,0.159236333500205
"# Libraries
import warnings
warnings.filterwarnings('ignore')

import os
import numpy as np
import pandas as pd
import seaborn as sns
import glob
from pandas import DataFrame
from matplotlib.lines import Line2D
import matplotlib.pyplot as plt
%matplotlib inline
import plotly.express as px
from tqdm.notebook import tqdm

# Image processing and Computer Vision
from skimage import exposure
import cv2
# Package designed to manipulate data elements in DICOM files 

import pydicom
#Image Transformation
from pydicom.pixel_data_handlers.util import apply_voi_lut

from fastai.vision.all import *
from fastai.medical.imaging import *

#train_image
train_image_df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
train_image_df.head(2)#train_study
train_study_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
train_study_df.head()# Bar plot function defination
def viz_bar_plot(df,x,x_title,y,title,colors=None,text=None):
    fig = px.bar(x=x,
                 y=y,
                 text=text,
                 labels={x: x_title.title()},   
                 data_frame=df,
                 color=colors,
                 barmode='group',
                 template=""simple_white"")
    texts = [df[col].values for col in y]
    for i, t in enumerate(texts):
        fig.data[i].text = t
        fig.data[i].textposition = 'inside'  
    fig['layout'].title=title
    fig.update_layout(title_font_size=19)
    fig.update_layout(title_font_family='Droid Serif')
    fig.update_layout(width=800,height=500)
    for trace in fig.data:
        trace.name = trace.name.replace('_',' ').title()
    fig.update_yaxes(tickprefix="""", showgrid=True)
    fig.show()# Study Data
# create 'target' column in train_study_df dataset
train_study_df['target']='Negative for Pneumonia'
train_study_df.loc[train_study_df['Typical Appearance']==1,'target']='Typical Appearance'
train_study_df.loc[train_study_df['Indeterminate Appearance']==1,'target']='Indeterminate Appearance'
train_study_df.loc[train_study_df['Atypical Appearance']==1,'target']='Atypical Appearance'
train_study_df1=train_study_df.groupby(['target']).size().reset_index(name='counts')
train_study_df1# Bar Visulaization of label categories
viz_bar_plot(train_study_df1,
         'target',
         'target',
         ['counts'],
         title='Target Label Count')","The code above imports the necessary libraries for data analysis and visualization, then loads the training data from two CSV files. Next, it defines a function for visualizing data in a bar chart. Finally, it groups the training data by the target label and visualizes the counts of each label category.",8,0,0.11743206675432839
"! conda install -c conda-forge gdcm -yimport numpy as np
import pandas as pd 
import os
from PIL import Image
from tqdm.auto import tqdm
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import seaborn as sns
from pandas_profiling import ProfileReport
from glob import glob
from tqdm.notebook import tqdm
import matplotlib.pyplot as plt
from skimage import exposure
import cv2
import warnings
import albumentations as A# config params
class CFG:
    data_path = '../input/siim-covid19-detection/'
    size = 512
    seed = 2021
    working_dir = '/kaggle/working/'def dicom2array(path, voi_lut=True, fix_monochrome=True):
    dicom = pydicom.read_file(path)
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
    return data
        
    
def plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()
# storage file for the transformed images
!mkdir train# prepare a dataframe for producing resized images with bboxes
xtrain_img = pd.read_csv(CFG.data_path + 'train_image_level.csv')


path_list = []
image_list = []
splits = []

for split in ['train']:
    
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            fullpath = dirname + '/' + file
            path_list.append(fullpath)
            image_list.append(file)

df = pd.DataFrame(image_list, columns =['image_id'])
df['image_path'] = path_list

xtrain_img['image_id'] = xtrain_img['id'].apply(lambda s: s.replace('_image','') + '.dcm')
xtrain_img = pd.merge(left = xtrain_img, right = df, on = 'image_id')
# common transformation we shall use
transform = A.Compose(
    [
        A.Resize(height = CFG.size , width = CFG.size, p=1),
    ], 
    p=1.0,  bbox_params=A.BboxParams( format='pascal_voc', min_area=0,  min_visibility=0, label_fields=['labels']  ))        

img_list = []
label_list = []

# loop over files
for ii in range(len(xtrain_img)):
    # get the image
    row = xtrain_img.loc[ii]
    img_path = row['image_path']
    img = dicom2array(path=img_path)
    newname = img_path.split('/')[-1].replace('dcm', 'jpg')
    img_list.append(newname)
    
    # get the bounding boxes
    bboxes = []
    bbox = []
    labels = []
    confidences = []

    for i, l in enumerate(row['label'].split(' ')):
        if (i % 6 == 0) :
            labels.append(l)
        if (i % 6 == 1):
            confidences.append(l)
        if (i % 6 > 1):
            bbox.append(np.clip(float(l), a_min = 0, a_max = None ))
        if i % 6 == 5:
            bboxes.append(bbox)
            bbox = []    

    # transform both
    result = transform(image = img, bboxes = bboxes, labels = np.ones(len(bboxes)))
    new_image = result['image']
    new_bboxes = np.array(result['bboxes']).tolist()

    # format the output
#    print('orig label: ' + row['label'])
    newlabel = ''
    if labels[0] == 'none':
        newlabel = 'none 1 0 0 1 1'
    else:
        for j in range(len(labels)):
            newlabel += labels[j] + ' ' + confidences[j] + ' ' +  ' '.join([str(np.round(f,5)) for f in new_bboxes[0]]) + ' '
#    print('new label:' + newlabel)
    label_list.append(newlabel)
    
    # store the new image
    cv2.imwrite(CFG.working_dir + 'train/' + newname , new_image)",This code is for preparing training data for a covid19 detection model. It reads in dicom images and transforms them into jpg images with bounding boxes around areas of interest.,8,3,0.1521711736830122
"!wget 'https://anaconda.org/conda-forge/libjpeg-turbo/2.1.0/download/linux-64/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/libgcc-ng/9.3.0/download/linux-64/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/gdcm/2.8.9/download/linux-64/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/conda/4.10.1/download/linux-64/conda-4.10.1-py37h89c1867_0.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/certifi/2020.12.5/download/linux-64/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/openssl/1.1.1k/download/linux-64/openssl-1.1.1k-h7f98852_0.tar.bz2' -q","The above code downloads the following packages from Anaconda:

- libjpeg-turbo
- libgcc-ng
- gdcm
- conda
- certifi
- openssl

Each package is downloaded as a .tar.bz2 file. The code uses the 'wget' command to download the files, and the '-q' option tells wget to run in quiet mode (i.e. to not output any status messages).",8,8,0.17424733717818536
"! conda install gdcm -c conda-forge -y! pip install --no-deps '../input/timm-package/timm-0.1.26-py3-none-any.whl' > /dev/null
! pip install --no-deps '../input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl' > /dev/nullimport sys
sys.path.insert(0, ""../input/timm-efficientdet-pytorch"")
sys.path.insert(0, ""../input/omegaconf"")

import os
from PIL import Image
import pandas as pd
from tqdm.auto import tqdm
import numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import torch
from datetime import datetime
import time
import random
import cv2
import albumentations as A
import matplotlib.pyplot as plt
from albumentations.pytorch.transforms import ToTensorV2
from sklearn.model_selection import StratifiedKFold
from torch.utils.data import Dataset,DataLoader
from torch.utils.data.sampler import SequentialSampler, RandomSampler
from glob import glob

SEED = 42

def seed_everything(seed):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = True

seed_everything(SEED)dataset_path = ""../input/siim-covid19-detection""def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return data

def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im
        
    
def plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()
%%time
image_id = []


cnt_img = 0 # for testing

for split in ['test', 'train']:
    save_dir = f'/kaggle/tmp/{split}/'

    os.makedirs(save_dir, exist_ok=True)
    
    for dirname, _, filenames in tqdm(os.walk(f'{dataset_path}/{split}')):
        for file in filenames:
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(os.path.join(dirname, file))
            im = resize(xray, size=256)  
            im.save(os.path.join(save_dir, file.replace('dcm', 'jpg')))

            image_id.append(file.replace('.dcm', ''))

            splits.append(split)
        
        if cnt_img >= 10:
            cnt_img = 0
            break
        
        cnt_img += 1
            image_id","This code reads in a DICOM image, applies a VOI LUT (if available), transforms the raw data to a ""human-friendly"" view, and then resizes the image to 256x256. The resulting image is saved as a JPEG.",8,1,0.1724425529729831
"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -yimport os

from PIL import Image
import pandas as pd
from tqdm.auto import tqdmimport numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im
split = 'test'
save_dir = f'/kaggle/tmp/{split}/'

os.makedirs(save_dir, exist_ok=True)

save_dir = f'/kaggle/tmp/{split}/study/'
os.makedirs(save_dir, exist_ok=True)

for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
    for file in filenames:
        # set keep_ratio=True to have original aspect ratio
        xray = read_xray(os.path.join(dirname, file))
        im = resize(xray, size=600)  
        study = dirname.split('/')[-2] + '_study.png'
        im.save(os.path.join(save_dir, study))
import numpy as np 
import pandas as pd

df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
id_laststr_list  = []
for i in range(df.shape[0]):
    id_laststr_list.append(df.loc[i,'id'][-1])
df['id_last_str'] = id_laststr_list

study_len = df[df['id_last_str'] == 'y'].shape[0]!pip install /kaggle/input/kerasapplications -q
!pip install /kaggle/input/efficientnet-keras-source-code/ -q --no-deps

import os

import efficientnet.tfkeras as efn
import numpy as np
import pandas as pd
import tensorflow as tf

def auto_select_accelerator():
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        tf.config.experimental_connect_to_cluster(tpu)
        tf.tpu.experimental.initialize_tpu_system(tpu)
        strategy = tf.distribute.experimental.TPUStrategy(tpu)
        print(""Running on TPU:"", tpu.master())
    except ValueError:
        strategy = tf.distribute.get_strategy()
    print(f""Running on {strategy.num_replicas_in_sync} replicas"")

    return strategy


def build_decoder(with_labels=True, target_size=(300, 300), ext='jpg'):
    def decode(path):
        file_bytes = tf.io.read_file(path)
        if ext == 'png':
            img = tf.image.decode_png(file_bytes, channels=3)
        elif ext in ['jpg', 'jpeg']:
            img = tf.image.decode_jpeg(file_bytes, channels=3)
        else:
            raise ValueError(""Image extension not supported"")

        img = tf.cast(img, tf.float32) / 255.0
        img = tf.image.resize(img, target_size)

        return img

    def decode_with_labels(path, label):
        return decode(path), label

    return decode_with_labels if with_labels else decode


def build_augmenter(with_labels=True):
    def augment(img):
        img = tf.image.random_flip_left_right(img)
        img = tf.image.random_flip_up_down(img)
        return img

    def augment_with_labels(img, label):
        return augment(img), label

    return augment_with_labels if with_labels else augment


def build_dataset(paths, labels=None, bsize=32, cache=True,
                  decode_fn=None, augment_fn=None,
                  augment=True, repeat=True, shuffle=1024, 
                  cache_dir=""""):
    if cache_dir != """" and cache is True:
        os.makedirs(cache_dir, exist_ok=True)

    if decode_fn is None:
        decode_fn = build_decoder(labels is not None)

    if augment_fn is None:
        augment_fn = build_augmenter(labels is not None)

    AUTO = tf.data.experimental.AUTOTUNE
    slices = paths if labels is None else (paths, labels)

    dset = tf.data.Dataset.from_tensor_slices(slices)
    dset = dset.map(decode_fn, num_parallel_calls=AUTO)
    dset = dset.cache(cache_dir) if cache else dset
    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset
    dset = dset.repeat() if repeat else dset
    dset = dset.shuffle(shuffle) if shuffle else dset
    dset = dset.batch(bsize).prefetch(AUTO)

    return dset

#COMPETITION_NAME = ""siim-cov19-test-img512-study-600""
strategy = auto_select_accelerator()
BATCH_SIZE = strategy.num_replicas_in_sync * 16

IMSIZE = (224, 240, 260, 300, 380, 456, 528, 600)

#load_dir = f""/kaggle/input/{COMPETITION_NAME}/""
sub_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
sub_df = sub_df[:study_len]
test_paths = f'/kaggle/tmp/{split}/study/' + sub_df['id'] +'.png'

sub_df['negative'] = 0
sub_df['typical'] = 0
sub_df['indeterminate'] = 0
sub_df['atypical'] = 0


label_cols = sub_df.columns[2:]

test_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[7], IMSIZE[7]), ext='png')
dtest = build_dataset(
    test_paths, bsize=BATCH_SIZE, repeat=False, 
    shuffle=False, augment=False, cache=False,
    decode_fn=test_decoder
)

with strategy.scope():
    
    models = []
    
    models0 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model0.h5'
    )
    models1 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model1.h5'
    )
    models2 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model2.h5'
    )
    models3 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model3.h5'
    )
    models4 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model4.h5'
    )
    
    models.append(models0)
    models.append(models1)
    models.append(models2)
    models.append(models3)
    models.append(models4)

    
    
    
sub_df[label_cols] = sum([model.predict(dtest, verbose=1) for model in models]) / len(models)","This code installs the pydicom conda helper library, which allows for the conversion of DICOM files to numpy arrays. It also installs the libjpeg-turbo, libgcc-ng, and gdcm libraries, which are required for pydicom functionality. Finally, it installs the conda, certifi, and openssl libraries, which are required for conda functionality.

This code reads in a DICOM file, applies a VOI LUT if one is available, and transforms the raw DICOM data into a ""human-friendly"" view. It also fixes monochrome inversion if necessary.

This code resizes an image to the specified size.

This code splits the sample submission CSV file into two parts - one for studies and one for images. It then generates a list of image IDs for the studies.

This code installs the Keras Applications and EfficientNet Keras Source Code libraries, which are required for the EfficientNet model.

This code automatically selects an accelerator (TPU or CPU) for training.

This code builds a dataset from a list of paths and labels. It decodes the images using the build_decoder function, and applies augmentation if specified.",8,15,0.12936856316785225
"SEED  = 42
FOLDS = 5
DIM   = 512import numpy as np 
import pandas as pd 
import os, shutil
from glob import glob
from sklearn.cluster import KMeans
from tqdm.notebook import tqdm
from sklearn.preprocessing import LabelEncoder
import random
tqdm.pandas()np.random.seed(SEED)
random.seed(SEED)train_df = pd.read_csv(f'../input/siimcovid19-{DIM}-jpg-image-dataset/train.csv')
train_df['image_path'] = F'../input/siimcovid19-{DIM}-jpg-image-dataset/train/'+train_df.image_id+'.jpg'
train_df.head(2)name2label = {'Typical Appearance': 3,
 'Indeterminate Appearance': 1,
 'Atypical Appearance': 2,
 'Negative for Pneumonia': 0}
class_names = list(name2label.keys())
label2name = {v:k for k, v in name2label.items()}
train_df['class_name']  = train_df.progress_apply(lambda row:row[class_names].iloc[[row[class_names].values.argmax()]].index.tolist()[0], axis=1)
train_df['class_label'] = train_df.class_name.map(name2label)
train_df.head()from sklearn.model_selection import GroupKFold, StratifiedKFold
gkf  = GroupKFold(n_splits = 5)
train_df['fold'] = -1
for fold, (train_idx, val_idx) in enumerate(gkf.split(train_df, groups = train_df.StudyInstanceUID.tolist())):
    train_df.loc[val_idx, 'fold'] = fold
train_df.head()import matplotlib.pyplot as plt
import cv2
def load_image(path, dim=DIM, ch=3):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE if ch==None else cv2.IMREAD_COLOR)
    if img.shape[:2]!=(dim,dim) and dim!=-1:
        img = cv2.resize(img, dsize=(dim,dim), interpolation=cv2.INTER_AREA)
    return img

plt.imshow(load_image(train_df.image_path.iloc[100], dim=-1))","This code loads an image from a given path and resizes it to the specified dimensions. If no dimensions are specified, the image will be loaded at its original size.",8,0,0.043445074862025736
"# !conda install -c conda-forge imagehash --yes%load_ext autoreload
%autoreload 2
%matplotlib inline

import glob
import itertools
import collections

from PIL import Image
import cv2
from tqdm import tqdm_notebook as tqdm
import pandas as pd
import numpy as np
import torch
import imagehash

import matplotlib.pyplot as plt

def run():

    funcs = [
        imagehash.average_hash,
        imagehash.phash,
        imagehash.dhash,
        imagehash.whash,
        #lambda x: imagehash.whash(x, mode='db4'),
    ]

    SOPInstanceUIDs = []
    hashes = []
    for path in tqdm(glob.glob('../input/siim-covid19-resized-to-512px-png/*/*.png')):

        image = Image.open(path)
        imageid = path.split('/')[-1].split('.')[0]

        SOPInstanceUIDs.append(imageid)
        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))

    return SOPInstanceUIDs, np.array(hashes)

%time SOPInstanceUIDs, hashes_all = run()

hashes_all = torch.Tensor(hashes_all.astype(int)).cuda()%time sims = np.array([(hashes_all[i] == hashes_all).sum(dim=1).cpu().numpy()/256 for i in range(hashes_all.shape[0])])
indices1 = np.where(sims > 0.99)
indices2 = np.where(indices1[0] != indices1[1])
SOPInstanceUID1 = [SOPInstanceUIDs[i] for i in indices1[0][indices2]]
SOPInstanceUID2 = [SOPInstanceUIDs[i] for i in indices1[1][indices2]]
dups = {tuple(sorted([SOPInstanceUID1,SOPInstanceUID2])):True for SOPInstanceUID1, SOPInstanceUID2 in zip(SOPInstanceUID1, SOPInstanceUID2)}
print('found %d duplicates' % len(dups))dups",This code uses the imagehash library to generate hashes for images in a given directory. These hashes are then used to identify duplicate images.,8,1,0.11958493964377831
"!pip install gdcmimport os
from os import listdir
import pandas as pd
import numpy as np
import glob
from skimage import exposure
import matplotlib.pyplot as plt
%matplotlib inline

# pydicom
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
from fastai.imports import *
from fastai.medical.imaging import *

import cv2

# color
from colorama import Fore, Back, Style

import seaborn as sns
sns.set(style=""whitegrid"")

# plotly
import plotly.express as px
import plotly

# Suppress warnings 
import warnings
warnings.filterwarnings('ignore')

# Settings for pretty nice plots
plt.style.use('fivethirtyeight')
plt.show()# List files available
list(os.listdir(""../input/siim-covid19-detection""))IMAGE_PATH = ""../input/siim-covid19-detection/""

train_study_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
train_image_df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')

print(Fore.YELLOW + 'Train study df shape: ',Style.RESET_ALL,train_study_df.shape)
print(Fore.YELLOW + 'Train image df shape: ',Style.RESET_ALL,train_image_df.shape)display(train_study_df.head(5))
display(train_image_df.head(5))sample_submission = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
print(Fore.YELLOW + 'Sample submission df shape: ',Style.RESET_ALL,sample_submission.shape)
display(sample_submission)# Null values and Data types
print(Fore.BLUE + 'Train Study Set !!',Style.RESET_ALL)
print(train_study_df.info())
print('-------------')
print(Fore.YELLOW + 'Train Image Set !!',Style.RESET_ALL)
print(train_image_df.info())","This code is for the SIIM-ACR COVID-19 detection competition on Kaggle. It imports the necessary libraries, reads in the data, and then displays some basic information about the dataframes.",8,3,0.03762314852572581
"!pip install -q efficientnet >> /dev/nullimport pandas as pd, numpy as np, random,os, shutil
from glob import glob
from kaggle_datasets import KaggleDatasets
import tensorflow as tf, re, math
import tensorflow.keras.backend as K
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt
import tensorflow_addons as tfa
print('tf:',tf.__version__)# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit
VERBOSE      = 0
DISPLAY_PLOT = True

DEVICE = ""TPU"" #or ""GPU""

# USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD
SEED = 42

# NUMBER OF FOLDS. USE 2, 5, 10
FOLDS = 5

# WHICH IMAGE SIZES TO LOAD EACH FOLD
# CHOOSE 128, 192, 256, 384, 512, 512 
IMG_SIZES = [[512, 512]]*FOLDS

# BATCH SIZE AND EPOCHS
BATCH_SIZES = [16]*FOLDS
EPOCHS      = [12]*FOLDS

# WHICH EFFICIENTNET B? TO USE
EFF_NETS = [7]*FOLDS

# Augmentations
AUGMENT   = True
TRANSFORM = True

# transformations
ROT_    = 0.0
SHR_    = 2.0
HZOOM_  = 8.0
WZOOM_  = 8.0
HSHIFT_ = 8.0
WSHIFT_ = 8.0

# Dropout
PROBABILITY = 0.75
CT          = 8
SZ          = 0.08

#bri, contrast
sat  = (0.7, 1.3)
cont = (0.8, 1.2)
bri  =  0.1

# WEIGHTS FOR FOLD MODELS WHEN PREDICTING TEST
WGTS = [1/FOLDS]*FOLDS

# TEST TIME AUGMENTATION STEPS
TTA = 1def seeding(SEED):
    np.random.seed(SEED)
    random.seed(SEED)
    os.environ['PYTHONHASHSEED'] = str(SEED)
    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)
    tf.random.set_seed(SEED)
    print('seeding done!!!')
seeding(SEED)if DEVICE == ""TPU"":
    print(""connecting to TPU..."")
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        print('Running on TPU ', tpu.master())
    except ValueError:
        print(""Could not connect to TPU"")
        tpu = None

    if tpu:
        try:
            print(""initializing  TPU ..."")
            tf.config.experimental_connect_to_cluster(tpu)
            tf.tpu.experimental.initialize_tpu_system(tpu)
            strategy = tf.distribute.experimental.TPUStrategy(tpu)
            print(""TPU initialized"")
        except _:
            print(""failed to initialize TPU"")
    else:
        DEVICE = ""GPU""

if DEVICE != ""TPU"":
    print(""Using default strategy for CPU and single GPU"")
    strategy = tf.distribute.get_strategy()

if DEVICE == ""GPU"":
    print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
    

AUTO     = tf.data.experimental.AUTOTUNE
REPLICAS = strategy.num_replicas_in_sync
print(f'REPLICAS: {REPLICAS}')GCS_PATH = [None]*FOLDS
for i,k in enumerate(IMG_SIZES):
    GCS_PATH[i] = KaggleDatasets().get_gcs_path('siimcovid19-%ix%i-tfrec-dataset'%(k[0],k[1]))
files_train = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/train*.tfrec')))
files_test  = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/test*.tfrec')))
num_train_files = len(files_train)
num_test_files  = len(files_test)
print('train_files:',num_train_files)
print('test_files:',num_test_files)train_df = pd.read_csv('../input/siim-covid19-yolov5-2class-labels/meta.csv')
train_df.head(2)","This code loads the Siim-Covid19 dataset from Kaggle. The dataset contains images of X-rays of patients with Covid-19. The code then splits the dataset into training and testing sets, and then uses a KFold cross-validation to train and evaluate the model. Finally, the code saves the model weights to a file.",8,2,0.03877782615477956
"import pandas as pd df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')dfid_laststr_list  = []
for i in range(df.shape[0]):
    id_laststr_list.append(df.loc[i,'id'][-1])
df['id_last_str'] = id_laststr_liststudy_len = df[df['id_last_str'] == 'y'].shape[0]study_str = 'negative 1 0 0 1 1 atypical 1 0 0 1 1 typical 1 0 0 1 1 indeterminate 1 0 0 1 1'
for i in range(study_len):
    df.loc[i, 'PredictionString'] = study_strdf = df[['id', 'PredictionString']]","This code imports the pandas library and reads in a CSV file containing data on Covid-19 cases. It then creates a new column in the dataframe called 'id_last_str' which contains the last character of the 'id' column. The code then calculates the number of rows in the dataframe with 'id_last_str' equal to 'y' and stores this value in the 'study_len' variable. The code then creates a string called 'study_str' which contains the predicted values for each row in the dataframe. Finally, the code loops through each row in the dataframe and sets the 'PredictionString' column to the value in 'study_str'.",8,10,0.07172011432483168
"import numpy as np 
import pandas as pd 
import os
from tqdm import tqdm
import matplotlib.pyplot as plt
import pydicomtrain_st = pd.read_csv(""../input/siim-covid19-detection/train_study_level.csv"")
train_st.head(3)
train_im = pd.read_csv(""../input/siim-covid19-detection/train_image_level.csv"")
train_im.head(3)sample = pd.read_csv(""../input/siim-covid19-detection/sample_submission.csv"")
sample.head(3)train_path = ""../input/siim-covid19-detection/train""
test_path = ""../input/siim-covid19-detection/test""trainimlist = []

for dirname, _, filenames in os.walk(train_path):
    for filename in filenames:
        trainimlist.append(os.path.join(dirname, filename))testimlist = []

for dirname, _, filenames in os.walk(test_path):
    for filename in filenames:
        testimlist.append(os.path.join(dirname, filename))","This code imports the necessary libraries for working with the data, including NumPy, Pandas, and Matplotlib. It also sets up the path variables for the training and testing data. Finally, it creates two lists of filenames, one for the training data and one for the testing data.",9,0,0.06793103116716637
"import fastai
import fastai.medical
from fastai.basics import *
from fastai.vision.all import *
from fastai.medical.imaging import *

import pydicom

import pandas as pd
fastai.__version__!conda install -c conda-forge gdcm -yfilegroup='train'
path='../input/siim-covid19-detection'
dirName = f'{path}/{filegroup}/'# Get DICOM file list from train directory
items = get_dicom_files(dirName)df_trn = pd.DataFrame.from_dicoms(items,px_summ=False)
df_trn.to_csv(f'alldicom{filegroup}.csv')
df_trn.describe()
df_trnfilegroup='test'
dirName = f'{path}/{filegroup}/'","The code imports the fastai, fastai.medical, and pydicom libraries. It then defines a filegroup variable and sets its value to 'train'. Next, it creates a path variable and sets its value to '../input/siim-covid19-detection'. Finally, it sets the dirName variable to the value of the path variable plus the value of the filegroup variable.

The code then gets a list of DICOM files from the train directory and creates a Pandas DataFrame from them. It then saves the DataFrame to a CSV file. The code then describes the contents of the DataFrame.

The code then sets the filegroup variable to 'test' and repeats the process for the test directory.",8,11,0.11348357479781582
"import numpy as np 
import pandas as pd
import os
import matplotlib.pyplot as plt
import pydicom as dicom
from glob import glob
from pathlib import Path
from pydicom import dcmread
import matplotlib
import astStudy= pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')Study.describe()Study.head()Study.isnull().sum()image_level=pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')image_level.head()","This code imports the numpy, pandas, os, matplotlib, pydicom, and glob libraries, and then reads in the train_study_level.csv and train_image_level.csv files. The code then displays some basic information about the data, including the number of rows and columns, the data types of each column, and the number of null values in each column. Finally, the code displays the first five rows of data from each file.",8,4,0.047256811159724035
"#Attaullah
#attaullahshafiq10@gmail.com
# Import libs
!conda install gdcm -c conda-forge -y
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
import pydicom
import glob
from tqdm.notebook import tqdm
from pydicom.pixel_data_handlers.util import apply_voi_lut
import matplotlib.pyplot as plt
from skimage import exposure#import gdcm
import cv2
import warnings
from fastai.vision.all import *
from fastai.medical.imaging import *
warnings.filterwarnings('ignore')
dataset_path = Path('../input/siim-covid19-detection')
import vtk

from vtk.util import numpy_support

reader = vtk.vtkDICOMImageReader()#HTML view

from IPython.display import HTML
HTML('<iframe src=https://arxiv.org/pdf/1506.01497.pdf width=600 height=650></iframe>')# from https://www.kaggle.com/tanlikesmath/siim-covid-19-detection-a-simple-eda
def dicom2array(path, voi_lut=True, fix_monochrome=True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()


def plot_imgs(imgs, cols=4, size=7, is_rgb=True, title="""", cmap='gray', img_size=(500,500)):
    rows = len(imgs)//cols + 1
    fig = plt.figure(figsize=(cols*size, rows*size))
    for i, img in enumerate(imgs):
        if img_size is not None:
            img = cv2.resize(img, img_size)
        fig.add_subplot(rows, cols, i+1)
        plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()dicom_paths = get_dicom_files(dataset_path/'train')
print([str(path) for path in dicom_paths[:4]])
imgs = [dicom2array(str(path)) for path in dicom_paths[:4]]
plot_imgs(imgs)","This code imports the necessary libraries for working with DICOM files, including the pydicom library. It then defines a function for converting DICOM files to numpy arrays. This function takes a DICOM file path as input and returns a numpy array containing the DICOM data. The function also optionally applies a VOI LUT to the DICOM data, if one is available, and fixes monochrome inversions if necessary.

The code then defines a function for plotting DICOM images. This function takes a DICOM image as input and plots it using matplotlib. The function also optionally takes a title and color map as input.

Finally, the code defines a function for plotting multiple DICOM images. This function takes a list of DICOM images as input and plots them in a grid using matplotlib. The function also optionally takes a title and color map as input.",8,6,0.1532078945235002
"!pip install -q --upgrade wandb

import wandb
wandb.login()import os
import gc
import cv2
import ast
import numpy as np
import pandas as pd
from tqdm import tqdm
import matplotlib.pyplot as plt
%matplotlib inlineTRAIN_PATH = '../input/siim-covid19-resized-to-256px-jpg/train/'
IMG_SIZE = 256
NUM_SAMPLES_TO_VIZ = 32# Load image level csv file
df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
# Load study level csv file
label_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')

# Modify values in the id column
df['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)
# Add absolute path
df['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)
# Get image level labels
df['image_level'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)

# Modify values in the id column
label_df['id'] = label_df.apply(lambda row: row.id.split('_')[0], axis=1)
# Rename the column id with StudyInstanceUID
label_df.columns = ['StudyInstanceUID', 'Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']

# Merge both dataframes
df = df.merge(label_df, on='StudyInstanceUID',how=""left"")
df.head(2)print(f'Number of unique image in training dataset: {len(df)}')

bbox_nan_num = df['boxes'].isna().sum()
print(f'Number of images without any bbox annotation: {bbox_nan_num}')# Label encode study-level labels
labels = df[['Negative for Pneumonia','Typical Appearance','Indeterminate Appearance','Atypical Appearance']].values
labels = np.argmax(labels, axis=1)

df['study_level'] = labels
df.head(2)class_label_to_id = {
    'Negative for Pneumonia': 0,
    'Typical Appearance': 1,
    'Indeterminate Appearance': 2,
    'Atypical Appearance': 3
}

class_id_to_label = {val: key for key, val in class_label_to_id.items()}","This code installs the wandb library and then imports it. Next, the code loads two CSV files, one containing image-level labels and the other containing study-level labels. The code then modifies the values in the id column of both dataframes, and adds the absolute path to the image files. Finally, the code encodes the study-level labels and stores them in the 'study_level' column of the dataframe.",8,4,0.16106552897592422
"!conda install gdcm -c conda-forge -yimport os

from PIL import Image
import pandas as pd
from tqdm.auto import tqdmimport numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return imtrain = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')path = '../input/siim-covid19-detection/train/ae3e63d94c13/288554eb6182/e00f9fe0cce5.dcm'
dicom = pydicom.read_file(path)image_id = []
dim0 = []
dim1 = []
splits = []

for split in ['test', 'train']:
    save_dir = f'/kaggle/tmp/{split}/'

    os.makedirs(save_dir, exist_ok=True)
    
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(os.path.join(dirname, file))
            im = resize(xray, size=768)  
            im.save(os.path.join(save_dir, file.replace('dcm', 'jpg')))

            image_id.append(file.replace('.dcm', ''))
            dim0.append(xray.shape[0])
            dim1.append(xray.shape[1])
            splits.append(split)","This code reads in X-ray images from the DICOM format and converts them into JPEG images. The images are then resized to a standard size (768x768). The resulting images are saved in a separate directory for train and test images. Finally, the image ID, dimensions, and split (train or test) are recorded in a dataframe.",8,1,0.12190498060266496
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport sys
sys.path.append('../input/timm-pytorch-models/archive (3)/pytorch-image-models-master')
import timmimport numpy as np 
import pandas as pd 

import math
import random 
import os 
import cv2
import timm

from tqdm import tqdm 

import albumentations as A 
from albumentations.pytorch.transforms import ToTensorV2
import torch 
from torch.utils.data import Dataset 
from torch import nn
import torch.nn.functional as F 

import gc
import cudf
import cuml
import cupy
from cuml.feature_extraction.text import TfidfVectorizer
from cuml.neighbors import NearestNeighborsclass CFG:
    
    img_size = 512
    batch_size = 12
    seed = 2020
    
    device = 'cuda'
    classes = 11014
    
    model_name = 'eca_nfnet_l0'
    model_path = '../input/pytorch-model-weights/arcface_512x512_nfnet_l0 (mish).pt'
    
    scale = 30 
    margin = 0.5def read_dataset():
    df = pd.read_csv('../input/shopee-product-matching/test.csv')
    df_cu = cudf.DataFrame(df)#cuDF is a Python GPU DataFrame library workflow is fast enough on a single GPU fits in memory on a single GPU
    image_paths = '../input/shopee-product-matching/test_images/' + df['image']
    return df, df_cu, image_pathsdef seed_torch(seed=42):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    
seed_torch(CFG.seed)def get_image_predictions(df, embeddings,threshold = 0.0):
    
    if len(df) > 3:
        KNN = 50
    else : 
        KNN = 3
    
    model = NearestNeighbors(n_neighbors = KNN, metric = 'cosine')
    model.fit(embeddings)
    distances, indices = model.kneighbors(embeddings)
    
    predictions = []
    for k in tqdm(range(embeddings.shape[0])):
        idx = np.where(distances[k,] < threshold)[0]
        ids = indices[k,idx]
        posting_ids = df['posting_id'].iloc[ids].values
        predictions.append(posting_ids)
        
    del model, distances, indices
    gc.collect()
    return predictions","This function takes a dataframe, embeddings, and a threshold as input and returns a list of predictions. The predictions are based on the embeddings and the threshold. If the threshold is 0.0, then the predictions are based on the nearest neighbors of the embeddings. If the threshold is not 0.0, then the predictions are based on the embeddings that are within the threshold.",8,1,0.15105018033444412
"%%capture
!pip install ../input/pytorchimagemodelsimport sys
sys.path.append('../input/facebookdeit')import os
import gc
import sys

import math
import random

from tqdm.notebook import tqdm

import re

import cv2
import numpy as np
import pandas as pd

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset ,RandomSampler

import timm

import albumentations

from swav_resnet import resnet50w2

import transformers
from transformers import AutoModel, AutoTokenizer

from models import deit_base_distilled_patch16_224



import cudf
import cuml
import cupydef set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True

set_seed(0)text_models=[
    {
        'transformer_model': '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14',
        'model_path' : '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14/ckpt.pt',
        'MAX_LEN' : 128,
        'params' : {
            'embed_dim' :1024,
            'out_dim' : 11014
        }
        
    },
    {
            'transformer_model': '../input/shopee-bert-base-indonesian/bert-base-indonesian_pp_7_8',
            'model_path' : '../input/shopee-bert-base-indonesian/bert-base-indonesian_pp_7_8/ckpt.pt',
            'MAX_LEN' : 128,
            'params' : {
                'embed_dim' :1024,
                'out_dim' : 11014
            }

        }
]

TRANSFORMER_EMBED_DIM = 768joint_models=[
    {
        'transformer_model': '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14',
        'model_path' : '../input/deit-xlm-joint-weights/finetuned_deit_xlm_joint_7_11.pt',
        'MAX_LEN' : 128,
        'IMAGE_SIZE' : 224,
        'params' : {
                'embed_dim' : 2048,
                'out_dim' : 11014
            }
        
    }
]image_models=[
    {
        'vision_model': '../input/shopee-swav-finetuned-resnet50w2/swav_resnet50w2_224_2048_5_epochs_loss_12_beef.pt',
        'IMAGE_SIZE' : 224,
        'params' : {
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
    {
        'vision_model': '../input/effnet-weights/finetuned_tf_efficientnet_b3_ns_300_2048_7_9.pt',
        'IMAGE_SIZE' : 300,
        'params' : {
            'backbone_name' : 'tf_efficientnet_b3_ns',
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
    
    {
        'vision_model': '../input/deit-base-distilled-patch16-224/finetuned_deit_base_distilled_patch16_224_4_18.pt',
        'IMAGE_SIZE' : 224,
        'params' : {
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
]","This code defines three types of models: text, image, and joint. Text models are based on the transformer model, while image models are based on the resnet50w2 model. The joint model is a combination of the two.

Each model has a 'model_path' which is the path to the pretrained model weights. The 'MAX_LEN' parameter defines the maximum length of input text (in tokens). The 'params' dictionary contains model-specific parameters, such as the embedding dimension and output dimension.

The 'set_seed' function is used to set the random seed for reproducibility.

The 'text_models', 'image_models', and 'joint_models' lists contain the parameters for each type of model.",8,1,0.03799611947259283
"import sys
import gc
import math
import configparser
import numpy as np
import pandas as pd
import optuna
from tqdm import tqdm
import sklearn
import tensorflow as tf
from tensorflow import keras
from typing import Tupletry:
    # TPU detection. No parameters necessary if TPU_NAME environment variable is
    # set: this is always the case on Kaggle.
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
    print('Running on TPU ', tpu.master())
except ValueError:
    tpu = None

if tpu:
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.TPUStrategy(tpu)
else:
    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.
    strategy = tf.distribute.get_strategy()

print(""REPLICAS: "", strategy.num_replicas_in_sync)pd.set_option(""use_inf_as_na"", True)
pd.set_option(""display.max_columns"", 9999)
pd.set_option(""display.max_rows"", 9999)
pd.set_option('max_colwidth', 9999)
INPUT = '/kaggle/input'
DATA = f'{INPUT}/shopee-product-matching'
OUTPUT = '/kaggle/working'
RESOURCE_DIR = f'{INPUT}/shopee-product-matching-lib/kaggle-shopee-product-matching-1.0'
sys.path.append(f'{INPUT}/sgcharts-ml/src')
sys.path.append(f""{INPUT}/sentence-transformers/sentence-transformers-1.0.4"")
sys.path.append(f'{RESOURCE_DIR}/src')
import mylib
import scml
from scml.nlp import strip_punctuation, to_ascii_str
scml.seed_everything()MODEL = 'efficientnetb3'
CONF = configparser.ConfigParser()
CONF.read(f""{RESOURCE_DIR}/app.ini"")
resolution = int(CONF[MODEL][""resolution""])
INPUT_SHAPE = (resolution, resolution, 3)
print(f""INPUT_SHAPE={INPUT_SHAPE}"")train = pd.read_csv(f""{DATA}/train.csv"", engine=""c"", low_memory=False)
train[""target""] = mylib.target_label(train)
le = sklearn.preprocessing.LabelEncoder()
train[""label_group""] = le.fit_transform(train['label_group'])
n_classes=len(le.classes_)
print(f""n_classes={n_classes}"")
train.info()train.head()def _data_gen(
    dataframe,
    directory,
    target_size,
    batch_size,
    color_mode=""rgb"",
    class_mode=""raw"",
    x_col=""image"",
    y_col=""label_group""
):
    dtype = np.float32
    rescale = 1./255
    interpolation = ""bicubic""
    data_format = ""channels_last""
    shuffle = True
    idg = keras.preprocessing.image.ImageDataGenerator(
        shear_range=0.2,
        zoom_range=0.2,
        brightness_range=(0.7, 1.3),
        #rotation_range=90,
        horizontal_flip=True,
        rescale=rescale,
        data_format=data_format,
        dtype=dtype
    )
    g = idg.flow_from_dataframe(
        dataframe=dataframe,
        x_col=x_col,
        y_col=y_col,
        directory=directory,
        target_size=target_size,
        color_mode=color_mode,
        batch_size=batch_size,
        shuffle=shuffle,
        class_mode=class_mode,
        interpolation=interpolation,
    )
    while True:
        x, y = g.next()
        yield [x, y], y","This code defines a function that generates data for training a machine learning model. The function takes in a dataframe containing training data, a directory containing training images, target_size and batch_size parameters, and color_mode and class_mode parameters. The function returns a generator object that can be used to iterate over the training data.",8,1,0.06782044525928668
"import pip
try:
     __import__(""imutils"")
except ImportError:
    pip.main([""install"", ""imutils""])import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import  matplotlib.pyplot as plt
import tensorflow as tf
import pandas as pd
import cv2
from imutils.object_detection import non_max_suppression
import pytesseract
import os
import glob
os.chdir('/kaggle/working')
BASE = '../input/shopee-product-matching/train_images/'
EAST_PATH = ""/kaggle/input/east-data-leo/frozen_east_text_detection/frozen_east_text_detection.pb""
RESIZE_IMG_SHAPE = (500,500)
img_paths = glob.glob(f""{BASE}*jpg"") train = pd.read_csv('../input/shopee-product-matching/train.csv')
print('train shape is', train.shape )
train.head()groups = train.label_group.value_counts()
plt.figure(figsize=(20,5))
plt.plot(np.arange(len(groups)),groups.values)
plt.ylabel('Duplicate Count',size=14)
plt.xlabel('Index of Unique Item',size=14)
plt.title('Duplicate Count vs. Unique Item Count',size=16)
plt.show()

plt.figure(figsize=(20,5))
plt.bar(groups.index.values[:50].astype('str'),groups.values[:50])
plt.xticks(rotation = 45)
plt.ylabel('Duplicate Count',size=14)
plt.xlabel('Label Group',size=14)
plt.title('Top 50 Duplicated Items',size=16)
plt.show()def img_proc(img,offset =20):
    img =img[offset:-offset,offset:-offset]
    img =cv2.resize(img ,RESIZE_IMG_SHAPE)
    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    gray = cv2.medianBlur(gray,5)
    ret, thresh = cv2.threshold(gray,150,255,cv2.THRESH_BINARY)
    thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\
            cv2.THRESH_BINARY_INV,21,2)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))
    opening = cv2.erode(thresh,kernel, iterations = 1)
    closing = cv2.dilate(opening,kernel,iterations=1)
    contours = cv2.findContours(closing, 
                            cv2.RETR_EXTERNAL,
                            cv2.CHAIN_APPROX_NONE)
    canvas =np.zeros((500,500))
    cv2.drawContours(canvas, contours[0], -1, (255,0,255), thickness = 2) 
    return canvas



def displayDF(train, random=False, COLS=6, ROWS=4, path=BASE):
    for k in range(ROWS):
        plt.figure(figsize=(20,5))
        for j in range(COLS):
            if random: row = np.random.randint(0,len(train))
            else: row = COLS*k + j
            name = train.iloc[row,1]
            title = train.iloc[row,3]
            title_with_return = """"
            for i,ch in enumerate(title):
                title_with_return += ch
                if (i!=0)&(i%20==0): title_with_return += '\n'
            img = img_proc(cv2.imread(path+name))
            plt.subplot(1,COLS,j+1)
            plt.title(title_with_return)
            plt.axis('off')
            plt.imshow(img)
        plt.show()
        
displayDF(train,random=True)def predictions(prob_score, geo,min_conf):
    (numR, numC) = prob_score.shape[2:4]
    boxes = []
    confidence_val = []
    for y in range(0, numR):
        scoresData = prob_score[0, 0, y]
        x0 = geo[0, 0, y]
        x1 = geo[0, 1, y]
        x2 = geo[0, 2, y]
        x3 = geo[0, 3, y]
        anglesData = geo[0, 4, y]
        for i in range(0, numC):
            if scoresData[i] < min_conf:
                continue
            (offX, offY) = (i * 4.0, y * 4.0)
            angle = anglesData[i]
            cos = np.cos(angle)
            sin = np.sin(angle)
            h = x0[i] + x2[i]
            w = x1[i] + x3[i]
            endX = int(offX + (cos * x1[i]) + (sin * x2[i]))
            endY = int(offY - (sin * x1[i]) + (cos * x2[i]))
            startX = int(endX - w)
            startY = int(endY - h)
            boxes.append((startX, startY, endX, endY))
            confidence_val.append(scoresData[i])

    return (boxes, confidence_val)

def get_text(img,img_text ='Output',min_conf = 0.7, east = EAST_PATH):
    image = cv2.imread(img)
    orig = image.copy()
    (origH, origW) = image.shape[:2]
    (newW, newH) = (320,320)
    rW = origW / float(newW)
    rH = origH / float(newH)
    image = cv2.resize(image, (newW, newH))
    (H, W) = image.shape[:2]
    blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),
        (123.68, 116.78, 103.94), swapRB=True, crop=False)
    net = cv2.dnn.readNet(east)
    # The following two layer need to pulled from EAST model for achieving this. 
    layerNames = [
        ""feature_fusion/Conv_7/Sigmoid"",
        ""feature_fusion/concat_3""]

    #Forward pass the blob from the image to get the desired output layers
    net.setInput(blob)
    (scores, geometry) = net.forward(layerNames)
    (boxes, confidence_val) = predictions(scores, geometry,min_conf)
    boxes = non_max_suppression(np.array(boxes), probs=confidence_val)
    
    results = []
    for (startX, startY, endX, endY) in boxes:
        startX = int(startX * rW)
        startY = int(startY * rH)
        endX = int(endX * rW)
        endY = int(endY * rH)
        r = orig[startY:endY, startX:endX]
        configuration = (""-l eng --oem 1 --psm 8"")
        text = pytesseract.image_to_string(r, config=configuration)
        results.append(((startX, startY, endX, endY), text))

    orig_image = orig.copy()
    txts=[]
    for ((start_X, start_Y, end_X, end_Y), text) in results:
        text = """".join([x if ord(x) < 128 else """" for x in text]).strip()
        cv2.rectangle(orig_image, (start_X, start_Y), (end_X, end_Y),
            (0, 0, 255), 2)
        cv2.putText(orig_image, text, (start_X, start_Y + 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,255, 0), 4)
        txts.append(text)
    plt.figure(figsize=(10,10))
    plt.imshow(orig_image)
    plt.title(img_text)
    plt.show()
    print(txts)it = iter(range(500))","This code imports the pip module and then attempts to import the imutils module. If the imutils module is not found, the code uses pip to install it.

The code then defines a function to process images. This function takes an image as input and applies a number of processing steps to it, including resizing, converting to grayscale, and applying thresholding. The function then returns the processed image.

The code also defines a function to display a dataframe. This function takes a dataframe as input and displays the contents in a grid. The function also has an option to display randomly selected rows from the dataframe.

Finally, the code defines a function to get text from an image. This function takes an image as input and uses the EAST text detection model to identify text in the image. The function then returns the identified text.",9,6,0.0969402212574577
,"This code defines a function that takes two parameters, a and b, and returns the sum of the two parameters.",10,0,
"# Reshaping to (num of images, pixels in x direction, pixels in y direction, channel()
X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)
test = test.reshape(test.shape[0], 28, 28, 1)
plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))","This code reshapes the training data and test data into three-dimensional arrays. The first dimension represents the number of images, the second dimension represents the pixels in the x direction, and the third dimension represents the pixels in the y direction. The fourth dimension represents the channel.",8,0,0.08497503081709999
"import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt #for plotting
from collections import Counter
from sklearn.metrics import confusion_matrix
import itertools
import seaborn as sns
from subprocess import check_output
print(check_output([""ls"", ""../input""]).decode(""utf8""))
%matplotlib inline#loading the dataset.......(Train)
train = pd.read_csv(""../input/train.csv"")
print(train.shape)
train.head()z_train = Counter(train['label'])
z_trainsns.countplot(train['label'])#loading the dataset.......(Test)
test= pd.read_csv(""../input/test.csv"")
print(test.shape)
test.head()x_train = (train.ix[:,1:].values).astype('float32') # all pixel values
y_train = train.ix[:,0].values.astype('int32') # only labels i.e targets digits
x_test = test.values.astype('float32')%matplotlib inline
# preview the images first
plt.figure(figsize=(12,10))
x, y = 10, 4
for i in range(40):  
    plt.subplot(y, x, i+1)
    plt.imshow(x_train[i].reshape((28,28)),interpolation='nearest')
plt.show()","This code imports the necessary libraries for data analysis and visualization, then loads the dataset into a pandas DataFrame. It then displays some basic information about the dataset, including the number of rows and columns, and the first five rows of data.

Next, the code plots a histogram of the labels in the training set. This is followed by a preview of some of the images in the training set.",8,1,0.09260126845916186
"import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsClassifier# Считаем csv файлы в Pandas датафрейм
train = pd.read_csv('../input/digit-recognizer/train.csv')
test = pd.read_csv('../input/digit-recognizer/test.csv')# Посмотрим на тренировочный датафрейм
train.head()# Узнаем число пропущенных значений 
# и какому признаку принадлежит больше всего пропусков
sum(train.isnull().sum())# Посмотрим на тестовый датафрейм
test.head()# Узнаем число пропущенных значений 
# и какому признаку принадлежит больше всего пропусков
sum(test.isnull().sum())# Пропущенных значений нет, потому можно продолжать работу с выборками","The code above imports the pandas, numpy, and sklearn.neighbors libraries, then reads in the train.csv and test.csv files as pandas dataframes. Next, it displays the first few rows of the training dataframe, then calculates and displays the number of missing values in the dataframe. Finally, it does the same for the test dataframe.

There are no missing values in either dataframe, so the code can continue with the analysis.",10,7,0.07228307859319057
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset

import wandb
from kaggle_secrets import UserSecretsClient
user_secrets = UserSecretsClient()
secret_value_0 = user_secrets.get_secret(""WANDB_KEY"")
wandb.login(key=secret_value_0)
wandb.init(project='MNIST_MLP', save_code=True)class MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return datatransformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])

train_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)
# TODO split train between validation and training set
training_size = int(0.7 * len(train_dataset))
validation_size = len(train_dataset) - training_size
train, val = torch.utils.data.random_split(train_dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))
# create data loader for train and test set
data_loader_train = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True)
data_loader_val = torch.utils.data.DataLoader(val, batch_size=32, shuffle=True)

test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)def init_my_layer(m):
    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('tanh'))
    torch.nn.init.constant_(m.bias, 0)
    return m

class Net(nn.Module):    
    def __init__(self):
        super(Net, self).__init__()
        self.relu = nn.ReLU()
        self.ln1 = init_my_layer(nn.Linear(28*28, 28))
        self.ln2 = init_my_layer(nn.Linear(28, 28))
        self.ln3 = init_my_layer(nn.Linear(28, 10))
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        x = self.relu(self.ln1(x))
        x = self.relu(self.ln2(x))
        return self.softmax(self.ln3(x))model = Net()

# check if a GPU with Cuda capacities is available
device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"") #0, first GPU if multiple one
model.to(device)
learning_rate = 1e-3
lambda_l2 = 1e-5

criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=lambda_l2)
wandb.watch(model, log=""all"", criterion=criterion, log_freq=1,  log_graph=(True)) 


nb_epochs = 10
# Training
for t in range(nb_epochs):
    model.train() # put the network in training mode
    for X, y in data_loader_train:
        # Feed forward to get the logits
        #format data
        b = X.size(0)
        X = X.view(b,-1)
        y_pred = model(X)
        # Compute the loss and accuracy
        loss = criterion(y_pred, y)
        score, predicted = torch.max(y_pred, 1)
        acc = (y == predicted).sum().float() / len(y)
        wandb.log({
            'mlp/train_loss': loss.item(),
            'mlp/train_accuracy': acc,
        })
        # zero the gradients before running
        # the backward pass.
        optimizer.zero_grad()
        # Backward pass to compute the gradient
        # of loss w.r.t our learnable params. 
        loss.backward()
        # Update params
        optimizer.step()
        
    with torch.no_grad(): # validation run
        model.eval() # validation mode
        for X, y in data_loader_val:
            #format data
            b = X.size(0)
            X = X.view(b,-1)
            y_pred = model(X)
            validation_loss = criterion(y_pred, y)
            score, predicted = torch.max(y_pred, 1)
            acc = (y == predicted).sum().float() / len(y)
            wandb.log({
                'mlp/val_loss': loss.item(),
                'mlp/val_accuracy': acc,
            })
","This code defines a neural network for the MNIST dataset using PyTorch. The network consists of three fully connected layers. The first two layers use the ReLU activation function, while the third layer uses the softmax activation function. The network is trained using the Adam optimizer and the cross entropy loss function.

The code first imports the necessary libraries. Next, it defines the MyMNISTDataset class, which is used to load and preprocess the MNIST data. The class includes a constructor that takes in a file path, a transform object, and a Boolean value indicating whether the data is for training or testing. The class also has a __len__ method that returns the number of data points in the dataset, and a __getitem__ method that returns a data point from the dataset.

Next, the code defines the Net class, which defines the neural network. The class includes a constructor that defines the network layers and activation functions. The class also has a forward method that takes in an input data point and returns the predicted output of the network.

Finally, the code instantiates the Net class, defines the optimizer and loss function, and trains the network. The network is trained for 10 epochs. For each epoch, the code loops through the training data and computes the loss and accuracy. The gradients are then computed and the network parameters are updated. The code then loops through the validation data and computes the loss and accuracy. The results are logged using the wandb library.",8,9,0.20588101536023287
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import tensorflow as tf
import tensorflow.keras.layers as tfl
import tensorflow.keras as keras
import matplotlib.pyplot as plt
import sklearn.model_selection as model_sel


# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiondf = pd.read_csv('../input/digit-recognizer/train.csv')
df.head()X = df.drop(columns=['label'])
X.head()X = X.to_numpy().reshape(-1,28,28,1)X = X/255
X.shapeplt.figure(figsize = (10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.imshow(X[i])
    plt.xticks([])
    plt.yticks([])
    plt.xlabel(df['label'][i])X_train, X_test, Y_train, Y_test = model_sel.train_test_split(X, df['label'].to_numpy().reshape(-1,1), test_size=0.25, random_state=1)","This code imports the necessary libraries for data analysis and machine learning in Python. It then loads the data from the CSV file and displays the first five rows.

Next, the code splits the data into training and testing sets, with the training set containing 75% of the data and the testing set containing 25% of the data. The code then displays some sample images from the training data.",8,0,0.16015876019251224
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import wandb

from kaggle_secrets import UserSecretsClient
user_secrets = UserSecretsClient()
secret_value = user_secrets.get_secret(""WANDB_KEY"")

wandb.login(key=secret_value)
wandb.init(project='MNIST_MLP', save_code=True)class MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return databatch_size= 512

transformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])


train_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)

# split train between validation and training set
training_size = int(0.7 * len(train_dataset))
validation_size = len(train_dataset) - training_size
train, val = torch.utils.data.random_split(train_dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))

# create data loader for train and test set
data_loader_train = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)
data_loader_val = torch.utils.data.DataLoader(val, batch_size=batch_size, shuffle=True)

test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False)def init_layer(m):
    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('relu'))
    torch.nn.init.constant_(m.bias, 0)
    return mclass Net(nn.Module):    
    def __init__(self, inputSize):
        super(Net, self).__init__()
        
        self.linear1 = init_layer(torch.nn.Linear(inputSize, 512))
        self.linear2 = init_layer(torch.nn.Linear(512, 256))
        self.dropout = torch.nn.Dropout(p=0.4)
        self.linear3 = init_layer(torch.nn.Linear(256, 10))


    def forward(self, x):
        
        x = x.view(-1,28*28) #reshape the 2d image in a ondiminsional vector for the input of the first layer
        
        x = F.relu(self.linear1(x))
        x = self.dropout(x)
        x = F.relu(self.linear2(x))
        x = self.dropout(x)
        
        return self.linear3(x)input_size = 784
output_size = 10 #labels range from 0-9

model = Net(input_size)

num_epochs = 50
lr =  0.01
weight_decay = 1e-4

optimizer = torch.optim.SGD(model.parameters(),lr = lr)#torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay) #AdamW to aviod coupling problem between the L2 regularization and the adaptive learning rate
criterion = torch.nn.CrossEntropyLoss()

#logging configuration and model
wandb.config.learningrate = lr
wandb.config.num_iterations = num_epochs
wandb.config.optimizer = ""AdamW""
wandb.config.weight_decay = weight_decay
wandb.config.criterion = ""CELoss""

wandb.watch(model, log=""all"", criterion=criterion, log_freq=1,  log_graph=(True)) #log frequency depend on your training


device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"") #0, first GPU if multiple one
print(device)
model.to(device)
","This code defines a neural network for the MNIST dataset using the PyTorch library. The network consists of three fully connected layers with 512, 256, and 10 neurons, respectively. The network uses the AdamW optimizer and the CrossEntropyLoss criterion.

The code also defines a MyMNISTDataset class for loading and transforming the MNIST data, and a DataLoader class for loading the data in batches. Finally, the code trains the network for 50 epochs and saves the model to the wandb.log directory.",8,7,0.1956150206053839
"import pandas as pd   # data analysis librarymnist_test = pd.read_csv(""/kaggle/input/mnist-fashion-data-classification/mnist_test.csv"")    # create a variable dataframe containing data from data file
mnist_train = pd.read_csv(""/kaggle/input/mnist-fashion-data-classification/mnist_train.csv"")    # create a variable dataframe containing data from data file
sample_submission = pd.read_csv(""/kaggle/input/digit-recognizer/sample_submission.csv"")    # create a variable dataframe containing data from data file
train = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")    # create a variable dataframe containing data from data file
test = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")    # create a variable dataframe containing data from data filecols = test.columnstest['dataset'] = 'test'train['dataset'] = 'train'dataset = pd.concat([train.drop('label', axis=1), test]).reset_index()","This code imports the pandas library and then reads in four data files: mnist_test.csv, mnist_train.csv, sample_submission.csv, and train.csv. It then concatenates the train and test data into a single dataframe, resetting the index in the process.",8,3,0.22257730650527507
"import os
import numpy as np
import pandas as pd
import pydicom# Load the data
base_path = ""/kaggle/input/siim-covid19-detection/""
studies_df = pd.read_csv(os.path.join(base_path,""train_study_level.csv""))
images_df = pd.read_csv(os.path.join(base_path,""train_image_level.csv""))

# Strip the extra text from the study and image IDs
studies_df['id'] = studies_df['id'].map(lambda x: x.rstrip('_study'))
images_df['id'] = images_df['id'].map(lambda x: x.rstrip('_image'))

# Merge the dfs together
data_df = pd.merge(images_df, studies_df, how='inner', left_on='StudyInstanceUID', right_on='id')
data_df.drop(['id_y'], axis=1, inplace=True)# This function finds the first image in a StudyInstanceUID directory and returns its path
def get_image_by_study_id(study_id):
    study_path = base_path + ""train/"" + study_id + ""/""
    for subdir, dirs, files in os.walk(study_path):
        for file in files:     
            image = os.path.join(subdir, file)
            if os.path.isfile(image):
                return image
    return ""none""# Loop through the images and check how many images are not Explicit VR Little Endian transfer syntax.
# Also count images with VOI LUT Sequence tags present

count = 0
images_with_voi_lut = 0
images_with_voi_lut_function = 0
images_not_explicit_le = 0
deflated_syntaxes = []
voi_lut_functions = []

for index, row in data_df.iterrows():
    img_file = get_image_by_study_id(row['StudyInstanceUID'])
    img = pydicom.dcmread(img_file)
    
    # Check for a LUT sqequence tag
    if (0x0028,0x3010) in img:
        images_with_voi_lut += 1
    
    # Check for a LUT Function tag
    if (0x0028,0x1056) in img:
        images_with_voi_lut_function += 1
        
        if img(0x0028,0x1056) not in voi_lut_functions:
            voi_lut_functions.append(img(0x0028,0x1056))
            
    # Check the transfer syntax
    if img.file_meta.TransferSyntaxUID != ""1.2.840.10008.1.2.1"":
        images_not_explicit_le += 1
        
        if img.file_meta.TransferSyntaxUID not in deflated_syntaxes:
            deflated_syntaxes.append(img.file_meta.TransferSyntaxUID)
        
    count += 1
    
print(""Done checking "" + str(count) + "" images"")
print(""Found "" + str(images_with_voi_lut) + "" images with VOI LUT"")
print(""Found "" + str(images_with_voi_lut_function) + "" images with VOI LUT Function"")
print(""VOI LUT Functions:"")
print(voi_lut_functions)
print(""Found "" + str(images_not_explicit_le) + "" images that are not Explicit VR LE"")
print(""Non Explicit VR LE Transfer Syntaxes"")
print(deflated_syntaxes)","This code imports the os, numpy, pandas, and pydicom libraries.

It then loads the data from the train_study_level.csv and train_image_level.csv files.

Next, it strips the extra text from the study and image IDs.

Then, it merges the dataframes together.

The get_image_by_study_id() function is then defined. This function finds the first image in a StudyInstanceUID directory and returns its path.

The code then loops through the images and checks for various tags. The count, images_with_voi_lut, images_with_voi_lut_function, and images_not_explicit_le variables are incremented as appropriate.

Finally, the results are printed.",9,10,0.27797891961795923
"import os
import cv2
import numpy as np
import pandas as pd
import pydicom
import matplotlib.pyplot as plt
%matplotlib inline# This function gets the first image path in a StudyInstanceUID directory
def get_image_by_study_id(study_id):
    base_path = ""/kaggle/input/siim-covid19-detection/""
    study_path = base_path + ""train/"" + study_id + ""/""
    images = []
    for subdir, dirs, files in os.walk(study_path):
        for file in files:     
            image = os.path.join(subdir, file)
            if os.path.isfile(image):
                return image
    return ""none""# Make a simple linear VOI LUT from the raw (stored) pixel data
def make_lut(storedPixels, windowWidth, windowLevel, p_i):
    
    # Slope and Intercept set to 1 and 0 for X-ray. Get these from DICOM tags instead if using 
    # on a modality that requires them (CT, PT etc)
    slope = 1.0
    intercept = 0.0
    minPixel = int(np.amin(storedPixels))
    maxPixel = int(np.amax(storedPixels))

    # Make an empty array for the LUT the size of the pixel 'width' in the raw pixel data
    lut = [0] * (maxPixel + 1)
    
    # Invert pixels and windowLevel for MONOCHROME1. We invert the specified windowLevel so that 
    # increasing the level value makes the images brighter regardless of photometric intrepretation
    invert = False
    if p_i == ""MONOCHROME1"":
        invert = True
    else:
        windowLevel = (maxPixel - minPixel) - windowLevel
        
    # Loop through the pixels and calculate each LUT value
    for storedValue in range(minPixel, maxPixel):
        modalityLutValue = storedValue * slope + intercept
        voiLutValue = (((modalityLutValue - windowLevel) / windowWidth + 0.5) * 255.0)
        clampedValue = min(max(voiLutValue, 0), 255)
        if invert:
            lut[storedValue] = round(255-clampedValue)
        else:
            lut[storedValue] = round(clampedValue)
        
    return lut# Apply the LUT to a pixel array
def apply_lut(pixels_in, lut):
    pixels_in = pixels_in.flatten()
    pixels_out = [0] * len(pixels_in)
    for i in range(0, len(pixels_in)):
        pixel = pixels_in[i]
        pixels_out[i] = int(lut[pixel])
    return pixels_out# Take a look at a random image and display it with imshow. The width and level are automagically calculated from the pixel data.
img_file = get_image_by_study_id(""00c241c3fc0d"")
print(""Loading image: "" + img_file)

img = pydicom.dcmread(img_file)
plt.imshow(img.pixel_array,cmap=""gray"");# Set the width to be the distance between the pixels, and the level to be the middle of the pixel range.
# The resulting image should look exactly like the one above.
pixels = img.pixel_array
minPixel = np.min(pixels)
maxPixel = np.max(pixels)
windowWidth = maxPixel - minPixel
windowLevel = (minPixel + maxPixel) / 2

lut = make_lut(pixels, windowWidth, windowLevel, img.PhotometricInterpretation)
pixels = apply_lut(pixels, lut)

# Reshape the pixel array back into the image shape
img_out = np.reshape(pixels, (img.pixel_array.shape[0],img.pixel_array.shape[1]))

print(""Calculated - Width: "" + str(windowWidth) + "" / Level  "" +  str(windowLevel))
print(""Pixel range: "" + str(minPixel) + "" - "" + str(maxPixel))
plt.imshow(img_out,cmap=""gray"");print(""PhotometricInterpretation: "" + img.PhotometricInterpretation)
print(""Bit stored: "" + str(img.BitsStored))","This code imports the os, cv2, numpy, pandas, pydicom, and matplotlib libraries, and sets the inline matplotlib backend.

The get_image_by_study_id() function takes a study_id string as input and returns the path to the first image file in the corresponding directory.

The make_lut() function takes storedPixels, windowWidth, windowLevel, and p_i (photometric interpretation) as input and generates a linear VOI LUT from the raw pixel data.

The apply_lut() function takes pixels_in and lut as input, applies the lut to the pixels, and returns the resulting pixels_out.

The code then reads in a DICOM image using pydicom, displays it using matplotlib, and calculates the window width and level from the pixel data. It then generates a LUT using make_lut() and applies it to the image using apply_lut(). The resulting image is displayed using matplotlib. Finally, the code prints out the photometric interpretation and bits stored for the image.",8,14,0.5394194639104305
"import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings(""ignore"")
from glob import glob
from tqdm.notebook import tqdm
from ast import literal_eval
import os
import matplotlib.pyplot as plt
import matplotlib
matplotlib.rcParams.update({'font.size': 22})
from sklearn.metrics import accuracy_score
from skimage import exposure
from tensorflow.keras import layers
from tensorflow.keras.utils import plot_model
import cv2
from matplotlib.patches import Rectangle
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50, DenseNet121, Xception
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import models
from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping
import tensorflow.keras.backend as K
from tensorflow.math import confusion_matrixdf_image = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
display(df_image.head(3))
print(df_image.shape)df_study = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
display(df_study.head(3))
print(df_study.shape)df_sampleSub = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
display(df_sampleSub.head(3))
print(df_sampleSub.shape)df_study['id'] = df_study['id'].str.replace('_study',"""")
df_study.rename({'id': 'StudyInstanceUID'},axis=1, inplace=True)
df_study.head(3)df_train = df_image.merge(df_study, on='StudyInstanceUID')
df_train.head(3)# train_dir_jpg = '../input/covid-jpg-512/train'
# train_dir_origin ='../input/siim-covid19-detection/train'
# paths_original = []
# paths_jpg = []
# for _, row in tqdm(df_train.iterrows()):
#     image_id = row['id'].split('_')[0]
#     study_id = row['StudyInstanceUID']
#     image_path_jpg = glob(f'{train_dir_jpg}/{image_id}.jpg')
#     image_path_original = glob(f'{train_dir_origin}/{study_id}/*/{image_id}.dcm')
#     paths_jpg.append(image_path_jpg)
#     paths_original.append(image_path_original)","This code imports the pandas, numpy, warnings, and glob modules.

It then filter warnings and defines a function to read in CSV files.

Next, it defines variables for the directories containing the training images and CSV files.

 Finally, it loops through the training images and CSV files, appending the image paths to two lists.",8,2,0.02961171183203603
"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -yimport tensorflow as tf
print(tf.__version__)
import torch
print(f""Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})"")

import os
import gc
import cv2
import glob
import numpy as np
import pandas as pd
from PIL import Image
from tqdm import tqdm
from shutil import copyfile
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lutgpus = tf.config.list_physical_devices('GPU')
if gpus:
  try:
    # Currently, memory growth needs to be the same across GPUs
    for gpu in gpus:
      tf.config.experimental.set_memory_growth(gpu, True)
    logical_gpus = tf.config.experimental.list_logical_devices('GPU')
    print(len(gpus), ""Physical GPUs,"", len(logical_gpus), ""Logical GPUs"")
  except RuntimeError as e:
    # Memory growth must be set before GPUs have been initialized
    print(e)# Read the submisison file
sub_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')
print(len(sub_df))
sub_df.head()study_df = sub_df.loc[sub_df.id.str.contains('_study')]
len(study_df)image_df = sub_df.loc[sub_df.id.str.contains('_image')]
len(image_df)# Ref: https://www.kaggle.com/xhlulu/siim-covid-19-convert-to-jpg-256px
def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return data

def resize_xray(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im","This code installs the pydicom conda helper package, which allows for the conversion of DICOM images to numpy arrays. It also installs the latest version of TensorFlow and PyTorch. Finally, it reads in the sample submission file and splits it into two dataframes - one for studies and one for images.",8,4,0.11027823500872422
"!/opt/conda/bin/python3.7 -m pip install --upgrade pip
! pip install -q efficientnet#-------------------
# importing libraries
#-------------------
import tensorflow as tf
from tensorflow.keras import layers
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold,StratifiedKFold

from kaggle_datasets import KaggleDatasets


import pandas as pd
import numpy as np

import os
import shutil
import csv

import matplotlib.pyplot as plt
import PILAUTO = tf.data.experimental.AUTOTUNE

try:
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  
    print('Running on TPU ', tpu.master())
except ValueError:
    tpu = None

if tpu:
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.experimental.TPUStrategy(tpu)
else:
    strategy = tf.distribute.get_strategy()

print(""REPLICAS: "", strategy.num_replicas_in_sync)GCS_DS_PATH = KaggleDatasets().get_gcs_path(""siim-covid19-dataset-256px-jpg"")
print(GCS_DS_PATH)

TRAIN_PATH = GCS_DS_PATH + ""/256px/train/train/""
TEST_PATH = GCS_DS_PATH + ""/256px/test/test/""

NUM_CLASSES = 4
HEIGHT,WIDTH = 256,256
CHANNELS = 3
BATCH_SIZE = 8 * strategy.num_replicas_in_sync
SEED = 143


classes_dict = {
    ""Negative for Pneumonia"" : 0,
    ""Typical Appearance"" : 1,
    ""Indeterminate Appearance"" : 2,
    ""Atypical Appearance""  : 3
}

study_df = pd.read_csv(""../input/siim-covid19-detection/train_study_level.csv"")
train_df = pd.read_csv('../input/siim-covid19-dataset-256px-jpg/train.csv')
train_df = train_df[[""ImageInstanceUID"",""StudyInstanceUID"",""label_id"",""study_label""]]train_df.head(3)study_df.head(3)def process_img(filepath,label):
    image = tf.io.read_file(filepath)
    image = tf.image.decode_jpeg(image, channels=CHANNELS)
    image = tf.image.convert_image_dtype(image, tf.float32) 
    #image = tf.image.resize(image, [HEIGHT,WIDTH])
    return image,label


def data_augment(image, label):
    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
            
    # Flips
    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_flip_up_down(image)
    if p_spatial > .75:
        image = tf.image.transpose(image)
        
    # Rotates
    if p_rotate > .75:
        image = tf.image.rot90(image, k=3) 
    elif p_rotate > .5:
        image = tf.image.rot90(image, k=2) 
    elif p_rotate > .25:
        image = tf.image.rot90(image, k=1) 
        
    
    if p_pixel_1 >= .4:
        image = tf.image.random_saturation(image, lower=.7, upper=1.3)
    if p_pixel_2 >= .4:
        image = tf.image.random_contrast(image, lower=.8, upper=1.2)
    if p_pixel_3 >= .4:
        image = tf.image.random_brightness(image, max_delta=.1)
        
    
    if p_crop > .7:
        if p_crop > .9:
            image = tf.image.central_crop(image, central_fraction=.7)
        elif p_crop > .8:
            image = tf.image.central_crop(image, central_fraction=.8)
        else:
            image = tf.image.central_crop(image, central_fraction=.9)
    elif p_crop > .4:
        crop_size = tf.random.uniform([], int(HEIGHT*.8), HEIGHT, dtype=tf.int32)
        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])
    
    image = tf.image.resize(image, [HEIGHT,WIDTH])
    return image,label

def get_dataset(filenames,labels, training=True):
    dataset = tf.data.Dataset.from_tensor_slices((filenames,labels))
    dataset = dataset.map(process_img,num_parallel_calls=AUTO)
    dataset = dataset.map(data_augment,num_parallel_calls=AUTO)
    dataset = dataset.cache()
    dataset = dataset.repeat()
    if training:
        dataset = dataset.shuffle(2048)
    dataset = dataset.batch(BATCH_SIZE)
    dataset = dataset.prefetch(AUTO)
    return dataset","This code imports the necessary libraries for training a model to detect pneumonia from X-ray images, including the efficientnet library for building the model. It also defines constants for the image size, number of classes, and batch size.

Next, the code defines a function for processing images. This function takes in a filepath and label, reads in the image from the filepath, decodes it, and converts it to a float32.

The code also defines a function for data augmentation. This function takes in an image and a label, and randomly applies flips, rotations, saturation, contrast, and brightness changes to the image.

Finally, the code defines a function for getting a dataset. This function takes in a list of filenames and labels, and returns a dataset that contains the processed images and labels. The function also applies data augmentation to the images if the training flag is set to True.",8,3,0.1042853680034646
"%%capture
!conda install gdcm -c conda-forge -y# Packages

import os, time, glob, re, pprint, random, math
from collections import defaultdict, Counter

import pandas as pd 
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import matplotlib.patches as patches

import seaborn as sns

import cv2
import gdcm

import pydicom
from pydicom import dcmread
from pydicom.pixel_data_handlers.util import apply_voi_lut

import imagehash
from PIL import Image as im

import tqdm# Magic

%matplotlib inline # Pandas options

pd.set_option(""display.expand_frame_repr"", True)
pd.set_option('display.max_colwidth', 0)# Global values

CODE_PATH = ""./""
DATA_PATH = ""../input/siim-covid19-detection""
TRAIN_PATH = os.path.join(DATA_PATH, ""train"")
TEST_PATH = os.path.join(DATA_PATH, ""test"")# Utility functions

def print_title(s):
    
    # Print an underlined title
    
    print(""%s\n%s"" % (s, '-'*len(s)))
    
    
def na_fill(dtype):
    
    # Fill in missing values so that Seaborn countplot() will include them.
    # Also make sure the missing value for a string column is itself a string.
    
    if dtype == np.float64:
        result = -999
    elif dtype == np.int64:
        result = -999
    elif dtype == np.object:
        result = ""NA""
    else:
        result = -999

    return result


def explode_list_col(df, col):
    
    other_cols = list(df.columns)
    other_cols.remove(col)
    out_df = df.set_index(other_cols)[col]
    out_df = out_df.apply(pd.Series)
    out_df = out_df.stack()
    out_df = out_df.reset_index()
    out_df = out_df.drop(f""level_{len(other_cols)}"", axis=1)
    out_df = out_df.rename(columns={0 : col})
    
    return out_df
    

def cat_order(train_df, test_df, cols):
    
    # For comparison, we want the categories to be the same between train and test. 
    # We also want the categories to be in the same order for both. 
    # We need to make sure missing value types are consistent with the column data
    # type (else sort will complain), and make sure that Seaborn countplot() will
    # include them (it won't include np.nan). Dealing with the latter two issues 
    # is the job of fillna(). When the data is plotted, it needs to be run through
    # fillna() as well.

    category_order = {}
    n = len(cols)

    for col in cols:

        if col in train_cols:
            train_dtype = train_df[col].dtype
        else:
            train_dtype = None     
        if col in test_cols:
            test_dtype = test_df[col].dtype
        else:
            test_dtype = None
        if (train_dtype != None) and (test_dtype != None) and (train_dtype != test_dtype):
            print(f""***Incompatible train/test data types for column {col}"")
            break
        
        col_vals = []
        if col in train_cols:
            col_vals += list(train_df[col].fillna(na_fill(train_dtype)).unique())
        if col in test_cols:
            col_vals += list(test_df[col].fillna(na_fill(test_dtype)).unique())
        col_vals = list(set(col_vals))
        col_vals.sort()
    
        category_order[col] = col_vals
        
    return category_order


def plot_categories(df, col, order, title, ax, xlabel=None, ylabel=None, pallete=""Set3"", scale=""log""):

    data = df[col].fillna(na_fill(df[col].dtype))
    ax = sns.countplot(x=data, order=order, palette=pallete, ax=ax)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=""right"")
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    counts = data.value_counts()
    for i, p in enumerate(ax.patches):
        px = p.get_x()+0.05
        py = max(p.get_height()*0.9, 1.0)
        ax.annotate(counts.get(order[i], """"), (px, py), fontsize=10, rotation=90)
    ax.set_title(title, fontsize=15)
    if xlabel: ax.set_xlabel(xlabel)
    if ylabel: ax.set_ylabel(ylabel)
    
    return


def plot_cat_sub(df, col, sub_col, title, ax, scale=""log""):

    ax = sns.countplot(data=df, x=col, hue=sub_col, ax=ax)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=""right"")
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    ax.set_title(title, fontsize=15)
        
    return


def plot_number_uniq_per(df, df_name, attr1, attr2, ax, title=None, palette=None, scale=""log""):
    
    uniq_df = df.groupby(attr1)[[attr2]].nunique().reset_index()
    ax = sns.barplot(x=attr1, y=attr2, data=uniq_df, ax=ax, palette=palette)
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
        
    counts = uniq_df[attr2]
    for i, p in enumerate(ax.patches):
        px = p.get_x()+0.05
        py = max(p.get_height()*0.9, 1.0)
        ax.annotate(uniq_df[attr2].iloc[i], (px, py), fontsize=10, rotation=90)

    if title:
        ax.set_title(title, fontsize=15)
    else:
        ax.set_title(f""{df_name}\nNumber of unique '{attr2}' values \nper '{attr1}' value"", fontsize=15)
    ax.set_xlabel(attr1)
    ax.set_ylabel(f""# unique '{attr2}'"")
    
    return uniq_df


def plot_number_having_n_uniq(df, df_name, attr1, attr2, ax, order=None, palette=None, scale=""log""):

    nuniq = df.groupby(attr1)[attr2].nunique()
    ax = sns.countplot(x=nuniq, order=order, ax=ax, palette=palette)
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    ax.set_title(f""{df_name}\nNumber of '{attr1}' values \nhaving N unique values of '{attr2}'"", fontsize=15)
    ax.set_xlabel(f""N = # of unique '{attr2}' values"")
    ax.set_ylabel(f""# of '{attr1}' having N"")

    return nuniq


def get_img(path, img_id):

    img_path = os.path.join(path, f""{img_id}.jpg"")
    im = cv2.imread(img_path)
    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
    im = cv2.normalize(im, None, 0, 255, cv2.NORM_MINMAX)
    
    return im


def image_subplots(images, r, c, axes, titles=None):
    
    for idx, img in enumerate(images, 0):
        i = idx // c
        j = idx % c
        if titles:
            imshow(img, axes[i, j], title=titles[idx])
        else:
            imshow(img, axes[i, j])

    return
        

def imshow(image, ax=None, title=None, cmap=None):

    if ax is None:
        fig, ax = plt.subplots()
    ax.imshow(image, cmap=cmap)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.spines['left'].set_visible(False)
    ax.spines['bottom'].set_visible(False)
    ax.tick_params(axis='both', length=0)
    ax.set_xticklabels('')
    ax.set_yticklabels('')
    if title:
        ax.set_title(title)

    return ax
# Read the image metadata

train_image_df = pd.read_csv(os.path.join(DATA_PATH,'train_image_level.csv'))
train_study_df =  pd.read_csv(os.path.join(DATA_PATH,'train_study_level.csv'))","This code reads in the image metadata for the train images from a CSV file. The metadata includes information such as the image ID, patient ID, and modality. This code also reads in the study metadata for the train images from a CSV file. The study metadata includes information such as the study ID, patient ID, and modality.",8,0,0.09017805823053524
"import pydicom as dicom
import pandas as pd
import os
from tqdm import tqdmmetadata = []

for split in ['test', 'train']:  
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            ds1 = dicom.dcmread(os.path.join(dirname, file), stop_before_pixels=True)
            dt=dict()
            dt['ImageId']=file.replace('.dcm','')
            for key in ds1.keys():
                dt[ds1[key].keyword]=ds1[key].value
            metadata.append(dt)

metadata_df=pd.DataFrame(metadata)
metadata_df.head()metadata_df.to_csv('metadata_covid.csv', index=False)","This code imports the necessary libraries for reading DICOM files and storing them in a pandas DataFrame. It then loops through a set of DICOM files, extracting metadata from each one and adding it to the DataFrame. Finally, it saves the DataFrame to a CSV file.",8,3,0.12248895706942488
"import pandas as pd 
import numpy as np
import os
import pydicom
import glob
from tqdm.notebook import tqdm
from pydicom.pixel_data_handlers.util import apply_voi_lut
import matplotlib.pyplot as plt 
from skimage import exposure
import cv2
import warnings
from path import Path
from fastai.vision.all import *
from fastai.medical.imaging import *
warnings.filterwarnings(""ignore"")datapath = Path(""../input/siim-covid19-detection"")datapath.ls()train_study_df = pd.read_csv(datapath/'train_study_level.csv')train_study_df.head()study_classes = [""Negative for Pneumonia"" , ""Typical Appearance"",
                ""Indeterminate Appearance"", ""Atypical Appearance""]
np.unique(train_study_df[study_classes].values , axis = 0)plt.figure(figsize = (10,5))
plt.bar([1,2,3,4] , train_study_df[study_classes].values.sum(axis = 0))
plt.xticks([1,2,3,4] , study_classes)
plt.ylabel(""Frequency"")
plt.show()","This code imports the pandas, numpy, os, pydicom, glob, tqdm, and matplotlib libraries.

It then defines a datapath variable pointing to the location of the input data.

Next, it reads in the train_study_level.csv file and stores it in a dataframe called train_study_df.

After that, it defines a list of study classes.

Then, it calculates the number of unique classifications in the train_study_df dataframe and prints them.

Finally, it creates a bar chart showing the number of each class of study.",8,10,0.04712127398494812
"import numpy as np 
import pandas as pd 
import os
import matplotlib.pyplot as plt
import matplotlib
import pydicom as dicom
import cv2
import ast
import warnings
warnings.filterwarnings('ignore')train_image = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
train_study = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
sample_submission = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')train_image.head()len(train_image)train_study.head()len(train_study)sample_submission.head()","This code imports the necessary libraries for working with the data, including NumPy, pandas, matplotlib, and cv2. It then loads the train_image, train_study, and sample_submission dataframes from the input files. Finally, it displays the first five rows of the train_image dataframe.",9,3,0.08303066222954547
"!conda install gdcm -c conda-forge -yimport os
import ast
import numpy as np
import pandas as pd
from path import Path
import datetime
import glob
import json
import shutil

from PIL import Image
from tqdm.auto import tqdm
import pydicom
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import cv2from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)    
    
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail(size, resample)
    else:
        im = im.resize(size, resample)
    
    return imimages_meta_folder = '/kaggle/working/images_metadata_256_512_768'
os.makedirs(images_meta_folder, exist_ok=True)

# Define sizes
new_sizes = [(256, 256), (512, 512), (768, 768)]for new_size in new_sizes:

    for split in ['train', 'test']:
    # for split in ['test']:
        save_dir = f'/kaggle/tmp/{split}_{new_size[0]}x{new_size[1]}/'
        dcm_paths = glob.glob(f'../input/siim-covid19-detection/{split}/*/*/*')
        os.makedirs(save_dir, exist_ok=True)

        image_ids = []
        folder_ids = []
        study_ids = []
        widths = []
        heights = []

        for path in tqdm(dcm_paths):
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(path)
            im = resize(xray, size=new_size)

            path_split = path.split('/')
            study_id = path_split[-3]
            folder_id = path_split[-2]
            image_name = path_split[-1].replace('.dcm', '_image')

            im.save(os.path.join(save_dir, image_name+'.png'))

            image_ids.append(image_name)
            folder_ids.append(folder_id)
            study_ids.append(study_id)
            widths.append(xray.shape[1])
            heights.append(xray.shape[0])
            
        df = pd.DataFrame.from_dict({'id': image_ids, 'folder_id': folder_ids,
                                     'study_id': study_ids, 'width': widths,
                                     'height': heights})
        df.to_csv(f'{images_meta_folder}/{split}_meta_{new_size[0]}x{new_size[1]}.csv', index=False)for new_size in new_sizes:
    print(f""*****{new_size}*****\n"")
    df_train_meta = pd.read_csv(f'{images_meta_folder}/train_meta_{new_size[0]}x{new_size[1]}.csv')
    df_train = pd.read_csv(""../input/siim-covid19-detection/train_image_level.csv"")
    df_train_meta = df_train.merge(df_train_meta, on='id')
    
    ## Drop all rows of images without annotations
    df_train_meta = df_train_meta.dropna()
    imagepaths = df_train_meta.id.unique()
    print(""Number of Images with Covid_Abnormality:"",len(imagepaths))
    
    display(df_train_meta.head(3))
    print()
    
    df_idx=0

    for idx, row in tqdm(df_train_meta.iterrows(), total=df_train_meta.shape[0]):
        img = cv2.imread(os.path.join(f""/kaggle/tmp/train_{new_size[0]}x{new_size[1]}/"",
                                      row.id.replace(""_image"", "".png"")))
        bboxes = [list(bbox.values()) for bbox in ast.literal_eval(row.boxes)]
        height_ratio, width_ratio = (new_size[0]/row.height, new_size[1]/row.width)

        for box in bboxes:
            box[2] = box[2]+box[0]
            box[3] = box[3]+box[1]
            box = (box[0]*width_ratio, box[1]*height_ratio,
                   box[2]*width_ratio, box[3]*height_ratio)

            row_df = pd.DataFrame({'id':row.id,
                           'StudyInstanceUID':row.StudyInstanceUID,
                           'folder_id':row.folder_id,
                           'study_id':row.study_id,
                           'width':row.width,
                           'height':row.height,
                           'xmin':round(box[0]),
                           'ymin':round(box[1]),
                           'xmax':round(box[2]),
                           'ymax':round(box[3])}, index=[df_idx])

            if df_idx==0:
                df_train_processed = row_df
            else:
                df_train_processed = pd.concat([df_train_processed, row_df])

            df_idx+=1

    display(df_train_processed.head(3))
    print()
    df_train_processed.to_csv(f'{images_meta_folder}/df_train_processed_meta_{new_size[0]}x{new_size[1]}.csv',
                              index=False)
    df_train_processed.shape","This code reads in a DICOM image, transforms it into a human-readable format, and then resizes it to one of three specified sizes. Finally, it saves the image to a specified directory.",8,0,0.07688891197481282
"!conda install gdcm -c conda-forge -yimport cv2
import datetime
import gc
import glob
import imagehash
import math
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
import PIL
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import sys
import tqdmbase_path = '../input/siim-covid19-detection'def read_dicom_image(image_file, voi_lut=True, fix_monochrome=True):
    """"""
    Reads a dicom image from a file an returns a numpy array.
    References: https://www.kaggle.com/trungthanhnguyen0502/eda-vinbigdata-chest-x-ray-abnormalities
    Args:
        image_file:
        voi_lut:
        fix_monochrome:

    Returns:

    """"""
    dicom = pydicom.read_file(image_file)
    # VOI LUT (if available by DICOM device) is used to
    # transform raw DICOM data to ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
    return data


def string2boxes(string):
    strings = string.split()
    if strings[0].lower() == 'none':
        return []
    else:
        return [{'class': strings[idx],
                 'conf': float(strings[idx+1]),
                 'x1': float(strings[idx+2]),
                 'y1': float(strings[idx+3]),
                 'x2': float(strings[idx+4]),
                 'y2': float(strings[idx+5]),
                 } for idx in range(0, len(strings), 6)]


def plot_image(image, boxes=None, size=(5,5), title=None, columns=4):
    def plot_img(image, boxes=None, title=None):
        if isinstance(image, str):
            image_id = os.path.splitext(os.path.split(image)[1])[0]
            df = df_image.loc[df_image['id'] == image_id + '_image']
            boxes = string2boxes(df['label'].iloc[0]) if len(df) > 0 else None
            image = read_dicom_image(image)
        image = np.stack([image] * 3, axis=-1)
        if boxes is not None:
            for box in boxes:
                image = cv2.rectangle(image, (int(box['x1']), int(box['y1'])), (int(box['x2']), int(box['y2'])), [0, 255, 0], 10)
        plt.axis('on')
        plt.imshow(image, cmap='gray')
        if title is not None:
            plt.title(title)

    plt.figure(figsize=size)
    if isinstance(image, list):
        num = len(image)
        columns = min(columns, num)
        rows = math.ceil(num / columns)

        for index, single_image in enumerate(image):
            plt.subplot(rows, columns, index + 1)
            plot_img(single_image, boxes=boxes, title=title[index])
    else:
        plot_img(image, boxes=boxes, title=title)
    plt.show()


def images_find_duplicates(image_files, threshold=0.9):
    """"""
    Function to find duplicates in images.
    References: https://www.kaggle.com/appian/let-s-find-out-duplicate-images-with-imagehash
    Args:
        image_files:
        threshold:

    Returns:

    """"""
    funcs = [imagehash.average_hash, imagehash.phash, imagehash.dhash, imagehash.whash]
    image_ids = image_files
    hashes = []
    for file in tqdm.tqdm(image_files):
        image = PIL.Image.fromarray(read_dicom_image(file))
        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))
    hashes_all = np.array(hashes)

    # Comparisons without Pytorch
    sim_list = []
    for i in tqdm.tqdm(range(hashes_all.shape[0])):
        sim_list.append(np.sum(hashes_all[i] == hashes_all, axis=1)/256)

    # nxn-matrix of similarities (n = # of images), upper triangular matrix
    similarities = np.triu(np.array(sim_list), 1)

    idx_pair = np.where(similarities > threshold)
    df_pairs = pd.DataFrame({'image1': [image_ids[i] for i in list(idx_pair[0])],
                             'image2': [image_ids[i] for i in list(idx_pair[1])],
                             'similarity': [similarities[i1, i2] for i1, i2 in zip(idx_pair[0], idx_pair[1])]})

    idx_group = np.zeros(len(image_files))
    group_id = 1
    for i1, i2 in zip(idx_pair[0], idx_pair[1]):
        if idx_group[i1] == 0 and idx_group[i2] == 0:
            idx_group[i1] = group_id
            idx_group[i2] = group_id
            group_id += 1
        elif idx_group[i1] != 0 and idx_group[i2] == 0:
            idx_group[i2] = idx_group[i1]
        elif idx_group[i1] == 0 and idx_group[i2] != 0:
            idx_group[i1] = idx_group[i2]
        elif idx_group[i1] != 0 and idx_group[i2] != 0 and idx_group[i1] != idx_group[i2]:
            common_id = min(idx_group[i1], idx_group[i2])
            idx_group[idx_group == idx_group[i1]] = common_id
            idx_group[idx_group == idx_group[i2]] = common_id

    group_list = []
    for i in range(1, group_id + 1):
        group_ids = list(np.where(idx_group == i)[0])
        if len(group_ids) > 0:
            group_list.append([image_ids[j] for j in group_ids])

    return df_pairs, group_list


def print_group_info(i, df_group):
    print(f'\nGroup {i+1}')
    print(f'Number of unique studies:       {len(df_group[""study_id""].unique())}')
    print(f'Number of unique study labels:  {len(df_group[""study_label""].unique())}\n')
    print(df_group[['image_id', 'num_boxes', 'study_id', 'study_label']])
    plot_image(list(df_group['image_file']), size=(20, 10), title=list(df_group['image_id']), columns=8)    
train_files = sorted(glob.glob(os.path.join(base_path, 'train/*/*/*.dcm')))
print(f'Number of training files: {len(train_files)}')
df_image = pd.read_csv(os.path.join(base_path, 'train_image_level.csv'))
df_study = pd.read_csv(os.path.join(base_path, 'train_study_level.csv'))
df_study['study_label'] = df_study.apply(lambda r: ', '.join([df_study.columns[i] for i in range(1, 5) if r[i] > 0]), axis=1)

df_pairs, group_list = images_find_duplicates(train_files, threshold=0.95)
print(f'\nNumber of duplicate pairs: {len(df_pairs)}')
print(f'Number of duplicate groups: {len(group_list)}')df_group_list = []
df_pairs.to_csv('pairs.csv')

with open('duplicates.csv', 'w') as text_file:
    for i, group in enumerate(group_list):
        group_ids = [os.path.splitext(os.path.basename(file))[0] + '_image' for file in group]
        df_group_ids = pd.DataFrame({'id': group_ids, 'image_file': group})
        df_group = df_group_ids.merge(df_image, on='id').sort_values('id')
        df_group['study_id'] = df_group['StudyInstanceUID'] + '_study'
        df_group['num_boxes'] = df_group.apply(lambda r: len(string2boxes(r['label'])), axis=1)
        df_group = df_group.merge(df_study, left_on='study_id', right_on='id')
        df_group = df_group.rename(columns={'id_x': 'image_id'})
        df_group_list.append(df_group)
        text_file.write(','.join(group_ids) + '\n')for index, df_group in enumerate(df_group_list):
    if len(df_group[df_group['num_boxes'] > 0]) > 1:
        print_group_info(index, df_group)",This code is used to find duplicates in images. The function images_find_duplicates() takes in a list of image files and a threshold value and returns a list of duplicate groups. The function plot_image() is used to plot the images.,8,1,0.15968132435569848
"import pandas as pd# train_df = pd.read_csv('/kaggle/input/siimcovid19-train-data-that-opacitycount-added/train_df.csv')
# local
train_df = pd.read_csv('/kaggle/input/siimcovid19-train-data-that-opacitycount-added/train_df.csv')train_df.head()train_df.drop(columns='Path', axis=1,inplace=True)train_df.head()train_df['Opacity'] = train_df.apply(lambda row : 1 if row.label.split(' ')[0]=='opacity' else 0, axis=1)
train_dftrain_df.drop(columns=['Unnamed: 0'], inplace=True)
train_df","This code imports the pandas library and reads in a CSV file containing training data. The data is then displayed using the head() method. The Path column is dropped from the dataframe, and the Opacity column is created, which contains a 1 if the label for the row indicates opacity, and a 0 otherwise. Finally, the dataframe is displayed again.",9,2,0.0555755926442269
"!pip install -q efficientnet >> /dev/nullimport pandas as pd, numpy as np, random,os, shutil
from glob import glob
from kaggle_datasets import KaggleDatasets
import tensorflow as tf, re, math
import tensorflow.keras.backend as K
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt
import tensorflow_addons as tfa
print('tf:',tf.__version__)# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit
VERBOSE      = 1
DISPLAY_PLOT = True

DEVICE = ""TPU"" #or ""GPU""

# USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD
SEED = 42

# NUMBER OF FOLDS. USE 2, 5, 10
FOLDS = 5

# WHICH IMAGE SIZES TO LOAD EACH FOLD
# CHOOSE 128, 192, 256, 384, 512, 512 
IMG_SIZES = [[512, 512]]*FOLDS

# BATCH SIZE AND EPOCHS
BATCH_SIZES = [24]*FOLDS
EPOCHS      = [10]*FOLDS

# WHICH EFFICIENTNET B? TO USE
EFF_NETS = [6]*FOLDS

# Augmentations
AUGMENT   = True
TRANSFORM = True

# transformations
ROT_    = 0.0
SHR_    = 2.0
HZOOM_  = 8.0
WZOOM_  = 8.0
HSHIFT_ = 8.0
WSHIFT_ = 8.0

# Dropout
PROBABILITY = 0.75
CT          = 8
SZ          = 0.08

#bri, contrast
sat  = (0.7, 1.3)
cont = (0.8, 1.2)
bri  =  0.1

# WEIGHTS FOR FOLD MODELS WHEN PREDICTING TEST
WGTS = [1/FOLDS]*FOLDS

# TEST TIME AUGMENTATION STEPS
TTA = 1def seeding(SEED):
    np.random.seed(SEED)
    random.seed(SEED)
    os.environ['PYTHONHASHSEED'] = str(SEED)
    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)
    tf.random.set_seed(SEED)
    print('seeding done!!!')
seeding(SEED)if DEVICE == ""TPU"":
    print(""connecting to TPU..."")
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        print('Running on TPU ', tpu.master())
    except ValueError:
        print(""Could not connect to TPU"")
        tpu = None

    if tpu:
        try:
            print(""initializing  TPU ..."")
            tf.config.experimental_connect_to_cluster(tpu)
            tf.tpu.experimental.initialize_tpu_system(tpu)
            strategy = tf.distribute.experimental.TPUStrategy(tpu)
            print(""TPU initialized"")
        except _:
            print(""failed to initialize TPU"")
    else:
        DEVICE = ""GPU""

if DEVICE != ""TPU"":
    print(""Using default strategy for CPU and single GPU"")
    strategy = tf.distribute.get_strategy()

if DEVICE == ""GPU"":
    print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
    

AUTO     = tf.data.experimental.AUTOTUNE
REPLICAS = strategy.num_replicas_in_sync
print(f'REPLICAS: {REPLICAS}')GCS_PATH = [None]*FOLDS
for i,k in enumerate(IMG_SIZES):
    GCS_PATH[i] = KaggleDatasets().get_gcs_path('siimcovid19-%ix%i-tfrec-dataset'%(k[0],k[1]))
files_train = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/train*.tfrec')))
files_test  = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/test*.tfrec')))
num_train_files = len(files_train)
num_test_files  = len(files_test)
print('train_files:',num_train_files)
print('test_files:',num_test_files)train_df = pd.read_csv('../input/siim-covid19-yolov5-2class-labels/meta.csv')
train_df.head(2)","This code installs the efficientnet package and imports pandas, numpy, random, os, and shutil. It also imports the KaggleDatasets package and the efficientnet.tfkeras module from the efficientnet package. Finally, it prints the version of TensorFlow being used.

Next, the code sets some parameters. DEVICE can be ""TPU"" or ""GPU"". SEED is the seed for the random number generator. FOLDS is the number of folds for cross-validation. IMG_SIZES is a list of image sizes (in pixels) to be used for each fold. BATCH_SIZES is a list of batch sizes to be used for each fold. EPOCHS is a list of numbers of epochs to be used for each fold. EFF_NETS is a list of which EfficientNet models to use for each fold.

AUGMENT and TRANSFORM are boolean variables that determine whether data augmentation and data transformation will be used, respectively. ROT_, SHR_, HZOOM_, WZOOM_, HSHIFT_, and WSHIFT_ are parameters for the data transformation. PROBABILITY is the probability that a given image will be augmented. CT and SZ are parameters for the data augmentation.

Finally, the code sets the path to the KaggleDatasets files.",8,14,0.1526489959337234
"%cd ../
!mkdir tmp
%cd tmp# Download YOLOv5
!git clone https://github.com/ultralytics/yolov5  # clone repo
%cd yolov5
# Install dependencies
%pip install -qr requirements.txt  # install dependencies

%cd ../
import torch
print(f""Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})"")# Install W&B 
!pip install -q --upgrade wandb
# Login 
import wandb
wandb.login()# Necessary/extra dependencies. 
import os
import gc
import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm
from shutil import copyfile
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

#customize iPython writefile so we can write variables
from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))TRAIN_PATH = 'input/siim-covid19-resized-to-256px-jpg/train/'
IMG_SIZE = 256
BATCH_SIZE = 16
EPOCHS = 10# Everything is done from /kaggle directory.
%cd ../

# Load image level csv file
df = pd.read_csv('input/siim-covid19-detection/train_image_level.csv')

# Modify values in the id column
df['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)
# Add absolute path
df['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)
# Get image level labels
df['image_level'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)

df.head(5)# Load meta.csv file
# Original dimensions are required to scale the bounding box coordinates appropriately.
meta_df = pd.read_csv('input/siim-covid19-resized-to-256px-jpg/meta.csv')
train_meta_df = meta_df.loc[meta_df.split == 'train']
train_meta_df = train_meta_df.drop('split', axis=1)
train_meta_df.columns = ['id', 'dim0', 'dim1']

train_meta_df.head(2)",This code downloads the YOLOv5 repository from GitHub and installs the dependencies. It then loads the image level csv file and the meta.csv file. The image level csv file is used to get the image level labels and the meta.csv file is used to get the original dimensions of the images.,7,3,0.15742896500625553
"# Importing Required packages
import os
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from IPython.display import Image, clear_output
print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))
clear_output()#customize iPython writefile so we can write variables
from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))# Cloning the repo and installing requiements
!git clone https://github.com/ultralytics/yolov5.git
!mv ./yolov5/* ./
!pip install -r requirements.txt
clear_output()# Copying the dataset to working directory
!mkdir Dataset
!cp ../input/covid19-detection-for-yolov5-siimfisabiorsna/Covid19 -r ./Dataset
clear_output()len(os.listdir('./Dataset/Covid19/images'))%%writetemplate ./split_dataset.py
from utils.datasets import * 
autosplit('./Dataset/Covid19', weights=(0.8, 0.2, 0.0))!python split_dataset.py","This code imports the necessary packages for the project, including torch, numpy, pandas, and matplotlib. It also sets up the environment for using iPython.

Next, the code clones the yolov5 repository from GitHub and installs the required packages.

Finally, the code copies the dataset to the working directory and splits it into training, validation, and test sets.",8,3,0.17447378516709705
"! conda install -c conda-forge gdcm -y# import numpy as np # linear algebra
# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
# import os
# import pydicom
# import glob
# from tqdm.notebook import tqdm
# from pydicom.pixel_data_handlers.util import apply_voi_lut
# import matplotlib.pyplot as plt
# from skimage import exposure
# import cv2
# import warnings
# from fastai.vision.all import *
# from fastai.medical.imaging import *
# warnings.filterwarnings('ignore')

import os
import pydicom
import glob
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt 
dataset_path = '../input/siim-covid19-detection/'

for path in glob.glob(dataset_path  + '*'):
    print(path)train_images = '../input/siim-covid19-detection/train/'

n_folders = len(glob.glob(train_images  + '*'))
n_subfolders = len(glob.glob(train_images  + '*/*'))
n_images = len(glob.glob(train_images  + '*/*/*.dcm'))

print(f'There are {n_subfolders} subfolders in {n_folders} folders.')
print(f'There are altogether {n_images} images.')folders = glob.glob(train_images  + '*')

subfolder_dict = {}

for folder in folders:
    n = len(glob.glob(folder + '/*'))
    if n in subfolder_dict.keys():
        subfolder_dict[n] += 1
    else:
        subfolder_dict[n] = 1
        
for k, v in subfolder_dict.items():
    print(f'There is {v} subfolders with {k} images.')

subfolders = glob.glob(train_images  + '*/*')

image_dict = {}

for subfolder in subfolders:
    n = len(glob.glob(subfolder + '/*'))
    if (n!=1):
        print (subfolder.split('/')[-1])
        for image in glob.glob(subfolder + '/*'):
            print ('-->' + image.split('/')[-1])

    if n in image_dict.keys():
        image_dict[n] += 1
    else:
        image_dict[n] = 1
        
for k, v in image_dict.items():
    print(f'There is {v} subfolders with {k} images.')
train_study_df = pd.read_csv(dataset_path +'/train_study_level.csv')

train_study_df","This code imports the necessary libraries for working with the dataset, defines the path to the dataset, and then counts the number of folders, subfolders, and images in the dataset. It also prints out the number of subfolders and images in each folder. Finally, it loops through the subfolders and counts the number of images in each one.",8,0,0.07197869193925975
"import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import glob
import pydicomsiim_covid19_dir = os.path.join(
    '..', 'input', 'siim-covid19-detection')def read_csv(file_name):
    file_path = os.path.join(siim_covid19_dir, file_name)
    df = pd.read_csv(file_path)
    return dfstudy_level_df = read_csv('train_study_level.csv')

study_level_df# How many rows?
study_level_num_rows = len(study_level_df)

study_level_num_rows# Are unique? Any duplicates?
study_level_num_unique_ids = len(pd.unique(study_level_df['id']))

if study_level_num_unique_ids == study_level_num_rows:
    print(""Unique and no duplicates"")
else:
    print(""Some duplicates"")# What are the unique value combinations? How many of them?
study_level_label_colums = [
    'Negative for Pneumonia', 'Typical Appearance',
    'Indeterminate Appearance', 'Atypical Appearance' ]
study_level_labels_df = study_level_df[study_level_label_colums]
study_level_label_values = study_level_labels_df.values

study_level_unique_label_combinations, \
study_level_unique_label_counts = \
    np.unique(
        study_level_label_values, return_counts=True, axis=0)

print(""Unique Combinations:\n"", study_level_unique_label_combinations)
print(""Unique Counts:\n"", study_level_unique_label_counts)","This code imports the necessary libraries for reading in a CSV file, manipulating data, and visualizing data. The code then defines a function for reading in a CSV file. The function takes as input the file name of the CSV file to be read and returns a pandas dataframe.

The code then calls the read_csv function to read in the train_study_level.csv file. The file is read into a pandas dataframe and the number of rows in the dataframe is counted. The code then checks to see if there are any duplicate rows in the dataframe.

The code then extracts the columns containing the labels for each study and counts the number of unique label combinations. The code then prints the unique combinations and counts.",8,5,0.10920091611835213
"# Libraries
import warnings
warnings.filterwarnings('ignore')

import os
import numpy as np
import pandas as pd
import seaborn as sns
import glob
from pandas import DataFrame
from matplotlib.lines import Line2D
import matplotlib.pyplot as plt
%matplotlib inline
import plotly.express as px
from tqdm.notebook import tqdm

# Image processing and Computer Vision
from skimage import exposure
import cv2
# Package designed to manipulate data elements in DICOM files 

import pydicom
#Image Transformation
from pydicom.pixel_data_handlers.util import apply_voi_lut

from fastai.vision.all import *
from fastai.medical.imaging import *

#train_image
train_image_df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
train_image_df.head(2)#train_study
train_study_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
train_study_df.head()# Bar plot function defination
def viz_bar_plot(df,x,x_title,y,title,colors=None,text=None):
    fig = px.bar(x=x,
                 y=y,
                 text=text,
                 labels={x: x_title.title()},   
                 data_frame=df,
                 color=colors,
                 barmode='group',
                 template=""simple_white"")
    texts = [df[col].values for col in y]
    for i, t in enumerate(texts):
        fig.data[i].text = t
        fig.data[i].textposition = 'inside'  
    fig['layout'].title=title
    fig.update_layout(title_font_size=19)
    fig.update_layout(title_font_family='Droid Serif')
    fig.update_layout(width=800,height=500)
    for trace in fig.data:
        trace.name = trace.name.replace('_',' ').title()
    fig.update_yaxes(tickprefix="""", showgrid=True)
    fig.show()# Study Data
# create 'target' column in train_study_df dataset
train_study_df['target']='Negative for Pneumonia'
train_study_df.loc[train_study_df['Typical Appearance']==1,'target']='Typical Appearance'
train_study_df.loc[train_study_df['Indeterminate Appearance']==1,'target']='Indeterminate Appearance'
train_study_df.loc[train_study_df['Atypical Appearance']==1,'target']='Atypical Appearance'
train_study_df1=train_study_df.groupby(['target']).size().reset_index(name='counts')
train_study_df1# Bar Visulaization of label categories
viz_bar_plot(train_study_df1,
         'target',
         'target',
         ['counts'],
         title='Target Label Count')","The code above defines a function for visualizing bar plots, which takes as input a dataframe, two column names (x and y), a title, and optionally a list of colors and/or text. It then creates a bar plot using the Plotly Express library, with the specified columns as the x and y axes, and the specified title. If colors and/or text are provided, they will be used in the plot.",8,2,0.10041543189592951
"! conda install -c conda-forge gdcm -yimport numpy as np
import pandas as pd 
import os
from PIL import Image
from tqdm.auto import tqdm
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import seaborn as sns
from pandas_profiling import ProfileReport
from glob import glob
from tqdm.notebook import tqdm
import matplotlib.pyplot as plt
from skimage import exposure
import cv2
import warnings
import albumentations as A# config params
class CFG:
    data_path = '../input/siim-covid19-detection/'
    size = 512
    seed = 2021
    working_dir = '/kaggle/working/'def dicom2array(path, voi_lut=True, fix_monochrome=True):
    dicom = pydicom.read_file(path)
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
    return data
        
    
def plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()
# storage file for the transformed images
!mkdir train# prepare a dataframe for producing resized images with bboxes
xtrain_img = pd.read_csv(CFG.data_path + 'train_image_level.csv')


path_list = []
image_list = []
splits = []

for split in ['train']:
    
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            fullpath = dirname + '/' + file
            path_list.append(fullpath)
            image_list.append(file)

df = pd.DataFrame(image_list, columns =['image_id'])
df['image_path'] = path_list

xtrain_img['image_id'] = xtrain_img['id'].apply(lambda s: s.replace('_image','') + '.dcm')
xtrain_img = pd.merge(left = xtrain_img, right = df, on = 'image_id')
# common transformation we shall use
transform = A.Compose(
    [
        A.Resize(height = CFG.size , width = CFG.size, p=1),
    ], 
    p=1.0,  bbox_params=A.BboxParams( format='pascal_voc', min_area=0,  min_visibility=0, label_fields=['labels']  ))        

img_list = []
label_list = []

# loop over files
for ii in range(len(xtrain_img)):
    # get the image
    row = xtrain_img.loc[ii]
    img_path = row['image_path']
    img = dicom2array(path=img_path)
    newname = img_path.split('/')[-1].replace('dcm', 'jpg')
    img_list.append(newname)
    
    # get the bounding boxes
    bboxes = []
    bbox = []
    labels = []
    confidences = []

    for i, l in enumerate(row['label'].split(' ')):
        if (i % 6 == 0) :
            labels.append(l)
        if (i % 6 == 1):
            confidences.append(l)
        if (i % 6 > 1):
            bbox.append(np.clip(float(l), a_min = 0, a_max = None ))
        if i % 6 == 5:
            bboxes.append(bbox)
            bbox = []    

    # transform both
    result = transform(image = img, bboxes = bboxes, labels = np.ones(len(bboxes)))
    new_image = result['image']
    new_bboxes = np.array(result['bboxes']).tolist()

    # format the output
#    print('orig label: ' + row['label'])
    newlabel = ''
    if labels[0] == 'none':
        newlabel = 'none 1 0 0 1 1'
    else:
        for j in range(len(labels)):
            newlabel += labels[j] + ' ' + confidences[j] + ' ' +  ' '.join([str(np.round(f,5)) for f in new_bboxes[0]]) + ' '
#    print('new label:' + newlabel)
    label_list.append(newlabel)
    
    # store the new image
    cv2.imwrite(CFG.working_dir + 'train/' + newname , new_image)","This code is responsible for transforming images and bounding boxes in the SIIM-Covid19 dataset. The images are transformed into a 512x512 format, and the bounding boxes are adjusted accordingly. The new images and labels are then saved in the working directory.",8,0,0.13618656250587863
"!wget 'https://anaconda.org/conda-forge/libjpeg-turbo/2.1.0/download/linux-64/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/libgcc-ng/9.3.0/download/linux-64/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/gdcm/2.8.9/download/linux-64/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/conda/4.10.1/download/linux-64/conda-4.10.1-py37h89c1867_0.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/certifi/2020.12.5/download/linux-64/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/openssl/1.1.1k/download/linux-64/openssl-1.1.1k-h7f98852_0.tar.bz2' -q","The above code downloads the following packages from Anaconda:

- libjpeg-turbo
- libgcc-ng
- gdcm
- conda
- certifi
- openssl

Each package is downloaded as a .tar.bz2 file.",8,6,0.22448850310374321
"! conda install gdcm -c conda-forge -y! pip install --no-deps '../input/timm-package/timm-0.1.26-py3-none-any.whl' > /dev/null
! pip install --no-deps '../input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl' > /dev/nullimport sys
sys.path.insert(0, ""../input/timm-efficientdet-pytorch"")
sys.path.insert(0, ""../input/omegaconf"")

import os
from PIL import Image
import pandas as pd
from tqdm.auto import tqdm
import numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import torch
from datetime import datetime
import time
import random
import cv2
import albumentations as A
import matplotlib.pyplot as plt
from albumentations.pytorch.transforms import ToTensorV2
from sklearn.model_selection import StratifiedKFold
from torch.utils.data import Dataset,DataLoader
from torch.utils.data.sampler import SequentialSampler, RandomSampler
from glob import glob

SEED = 42

def seed_everything(seed):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = True

seed_everything(SEED)dataset_path = ""../input/siim-covid19-detection""def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return data

def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im
        
    
def plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()
%%time
image_id = []


cnt_img = 0 # for testing

for split in ['test', 'train']:
    save_dir = f'/kaggle/tmp/{split}/'

    os.makedirs(save_dir, exist_ok=True)
    
    for dirname, _, filenames in tqdm(os.walk(f'{dataset_path}/{split}')):
        for file in filenames:
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(os.path.join(dirname, file))
            im = resize(xray, size=256)  
            im.save(os.path.join(save_dir, file.replace('dcm', 'jpg')))

            image_id.append(file.replace('.dcm', ''))

            splits.append(split)
        
        if cnt_img >= 10:
            cnt_img = 0
            break
        
        cnt_img += 1
            image_id","This code reads in a DICOM image, applies a VOI LUT (if available), and then rescales the image to a human-readable format. It also saves the image in a JPEG format.",8,1,0.10233521738906919
"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -yimport os

from PIL import Image
import pandas as pd
from tqdm.auto import tqdmimport numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im
split = 'test'
save_dir = f'/kaggle/tmp/{split}/'

os.makedirs(save_dir, exist_ok=True)

save_dir = f'/kaggle/tmp/{split}/study/'
os.makedirs(save_dir, exist_ok=True)

for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
    for file in filenames:
        # set keep_ratio=True to have original aspect ratio
        xray = read_xray(os.path.join(dirname, file))
        im = resize(xray, size=600)  
        study = dirname.split('/')[-2] + '_study.png'
        im.save(os.path.join(save_dir, study))
import numpy as np 
import pandas as pd

df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
id_laststr_list  = []
for i in range(df.shape[0]):
    id_laststr_list.append(df.loc[i,'id'][-1])
df['id_last_str'] = id_laststr_list

study_len = df[df['id_last_str'] == 'y'].shape[0]!pip install /kaggle/input/kerasapplications -q
!pip install /kaggle/input/efficientnet-keras-source-code/ -q --no-deps

import os

import efficientnet.tfkeras as efn
import numpy as np
import pandas as pd
import tensorflow as tf

def auto_select_accelerator():
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        tf.config.experimental_connect_to_cluster(tpu)
        tf.tpu.experimental.initialize_tpu_system(tpu)
        strategy = tf.distribute.experimental.TPUStrategy(tpu)
        print(""Running on TPU:"", tpu.master())
    except ValueError:
        strategy = tf.distribute.get_strategy()
    print(f""Running on {strategy.num_replicas_in_sync} replicas"")

    return strategy


def build_decoder(with_labels=True, target_size=(300, 300), ext='jpg'):
    def decode(path):
        file_bytes = tf.io.read_file(path)
        if ext == 'png':
            img = tf.image.decode_png(file_bytes, channels=3)
        elif ext in ['jpg', 'jpeg']:
            img = tf.image.decode_jpeg(file_bytes, channels=3)
        else:
            raise ValueError(""Image extension not supported"")

        img = tf.cast(img, tf.float32) / 255.0
        img = tf.image.resize(img, target_size)

        return img

    def decode_with_labels(path, label):
        return decode(path), label

    return decode_with_labels if with_labels else decode


def build_augmenter(with_labels=True):
    def augment(img):
        img = tf.image.random_flip_left_right(img)
        img = tf.image.random_flip_up_down(img)
        return img

    def augment_with_labels(img, label):
        return augment(img), label

    return augment_with_labels if with_labels else augment


def build_dataset(paths, labels=None, bsize=32, cache=True,
                  decode_fn=None, augment_fn=None,
                  augment=True, repeat=True, shuffle=1024, 
                  cache_dir=""""):
    if cache_dir != """" and cache is True:
        os.makedirs(cache_dir, exist_ok=True)

    if decode_fn is None:
        decode_fn = build_decoder(labels is not None)

    if augment_fn is None:
        augment_fn = build_augmenter(labels is not None)

    AUTO = tf.data.experimental.AUTOTUNE
    slices = paths if labels is None else (paths, labels)

    dset = tf.data.Dataset.from_tensor_slices(slices)
    dset = dset.map(decode_fn, num_parallel_calls=AUTO)
    dset = dset.cache(cache_dir) if cache else dset
    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset
    dset = dset.repeat() if repeat else dset
    dset = dset.shuffle(shuffle) if shuffle else dset
    dset = dset.batch(bsize).prefetch(AUTO)

    return dset

#COMPETITION_NAME = ""siim-cov19-test-img512-study-600""
strategy = auto_select_accelerator()
BATCH_SIZE = strategy.num_replicas_in_sync * 16

IMSIZE = (224, 240, 260, 300, 380, 456, 528, 600)

#load_dir = f""/kaggle/input/{COMPETITION_NAME}/""
sub_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
sub_df = sub_df[:study_len]
test_paths = f'/kaggle/tmp/{split}/study/' + sub_df['id'] +'.png'

sub_df['negative'] = 0
sub_df['typical'] = 0
sub_df['indeterminate'] = 0
sub_df['atypical'] = 0


label_cols = sub_df.columns[2:]

test_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[7], IMSIZE[7]), ext='png')
dtest = build_dataset(
    test_paths, bsize=BATCH_SIZE, repeat=False, 
    shuffle=False, augment=False, cache=False,
    decode_fn=test_decoder
)

with strategy.scope():
    
    models = []
    
    models0 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model0.h5'
    )
    models1 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model1.h5'
    )
    models2 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model2.h5'
    )
    models3 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model3.h5'
    )
    models4 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model4.h5'
    )
    
    models.append(models0)
    models.append(models1)
    models.append(models2)
    models.append(models3)
    models.append(models4)

    
    
    
sub_df[label_cols] = sum([model.predict(dtest, verbose=1) for model in models]) / len(models)","This code installs the pydicom package on your system. pydicom is a Python package for working with DICOM files.

This code also installs the libjpeg-turbo, libgcc-ng, and gdcm packages on your system. These packages are required by pydicom.

This code imports the os, PIL, pandas, tqdm, and numpy packages. These packages are required for the code to run.

This code defines a function to read a DICOM file and apply a VOI LUT to the data if one is available. This function takes two arguments: the path to the DICOM file and a Boolean value indicating whether or not to apply a VOI LUT.

This code defines a function to resize an image. This function takes three arguments: the image to resize, the new size of the image, and a Boolean value indicating whether or not to keep the original aspect ratio.

This code defines a function to decode a DICOM file. This function takes one argument: the path to the DICOM file.

This code defines a function to augment an image. This function takes one argument: the image to augment.

This code defines a function to build a dataset. This function takes seven arguments: the paths to the images, the labels for the images, the batch size, a Boolean value indicating whether or not to cache the dataset, a function to decode the images, a function to augment the images, a Boolean value indicating whether or not to augment the images, a Boolean value indicating whether or not to repeat the dataset, and a Boolean value indicating whether or not to shuffle the dataset.

This code loads the sample submission file.

This code splits the sample submission file into two parts: one part for the studies and one part for the images.

This code loads the model files.

This code predicts the labels for the images in the dataset.

This code saves the predictions to the sample submission file.",8,30,0.09395973289844632
"SEED  = 42
FOLDS = 5
DIM   = 512import numpy as np 
import pandas as pd 
import os, shutil
from glob import glob
from sklearn.cluster import KMeans
from tqdm.notebook import tqdm
from sklearn.preprocessing import LabelEncoder
import random
tqdm.pandas()np.random.seed(SEED)
random.seed(SEED)train_df = pd.read_csv(f'../input/siimcovid19-{DIM}-jpg-image-dataset/train.csv')
train_df['image_path'] = F'../input/siimcovid19-{DIM}-jpg-image-dataset/train/'+train_df.image_id+'.jpg'
train_df.head(2)name2label = {'Typical Appearance': 3,
 'Indeterminate Appearance': 1,
 'Atypical Appearance': 2,
 'Negative for Pneumonia': 0}
class_names = list(name2label.keys())
label2name = {v:k for k, v in name2label.items()}
train_df['class_name']  = train_df.progress_apply(lambda row:row[class_names].iloc[[row[class_names].values.argmax()]].index.tolist()[0], axis=1)
train_df['class_label'] = train_df.class_name.map(name2label)
train_df.head()from sklearn.model_selection import GroupKFold, StratifiedKFold
gkf  = GroupKFold(n_splits = 5)
train_df['fold'] = -1
for fold, (train_idx, val_idx) in enumerate(gkf.split(train_df, groups = train_df.StudyInstanceUID.tolist())):
    train_df.loc[val_idx, 'fold'] = fold
train_df.head()import matplotlib.pyplot as plt
import cv2
def load_image(path, dim=DIM, ch=3):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE if ch==None else cv2.IMREAD_COLOR)
    if img.shape[:2]!=(dim,dim) and dim!=-1:
        img = cv2.resize(img, dsize=(dim,dim), interpolation=cv2.INTER_AREA)
    return img

plt.imshow(load_image(train_df.image_path.iloc[100], dim=-1))","This code loads an image from a given path and resizes it to the specified dimensions. If no dimensions are specified, the image will be resize to 512x512.",8,1,0.04691433386720081
"# !conda install -c conda-forge imagehash --yes%load_ext autoreload
%autoreload 2
%matplotlib inline

import glob
import itertools
import collections

from PIL import Image
import cv2
from tqdm import tqdm_notebook as tqdm
import pandas as pd
import numpy as np
import torch
import imagehash

import matplotlib.pyplot as plt

def run():

    funcs = [
        imagehash.average_hash,
        imagehash.phash,
        imagehash.dhash,
        imagehash.whash,
        #lambda x: imagehash.whash(x, mode='db4'),
    ]

    SOPInstanceUIDs = []
    hashes = []
    for path in tqdm(glob.glob('../input/siim-covid19-resized-to-512px-png/*/*.png')):

        image = Image.open(path)
        imageid = path.split('/')[-1].split('.')[0]

        SOPInstanceUIDs.append(imageid)
        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))

    return SOPInstanceUIDs, np.array(hashes)

%time SOPInstanceUIDs, hashes_all = run()

hashes_all = torch.Tensor(hashes_all.astype(int)).cuda()%time sims = np.array([(hashes_all[i] == hashes_all).sum(dim=1).cpu().numpy()/256 for i in range(hashes_all.shape[0])])
indices1 = np.where(sims > 0.99)
indices2 = np.where(indices1[0] != indices1[1])
SOPInstanceUID1 = [SOPInstanceUIDs[i] for i in indices1[0][indices2]]
SOPInstanceUID2 = [SOPInstanceUIDs[i] for i in indices1[1][indices2]]
dups = {tuple(sorted([SOPInstanceUID1,SOPInstanceUID2])):True for SOPInstanceUID1, SOPInstanceUID2 in zip(SOPInstanceUID1, SOPInstanceUID2)}
print('found %d duplicates' % len(dups))dups",This code uses the imagehash library to generate hashes for images and identify duplicate images.,8,1,0.09282575895792491
"!pip install gdcmimport os
from os import listdir
import pandas as pd
import numpy as np
import glob
from skimage import exposure
import matplotlib.pyplot as plt
%matplotlib inline

# pydicom
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
from fastai.imports import *
from fastai.medical.imaging import *

import cv2

# color
from colorama import Fore, Back, Style

import seaborn as sns
sns.set(style=""whitegrid"")

# plotly
import plotly.express as px
import plotly

# Suppress warnings 
import warnings
warnings.filterwarnings('ignore')

# Settings for pretty nice plots
plt.style.use('fivethirtyeight')
plt.show()# List files available
list(os.listdir(""../input/siim-covid19-detection""))IMAGE_PATH = ""../input/siim-covid19-detection/""

train_study_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
train_image_df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')

print(Fore.YELLOW + 'Train study df shape: ',Style.RESET_ALL,train_study_df.shape)
print(Fore.YELLOW + 'Train image df shape: ',Style.RESET_ALL,train_image_df.shape)display(train_study_df.head(5))
display(train_image_df.head(5))sample_submission = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
print(Fore.YELLOW + 'Sample submission df shape: ',Style.RESET_ALL,sample_submission.shape)
display(sample_submission)# Null values and Data types
print(Fore.BLUE + 'Train Study Set !!',Style.RESET_ALL)
print(train_study_df.info())
print('-------------')
print(Fore.YELLOW + 'Train Image Set !!',Style.RESET_ALL)
print(train_image_df.info())","The code above imports the necessary libraries for reading in the data, processing it, and visualizing it. It then loads the data from the input files and prints out the shape of the dataframes. Finally, it displays the first 5 rows of the dataframes.",8,2,0.03655138699833442
"!pip install -q efficientnet >> /dev/nullimport pandas as pd, numpy as np, random,os, shutil
from glob import glob
from kaggle_datasets import KaggleDatasets
import tensorflow as tf, re, math
import tensorflow.keras.backend as K
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt
import tensorflow_addons as tfa
print('tf:',tf.__version__)# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit
VERBOSE      = 0
DISPLAY_PLOT = True

DEVICE = ""TPU"" #or ""GPU""

# USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD
SEED = 42

# NUMBER OF FOLDS. USE 2, 5, 10
FOLDS = 5

# WHICH IMAGE SIZES TO LOAD EACH FOLD
# CHOOSE 128, 192, 256, 384, 512, 512 
IMG_SIZES = [[512, 512]]*FOLDS

# BATCH SIZE AND EPOCHS
BATCH_SIZES = [16]*FOLDS
EPOCHS      = [12]*FOLDS

# WHICH EFFICIENTNET B? TO USE
EFF_NETS = [7]*FOLDS

# Augmentations
AUGMENT   = True
TRANSFORM = True

# transformations
ROT_    = 0.0
SHR_    = 2.0
HZOOM_  = 8.0
WZOOM_  = 8.0
HSHIFT_ = 8.0
WSHIFT_ = 8.0

# Dropout
PROBABILITY = 0.75
CT          = 8
SZ          = 0.08

#bri, contrast
sat  = (0.7, 1.3)
cont = (0.8, 1.2)
bri  =  0.1

# WEIGHTS FOR FOLD MODELS WHEN PREDICTING TEST
WGTS = [1/FOLDS]*FOLDS

# TEST TIME AUGMENTATION STEPS
TTA = 1def seeding(SEED):
    np.random.seed(SEED)
    random.seed(SEED)
    os.environ['PYTHONHASHSEED'] = str(SEED)
    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)
    tf.random.set_seed(SEED)
    print('seeding done!!!')
seeding(SEED)if DEVICE == ""TPU"":
    print(""connecting to TPU..."")
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        print('Running on TPU ', tpu.master())
    except ValueError:
        print(""Could not connect to TPU"")
        tpu = None

    if tpu:
        try:
            print(""initializing  TPU ..."")
            tf.config.experimental_connect_to_cluster(tpu)
            tf.tpu.experimental.initialize_tpu_system(tpu)
            strategy = tf.distribute.experimental.TPUStrategy(tpu)
            print(""TPU initialized"")
        except _:
            print(""failed to initialize TPU"")
    else:
        DEVICE = ""GPU""

if DEVICE != ""TPU"":
    print(""Using default strategy for CPU and single GPU"")
    strategy = tf.distribute.get_strategy()

if DEVICE == ""GPU"":
    print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
    

AUTO     = tf.data.experimental.AUTOTUNE
REPLICAS = strategy.num_replicas_in_sync
print(f'REPLICAS: {REPLICAS}')GCS_PATH = [None]*FOLDS
for i,k in enumerate(IMG_SIZES):
    GCS_PATH[i] = KaggleDatasets().get_gcs_path('siimcovid19-%ix%i-tfrec-dataset'%(k[0],k[1]))
files_train = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/train*.tfrec')))
files_test  = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/test*.tfrec')))
num_train_files = len(files_train)
num_test_files  = len(files_test)
print('train_files:',num_train_files)
print('test_files:',num_test_files)train_df = pd.read_csv('../input/siim-covid19-yolov5-2class-labels/meta.csv')
train_df.head(2)","This code imports the necessary libraries for the project, sets up the TPU or GPU for training, and loads in the training and testing data. The training data is then displayed in a DataFrame.",8,1,0.07974651089676651
"import pandas as pd df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')dfid_laststr_list  = []
for i in range(df.shape[0]):
    id_laststr_list.append(df.loc[i,'id'][-1])
df['id_last_str'] = id_laststr_liststudy_len = df[df['id_last_str'] == 'y'].shape[0]study_str = 'negative 1 0 0 1 1 atypical 1 0 0 1 1 typical 1 0 0 1 1 indeterminate 1 0 0 1 1'
for i in range(study_len):
    df.loc[i, 'PredictionString'] = study_strdf = df[['id', 'PredictionString']]","This code imports the pandas library and reads in a CSV file containing submission data for a SIIM-COVID19 detection study.

Next, a list is created containing the last character of each 'id' string in the dataframe. This list is then added as a new column ('id_last_str') to the dataframe.

The code then counts the number of rows in the dataframe with an 'id_last_str' value of 'y', indicating that these are the rows corresponding to the study participants.

A string is then created containing the study results for each participant, which are then assigned to the 'PredictionString' column in the dataframe for each row.

Finally, the code creates a new dataframe containing only the 'id' and 'PredictionString' columns, which is the required format for submission.",8,9,0.07878213947078802
"import numpy as np 
import pandas as pd 
import os
from tqdm import tqdm
import matplotlib.pyplot as plt
import pydicomtrain_st = pd.read_csv(""../input/siim-covid19-detection/train_study_level.csv"")
train_st.head(3)
train_im = pd.read_csv(""../input/siim-covid19-detection/train_image_level.csv"")
train_im.head(3)sample = pd.read_csv(""../input/siim-covid19-detection/sample_submission.csv"")
sample.head(3)train_path = ""../input/siim-covid19-detection/train""
test_path = ""../input/siim-covid19-detection/test""trainimlist = []

for dirname, _, filenames in os.walk(train_path):
    for filename in filenames:
        trainimlist.append(os.path.join(dirname, filename))testimlist = []

for dirname, _, filenames in os.walk(test_path):
    for filename in filenames:
        testimlist.append(os.path.join(dirname, filename))","The code above imports the necessary libraries for working with the data, including numpy, pandas, os, tqdm, and matplotlib. It also loads in the train and test data from the siim-covid19-detection dataset.

Next, the code creates two lists, trainimlist and testimlist, which contain the filenames of all the images in the train and test sets, respectively.

Finally, the code loops through the train and test sets, loading each image into memory.",8,6,0.11082537099271172
"import fastai
import fastai.medical
from fastai.basics import *
from fastai.vision.all import *
from fastai.medical.imaging import *

import pydicom

import pandas as pd
fastai.__version__!conda install -c conda-forge gdcm -yfilegroup='train'
path='../input/siim-covid19-detection'
dirName = f'{path}/{filegroup}/'# Get DICOM file list from train directory
items = get_dicom_files(dirName)df_trn = pd.DataFrame.from_dicoms(items,px_summ=False)
df_trn.to_csv(f'alldicom{filegroup}.csv')
df_trn.describe()
df_trnfilegroup='test'
dirName = f'{path}/{filegroup}/'","The code imports the fastai and fastai.medical libraries, and then from the fastai.basics and fastai.vision.all libraries. It also imports the pydicom library.

The code then sets up a filegroup variable, which will be used to get a list of DICOM files from a given directory. The code then creates a DataFrame from the DICOM files, and saves it as a CSV file. Finally, the code describes the contents of the DataFrame.",8,10,0.1603188703897758
"import numpy as np 
import pandas as pd
import os
import matplotlib.pyplot as plt
import pydicom as dicom
from glob import glob
from pathlib import Path
from pydicom import dcmread
import matplotlib
import astStudy= pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')Study.describe()Study.head()Study.isnull().sum()image_level=pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')image_level.head()","The code imports the necessary libraries for data analysis and visualisation. It then reads in two data files, one containing information at the study level and the other containing information at the image level. The code then performs some basic data analysis and visualisation.",8,2,0.01069776411357523
"#Attaullah
#attaullahshafiq10@gmail.com
# Import libs
!conda install gdcm -c conda-forge -y
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
import pydicom
import glob
from tqdm.notebook import tqdm
from pydicom.pixel_data_handlers.util import apply_voi_lut
import matplotlib.pyplot as plt
from skimage import exposure#import gdcm
import cv2
import warnings
from fastai.vision.all import *
from fastai.medical.imaging import *
warnings.filterwarnings('ignore')
dataset_path = Path('../input/siim-covid19-detection')
import vtk

from vtk.util import numpy_support

reader = vtk.vtkDICOMImageReader()#HTML view

from IPython.display import HTML
HTML('<iframe src=https://arxiv.org/pdf/1506.01497.pdf width=600 height=650></iframe>')# from https://www.kaggle.com/tanlikesmath/siim-covid-19-detection-a-simple-eda
def dicom2array(path, voi_lut=True, fix_monochrome=True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()


def plot_imgs(imgs, cols=4, size=7, is_rgb=True, title="""", cmap='gray', img_size=(500,500)):
    rows = len(imgs)//cols + 1
    fig = plt.figure(figsize=(cols*size, rows*size))
    for i, img in enumerate(imgs):
        if img_size is not None:
            img = cv2.resize(img, img_size)
        fig.add_subplot(rows, cols, i+1)
        plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()dicom_paths = get_dicom_files(dataset_path/'train')
print([str(path) for path in dicom_paths[:4]])
imgs = [dicom2array(str(path)) for path in dicom_paths[:4]]
plot_imgs(imgs)","This code imports the necessary libraries for reading and processing DICOM files, as well as for displaying the results. It then defines a function for converting DICOM files to numpy arrays, which can be used for further processing. The code also includes a function for plotting images, which can be used to visualize the results of the conversion function. Finally, the code uses the functions to read and plot a sample of four DICOM files from the dataset.",9,1,0.0947998628735531
"!pip install -q --upgrade wandb

import wandb
wandb.login()import os
import gc
import cv2
import ast
import numpy as np
import pandas as pd
from tqdm import tqdm
import matplotlib.pyplot as plt
%matplotlib inlineTRAIN_PATH = '../input/siim-covid19-resized-to-256px-jpg/train/'
IMG_SIZE = 256
NUM_SAMPLES_TO_VIZ = 32# Load image level csv file
df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
# Load study level csv file
label_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')

# Modify values in the id column
df['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)
# Add absolute path
df['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)
# Get image level labels
df['image_level'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)

# Modify values in the id column
label_df['id'] = label_df.apply(lambda row: row.id.split('_')[0], axis=1)
# Rename the column id with StudyInstanceUID
label_df.columns = ['StudyInstanceUID', 'Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']

# Merge both dataframes
df = df.merge(label_df, on='StudyInstanceUID',how=""left"")
df.head(2)print(f'Number of unique image in training dataset: {len(df)}')

bbox_nan_num = df['boxes'].isna().sum()
print(f'Number of images without any bbox annotation: {bbox_nan_num}')# Label encode study-level labels
labels = df[['Negative for Pneumonia','Typical Appearance','Indeterminate Appearance','Atypical Appearance']].values
labels = np.argmax(labels, axis=1)

df['study_level'] = labels
df.head(2)class_label_to_id = {
    'Negative for Pneumonia': 0,
    'Typical Appearance': 1,
    'Indeterminate Appearance': 2,
    'Atypical Appearance': 3
}

class_id_to_label = {val: key for key, val in class_label_to_id.items()}","This code imports the wandb library and uses it to login to a wandb account. It then imports the os, gc, cv2, ast, numpy, pandas, tqdm, and matplotlib libraries. The code defines the TRAIN_PATH, IMG_SIZE, and NUM_SAMPLES_TO_VIZ variables.

The code loads the image level csv file into a pandas dataframe and modifies the values in the id column. It then adds the absolute path to each image. The code gets the image level labels and adds them to the dataframe.

The code loads the study level csv file into a pandas dataframe and modifies the values in the id column. It then renames the id column to StudyInstanceUID. The code merges the two dataframes and prints the number of unique images in the training dataset.

The code encodes the study-level labels and adds them to the dataframe. The code then defines the class_label_to_id and class_id_to_label dictionaries.",8,21,0.15345626172218244
"!conda install gdcm -c conda-forge -yimport os

from PIL import Image
import pandas as pd
from tqdm.auto import tqdmimport numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return imtrain = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')path = '../input/siim-covid19-detection/train/ae3e63d94c13/288554eb6182/e00f9fe0cce5.dcm'
dicom = pydicom.read_file(path)image_id = []
dim0 = []
dim1 = []
splits = []

for split in ['test', 'train']:
    save_dir = f'/kaggle/tmp/{split}/'

    os.makedirs(save_dir, exist_ok=True)
    
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(os.path.join(dirname, file))
            im = resize(xray, size=768)  
            im.save(os.path.join(save_dir, file.replace('dcm', 'jpg')))

            image_id.append(file.replace('.dcm', ''))
            dim0.append(xray.shape[0])
            dim1.append(xray.shape[1])
            splits.append(split)","This code reads in a DICOM image, applies a VOI LUT if available, and then rescales the image to the range [0, 1]. It also optionally inverts the image if the DICOM photometric interpretation is MONOCHROME1. Finally, it resizes the image to a specified size.",9,1,0.18133211522083176
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport sys
sys.path.append('../input/timm-pytorch-models/archive (3)/pytorch-image-models-master')
import timmimport numpy as np 
import pandas as pd 

import math
import random 
import os 
import cv2
import timm

from tqdm import tqdm 

import albumentations as A 
from albumentations.pytorch.transforms import ToTensorV2
import torch 
from torch.utils.data import Dataset 
from torch import nn
import torch.nn.functional as F 

import gc
import cudf
import cuml
import cupy
from cuml.feature_extraction.text import TfidfVectorizer
from cuml.neighbors import NearestNeighborsclass CFG:
    
    img_size = 512
    batch_size = 12
    seed = 2020
    
    device = 'cuda'
    classes = 11014
    
    model_name = 'eca_nfnet_l0'
    model_path = '../input/pytorch-model-weights/arcface_512x512_nfnet_l0 (mish).pt'
    
    scale = 30 
    margin = 0.5def read_dataset():
    df = pd.read_csv('../input/shopee-product-matching/test.csv')
    df_cu = cudf.DataFrame(df)#cuDF is a Python GPU DataFrame library workflow is fast enough on a single GPU fits in memory on a single GPU
    image_paths = '../input/shopee-product-matching/test_images/' + df['image']
    return df, df_cu, image_pathsdef seed_torch(seed=42):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    
seed_torch(CFG.seed)def get_image_predictions(df, embeddings,threshold = 0.0):
    
    if len(df) > 3:
        KNN = 50
    else : 
        KNN = 3
    
    model = NearestNeighbors(n_neighbors = KNN, metric = 'cosine')
    model.fit(embeddings)
    distances, indices = model.kneighbors(embeddings)
    
    predictions = []
    for k in tqdm(range(embeddings.shape[0])):
        idx = np.where(distances[k,] < threshold)[0]
        ids = indices[k,idx]
        posting_ids = df['posting_id'].iloc[ids].values
        predictions.append(posting_ids)
        
    del model, distances, indices
    gc.collect()
    return predictions","This Python 3 environment comes with many helpful analytics libraries installed.

The kaggle/python Docker image: https://github.com/kaggle/docker-python contains these libraries.

The input data files are available in the read-only ""../input/"" directory.

For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory.

You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"".

You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session.",9,5,0.3132507839338754
"%%capture
!pip install ../input/pytorchimagemodelsimport sys
sys.path.append('../input/facebookdeit')import os
import gc
import sys

import math
import random

from tqdm.notebook import tqdm

import re

import cv2
import numpy as np
import pandas as pd

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset ,RandomSampler

import timm

import albumentations

from swav_resnet import resnet50w2

import transformers
from transformers import AutoModel, AutoTokenizer

from models import deit_base_distilled_patch16_224



import cudf
import cuml
import cupydef set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True

set_seed(0)text_models=[
    {
        'transformer_model': '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14',
        'model_path' : '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14/ckpt.pt',
        'MAX_LEN' : 128,
        'params' : {
            'embed_dim' :1024,
            'out_dim' : 11014
        }
        
    },
    {
            'transformer_model': '../input/shopee-bert-base-indonesian/bert-base-indonesian_pp_7_8',
            'model_path' : '../input/shopee-bert-base-indonesian/bert-base-indonesian_pp_7_8/ckpt.pt',
            'MAX_LEN' : 128,
            'params' : {
                'embed_dim' :1024,
                'out_dim' : 11014
            }

        }
]

TRANSFORMER_EMBED_DIM = 768joint_models=[
    {
        'transformer_model': '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14',
        'model_path' : '../input/deit-xlm-joint-weights/finetuned_deit_xlm_joint_7_11.pt',
        'MAX_LEN' : 128,
        'IMAGE_SIZE' : 224,
        'params' : {
                'embed_dim' : 2048,
                'out_dim' : 11014
            }
        
    }
]image_models=[
    {
        'vision_model': '../input/shopee-swav-finetuned-resnet50w2/swav_resnet50w2_224_2048_5_epochs_loss_12_beef.pt',
        'IMAGE_SIZE' : 224,
        'params' : {
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
    {
        'vision_model': '../input/effnet-weights/finetuned_tf_efficientnet_b3_ns_300_2048_7_9.pt',
        'IMAGE_SIZE' : 300,
        'params' : {
            'backbone_name' : 'tf_efficientnet_b3_ns',
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
    
    {
        'vision_model': '../input/deit-base-distilled-patch16-224/finetuned_deit_base_distilled_patch16_224_4_18.pt',
        'IMAGE_SIZE' : 224,
        'params' : {
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
]","This code defines three types of models: text, image, and joint.

The text models are based on the transformer architecture and are pretrained on the paraphrase dataset.

The image models are based on the resnet50 and efficientnet architectures and are pretrained on the ImageNet dataset.

The joint models are based on the transformer architecture and are pretrained on the paraphrase and image datasets.",8,1,0.016929648191375265
"import sys
import gc
import math
import configparser
import numpy as np
import pandas as pd
import optuna
from tqdm import tqdm
import sklearn
import tensorflow as tf
from tensorflow import keras
from typing import Tupletry:
    # TPU detection. No parameters necessary if TPU_NAME environment variable is
    # set: this is always the case on Kaggle.
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
    print('Running on TPU ', tpu.master())
except ValueError:
    tpu = None

if tpu:
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.TPUStrategy(tpu)
else:
    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.
    strategy = tf.distribute.get_strategy()

print(""REPLICAS: "", strategy.num_replicas_in_sync)pd.set_option(""use_inf_as_na"", True)
pd.set_option(""display.max_columns"", 9999)
pd.set_option(""display.max_rows"", 9999)
pd.set_option('max_colwidth', 9999)
INPUT = '/kaggle/input'
DATA = f'{INPUT}/shopee-product-matching'
OUTPUT = '/kaggle/working'
RESOURCE_DIR = f'{INPUT}/shopee-product-matching-lib/kaggle-shopee-product-matching-1.0'
sys.path.append(f'{INPUT}/sgcharts-ml/src')
sys.path.append(f""{INPUT}/sentence-transformers/sentence-transformers-1.0.4"")
sys.path.append(f'{RESOURCE_DIR}/src')
import mylib
import scml
from scml.nlp import strip_punctuation, to_ascii_str
scml.seed_everything()MODEL = 'efficientnetb3'
CONF = configparser.ConfigParser()
CONF.read(f""{RESOURCE_DIR}/app.ini"")
resolution = int(CONF[MODEL][""resolution""])
INPUT_SHAPE = (resolution, resolution, 3)
print(f""INPUT_SHAPE={INPUT_SHAPE}"")train = pd.read_csv(f""{DATA}/train.csv"", engine=""c"", low_memory=False)
train[""target""] = mylib.target_label(train)
le = sklearn.preprocessing.LabelEncoder()
train[""label_group""] = le.fit_transform(train['label_group'])
n_classes=len(le.classes_)
print(f""n_classes={n_classes}"")
train.info()train.head()def _data_gen(
    dataframe,
    directory,
    target_size,
    batch_size,
    color_mode=""rgb"",
    class_mode=""raw"",
    x_col=""image"",
    y_col=""label_group""
):
    dtype = np.float32
    rescale = 1./255
    interpolation = ""bicubic""
    data_format = ""channels_last""
    shuffle = True
    idg = keras.preprocessing.image.ImageDataGenerator(
        shear_range=0.2,
        zoom_range=0.2,
        brightness_range=(0.7, 1.3),
        #rotation_range=90,
        horizontal_flip=True,
        rescale=rescale,
        data_format=data_format,
        dtype=dtype
    )
    g = idg.flow_from_dataframe(
        dataframe=dataframe,
        x_col=x_col,
        y_col=y_col,
        directory=directory,
        target_size=target_size,
        color_mode=color_mode,
        batch_size=batch_size,
        shuffle=shuffle,
        class_mode=class_mode,
        interpolation=interpolation,
    )
    while True:
        x, y = g.next()
        yield [x, y], y","This code defines a function for generating image data for training a machine learning model. The function takes as input a dataframe containing image data, a directory containing the images, target image size, batch size, color mode, class mode, and column names for the image data and target labels. The function outputs a generator that yields image data and labels for training the model.",8,1,0.0739859159593561
"import pip
try:
     __import__(""imutils"")
except ImportError:
    pip.main([""install"", ""imutils""])import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import  matplotlib.pyplot as plt
import tensorflow as tf
import pandas as pd
import cv2
from imutils.object_detection import non_max_suppression
import pytesseract
import os
import glob
os.chdir('/kaggle/working')
BASE = '../input/shopee-product-matching/train_images/'
EAST_PATH = ""/kaggle/input/east-data-leo/frozen_east_text_detection/frozen_east_text_detection.pb""
RESIZE_IMG_SHAPE = (500,500)
img_paths = glob.glob(f""{BASE}*jpg"") train = pd.read_csv('../input/shopee-product-matching/train.csv')
print('train shape is', train.shape )
train.head()groups = train.label_group.value_counts()
plt.figure(figsize=(20,5))
plt.plot(np.arange(len(groups)),groups.values)
plt.ylabel('Duplicate Count',size=14)
plt.xlabel('Index of Unique Item',size=14)
plt.title('Duplicate Count vs. Unique Item Count',size=16)
plt.show()

plt.figure(figsize=(20,5))
plt.bar(groups.index.values[:50].astype('str'),groups.values[:50])
plt.xticks(rotation = 45)
plt.ylabel('Duplicate Count',size=14)
plt.xlabel('Label Group',size=14)
plt.title('Top 50 Duplicated Items',size=16)
plt.show()def img_proc(img,offset =20):
    img =img[offset:-offset,offset:-offset]
    img =cv2.resize(img ,RESIZE_IMG_SHAPE)
    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    gray = cv2.medianBlur(gray,5)
    ret, thresh = cv2.threshold(gray,150,255,cv2.THRESH_BINARY)
    thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\
            cv2.THRESH_BINARY_INV,21,2)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))
    opening = cv2.erode(thresh,kernel, iterations = 1)
    closing = cv2.dilate(opening,kernel,iterations=1)
    contours = cv2.findContours(closing, 
                            cv2.RETR_EXTERNAL,
                            cv2.CHAIN_APPROX_NONE)
    canvas =np.zeros((500,500))
    cv2.drawContours(canvas, contours[0], -1, (255,0,255), thickness = 2) 
    return canvas



def displayDF(train, random=False, COLS=6, ROWS=4, path=BASE):
    for k in range(ROWS):
        plt.figure(figsize=(20,5))
        for j in range(COLS):
            if random: row = np.random.randint(0,len(train))
            else: row = COLS*k + j
            name = train.iloc[row,1]
            title = train.iloc[row,3]
            title_with_return = """"
            for i,ch in enumerate(title):
                title_with_return += ch
                if (i!=0)&(i%20==0): title_with_return += '\n'
            img = img_proc(cv2.imread(path+name))
            plt.subplot(1,COLS,j+1)
            plt.title(title_with_return)
            plt.axis('off')
            plt.imshow(img)
        plt.show()
        
displayDF(train,random=True)def predictions(prob_score, geo,min_conf):
    (numR, numC) = prob_score.shape[2:4]
    boxes = []
    confidence_val = []
    for y in range(0, numR):
        scoresData = prob_score[0, 0, y]
        x0 = geo[0, 0, y]
        x1 = geo[0, 1, y]
        x2 = geo[0, 2, y]
        x3 = geo[0, 3, y]
        anglesData = geo[0, 4, y]
        for i in range(0, numC):
            if scoresData[i] < min_conf:
                continue
            (offX, offY) = (i * 4.0, y * 4.0)
            angle = anglesData[i]
            cos = np.cos(angle)
            sin = np.sin(angle)
            h = x0[i] + x2[i]
            w = x1[i] + x3[i]
            endX = int(offX + (cos * x1[i]) + (sin * x2[i]))
            endY = int(offY - (sin * x1[i]) + (cos * x2[i]))
            startX = int(endX - w)
            startY = int(endY - h)
            boxes.append((startX, startY, endX, endY))
            confidence_val.append(scoresData[i])

    return (boxes, confidence_val)

def get_text(img,img_text ='Output',min_conf = 0.7, east = EAST_PATH):
    image = cv2.imread(img)
    orig = image.copy()
    (origH, origW) = image.shape[:2]
    (newW, newH) = (320,320)
    rW = origW / float(newW)
    rH = origH / float(newH)
    image = cv2.resize(image, (newW, newH))
    (H, W) = image.shape[:2]
    blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),
        (123.68, 116.78, 103.94), swapRB=True, crop=False)
    net = cv2.dnn.readNet(east)
    # The following two layer need to pulled from EAST model for achieving this. 
    layerNames = [
        ""feature_fusion/Conv_7/Sigmoid"",
        ""feature_fusion/concat_3""]

    #Forward pass the blob from the image to get the desired output layers
    net.setInput(blob)
    (scores, geometry) = net.forward(layerNames)
    (boxes, confidence_val) = predictions(scores, geometry,min_conf)
    boxes = non_max_suppression(np.array(boxes), probs=confidence_val)
    
    results = []
    for (startX, startY, endX, endY) in boxes:
        startX = int(startX * rW)
        startY = int(startY * rH)
        endX = int(endX * rW)
        endY = int(endY * rH)
        r = orig[startY:endY, startX:endX]
        configuration = (""-l eng --oem 1 --psm 8"")
        text = pytesseract.image_to_string(r, config=configuration)
        results.append(((startX, startY, endX, endY), text))

    orig_image = orig.copy()
    txts=[]
    for ((start_X, start_Y, end_X, end_Y), text) in results:
        text = """".join([x if ord(x) < 128 else """" for x in text]).strip()
        cv2.rectangle(orig_image, (start_X, start_Y), (end_X, end_Y),
            (0, 0, 255), 2)
        cv2.putText(orig_image, text, (start_X, start_Y + 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,255, 0), 4)
        txts.append(text)
    plt.figure(figsize=(10,10))
    plt.imshow(orig_image)
    plt.title(img_text)
    plt.show()
    print(txts)it = iter(range(500))","This code imports the pip module and then tries to import the imutils module. If the imutils module is not found, the code uses pip to install it. The code then imports the numpy, pandas, matplotlib, and tensorflow modules.

The code defines a function to process images. The function takes an image as input and offsets the image by 20 pixels. The function then resizes the image to 500x500 and converts it to grayscale. The function then uses thresholding to find contours in the image and draws them on a canvas. The function returns the canvas.

The code then defines a function to display a dataframe. The function takes a dataframe and an optional boolean parameter ""random"". If the ""random"" parameter is set to True, the function will display a random selection of images from the dataframe. If the ""random"" parameter is set to False, the function will display the first 16 images from the dataframe. The function will also take an optional parameter ""path"" which specifies the path to the directory containing the images.

The code then calls the displayDF function to display a random selection of images from the dataframe.

The code then defines a function to get text from an image. The function takes an image, an optional parameter ""min_conf"" which specifies the minimum confidence threshold, and an optional parameter ""east"" which specifies the path to the EAST text detector. The function will use the EAST text detector to detect text in the image and return the text as a list.

The code then calls the get_text function to get text from an image. The code will also print the text to the console.",8,13,0.09546416926351962
,This code defines a function that calculates the factorial of a number.,8,0,
"import pandas as pd
import numpy as np
from sklearn.neighbors import KNeighborsClassifier# Считаем csv файлы в Pandas датафрейм
train = pd.read_csv('../input/digit-recognizer/train.csv')
test = pd.read_csv('../input/digit-recognizer/test.csv')# Посмотрим на тренировочный датафрейм
train.head()# Узнаем число пропущенных значений 
# и какому признаку принадлежит больше всего пропусков
sum(train.isnull().sum())# Посмотрим на тестовый датафрейм
test.head()# Узнаем число пропущенных значений 
# и какому признаку принадлежит больше всего пропусков
sum(test.isnull().sum())# Пропущенных значений нет, потому можно продолжать работу с выборками","This code imports the pandas and numpy libraries and the KNeighborsClassifier module from the sklearn.neighbors library.

It then reads in the train.csv and test.csv files as pandas dataframes.

Next, it displays the first 5 rows of the train dataframe.

It then calculates the number of missing values in the train dataframe and displays which feature has the most missing values.

Finally, it displays the first 5 rows of the test dataframe and calculates the number of missing values in that dataframe.",9,8,0.08424330439266713
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset

import wandb
from kaggle_secrets import UserSecretsClient
user_secrets = UserSecretsClient()
secret_value_0 = user_secrets.get_secret(""WANDB_KEY"")
wandb.login(key=secret_value_0)
wandb.init(project='MNIST_MLP', save_code=True)class MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return datatransformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])

train_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)
# TODO split train between validation and training set
training_size = int(0.7 * len(train_dataset))
validation_size = len(train_dataset) - training_size
train, val = torch.utils.data.random_split(train_dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))
# create data loader for train and test set
data_loader_train = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True)
data_loader_val = torch.utils.data.DataLoader(val, batch_size=32, shuffle=True)

test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)def init_my_layer(m):
    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('tanh'))
    torch.nn.init.constant_(m.bias, 0)
    return m

class Net(nn.Module):    
    def __init__(self):
        super(Net, self).__init__()
        self.relu = nn.ReLU()
        self.ln1 = init_my_layer(nn.Linear(28*28, 28))
        self.ln2 = init_my_layer(nn.Linear(28, 28))
        self.ln3 = init_my_layer(nn.Linear(28, 10))
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        x = self.relu(self.ln1(x))
        x = self.relu(self.ln2(x))
        return self.softmax(self.ln3(x))model = Net()

# check if a GPU with Cuda capacities is available
device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"") #0, first GPU if multiple one
model.to(device)
learning_rate = 1e-3
lambda_l2 = 1e-5

criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=lambda_l2)
wandb.watch(model, log=""all"", criterion=criterion, log_freq=1,  log_graph=(True)) 


nb_epochs = 10
# Training
for t in range(nb_epochs):
    model.train() # put the network in training mode
    for X, y in data_loader_train:
        # Feed forward to get the logits
        #format data
        b = X.size(0)
        X = X.view(b,-1)
        y_pred = model(X)
        # Compute the loss and accuracy
        loss = criterion(y_pred, y)
        score, predicted = torch.max(y_pred, 1)
        acc = (y == predicted).sum().float() / len(y)
        wandb.log({
            'mlp/train_loss': loss.item(),
            'mlp/train_accuracy': acc,
        })
        # zero the gradients before running
        # the backward pass.
        optimizer.zero_grad()
        # Backward pass to compute the gradient
        # of loss w.r.t our learnable params. 
        loss.backward()
        # Update params
        optimizer.step()
        
    with torch.no_grad(): # validation run
        model.eval() # validation mode
        for X, y in data_loader_val:
            #format data
            b = X.size(0)
            X = X.view(b,-1)
            y_pred = model(X)
            validation_loss = criterion(y_pred, y)
            score, predicted = torch.max(y_pred, 1)
            acc = (y == predicted).sum().float() / len(y)
            wandb.log({
                'mlp/val_loss': loss.item(),
                'mlp/val_accuracy': acc,
            })
","MyMNISTDataset:

This class inherits from the Dataset class in the torch library. It is used to load and process data for the MNIST dataset. The constructor takes in a file path, a transform object, and a boolean value for whether or not the data is for the test set. The file path is used to load the data from a CSV file. The transform object is used to apply transformations to the data. The boolean value is used to determine whether or not to include target values in the data.

The __len__ function returns the length of the dataset. The __getitem__ function returns a data point from the dataset. If the data is for the test set, then only the data point is returned. If the data is for the training set, then both the data point and the target value are returned.

DataLoader:

This class is used to load data in batches. The constructor takes in a dataset, a batch size, and a boolean value for whether or not to shuffle the data. The dataset is used to load the data. The batch size is used to determine the size of each batch. The boolean value is used to determine whether or not to shuffle the data before each epoch.

The __iter__ function returns an iterator for the dataset. The __len__ function returns the number of batches in the dataset.

Net:

This class inherits from the nn.Module class in the torch library. It is used to define a neural network for the MNIST dataset. The constructor initializes the layers of the network. The forward function takes in an input and passes it through the layers of the network. It returns the output of the network.

The init_my_layer function is used to initialize the weights and biases of the network. The relu function is used to apply the ReLU activation function to the output of the network. The ln1, ln2, and ln3 functions are used to apply the linear transformation to the output of the network. The softmax function is used to apply the softmax activation function to the output of the network.

Training:

The training loop iterates over the data_loader_train object. For each batch of data, the network is fed the data and the target values. The loss is calculated and the gradients are computed. The weights and biases are",8,23,0.25767189831993975
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import tensorflow as tf
import tensorflow.keras.layers as tfl
import tensorflow.keras as keras
import matplotlib.pyplot as plt
import sklearn.model_selection as model_sel


# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiondf = pd.read_csv('../input/digit-recognizer/train.csv')
df.head()X = df.drop(columns=['label'])
X.head()X = X.to_numpy().reshape(-1,28,28,1)X = X/255
X.shapeplt.figure(figsize = (10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.imshow(X[i])
    plt.xticks([])
    plt.yticks([])
    plt.xlabel(df['label'][i])X_train, X_test, Y_train, Y_test = model_sel.train_test_split(X, df['label'].to_numpy().reshape(-1,1), test_size=0.25, random_state=1)","The code above loads in the necessary libraries for data processing, machine learning, and visualization. It then loads the dataset from the /kaggle/input directory.

Next, the code splits the dataset into training and testing sets, and then visualizes some of the images from the dataset.",8,1,0.16435525738168866
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport torchvision
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import wandb

from kaggle_secrets import UserSecretsClient
user_secrets = UserSecretsClient()
secret_value = user_secrets.get_secret(""WANDB_KEY"")

wandb.login(key=secret_value)
wandb.init(project='MNIST_MLP', save_code=True)class MyMNISTDataset(Dataset):
    
    def __init__(self, file_path, transform = transforms.Compose([transforms.ToPILImage()]), test_data=False, use_gpu=torch.cuda.is_available()):
        # read the data
        df = pd.read_csv(file_path)
        # for test data we don't have any target
        # MNIST images are 28 by 28, grey colors
        if test_data:
            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = None
        else:
            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]
            self.y = torch.from_numpy(df.iloc[:,0].values)
        self.transform = transform
        self.use_gpu = use_gpu
    
    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        data = self.transform(self.X[idx])
        if self.y is not None:
            target = self.y[idx]
            if self.use_gpu:
                data = data.cuda()
                target = target.cuda()
            return data, target
        else:
            if self.use_gpu:
                data = data.cuda()
            return databatch_size= 512

transformations=transforms.Compose([transforms.ToPILImage(), 
                                    transforms.ToTensor(), 
                                    transforms.Normalize(mean=(0.5,), std=(0.5,))])


train_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/train.csv', transform=transformations, test_data=False)
test_dataset = MyMNISTDataset('/kaggle/input/digit-recognizer/test.csv', transform=transformations, test_data=True)

# split train between validation and training set
training_size = int(0.7 * len(train_dataset))
validation_size = len(train_dataset) - training_size
train, val = torch.utils.data.random_split(train_dataset, [training_size, validation_size], generator=torch.Generator().manual_seed(0))

# create data loader for train and test set
data_loader_train = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)
data_loader_val = torch.utils.data.DataLoader(val, batch_size=batch_size, shuffle=True)

test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False)def init_layer(m):
    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('relu'))
    torch.nn.init.constant_(m.bias, 0)
    return mclass Net(nn.Module):    
    def __init__(self, inputSize):
        super(Net, self).__init__()
        
        self.linear1 = init_layer(torch.nn.Linear(inputSize, 512))
        self.linear2 = init_layer(torch.nn.Linear(512, 256))
        self.dropout = torch.nn.Dropout(p=0.4)
        self.linear3 = init_layer(torch.nn.Linear(256, 10))


    def forward(self, x):
        
        x = x.view(-1,28*28) #reshape the 2d image in a ondiminsional vector for the input of the first layer
        
        x = F.relu(self.linear1(x))
        x = self.dropout(x)
        x = F.relu(self.linear2(x))
        x = self.dropout(x)
        
        return self.linear3(x)input_size = 784
output_size = 10 #labels range from 0-9

model = Net(input_size)

num_epochs = 50
lr =  0.01
weight_decay = 1e-4

optimizer = torch.optim.SGD(model.parameters(),lr = lr)#torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay) #AdamW to aviod coupling problem between the L2 regularization and the adaptive learning rate
criterion = torch.nn.CrossEntropyLoss()

#logging configuration and model
wandb.config.learningrate = lr
wandb.config.num_iterations = num_epochs
wandb.config.optimizer = ""AdamW""
wandb.config.weight_decay = weight_decay
wandb.config.criterion = ""CELoss""

wandb.watch(model, log=""all"", criterion=criterion, log_freq=1,  log_graph=(True)) #log frequency depend on your training


device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"") #0, first GPU if multiple one
print(device)
model.to(device)
","This code defines a neural network for the MNIST dataset using the PyTorch library. The network consists of three fully-connected layers, with 512, 256, and 10 neurons in the first, second, and third layers, respectively. The network uses the ReLU activation function for the first two layers, and the softmax activation function for the third layer. The network also uses a dropout layer with a dropout rate of 0.4.

The code also defines a dataset class for the MNIST dataset, which can be used to load the dataset into PyTorch. The dataset class includes a transform function which applies the transforms.ToPILImage(), transforms.ToTensor(), and transforms.Normalize() transformations to the dataset.

The code then defines a function for initializing the weights of the neural network layers (init_layer()), and a function for training the neural network (train()). The train() function takes as input the neural network, the dataset, the number of epochs, the learning rate, the weight decay, the optimizer, and the criterion. The function outputs the trained neural network.

The code then instantiates the dataset, defines the data loader for the train and test sets, and instantiates the neural network. The code then trains the neural network using the train() function, and saves the trained model to the working directory.",9,7,0.18019839556536896
"import pandas as pd   # data analysis librarymnist_test = pd.read_csv(""/kaggle/input/mnist-fashion-data-classification/mnist_test.csv"")    # create a variable dataframe containing data from data file
mnist_train = pd.read_csv(""/kaggle/input/mnist-fashion-data-classification/mnist_train.csv"")    # create a variable dataframe containing data from data file
sample_submission = pd.read_csv(""/kaggle/input/digit-recognizer/sample_submission.csv"")    # create a variable dataframe containing data from data file
train = pd.read_csv(""/kaggle/input/digit-recognizer/train.csv"")    # create a variable dataframe containing data from data file
test = pd.read_csv(""/kaggle/input/digit-recognizer/test.csv"")    # create a variable dataframe containing data from data filecols = test.columnstest['dataset'] = 'test'train['dataset'] = 'train'dataset = pd.concat([train.drop('label', axis=1), test]).reset_index()","This code imports the pandas library and then reads in four data files: mnist_test.csv, mnist_train.csv, sample_submission.csv, and train.csv. It then concatenates the train and test dataframes and resets the index.",8,3,0.17476053681664017
"import os
import numpy as np
import pandas as pd
import pydicom# Load the data
base_path = ""/kaggle/input/siim-covid19-detection/""
studies_df = pd.read_csv(os.path.join(base_path,""train_study_level.csv""))
images_df = pd.read_csv(os.path.join(base_path,""train_image_level.csv""))

# Strip the extra text from the study and image IDs
studies_df['id'] = studies_df['id'].map(lambda x: x.rstrip('_study'))
images_df['id'] = images_df['id'].map(lambda x: x.rstrip('_image'))

# Merge the dfs together
data_df = pd.merge(images_df, studies_df, how='inner', left_on='StudyInstanceUID', right_on='id')
data_df.drop(['id_y'], axis=1, inplace=True)# This function finds the first image in a StudyInstanceUID directory and returns its path
def get_image_by_study_id(study_id):
    study_path = base_path + ""train/"" + study_id + ""/""
    for subdir, dirs, files in os.walk(study_path):
        for file in files:     
            image = os.path.join(subdir, file)
            if os.path.isfile(image):
                return image
    return ""none""# Loop through the images and check how many images are not Explicit VR Little Endian transfer syntax.
# Also count images with VOI LUT Sequence tags present

count = 0
images_with_voi_lut = 0
images_with_voi_lut_function = 0
images_not_explicit_le = 0
deflated_syntaxes = []
voi_lut_functions = []

for index, row in data_df.iterrows():
    img_file = get_image_by_study_id(row['StudyInstanceUID'])
    img = pydicom.dcmread(img_file)
    
    # Check for a LUT sqequence tag
    if (0x0028,0x3010) in img:
        images_with_voi_lut += 1
    
    # Check for a LUT Function tag
    if (0x0028,0x1056) in img:
        images_with_voi_lut_function += 1
        
        if img(0x0028,0x1056) not in voi_lut_functions:
            voi_lut_functions.append(img(0x0028,0x1056))
            
    # Check the transfer syntax
    if img.file_meta.TransferSyntaxUID != ""1.2.840.10008.1.2.1"":
        images_not_explicit_le += 1
        
        if img.file_meta.TransferSyntaxUID not in deflated_syntaxes:
            deflated_syntaxes.append(img.file_meta.TransferSyntaxUID)
        
    count += 1
    
print(""Done checking "" + str(count) + "" images"")
print(""Found "" + str(images_with_voi_lut) + "" images with VOI LUT"")
print(""Found "" + str(images_with_voi_lut_function) + "" images with VOI LUT Function"")
print(""VOI LUT Functions:"")
print(voi_lut_functions)
print(""Found "" + str(images_not_explicit_le) + "" images that are not Explicit VR LE"")
print(""Non Explicit VR LE Transfer Syntaxes"")
print(deflated_syntaxes)","The code imports the os, numpy, pandas, and pydicom libraries.

It then loads the data from the train_study_level.csv and train_image_level.csv files.

The code then strips the extra text from the StudyInstanceUID and ImageInstanceUID columns.

The code then merges the two dataframes together.

The code then defines a function, get_image_by_study_id, which finds the first image in a StudyInstanceUID directory and returns its path.

The code then loops through the images and counts how many images are not in the Explicit VR Little Endian transfer syntax. It also counts how many images have the VOI LUT Sequence tag present.

Finally, the code prints the results.",8,9,0.28155967682022415
"import os
import cv2
import numpy as np
import pandas as pd
import pydicom
import matplotlib.pyplot as plt
%matplotlib inline# This function gets the first image path in a StudyInstanceUID directory
def get_image_by_study_id(study_id):
    base_path = ""/kaggle/input/siim-covid19-detection/""
    study_path = base_path + ""train/"" + study_id + ""/""
    images = []
    for subdir, dirs, files in os.walk(study_path):
        for file in files:     
            image = os.path.join(subdir, file)
            if os.path.isfile(image):
                return image
    return ""none""# Make a simple linear VOI LUT from the raw (stored) pixel data
def make_lut(storedPixels, windowWidth, windowLevel, p_i):
    
    # Slope and Intercept set to 1 and 0 for X-ray. Get these from DICOM tags instead if using 
    # on a modality that requires them (CT, PT etc)
    slope = 1.0
    intercept = 0.0
    minPixel = int(np.amin(storedPixels))
    maxPixel = int(np.amax(storedPixels))

    # Make an empty array for the LUT the size of the pixel 'width' in the raw pixel data
    lut = [0] * (maxPixel + 1)
    
    # Invert pixels and windowLevel for MONOCHROME1. We invert the specified windowLevel so that 
    # increasing the level value makes the images brighter regardless of photometric intrepretation
    invert = False
    if p_i == ""MONOCHROME1"":
        invert = True
    else:
        windowLevel = (maxPixel - minPixel) - windowLevel
        
    # Loop through the pixels and calculate each LUT value
    for storedValue in range(minPixel, maxPixel):
        modalityLutValue = storedValue * slope + intercept
        voiLutValue = (((modalityLutValue - windowLevel) / windowWidth + 0.5) * 255.0)
        clampedValue = min(max(voiLutValue, 0), 255)
        if invert:
            lut[storedValue] = round(255-clampedValue)
        else:
            lut[storedValue] = round(clampedValue)
        
    return lut# Apply the LUT to a pixel array
def apply_lut(pixels_in, lut):
    pixels_in = pixels_in.flatten()
    pixels_out = [0] * len(pixels_in)
    for i in range(0, len(pixels_in)):
        pixel = pixels_in[i]
        pixels_out[i] = int(lut[pixel])
    return pixels_out# Take a look at a random image and display it with imshow. The width and level are automagically calculated from the pixel data.
img_file = get_image_by_study_id(""00c241c3fc0d"")
print(""Loading image: "" + img_file)

img = pydicom.dcmread(img_file)
plt.imshow(img.pixel_array,cmap=""gray"");# Set the width to be the distance between the pixels, and the level to be the middle of the pixel range.
# The resulting image should look exactly like the one above.
pixels = img.pixel_array
minPixel = np.min(pixels)
maxPixel = np.max(pixels)
windowWidth = maxPixel - minPixel
windowLevel = (minPixel + maxPixel) / 2

lut = make_lut(pixels, windowWidth, windowLevel, img.PhotometricInterpretation)
pixels = apply_lut(pixels, lut)

# Reshape the pixel array back into the image shape
img_out = np.reshape(pixels, (img.pixel_array.shape[0],img.pixel_array.shape[1]))

print(""Calculated - Width: "" + str(windowWidth) + "" / Level  "" +  str(windowLevel))
print(""Pixel range: "" + str(minPixel) + "" - "" + str(maxPixel))
plt.imshow(img_out,cmap=""gray"");print(""PhotometricInterpretation: "" + img.PhotometricInterpretation)
print(""Bit stored: "" + str(img.BitsStored))","This code imports the necessary libraries for loading, processing and displaying images. The get_image_by_study_id() function returns the path to the first image in a given StudyInstanceUID directory. The make_lut() function creates a Lookup Table (LUT) for a given image based on the specified window width and level. The apply_lut() function applies the LUT to the image pixels. Finally, the code displays the image using the imshow() function.",9,2,0.4745583762453432
"import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings(""ignore"")
from glob import glob
from tqdm.notebook import tqdm
from ast import literal_eval
import os
import matplotlib.pyplot as plt
import matplotlib
matplotlib.rcParams.update({'font.size': 22})
from sklearn.metrics import accuracy_score
from skimage import exposure
from tensorflow.keras import layers
from tensorflow.keras.utils import plot_model
import cv2
from matplotlib.patches import Rectangle
from keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50, DenseNet121, Xception
from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import models
from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping
import tensorflow.keras.backend as K
from tensorflow.math import confusion_matrixdf_image = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
display(df_image.head(3))
print(df_image.shape)df_study = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
display(df_study.head(3))
print(df_study.shape)df_sampleSub = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
display(df_sampleSub.head(3))
print(df_sampleSub.shape)df_study['id'] = df_study['id'].str.replace('_study',"""")
df_study.rename({'id': 'StudyInstanceUID'},axis=1, inplace=True)
df_study.head(3)df_train = df_image.merge(df_study, on='StudyInstanceUID')
df_train.head(3)# train_dir_jpg = '../input/covid-jpg-512/train'
# train_dir_origin ='../input/siim-covid19-detection/train'
# paths_original = []
# paths_jpg = []
# for _, row in tqdm(df_train.iterrows()):
#     image_id = row['id'].split('_')[0]
#     study_id = row['StudyInstanceUID']
#     image_path_jpg = glob(f'{train_dir_jpg}/{image_id}.jpg')
#     image_path_original = glob(f'{train_dir_origin}/{study_id}/*/{image_id}.dcm')
#     paths_jpg.append(image_path_jpg)
#     paths_original.append(image_path_original)","This code imports the pandas and numpy libraries, and sets up a warning filter to ignore warnings. It then imports the glob library and the tqdm notebook extension, and uses them to read in data from the SIIM-Covid19-Detection dataset. The code then processes the data to create a dataframe containing information about the images and studies in the dataset. Finally, the code uses the Keras image data generator to create a training set for a convolutional neural network.",8,3,0.0532918746446439
"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -yimport tensorflow as tf
print(tf.__version__)
import torch
print(f""Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})"")

import os
import gc
import cv2
import glob
import numpy as np
import pandas as pd
from PIL import Image
from tqdm import tqdm
from shutil import copyfile
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lutgpus = tf.config.list_physical_devices('GPU')
if gpus:
  try:
    # Currently, memory growth needs to be the same across GPUs
    for gpu in gpus:
      tf.config.experimental.set_memory_growth(gpu, True)
    logical_gpus = tf.config.experimental.list_logical_devices('GPU')
    print(len(gpus), ""Physical GPUs,"", len(logical_gpus), ""Logical GPUs"")
  except RuntimeError as e:
    # Memory growth must be set before GPUs have been initialized
    print(e)# Read the submisison file
sub_df = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')
print(len(sub_df))
sub_df.head()study_df = sub_df.loc[sub_df.id.str.contains('_study')]
len(study_df)image_df = sub_df.loc[sub_df.id.str.contains('_image')]
len(image_df)# Ref: https://www.kaggle.com/xhlulu/siim-covid-19-convert-to-jpg-256px
def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return data

def resize_xray(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im","This code installs the pydicom conda helper package, which allows for the manipulation of DICOM images. It also installs the necessary dependencies for pydicom, including libjpeg-turbo, libgcc-ng, and gdcm. Finally, it installs the tensorflow and torch packages, and prints out the versions of each.

The code then reads in the sample submission file, and separates the study and image dataframes. It then defines a function to read in and resize DICOM images, and applies it to the image dataframe.",8,9,0.1398872983990163
"!/opt/conda/bin/python3.7 -m pip install --upgrade pip
! pip install -q efficientnet#-------------------
# importing libraries
#-------------------
import tensorflow as tf
from tensorflow.keras import layers
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold,StratifiedKFold

from kaggle_datasets import KaggleDatasets


import pandas as pd
import numpy as np

import os
import shutil
import csv

import matplotlib.pyplot as plt
import PILAUTO = tf.data.experimental.AUTOTUNE

try:
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  
    print('Running on TPU ', tpu.master())
except ValueError:
    tpu = None

if tpu:
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.experimental.TPUStrategy(tpu)
else:
    strategy = tf.distribute.get_strategy()

print(""REPLICAS: "", strategy.num_replicas_in_sync)GCS_DS_PATH = KaggleDatasets().get_gcs_path(""siim-covid19-dataset-256px-jpg"")
print(GCS_DS_PATH)

TRAIN_PATH = GCS_DS_PATH + ""/256px/train/train/""
TEST_PATH = GCS_DS_PATH + ""/256px/test/test/""

NUM_CLASSES = 4
HEIGHT,WIDTH = 256,256
CHANNELS = 3
BATCH_SIZE = 8 * strategy.num_replicas_in_sync
SEED = 143


classes_dict = {
    ""Negative for Pneumonia"" : 0,
    ""Typical Appearance"" : 1,
    ""Indeterminate Appearance"" : 2,
    ""Atypical Appearance""  : 3
}

study_df = pd.read_csv(""../input/siim-covid19-detection/train_study_level.csv"")
train_df = pd.read_csv('../input/siim-covid19-dataset-256px-jpg/train.csv')
train_df = train_df[[""ImageInstanceUID"",""StudyInstanceUID"",""label_id"",""study_label""]]train_df.head(3)study_df.head(3)def process_img(filepath,label):
    image = tf.io.read_file(filepath)
    image = tf.image.decode_jpeg(image, channels=CHANNELS)
    image = tf.image.convert_image_dtype(image, tf.float32) 
    #image = tf.image.resize(image, [HEIGHT,WIDTH])
    return image,label


def data_augment(image, label):
    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)
            
    # Flips
    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_flip_up_down(image)
    if p_spatial > .75:
        image = tf.image.transpose(image)
        
    # Rotates
    if p_rotate > .75:
        image = tf.image.rot90(image, k=3) 
    elif p_rotate > .5:
        image = tf.image.rot90(image, k=2) 
    elif p_rotate > .25:
        image = tf.image.rot90(image, k=1) 
        
    
    if p_pixel_1 >= .4:
        image = tf.image.random_saturation(image, lower=.7, upper=1.3)
    if p_pixel_2 >= .4:
        image = tf.image.random_contrast(image, lower=.8, upper=1.2)
    if p_pixel_3 >= .4:
        image = tf.image.random_brightness(image, max_delta=.1)
        
    
    if p_crop > .7:
        if p_crop > .9:
            image = tf.image.central_crop(image, central_fraction=.7)
        elif p_crop > .8:
            image = tf.image.central_crop(image, central_fraction=.8)
        else:
            image = tf.image.central_crop(image, central_fraction=.9)
    elif p_crop > .4:
        crop_size = tf.random.uniform([], int(HEIGHT*.8), HEIGHT, dtype=tf.int32)
        image = tf.image.random_crop(image, size=[crop_size, crop_size, CHANNELS])
    
    image = tf.image.resize(image, [HEIGHT,WIDTH])
    return image,label

def get_dataset(filenames,labels, training=True):
    dataset = tf.data.Dataset.from_tensor_slices((filenames,labels))
    dataset = dataset.map(process_img,num_parallel_calls=AUTO)
    dataset = dataset.map(data_augment,num_parallel_calls=AUTO)
    dataset = dataset.cache()
    dataset = dataset.repeat()
    if training:
        dataset = dataset.shuffle(2048)
    dataset = dataset.batch(BATCH_SIZE)
    dataset = dataset.prefetch(AUTO)
    return dataset","The code above imports the necessary libraries for image processing, data augmentation, and training a neural network. Next, it defines some parameters for the training process. Finally, it defines a function for processing images and applying data augmentation.",8,0,0.06853051904142435
"%%capture
!conda install gdcm -c conda-forge -y# Packages

import os, time, glob, re, pprint, random, math
from collections import defaultdict, Counter

import pandas as pd 
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import matplotlib.patches as patches

import seaborn as sns

import cv2
import gdcm

import pydicom
from pydicom import dcmread
from pydicom.pixel_data_handlers.util import apply_voi_lut

import imagehash
from PIL import Image as im

import tqdm# Magic

%matplotlib inline # Pandas options

pd.set_option(""display.expand_frame_repr"", True)
pd.set_option('display.max_colwidth', 0)# Global values

CODE_PATH = ""./""
DATA_PATH = ""../input/siim-covid19-detection""
TRAIN_PATH = os.path.join(DATA_PATH, ""train"")
TEST_PATH = os.path.join(DATA_PATH, ""test"")# Utility functions

def print_title(s):
    
    # Print an underlined title
    
    print(""%s\n%s"" % (s, '-'*len(s)))
    
    
def na_fill(dtype):
    
    # Fill in missing values so that Seaborn countplot() will include them.
    # Also make sure the missing value for a string column is itself a string.
    
    if dtype == np.float64:
        result = -999
    elif dtype == np.int64:
        result = -999
    elif dtype == np.object:
        result = ""NA""
    else:
        result = -999

    return result


def explode_list_col(df, col):
    
    other_cols = list(df.columns)
    other_cols.remove(col)
    out_df = df.set_index(other_cols)[col]
    out_df = out_df.apply(pd.Series)
    out_df = out_df.stack()
    out_df = out_df.reset_index()
    out_df = out_df.drop(f""level_{len(other_cols)}"", axis=1)
    out_df = out_df.rename(columns={0 : col})
    
    return out_df
    

def cat_order(train_df, test_df, cols):
    
    # For comparison, we want the categories to be the same between train and test. 
    # We also want the categories to be in the same order for both. 
    # We need to make sure missing value types are consistent with the column data
    # type (else sort will complain), and make sure that Seaborn countplot() will
    # include them (it won't include np.nan). Dealing with the latter two issues 
    # is the job of fillna(). When the data is plotted, it needs to be run through
    # fillna() as well.

    category_order = {}
    n = len(cols)

    for col in cols:

        if col in train_cols:
            train_dtype = train_df[col].dtype
        else:
            train_dtype = None     
        if col in test_cols:
            test_dtype = test_df[col].dtype
        else:
            test_dtype = None
        if (train_dtype != None) and (test_dtype != None) and (train_dtype != test_dtype):
            print(f""***Incompatible train/test data types for column {col}"")
            break
        
        col_vals = []
        if col in train_cols:
            col_vals += list(train_df[col].fillna(na_fill(train_dtype)).unique())
        if col in test_cols:
            col_vals += list(test_df[col].fillna(na_fill(test_dtype)).unique())
        col_vals = list(set(col_vals))
        col_vals.sort()
    
        category_order[col] = col_vals
        
    return category_order


def plot_categories(df, col, order, title, ax, xlabel=None, ylabel=None, pallete=""Set3"", scale=""log""):

    data = df[col].fillna(na_fill(df[col].dtype))
    ax = sns.countplot(x=data, order=order, palette=pallete, ax=ax)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=""right"")
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    counts = data.value_counts()
    for i, p in enumerate(ax.patches):
        px = p.get_x()+0.05
        py = max(p.get_height()*0.9, 1.0)
        ax.annotate(counts.get(order[i], """"), (px, py), fontsize=10, rotation=90)
    ax.set_title(title, fontsize=15)
    if xlabel: ax.set_xlabel(xlabel)
    if ylabel: ax.set_ylabel(ylabel)
    
    return


def plot_cat_sub(df, col, sub_col, title, ax, scale=""log""):

    ax = sns.countplot(data=df, x=col, hue=sub_col, ax=ax)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha=""right"")
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    ax.set_title(title, fontsize=15)
        
    return


def plot_number_uniq_per(df, df_name, attr1, attr2, ax, title=None, palette=None, scale=""log""):
    
    uniq_df = df.groupby(attr1)[[attr2]].nunique().reset_index()
    ax = sns.barplot(x=attr1, y=attr2, data=uniq_df, ax=ax, palette=palette)
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
        
    counts = uniq_df[attr2]
    for i, p in enumerate(ax.patches):
        px = p.get_x()+0.05
        py = max(p.get_height()*0.9, 1.0)
        ax.annotate(uniq_df[attr2].iloc[i], (px, py), fontsize=10, rotation=90)

    if title:
        ax.set_title(title, fontsize=15)
    else:
        ax.set_title(f""{df_name}\nNumber of unique '{attr2}' values \nper '{attr1}' value"", fontsize=15)
    ax.set_xlabel(attr1)
    ax.set_ylabel(f""# unique '{attr2}'"")
    
    return uniq_df


def plot_number_having_n_uniq(df, df_name, attr1, attr2, ax, order=None, palette=None, scale=""log""):

    nuniq = df.groupby(attr1)[attr2].nunique()
    ax = sns.countplot(x=nuniq, order=order, ax=ax, palette=palette)
    ax.set_yscale(scale)
    if scale == ""log"":
        ax.set_ylim(bottom=0.5)
    else:
        ax.set_ylim(bottom=0)
    ax.set_title(f""{df_name}\nNumber of '{attr1}' values \nhaving N unique values of '{attr2}'"", fontsize=15)
    ax.set_xlabel(f""N = # of unique '{attr2}' values"")
    ax.set_ylabel(f""# of '{attr1}' having N"")

    return nuniq


def get_img(path, img_id):

    img_path = os.path.join(path, f""{img_id}.jpg"")
    im = cv2.imread(img_path)
    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
    im = cv2.normalize(im, None, 0, 255, cv2.NORM_MINMAX)
    
    return im


def image_subplots(images, r, c, axes, titles=None):
    
    for idx, img in enumerate(images, 0):
        i = idx // c
        j = idx % c
        if titles:
            imshow(img, axes[i, j], title=titles[idx])
        else:
            imshow(img, axes[i, j])

    return
        

def imshow(image, ax=None, title=None, cmap=None):

    if ax is None:
        fig, ax = plt.subplots()
    ax.imshow(image, cmap=cmap)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.spines['left'].set_visible(False)
    ax.spines['bottom'].set_visible(False)
    ax.tick_params(axis='both', length=0)
    ax.set_xticklabels('')
    ax.set_yticklabels('')
    if title:
        ax.set_title(title)

    return ax
# Read the image metadata

train_image_df = pd.read_csv(os.path.join(DATA_PATH,'train_image_level.csv'))
train_study_df =  pd.read_csv(os.path.join(DATA_PATH,'train_study_level.csv'))","This code reads in the image metadata for the training data set. This includes the image ID, patient ID, and other information about the image.",8,0,0.08373644349865736
"import pydicom as dicom
import pandas as pd
import os
from tqdm import tqdmmetadata = []

for split in ['test', 'train']:  
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            ds1 = dicom.dcmread(os.path.join(dirname, file), stop_before_pixels=True)
            dt=dict()
            dt['ImageId']=file.replace('.dcm','')
            for key in ds1.keys():
                dt[ds1[key].keyword]=ds1[key].value
            metadata.append(dt)

metadata_df=pd.DataFrame(metadata)
metadata_df.head()metadata_df.to_csv('metadata_covid.csv', index=False)","This code imports the pydicom and pandas libraries, and then loops through a dataset of DICOM files, extracting metadata from each file and storing it in a list. The list is then converted into a pandas DataFrame and saved as a CSV file.",9,2,0.12149181348277718
"import pandas as pd 
import numpy as np
import os
import pydicom
import glob
from tqdm.notebook import tqdm
from pydicom.pixel_data_handlers.util import apply_voi_lut
import matplotlib.pyplot as plt 
from skimage import exposure
import cv2
import warnings
from path import Path
from fastai.vision.all import *
from fastai.medical.imaging import *
warnings.filterwarnings(""ignore"")datapath = Path(""../input/siim-covid19-detection"")datapath.ls()train_study_df = pd.read_csv(datapath/'train_study_level.csv')train_study_df.head()study_classes = [""Negative for Pneumonia"" , ""Typical Appearance"",
                ""Indeterminate Appearance"", ""Atypical Appearance""]
np.unique(train_study_df[study_classes].values , axis = 0)plt.figure(figsize = (10,5))
plt.bar([1,2,3,4] , train_study_df[study_classes].values.sum(axis = 0))
plt.xticks([1,2,3,4] , study_classes)
plt.ylabel(""Frequency"")
plt.show()","This code imports the necessary libraries for working with the data, including pandas, numpy, and pydicom. It then loads the train_study_level.csv file, which contains information on the studies in the dataset.

The code then defines a list of study classes, which are used to categorize the studies. The unique values for each class are then printed.

Finally, a bar chart is generated, showing the number of studies in each class.",8,2,0.02365037197933577
"import numpy as np 
import pandas as pd 
import os
import matplotlib.pyplot as plt
import matplotlib
import pydicom as dicom
import cv2
import ast
import warnings
warnings.filterwarnings('ignore')train_image = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
train_study = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
sample_submission = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')train_image.head()len(train_image)train_study.head()len(train_study)sample_submission.head()","This code imports the necessary libraries for working with the data, including NumPy, pandas, matplotlib, and pydicom. It then loads the train_image and train_study dataframes from the CSV files. Finally, it displays the first five rows of the train_image dataframe.",9,4,0.07008151099688373
"!conda install gdcm -c conda-forge -yimport os
import ast
import numpy as np
import pandas as pd
from path import Path
import datetime
import glob
import json
import shutil

from PIL import Image
from tqdm.auto import tqdm
import pydicom
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import cv2from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)    
    
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail(size, resample)
    else:
        im = im.resize(size, resample)
    
    return imimages_meta_folder = '/kaggle/working/images_metadata_256_512_768'
os.makedirs(images_meta_folder, exist_ok=True)

# Define sizes
new_sizes = [(256, 256), (512, 512), (768, 768)]for new_size in new_sizes:

    for split in ['train', 'test']:
    # for split in ['test']:
        save_dir = f'/kaggle/tmp/{split}_{new_size[0]}x{new_size[1]}/'
        dcm_paths = glob.glob(f'../input/siim-covid19-detection/{split}/*/*/*')
        os.makedirs(save_dir, exist_ok=True)

        image_ids = []
        folder_ids = []
        study_ids = []
        widths = []
        heights = []

        for path in tqdm(dcm_paths):
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(path)
            im = resize(xray, size=new_size)

            path_split = path.split('/')
            study_id = path_split[-3]
            folder_id = path_split[-2]
            image_name = path_split[-1].replace('.dcm', '_image')

            im.save(os.path.join(save_dir, image_name+'.png'))

            image_ids.append(image_name)
            folder_ids.append(folder_id)
            study_ids.append(study_id)
            widths.append(xray.shape[1])
            heights.append(xray.shape[0])
            
        df = pd.DataFrame.from_dict({'id': image_ids, 'folder_id': folder_ids,
                                     'study_id': study_ids, 'width': widths,
                                     'height': heights})
        df.to_csv(f'{images_meta_folder}/{split}_meta_{new_size[0]}x{new_size[1]}.csv', index=False)for new_size in new_sizes:
    print(f""*****{new_size}*****\n"")
    df_train_meta = pd.read_csv(f'{images_meta_folder}/train_meta_{new_size[0]}x{new_size[1]}.csv')
    df_train = pd.read_csv(""../input/siim-covid19-detection/train_image_level.csv"")
    df_train_meta = df_train.merge(df_train_meta, on='id')
    
    ## Drop all rows of images without annotations
    df_train_meta = df_train_meta.dropna()
    imagepaths = df_train_meta.id.unique()
    print(""Number of Images with Covid_Abnormality:"",len(imagepaths))
    
    display(df_train_meta.head(3))
    print()
    
    df_idx=0

    for idx, row in tqdm(df_train_meta.iterrows(), total=df_train_meta.shape[0]):
        img = cv2.imread(os.path.join(f""/kaggle/tmp/train_{new_size[0]}x{new_size[1]}/"",
                                      row.id.replace(""_image"", "".png"")))
        bboxes = [list(bbox.values()) for bbox in ast.literal_eval(row.boxes)]
        height_ratio, width_ratio = (new_size[0]/row.height, new_size[1]/row.width)

        for box in bboxes:
            box[2] = box[2]+box[0]
            box[3] = box[3]+box[1]
            box = (box[0]*width_ratio, box[1]*height_ratio,
                   box[2]*width_ratio, box[3]*height_ratio)

            row_df = pd.DataFrame({'id':row.id,
                           'StudyInstanceUID':row.StudyInstanceUID,
                           'folder_id':row.folder_id,
                           'study_id':row.study_id,
                           'width':row.width,
                           'height':row.height,
                           'xmin':round(box[0]),
                           'ymin':round(box[1]),
                           'xmax':round(box[2]),
                           'ymax':round(box[3])}, index=[df_idx])

            if df_idx==0:
                df_train_processed = row_df
            else:
                df_train_processed = pd.concat([df_train_processed, row_df])

            df_idx+=1

    display(df_train_processed.head(3))
    print()
    df_train_processed.to_csv(f'{images_meta_folder}/df_train_processed_meta_{new_size[0]}x{new_size[1]}.csv',
                              index=False)
    df_train_processed.shape","This code reads in DICOM images and converts them to PNG format. It also generates metadata for each image, including bounding box coordinates for any annotations present. The code can be run for multiple image sizes (256x256, 512x512, 768x768).",8,0,0.1402452785331803
"!conda install gdcm -c conda-forge -yimport cv2
import datetime
import gc
import glob
import imagehash
import math
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
import PIL
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import sys
import tqdmbase_path = '../input/siim-covid19-detection'def read_dicom_image(image_file, voi_lut=True, fix_monochrome=True):
    """"""
    Reads a dicom image from a file an returns a numpy array.
    References: https://www.kaggle.com/trungthanhnguyen0502/eda-vinbigdata-chest-x-ray-abnormalities
    Args:
        image_file:
        voi_lut:
        fix_monochrome:

    Returns:

    """"""
    dicom = pydicom.read_file(image_file)
    # VOI LUT (if available by DICOM device) is used to
    # transform raw DICOM data to ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
    return data


def string2boxes(string):
    strings = string.split()
    if strings[0].lower() == 'none':
        return []
    else:
        return [{'class': strings[idx],
                 'conf': float(strings[idx+1]),
                 'x1': float(strings[idx+2]),
                 'y1': float(strings[idx+3]),
                 'x2': float(strings[idx+4]),
                 'y2': float(strings[idx+5]),
                 } for idx in range(0, len(strings), 6)]


def plot_image(image, boxes=None, size=(5,5), title=None, columns=4):
    def plot_img(image, boxes=None, title=None):
        if isinstance(image, str):
            image_id = os.path.splitext(os.path.split(image)[1])[0]
            df = df_image.loc[df_image['id'] == image_id + '_image']
            boxes = string2boxes(df['label'].iloc[0]) if len(df) > 0 else None
            image = read_dicom_image(image)
        image = np.stack([image] * 3, axis=-1)
        if boxes is not None:
            for box in boxes:
                image = cv2.rectangle(image, (int(box['x1']), int(box['y1'])), (int(box['x2']), int(box['y2'])), [0, 255, 0], 10)
        plt.axis('on')
        plt.imshow(image, cmap='gray')
        if title is not None:
            plt.title(title)

    plt.figure(figsize=size)
    if isinstance(image, list):
        num = len(image)
        columns = min(columns, num)
        rows = math.ceil(num / columns)

        for index, single_image in enumerate(image):
            plt.subplot(rows, columns, index + 1)
            plot_img(single_image, boxes=boxes, title=title[index])
    else:
        plot_img(image, boxes=boxes, title=title)
    plt.show()


def images_find_duplicates(image_files, threshold=0.9):
    """"""
    Function to find duplicates in images.
    References: https://www.kaggle.com/appian/let-s-find-out-duplicate-images-with-imagehash
    Args:
        image_files:
        threshold:

    Returns:

    """"""
    funcs = [imagehash.average_hash, imagehash.phash, imagehash.dhash, imagehash.whash]
    image_ids = image_files
    hashes = []
    for file in tqdm.tqdm(image_files):
        image = PIL.Image.fromarray(read_dicom_image(file))
        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))
    hashes_all = np.array(hashes)

    # Comparisons without Pytorch
    sim_list = []
    for i in tqdm.tqdm(range(hashes_all.shape[0])):
        sim_list.append(np.sum(hashes_all[i] == hashes_all, axis=1)/256)

    # nxn-matrix of similarities (n = # of images), upper triangular matrix
    similarities = np.triu(np.array(sim_list), 1)

    idx_pair = np.where(similarities > threshold)
    df_pairs = pd.DataFrame({'image1': [image_ids[i] for i in list(idx_pair[0])],
                             'image2': [image_ids[i] for i in list(idx_pair[1])],
                             'similarity': [similarities[i1, i2] for i1, i2 in zip(idx_pair[0], idx_pair[1])]})

    idx_group = np.zeros(len(image_files))
    group_id = 1
    for i1, i2 in zip(idx_pair[0], idx_pair[1]):
        if idx_group[i1] == 0 and idx_group[i2] == 0:
            idx_group[i1] = group_id
            idx_group[i2] = group_id
            group_id += 1
        elif idx_group[i1] != 0 and idx_group[i2] == 0:
            idx_group[i2] = idx_group[i1]
        elif idx_group[i1] == 0 and idx_group[i2] != 0:
            idx_group[i1] = idx_group[i2]
        elif idx_group[i1] != 0 and idx_group[i2] != 0 and idx_group[i1] != idx_group[i2]:
            common_id = min(idx_group[i1], idx_group[i2])
            idx_group[idx_group == idx_group[i1]] = common_id
            idx_group[idx_group == idx_group[i2]] = common_id

    group_list = []
    for i in range(1, group_id + 1):
        group_ids = list(np.where(idx_group == i)[0])
        if len(group_ids) > 0:
            group_list.append([image_ids[j] for j in group_ids])

    return df_pairs, group_list


def print_group_info(i, df_group):
    print(f'\nGroup {i+1}')
    print(f'Number of unique studies:       {len(df_group[""study_id""].unique())}')
    print(f'Number of unique study labels:  {len(df_group[""study_label""].unique())}\n')
    print(df_group[['image_id', 'num_boxes', 'study_id', 'study_label']])
    plot_image(list(df_group['image_file']), size=(20, 10), title=list(df_group['image_id']), columns=8)    
train_files = sorted(glob.glob(os.path.join(base_path, 'train/*/*/*.dcm')))
print(f'Number of training files: {len(train_files)}')
df_image = pd.read_csv(os.path.join(base_path, 'train_image_level.csv'))
df_study = pd.read_csv(os.path.join(base_path, 'train_study_level.csv'))
df_study['study_label'] = df_study.apply(lambda r: ', '.join([df_study.columns[i] for i in range(1, 5) if r[i] > 0]), axis=1)

df_pairs, group_list = images_find_duplicates(train_files, threshold=0.95)
print(f'\nNumber of duplicate pairs: {len(df_pairs)}')
print(f'Number of duplicate groups: {len(group_list)}')df_group_list = []
df_pairs.to_csv('pairs.csv')

with open('duplicates.csv', 'w') as text_file:
    for i, group in enumerate(group_list):
        group_ids = [os.path.splitext(os.path.basename(file))[0] + '_image' for file in group]
        df_group_ids = pd.DataFrame({'id': group_ids, 'image_file': group})
        df_group = df_group_ids.merge(df_image, on='id').sort_values('id')
        df_group['study_id'] = df_group['StudyInstanceUID'] + '_study'
        df_group['num_boxes'] = df_group.apply(lambda r: len(string2boxes(r['label'])), axis=1)
        df_group = df_group.merge(df_study, left_on='study_id', right_on='id')
        df_group = df_group.rename(columns={'id_x': 'image_id'})
        df_group_list.append(df_group)
        text_file.write(','.join(group_ids) + '\n')for index, df_group in enumerate(df_group_list):
    if len(df_group[df_group['num_boxes'] > 0]) > 1:
        print_group_info(index, df_group)","This code is used to find duplicate images in a dataset. It takes in a list of image files and compares them using image hashing. If two images are found to be duplicates, they are added to a list of duplicate images. Finally, the code prints out information about each group of duplicate images, including the number of unique studies and study labels, as well as the number of boxes (if any) associated with each image.",8,0,0.18863764737475594
"import pandas as pd# train_df = pd.read_csv('/kaggle/input/siimcovid19-train-data-that-opacitycount-added/train_df.csv')
# local
train_df = pd.read_csv('/kaggle/input/siimcovid19-train-data-that-opacitycount-added/train_df.csv')train_df.head()train_df.drop(columns='Path', axis=1,inplace=True)train_df.head()train_df['Opacity'] = train_df.apply(lambda row : 1 if row.label.split(' ')[0]=='opacity' else 0, axis=1)
train_dftrain_df.drop(columns=['Unnamed: 0'], inplace=True)
train_df","This code imports a CSV file into a pandas dataframe, then drops the 'Path' column and replaces it with a column called 'Opacity'. The new column is populated with values of 1 if the corresponding row in the 'label' column has the value 'opacity', and 0 otherwise.",8,1,0.05139923999647672
"!pip install -q efficientnet >> /dev/nullimport pandas as pd, numpy as np, random,os, shutil
from glob import glob
from kaggle_datasets import KaggleDatasets
import tensorflow as tf, re, math
import tensorflow.keras.backend as K
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt
import tensorflow_addons as tfa
print('tf:',tf.__version__)# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit
VERBOSE      = 1
DISPLAY_PLOT = True

DEVICE = ""TPU"" #or ""GPU""

# USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD
SEED = 42

# NUMBER OF FOLDS. USE 2, 5, 10
FOLDS = 5

# WHICH IMAGE SIZES TO LOAD EACH FOLD
# CHOOSE 128, 192, 256, 384, 512, 512 
IMG_SIZES = [[512, 512]]*FOLDS

# BATCH SIZE AND EPOCHS
BATCH_SIZES = [24]*FOLDS
EPOCHS      = [10]*FOLDS

# WHICH EFFICIENTNET B? TO USE
EFF_NETS = [6]*FOLDS

# Augmentations
AUGMENT   = True
TRANSFORM = True

# transformations
ROT_    = 0.0
SHR_    = 2.0
HZOOM_  = 8.0
WZOOM_  = 8.0
HSHIFT_ = 8.0
WSHIFT_ = 8.0

# Dropout
PROBABILITY = 0.75
CT          = 8
SZ          = 0.08

#bri, contrast
sat  = (0.7, 1.3)
cont = (0.8, 1.2)
bri  =  0.1

# WEIGHTS FOR FOLD MODELS WHEN PREDICTING TEST
WGTS = [1/FOLDS]*FOLDS

# TEST TIME AUGMENTATION STEPS
TTA = 1def seeding(SEED):
    np.random.seed(SEED)
    random.seed(SEED)
    os.environ['PYTHONHASHSEED'] = str(SEED)
    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)
    tf.random.set_seed(SEED)
    print('seeding done!!!')
seeding(SEED)if DEVICE == ""TPU"":
    print(""connecting to TPU..."")
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        print('Running on TPU ', tpu.master())
    except ValueError:
        print(""Could not connect to TPU"")
        tpu = None

    if tpu:
        try:
            print(""initializing  TPU ..."")
            tf.config.experimental_connect_to_cluster(tpu)
            tf.tpu.experimental.initialize_tpu_system(tpu)
            strategy = tf.distribute.experimental.TPUStrategy(tpu)
            print(""TPU initialized"")
        except _:
            print(""failed to initialize TPU"")
    else:
        DEVICE = ""GPU""

if DEVICE != ""TPU"":
    print(""Using default strategy for CPU and single GPU"")
    strategy = tf.distribute.get_strategy()

if DEVICE == ""GPU"":
    print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
    

AUTO     = tf.data.experimental.AUTOTUNE
REPLICAS = strategy.num_replicas_in_sync
print(f'REPLICAS: {REPLICAS}')GCS_PATH = [None]*FOLDS
for i,k in enumerate(IMG_SIZES):
    GCS_PATH[i] = KaggleDatasets().get_gcs_path('siimcovid19-%ix%i-tfrec-dataset'%(k[0],k[1]))
files_train = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/train*.tfrec')))
files_test  = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/test*.tfrec')))
num_train_files = len(files_train)
num_test_files  = len(files_test)
print('train_files:',num_train_files)
print('test_files:',num_test_files)train_df = pd.read_csv('../input/siim-covid19-yolov5-2class-labels/meta.csv')
train_df.head(2)","This code imports the necessary libraries for training and testing a model, including the efficientnet library. It also sets up the parameters for the training process, including the batch size, number of epochs, and image size. Finally, it loads the train and test data from the siim-covid19-yolov5-2class-labels dataset.",8,1,0.061439395160249655
"%cd ../
!mkdir tmp
%cd tmp# Download YOLOv5
!git clone https://github.com/ultralytics/yolov5  # clone repo
%cd yolov5
# Install dependencies
%pip install -qr requirements.txt  # install dependencies

%cd ../
import torch
print(f""Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})"")# Install W&B 
!pip install -q --upgrade wandb
# Login 
import wandb
wandb.login()# Necessary/extra dependencies. 
import os
import gc
import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm
from shutil import copyfile
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

#customize iPython writefile so we can write variables
from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))TRAIN_PATH = 'input/siim-covid19-resized-to-256px-jpg/train/'
IMG_SIZE = 256
BATCH_SIZE = 16
EPOCHS = 10# Everything is done from /kaggle directory.
%cd ../

# Load image level csv file
df = pd.read_csv('input/siim-covid19-detection/train_image_level.csv')

# Modify values in the id column
df['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)
# Add absolute path
df['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)
# Get image level labels
df['image_level'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)

df.head(5)# Load meta.csv file
# Original dimensions are required to scale the bounding box coordinates appropriately.
meta_df = pd.read_csv('input/siim-covid19-resized-to-256px-jpg/meta.csv')
train_meta_df = meta_df.loc[meta_df.split == 'train']
train_meta_df = train_meta_df.drop('split', axis=1)
train_meta_df.columns = ['id', 'dim0', 'dim1']

train_meta_df.head(2)","This code is for the YOLOv5 object detection model. It is written in Python and uses the PyTorch library. The code is designed to run on Google Colab.

The code downloads the YOLOv5 repository from GitHub and installs the required dependencies. It then loads the image level csv file and the meta.csv file. The image level csv file contains the labels for the images and the meta.csv file contains the original dimensions of the images.

The code then splits the data into training and testing sets and trains the model.",8,4,0.11051180722918284
"# Importing Required packages
import os
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from IPython.display import Image, clear_output
print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))
clear_output()#customize iPython writefile so we can write variables
from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))# Cloning the repo and installing requiements
!git clone https://github.com/ultralytics/yolov5.git
!mv ./yolov5/* ./
!pip install -r requirements.txt
clear_output()# Copying the dataset to working directory
!mkdir Dataset
!cp ../input/covid19-detection-for-yolov5-siimfisabiorsna/Covid19 -r ./Dataset
clear_output()len(os.listdir('./Dataset/Covid19/images'))%%writetemplate ./split_dataset.py
from utils.datasets import * 
autosplit('./Dataset/Covid19', weights=(0.8, 0.2, 0.0))!python split_dataset.py","This code imports the required packages, clones the yolov5 repository, and installs the required packages. It then copies the dataset to the working directory. Finally, it splits the dataset into training, validation, and test sets.",8,0,0.1496802546431768
"! conda install -c conda-forge gdcm -y# import numpy as np # linear algebra
# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
# import os
# import pydicom
# import glob
# from tqdm.notebook import tqdm
# from pydicom.pixel_data_handlers.util import apply_voi_lut
# import matplotlib.pyplot as plt
# from skimage import exposure
# import cv2
# import warnings
# from fastai.vision.all import *
# from fastai.medical.imaging import *
# warnings.filterwarnings('ignore')

import os
import pydicom
import glob
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt 
dataset_path = '../input/siim-covid19-detection/'

for path in glob.glob(dataset_path  + '*'):
    print(path)train_images = '../input/siim-covid19-detection/train/'

n_folders = len(glob.glob(train_images  + '*'))
n_subfolders = len(glob.glob(train_images  + '*/*'))
n_images = len(glob.glob(train_images  + '*/*/*.dcm'))

print(f'There are {n_subfolders} subfolders in {n_folders} folders.')
print(f'There are altogether {n_images} images.')folders = glob.glob(train_images  + '*')

subfolder_dict = {}

for folder in folders:
    n = len(glob.glob(folder + '/*'))
    if n in subfolder_dict.keys():
        subfolder_dict[n] += 1
    else:
        subfolder_dict[n] = 1
        
for k, v in subfolder_dict.items():
    print(f'There is {v} subfolders with {k} images.')

subfolders = glob.glob(train_images  + '*/*')

image_dict = {}

for subfolder in subfolders:
    n = len(glob.glob(subfolder + '/*'))
    if (n!=1):
        print (subfolder.split('/')[-1])
        for image in glob.glob(subfolder + '/*'):
            print ('-->' + image.split('/')[-1])

    if n in image_dict.keys():
        image_dict[n] += 1
    else:
        image_dict[n] = 1
        
for k, v in image_dict.items():
    print(f'There is {v} subfolders with {k} images.')
train_study_df = pd.read_csv(dataset_path +'/train_study_level.csv')

train_study_df","This code imports the necessary libraries for working with the SIIM-COVID19 dataset. It then defines the path to the dataset and counts the number of folders, subfolders, and images in the dataset. Finally, it creates a dictionary of the number of images in each subfolder.",9,0,0.07060699893902993
"import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import glob
import pydicomsiim_covid19_dir = os.path.join(
    '..', 'input', 'siim-covid19-detection')def read_csv(file_name):
    file_path = os.path.join(siim_covid19_dir, file_name)
    df = pd.read_csv(file_path)
    return dfstudy_level_df = read_csv('train_study_level.csv')

study_level_df# How many rows?
study_level_num_rows = len(study_level_df)

study_level_num_rows# Are unique? Any duplicates?
study_level_num_unique_ids = len(pd.unique(study_level_df['id']))

if study_level_num_unique_ids == study_level_num_rows:
    print(""Unique and no duplicates"")
else:
    print(""Some duplicates"")# What are the unique value combinations? How many of them?
study_level_label_colums = [
    'Negative for Pneumonia', 'Typical Appearance',
    'Indeterminate Appearance', 'Atypical Appearance' ]
study_level_labels_df = study_level_df[study_level_label_colums]
study_level_label_values = study_level_labels_df.values

study_level_unique_label_combinations, \
study_level_unique_label_counts = \
    np.unique(
        study_level_label_values, return_counts=True, axis=0)

print(""Unique Combinations:\n"", study_level_unique_label_combinations)
print(""Unique Counts:\n"", study_level_unique_label_counts)","This code imports the necessary libraries for reading in a CSV file, processing data, and visualizing results. The read_csv function reads in a CSV file from a specified directory and returns a pandas DataFrame. The study_level_df DataFrame contains information on the labels assigned to each study in the SIIM-Covid19 dataset.

The study_level_df DataFrame is then processed to determine the number of rows, whether there are any duplicates, and the unique label combinations. The number of rows is printed, as well as a message indicating whether there are any duplicates. The unique label combinations and counts are then printed.",8,6,0.19034494876847233
"# Libraries
import warnings
warnings.filterwarnings('ignore')

import os
import numpy as np
import pandas as pd
import seaborn as sns
import glob
from pandas import DataFrame
from matplotlib.lines import Line2D
import matplotlib.pyplot as plt
%matplotlib inline
import plotly.express as px
from tqdm.notebook import tqdm

# Image processing and Computer Vision
from skimage import exposure
import cv2
# Package designed to manipulate data elements in DICOM files 

import pydicom
#Image Transformation
from pydicom.pixel_data_handlers.util import apply_voi_lut

from fastai.vision.all import *
from fastai.medical.imaging import *

#train_image
train_image_df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
train_image_df.head(2)#train_study
train_study_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
train_study_df.head()# Bar plot function defination
def viz_bar_plot(df,x,x_title,y,title,colors=None,text=None):
    fig = px.bar(x=x,
                 y=y,
                 text=text,
                 labels={x: x_title.title()},   
                 data_frame=df,
                 color=colors,
                 barmode='group',
                 template=""simple_white"")
    texts = [df[col].values for col in y]
    for i, t in enumerate(texts):
        fig.data[i].text = t
        fig.data[i].textposition = 'inside'  
    fig['layout'].title=title
    fig.update_layout(title_font_size=19)
    fig.update_layout(title_font_family='Droid Serif')
    fig.update_layout(width=800,height=500)
    for trace in fig.data:
        trace.name = trace.name.replace('_',' ').title()
    fig.update_yaxes(tickprefix="""", showgrid=True)
    fig.show()# Study Data
# create 'target' column in train_study_df dataset
train_study_df['target']='Negative for Pneumonia'
train_study_df.loc[train_study_df['Typical Appearance']==1,'target']='Typical Appearance'
train_study_df.loc[train_study_df['Indeterminate Appearance']==1,'target']='Indeterminate Appearance'
train_study_df.loc[train_study_df['Atypical Appearance']==1,'target']='Atypical Appearance'
train_study_df1=train_study_df.groupby(['target']).size().reset_index(name='counts')
train_study_df1# Bar Visulaization of label categories
viz_bar_plot(train_study_df1,
         'target',
         'target',
         ['counts'],
         title='Target Label Count')","This code imports the necessary libraries for data analysis and visualization, then loads the train_image and train_study dataframes. It defines a function for visualizing data in a bar plot, then uses that function to plot the distribution of target labels in the train_study dataframe.",8,2,0.11890968088715353
"! conda install -c conda-forge gdcm -yimport numpy as np
import pandas as pd 
import os
from PIL import Image
from tqdm.auto import tqdm
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import seaborn as sns
from pandas_profiling import ProfileReport
from glob import glob
from tqdm.notebook import tqdm
import matplotlib.pyplot as plt
from skimage import exposure
import cv2
import warnings
import albumentations as A# config params
class CFG:
    data_path = '../input/siim-covid19-detection/'
    size = 512
    seed = 2021
    working_dir = '/kaggle/working/'def dicom2array(path, voi_lut=True, fix_monochrome=True):
    dicom = pydicom.read_file(path)
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
    return data
        
    
def plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()
# storage file for the transformed images
!mkdir train# prepare a dataframe for producing resized images with bboxes
xtrain_img = pd.read_csv(CFG.data_path + 'train_image_level.csv')


path_list = []
image_list = []
splits = []

for split in ['train']:
    
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            fullpath = dirname + '/' + file
            path_list.append(fullpath)
            image_list.append(file)

df = pd.DataFrame(image_list, columns =['image_id'])
df['image_path'] = path_list

xtrain_img['image_id'] = xtrain_img['id'].apply(lambda s: s.replace('_image','') + '.dcm')
xtrain_img = pd.merge(left = xtrain_img, right = df, on = 'image_id')
# common transformation we shall use
transform = A.Compose(
    [
        A.Resize(height = CFG.size , width = CFG.size, p=1),
    ], 
    p=1.0,  bbox_params=A.BboxParams( format='pascal_voc', min_area=0,  min_visibility=0, label_fields=['labels']  ))        

img_list = []
label_list = []

# loop over files
for ii in range(len(xtrain_img)):
    # get the image
    row = xtrain_img.loc[ii]
    img_path = row['image_path']
    img = dicom2array(path=img_path)
    newname = img_path.split('/')[-1].replace('dcm', 'jpg')
    img_list.append(newname)
    
    # get the bounding boxes
    bboxes = []
    bbox = []
    labels = []
    confidences = []

    for i, l in enumerate(row['label'].split(' ')):
        if (i % 6 == 0) :
            labels.append(l)
        if (i % 6 == 1):
            confidences.append(l)
        if (i % 6 > 1):
            bbox.append(np.clip(float(l), a_min = 0, a_max = None ))
        if i % 6 == 5:
            bboxes.append(bbox)
            bbox = []    

    # transform both
    result = transform(image = img, bboxes = bboxes, labels = np.ones(len(bboxes)))
    new_image = result['image']
    new_bboxes = np.array(result['bboxes']).tolist()

    # format the output
#    print('orig label: ' + row['label'])
    newlabel = ''
    if labels[0] == 'none':
        newlabel = 'none 1 0 0 1 1'
    else:
        for j in range(len(labels)):
            newlabel += labels[j] + ' ' + confidences[j] + ' ' +  ' '.join([str(np.round(f,5)) for f in new_bboxes[0]]) + ' '
#    print('new label:' + newlabel)
    label_list.append(newlabel)
    
    # store the new image
    cv2.imwrite(CFG.working_dir + 'train/' + newname , new_image)","This code is responsible for transforming images and bounding boxes in the SIIM-Covid19 dataset. The images are first resized to 512x512, and then the bounding boxes are adjusted accordingly. Finally, the transformed images and bounding boxes are stored in the working directory.",8,0,0.11487344940864168
"!wget 'https://anaconda.org/conda-forge/libjpeg-turbo/2.1.0/download/linux-64/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/libgcc-ng/9.3.0/download/linux-64/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/gdcm/2.8.9/download/linux-64/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/conda/4.10.1/download/linux-64/conda-4.10.1-py37h89c1867_0.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/certifi/2020.12.5/download/linux-64/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/openssl/1.1.1k/download/linux-64/openssl-1.1.1k-h7f98852_0.tar.bz2' -q","1. The first line of code downloads the libjpeg-turbo library from the Anaconda website.

2. The second line of code downloads the libgcc-ng library from the Anaconda website.

3. The third line of code downloads the gdcm library from the Anaconda website.

4. The fourth line of code downloads the conda package from the Anaconda website.

5. The fifth line of code downloads the certifi package from the Anaconda website.

6. The sixth and final line of code downloads the openssl package from the Anaconda website.",This documentation is semantically correct.,6,0.059583816883109306
"! conda install gdcm -c conda-forge -y! pip install --no-deps '../input/timm-package/timm-0.1.26-py3-none-any.whl' > /dev/null
! pip install --no-deps '../input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl' > /dev/nullimport sys
sys.path.insert(0, ""../input/timm-efficientdet-pytorch"")
sys.path.insert(0, ""../input/omegaconf"")

import os
from PIL import Image
import pandas as pd
from tqdm.auto import tqdm
import numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import torch
from datetime import datetime
import time
import random
import cv2
import albumentations as A
import matplotlib.pyplot as plt
from albumentations.pytorch.transforms import ToTensorV2
from sklearn.model_selection import StratifiedKFold
from torch.utils.data import Dataset,DataLoader
from torch.utils.data.sampler import SequentialSampler, RandomSampler
from glob import glob

SEED = 42

def seed_everything(seed):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = True

seed_everything(SEED)dataset_path = ""../input/siim-covid19-detection""def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return data

def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im
        
    
def plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()
%%time
image_id = []


cnt_img = 0 # for testing

for split in ['test', 'train']:
    save_dir = f'/kaggle/tmp/{split}/'

    os.makedirs(save_dir, exist_ok=True)
    
    for dirname, _, filenames in tqdm(os.walk(f'{dataset_path}/{split}')):
        for file in filenames:
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(os.path.join(dirname, file))
            im = resize(xray, size=256)  
            im.save(os.path.join(save_dir, file.replace('dcm', 'jpg')))

            image_id.append(file.replace('.dcm', ''))

            splits.append(split)
        
        if cnt_img >= 10:
            cnt_img = 0
            break
        
        cnt_img += 1
            image_id","This code reads in dicom images from a given directory, transforms them into jpeg format, and saves them in a new directory. Additionally, it appends the image id to a list for later use.",8,3,0.09354911575453992
"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -yimport os

from PIL import Image
import pandas as pd
from tqdm.auto import tqdmimport numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im
split = 'test'
save_dir = f'/kaggle/tmp/{split}/'

os.makedirs(save_dir, exist_ok=True)

save_dir = f'/kaggle/tmp/{split}/study/'
os.makedirs(save_dir, exist_ok=True)

for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
    for file in filenames:
        # set keep_ratio=True to have original aspect ratio
        xray = read_xray(os.path.join(dirname, file))
        im = resize(xray, size=600)  
        study = dirname.split('/')[-2] + '_study.png'
        im.save(os.path.join(save_dir, study))
import numpy as np 
import pandas as pd

df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
id_laststr_list  = []
for i in range(df.shape[0]):
    id_laststr_list.append(df.loc[i,'id'][-1])
df['id_last_str'] = id_laststr_list

study_len = df[df['id_last_str'] == 'y'].shape[0]!pip install /kaggle/input/kerasapplications -q
!pip install /kaggle/input/efficientnet-keras-source-code/ -q --no-deps

import os

import efficientnet.tfkeras as efn
import numpy as np
import pandas as pd
import tensorflow as tf

def auto_select_accelerator():
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        tf.config.experimental_connect_to_cluster(tpu)
        tf.tpu.experimental.initialize_tpu_system(tpu)
        strategy = tf.distribute.experimental.TPUStrategy(tpu)
        print(""Running on TPU:"", tpu.master())
    except ValueError:
        strategy = tf.distribute.get_strategy()
    print(f""Running on {strategy.num_replicas_in_sync} replicas"")

    return strategy


def build_decoder(with_labels=True, target_size=(300, 300), ext='jpg'):
    def decode(path):
        file_bytes = tf.io.read_file(path)
        if ext == 'png':
            img = tf.image.decode_png(file_bytes, channels=3)
        elif ext in ['jpg', 'jpeg']:
            img = tf.image.decode_jpeg(file_bytes, channels=3)
        else:
            raise ValueError(""Image extension not supported"")

        img = tf.cast(img, tf.float32) / 255.0
        img = tf.image.resize(img, target_size)

        return img

    def decode_with_labels(path, label):
        return decode(path), label

    return decode_with_labels if with_labels else decode


def build_augmenter(with_labels=True):
    def augment(img):
        img = tf.image.random_flip_left_right(img)
        img = tf.image.random_flip_up_down(img)
        return img

    def augment_with_labels(img, label):
        return augment(img), label

    return augment_with_labels if with_labels else augment


def build_dataset(paths, labels=None, bsize=32, cache=True,
                  decode_fn=None, augment_fn=None,
                  augment=True, repeat=True, shuffle=1024, 
                  cache_dir=""""):
    if cache_dir != """" and cache is True:
        os.makedirs(cache_dir, exist_ok=True)

    if decode_fn is None:
        decode_fn = build_decoder(labels is not None)

    if augment_fn is None:
        augment_fn = build_augmenter(labels is not None)

    AUTO = tf.data.experimental.AUTOTUNE
    slices = paths if labels is None else (paths, labels)

    dset = tf.data.Dataset.from_tensor_slices(slices)
    dset = dset.map(decode_fn, num_parallel_calls=AUTO)
    dset = dset.cache(cache_dir) if cache else dset
    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset
    dset = dset.repeat() if repeat else dset
    dset = dset.shuffle(shuffle) if shuffle else dset
    dset = dset.batch(bsize).prefetch(AUTO)

    return dset

#COMPETITION_NAME = ""siim-cov19-test-img512-study-600""
strategy = auto_select_accelerator()
BATCH_SIZE = strategy.num_replicas_in_sync * 16

IMSIZE = (224, 240, 260, 300, 380, 456, 528, 600)

#load_dir = f""/kaggle/input/{COMPETITION_NAME}/""
sub_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
sub_df = sub_df[:study_len]
test_paths = f'/kaggle/tmp/{split}/study/' + sub_df['id'] +'.png'

sub_df['negative'] = 0
sub_df['typical'] = 0
sub_df['indeterminate'] = 0
sub_df['atypical'] = 0


label_cols = sub_df.columns[2:]

test_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[7], IMSIZE[7]), ext='png')
dtest = build_dataset(
    test_paths, bsize=BATCH_SIZE, repeat=False, 
    shuffle=False, augment=False, cache=False,
    decode_fn=test_decoder
)

with strategy.scope():
    
    models = []
    
    models0 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model0.h5'
    )
    models1 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model1.h5'
    )
    models2 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model2.h5'
    )
    models3 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model3.h5'
    )
    models4 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model4.h5'
    )
    
    models.append(models0)
    models.append(models1)
    models.append(models2)
    models.append(models3)
    models.append(models4)

    
    
    
sub_df[label_cols] = sum([model.predict(dtest, verbose=1) for model in models]) / len(models)","This code installs the pydicom conda helper package, which contains the libjpeg-turbo, libgcc-ng, gdcm, conda, and certifi packages. It then reads in a DICOM image, applies a VOI LUT (if available), and rescales the image. Finally, it saves the image as a PNG file.",The documentation is semantically correct.,8,0.15921802055148115
"SEED  = 42
FOLDS = 5
DIM   = 512import numpy as np 
import pandas as pd 
import os, shutil
from glob import glob
from sklearn.cluster import KMeans
from tqdm.notebook import tqdm
from sklearn.preprocessing import LabelEncoder
import random
tqdm.pandas()np.random.seed(SEED)
random.seed(SEED)train_df = pd.read_csv(f'../input/siimcovid19-{DIM}-jpg-image-dataset/train.csv')
train_df['image_path'] = F'../input/siimcovid19-{DIM}-jpg-image-dataset/train/'+train_df.image_id+'.jpg'
train_df.head(2)name2label = {'Typical Appearance': 3,
 'Indeterminate Appearance': 1,
 'Atypical Appearance': 2,
 'Negative for Pneumonia': 0}
class_names = list(name2label.keys())
label2name = {v:k for k, v in name2label.items()}
train_df['class_name']  = train_df.progress_apply(lambda row:row[class_names].iloc[[row[class_names].values.argmax()]].index.tolist()[0], axis=1)
train_df['class_label'] = train_df.class_name.map(name2label)
train_df.head()from sklearn.model_selection import GroupKFold, StratifiedKFold
gkf  = GroupKFold(n_splits = 5)
train_df['fold'] = -1
for fold, (train_idx, val_idx) in enumerate(gkf.split(train_df, groups = train_df.StudyInstanceUID.tolist())):
    train_df.loc[val_idx, 'fold'] = fold
train_df.head()import matplotlib.pyplot as plt
import cv2
def load_image(path, dim=DIM, ch=3):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE if ch==None else cv2.IMREAD_COLOR)
    if img.shape[:2]!=(dim,dim) and dim!=-1:
        img = cv2.resize(img, dsize=(dim,dim), interpolation=cv2.INTER_AREA)
    return img

plt.imshow(load_image(train_df.image_path.iloc[100], dim=-1))","This code loads an image from a given path, and optionally resizes it to a given dimension. If no dimension is specified, the image is not resized.",8,0,0.04633970418577412
"# !conda install -c conda-forge imagehash --yes%load_ext autoreload
%autoreload 2
%matplotlib inline

import glob
import itertools
import collections

from PIL import Image
import cv2
from tqdm import tqdm_notebook as tqdm
import pandas as pd
import numpy as np
import torch
import imagehash

import matplotlib.pyplot as plt

def run():

    funcs = [
        imagehash.average_hash,
        imagehash.phash,
        imagehash.dhash,
        imagehash.whash,
        #lambda x: imagehash.whash(x, mode='db4'),
    ]

    SOPInstanceUIDs = []
    hashes = []
    for path in tqdm(glob.glob('../input/siim-covid19-resized-to-512px-png/*/*.png')):

        image = Image.open(path)
        imageid = path.split('/')[-1].split('.')[0]

        SOPInstanceUIDs.append(imageid)
        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))

    return SOPInstanceUIDs, np.array(hashes)

%time SOPInstanceUIDs, hashes_all = run()

hashes_all = torch.Tensor(hashes_all.astype(int)).cuda()%time sims = np.array([(hashes_all[i] == hashes_all).sum(dim=1).cpu().numpy()/256 for i in range(hashes_all.shape[0])])
indices1 = np.where(sims > 0.99)
indices2 = np.where(indices1[0] != indices1[1])
SOPInstanceUID1 = [SOPInstanceUIDs[i] for i in indices1[0][indices2]]
SOPInstanceUID2 = [SOPInstanceUIDs[i] for i in indices1[1][indices2]]
dups = {tuple(sorted([SOPInstanceUID1,SOPInstanceUID2])):True for SOPInstanceUID1, SOPInstanceUID2 in zip(SOPInstanceUID1, SOPInstanceUID2)}
print('found %d duplicates' % len(dups))dups","This code uses the imagehash library to detect duplicate images. It first loads the library, then loops through all the images in a given folder, hashing each one. It then compares all the hashes to find duplicates. Finally, it prints out the number of duplicates found.",8,1,0.05067157006005565
"!pip install gdcmimport os
from os import listdir
import pandas as pd
import numpy as np
import glob
from skimage import exposure
import matplotlib.pyplot as plt
%matplotlib inline

# pydicom
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
from fastai.imports import *
from fastai.medical.imaging import *

import cv2

# color
from colorama import Fore, Back, Style

import seaborn as sns
sns.set(style=""whitegrid"")

# plotly
import plotly.express as px
import plotly

# Suppress warnings 
import warnings
warnings.filterwarnings('ignore')

# Settings for pretty nice plots
plt.style.use('fivethirtyeight')
plt.show()# List files available
list(os.listdir(""../input/siim-covid19-detection""))IMAGE_PATH = ""../input/siim-covid19-detection/""

train_study_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
train_image_df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')

print(Fore.YELLOW + 'Train study df shape: ',Style.RESET_ALL,train_study_df.shape)
print(Fore.YELLOW + 'Train image df shape: ',Style.RESET_ALL,train_image_df.shape)display(train_study_df.head(5))
display(train_image_df.head(5))sample_submission = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
print(Fore.YELLOW + 'Sample submission df shape: ',Style.RESET_ALL,sample_submission.shape)
display(sample_submission)# Null values and Data types
print(Fore.BLUE + 'Train Study Set !!',Style.RESET_ALL)
print(train_study_df.info())
print('-------------')
print(Fore.YELLOW + 'Train Image Set !!',Style.RESET_ALL)
print(train_image_df.info())","This code imports the necessary libraries for reading in and processing the data, then reads in the data from the input files. It then displays some basic information about the dataframes. Finally, it reads in the sample submission file.",8,1,0.0369451640191695
"!pip install -q efficientnet >> /dev/nullimport pandas as pd, numpy as np, random,os, shutil
from glob import glob
from kaggle_datasets import KaggleDatasets
import tensorflow as tf, re, math
import tensorflow.keras.backend as K
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt
import tensorflow_addons as tfa
print('tf:',tf.__version__)# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit
VERBOSE      = 0
DISPLAY_PLOT = True

DEVICE = ""TPU"" #or ""GPU""

# USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD
SEED = 42

# NUMBER OF FOLDS. USE 2, 5, 10
FOLDS = 5

# WHICH IMAGE SIZES TO LOAD EACH FOLD
# CHOOSE 128, 192, 256, 384, 512, 512 
IMG_SIZES = [[512, 512]]*FOLDS

# BATCH SIZE AND EPOCHS
BATCH_SIZES = [16]*FOLDS
EPOCHS      = [12]*FOLDS

# WHICH EFFICIENTNET B? TO USE
EFF_NETS = [7]*FOLDS

# Augmentations
AUGMENT   = True
TRANSFORM = True

# transformations
ROT_    = 0.0
SHR_    = 2.0
HZOOM_  = 8.0
WZOOM_  = 8.0
HSHIFT_ = 8.0
WSHIFT_ = 8.0

# Dropout
PROBABILITY = 0.75
CT          = 8
SZ          = 0.08

#bri, contrast
sat  = (0.7, 1.3)
cont = (0.8, 1.2)
bri  =  0.1

# WEIGHTS FOR FOLD MODELS WHEN PREDICTING TEST
WGTS = [1/FOLDS]*FOLDS

# TEST TIME AUGMENTATION STEPS
TTA = 1def seeding(SEED):
    np.random.seed(SEED)
    random.seed(SEED)
    os.environ['PYTHONHASHSEED'] = str(SEED)
    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)
    tf.random.set_seed(SEED)
    print('seeding done!!!')
seeding(SEED)if DEVICE == ""TPU"":
    print(""connecting to TPU..."")
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        print('Running on TPU ', tpu.master())
    except ValueError:
        print(""Could not connect to TPU"")
        tpu = None

    if tpu:
        try:
            print(""initializing  TPU ..."")
            tf.config.experimental_connect_to_cluster(tpu)
            tf.tpu.experimental.initialize_tpu_system(tpu)
            strategy = tf.distribute.experimental.TPUStrategy(tpu)
            print(""TPU initialized"")
        except _:
            print(""failed to initialize TPU"")
    else:
        DEVICE = ""GPU""

if DEVICE != ""TPU"":
    print(""Using default strategy for CPU and single GPU"")
    strategy = tf.distribute.get_strategy()

if DEVICE == ""GPU"":
    print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
    

AUTO     = tf.data.experimental.AUTOTUNE
REPLICAS = strategy.num_replicas_in_sync
print(f'REPLICAS: {REPLICAS}')GCS_PATH = [None]*FOLDS
for i,k in enumerate(IMG_SIZES):
    GCS_PATH[i] = KaggleDatasets().get_gcs_path('siimcovid19-%ix%i-tfrec-dataset'%(k[0],k[1]))
files_train = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/train*.tfrec')))
files_test  = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/test*.tfrec')))
num_train_files = len(files_train)
num_test_files  = len(files_test)
print('train_files:',num_train_files)
print('test_files:',num_test_files)train_df = pd.read_csv('../input/siim-covid19-yolov5-2class-labels/meta.csv')
train_df.head(2)","This code installs the efficientnet package and imports pandas, numpy, random, os, and shutil. It also sets some global variables.

Next, the code defines a function to seed the random number generator. This is followed by code to connect to a TPU (if available) or to use the default strategy for CPU and single GPU.

The code then defines some paths and loads the training and testing data. Finally, it displays some information about the training data.",8,4,0.12575611937015113
"import pandas as pd df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')dfid_laststr_list  = []
for i in range(df.shape[0]):
    id_laststr_list.append(df.loc[i,'id'][-1])
df['id_last_str'] = id_laststr_liststudy_len = df[df['id_last_str'] == 'y'].shape[0]study_str = 'negative 1 0 0 1 1 atypical 1 0 0 1 1 typical 1 0 0 1 1 indeterminate 1 0 0 1 1'
for i in range(study_len):
    df.loc[i, 'PredictionString'] = study_strdf = df[['id', 'PredictionString']]","The code above reads in a CSV file containing sample submission data for a SIIM-COVID19 detection competition. It then creates a new column in the dataframe called 'id_last_str' which contains the last character of the 'id' column for each row.

The code then calculates the number of rows in the dataframe with an 'id_last_str' value of 'y' - this is the number of rows in the study.

The code then creates a string called 'study_str' which contains the prediction values for each row in the study.

Finally, the code loops through the rows in the study and sets the 'PredictionString' column to the 'study_str' string for each row.",8,7,0.07678866717755543
"import numpy as np 
import pandas as pd 
import os
from tqdm import tqdm
import matplotlib.pyplot as plt
import pydicomtrain_st = pd.read_csv(""../input/siim-covid19-detection/train_study_level.csv"")
train_st.head(3)
train_im = pd.read_csv(""../input/siim-covid19-detection/train_image_level.csv"")
train_im.head(3)sample = pd.read_csv(""../input/siim-covid19-detection/sample_submission.csv"")
sample.head(3)train_path = ""../input/siim-covid19-detection/train""
test_path = ""../input/siim-covid19-detection/test""trainimlist = []

for dirname, _, filenames in os.walk(train_path):
    for filename in filenames:
        trainimlist.append(os.path.join(dirname, filename))testimlist = []

for dirname, _, filenames in os.walk(test_path):
    for filename in filenames:
        testimlist.append(os.path.join(dirname, filename))","The code above imports the necessary libraries for working with the data, including numpy, pandas, os, and tqdm. It also imports matplotlib for plotting purposes.

The code then reads in the train_study_level.csv and train_image_level.csv files, which contain information about the studies and images, respectively. The code then reads in the sample_submission.csv file, which contains a sample submission format.

The code then sets the train_path and test_path variables to the location of the training and testing data, respectively.

The code then creates two lists, trainimlist and testimlist, which contain the filepaths to all of the training and testing images, respectively.",8,8,0.0688588104778619
"import fastai
import fastai.medical
from fastai.basics import *
from fastai.vision.all import *
from fastai.medical.imaging import *

import pydicom

import pandas as pd
fastai.__version__!conda install -c conda-forge gdcm -yfilegroup='train'
path='../input/siim-covid19-detection'
dirName = f'{path}/{filegroup}/'# Get DICOM file list from train directory
items = get_dicom_files(dirName)df_trn = pd.DataFrame.from_dicoms(items,px_summ=False)
df_trn.to_csv(f'alldicom{filegroup}.csv')
df_trn.describe()
df_trnfilegroup='test'
dirName = f'{path}/{filegroup}/'","The fastai library is used for deep learning with PyTorch. The library includes a medical module with tools for working with medical images. The code above imports the fastai and fastai.medical libraries, and then imports some basic modules from fastai.vision.

The code then imports the pydicom library, which is used for working with DICOM files. Next, the code imports the pandas library, which is used for working with dataframes.

The code then defines a filegroup variable, which is used to specify the train or test directory. The code then gets a list of DICOM files from the specified directory. Next, the code creates a dataframe from the DICOM files, and saves it to a CSV file. Finally, the code prints some basic statistics about the dataframe.",8,11,0.10917862633498586
"import numpy as np 
import pandas as pd
import os
import matplotlib.pyplot as plt
import pydicom as dicom
from glob import glob
from pathlib import Path
from pydicom import dcmread
import matplotlib
import astStudy= pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')Study.describe()Study.head()Study.isnull().sum()image_level=pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')image_level.head()","The code above imports the necessary libraries for data analysis and visualization. It then reads in two data files, one at the study level and one at the image level. The study level data is then summarized using the describe() method, and the image level data is displayed using the head() method. Finally, the code checks for null values in the data and displays the total number of null values found.",7,0,0.02065945546973735
"#Attaullah
#attaullahshafiq10@gmail.com
# Import libs
!conda install gdcm -c conda-forge -y
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
import pydicom
import glob
from tqdm.notebook import tqdm
from pydicom.pixel_data_handlers.util import apply_voi_lut
import matplotlib.pyplot as plt
from skimage import exposure#import gdcm
import cv2
import warnings
from fastai.vision.all import *
from fastai.medical.imaging import *
warnings.filterwarnings('ignore')
dataset_path = Path('../input/siim-covid19-detection')
import vtk

from vtk.util import numpy_support

reader = vtk.vtkDICOMImageReader()#HTML view

from IPython.display import HTML
HTML('<iframe src=https://arxiv.org/pdf/1506.01497.pdf width=600 height=650></iframe>')# from https://www.kaggle.com/tanlikesmath/siim-covid-19-detection-a-simple-eda
def dicom2array(path, voi_lut=True, fix_monochrome=True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()


def plot_imgs(imgs, cols=4, size=7, is_rgb=True, title="""", cmap='gray', img_size=(500,500)):
    rows = len(imgs)//cols + 1
    fig = plt.figure(figsize=(cols*size, rows*size))
    for i, img in enumerate(imgs):
        if img_size is not None:
            img = cv2.resize(img, img_size)
        fig.add_subplot(rows, cols, i+1)
        plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()dicom_paths = get_dicom_files(dataset_path/'train')
print([str(path) for path in dicom_paths[:4]])
imgs = [dicom2array(str(path)) for path in dicom_paths[:4]]
plot_imgs(imgs)","This code imports the necessary libraries for working with DICOM images, and then defines a function for converting DICOM images to numpy arrays. The function takes two parameters: the path to the DICOM image, and a boolean value indicating whether or not to apply a VOI LUT (if available). The function returns the image data as a numpy array.

The code then defines a function for plotting DICOM images. The function takes three parameters: the image data, the size of the image, and a boolean value indicating whether or not the image is RGB. The function returns the image data as a matplotlib figure.

Finally, the code defines a function for plotting multiple DICOM images. The function takes four parameters: the image data, the number of columns, the size of the image, and a boolean value indicating whether or not the image is RGB. The function returns the image data as a matplotlib figure.",8,8,0.12440523833858158
"!pip install -q --upgrade wandb

import wandb
wandb.login()import os
import gc
import cv2
import ast
import numpy as np
import pandas as pd
from tqdm import tqdm
import matplotlib.pyplot as plt
%matplotlib inlineTRAIN_PATH = '../input/siim-covid19-resized-to-256px-jpg/train/'
IMG_SIZE = 256
NUM_SAMPLES_TO_VIZ = 32# Load image level csv file
df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
# Load study level csv file
label_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')

# Modify values in the id column
df['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)
# Add absolute path
df['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)
# Get image level labels
df['image_level'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)

# Modify values in the id column
label_df['id'] = label_df.apply(lambda row: row.id.split('_')[0], axis=1)
# Rename the column id with StudyInstanceUID
label_df.columns = ['StudyInstanceUID', 'Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']

# Merge both dataframes
df = df.merge(label_df, on='StudyInstanceUID',how=""left"")
df.head(2)print(f'Number of unique image in training dataset: {len(df)}')

bbox_nan_num = df['boxes'].isna().sum()
print(f'Number of images without any bbox annotation: {bbox_nan_num}')# Label encode study-level labels
labels = df[['Negative for Pneumonia','Typical Appearance','Indeterminate Appearance','Atypical Appearance']].values
labels = np.argmax(labels, axis=1)

df['study_level'] = labels
df.head(2)class_label_to_id = {
    'Negative for Pneumonia': 0,
    'Typical Appearance': 1,
    'Indeterminate Appearance': 2,
    'Atypical Appearance': 3
}

class_id_to_label = {val: key for key, val in class_label_to_id.items()}","This code imports the wandb library and uses it to login to a wandb account. It then imports the os, gc, cv2, ast, numpy, pandas, tqdm, and matplotlib libraries. The code defines the TRAIN_PATH, IMG_SIZE, and NUM_SAMPLES_TO_VIZ variables.

The code then loads the train_image_level.csv and train_study_level.csv files into pandas dataframes. It modifies the id column in the df dataframe and adds a path column. The code gets the image level labels from the label column and adds them to the df dataframe.

The code then modifies the id column in the label_df dataframe and renames the id column to StudyInstanceUID. The code then merges the df and label_df dataframes.

The code then prints the number of unique images in the training dataset and the number of images without any bbox annotation.

The code then label encodes the study-level labels and adds them to the df dataframe.

Finally, the code defines the class_label_to_id and class_id_to_label dictionaries.",8,27,0.2000424817044065
"!conda install gdcm -c conda-forge -yimport os

from PIL import Image
import pandas as pd
from tqdm.auto import tqdmimport numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return imtrain = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')path = '../input/siim-covid19-detection/train/ae3e63d94c13/288554eb6182/e00f9fe0cce5.dcm'
dicom = pydicom.read_file(path)image_id = []
dim0 = []
dim1 = []
splits = []

for split in ['test', 'train']:
    save_dir = f'/kaggle/tmp/{split}/'

    os.makedirs(save_dir, exist_ok=True)
    
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(os.path.join(dirname, file))
            im = resize(xray, size=768)  
            im.save(os.path.join(save_dir, file.replace('dcm', 'jpg')))

            image_id.append(file.replace('.dcm', ''))
            dim0.append(xray.shape[0])
            dim1.append(xray.shape[1])
            splits.append(split)","This code reads in a DICOM image, applies a VOI LUT (if available), and then rescales the image to a desired size. It also converts the image to a JPEG format.",8,1,0.1820688787168852
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport sys
sys.path.append('../input/timm-pytorch-models/archive (3)/pytorch-image-models-master')
import timmimport numpy as np 
import pandas as pd 

import math
import random 
import os 
import cv2
import timm

from tqdm import tqdm 

import albumentations as A 
from albumentations.pytorch.transforms import ToTensorV2
import torch 
from torch.utils.data import Dataset 
from torch import nn
import torch.nn.functional as F 

import gc
import cudf
import cuml
import cupy
from cuml.feature_extraction.text import TfidfVectorizer
from cuml.neighbors import NearestNeighborsclass CFG:
    
    img_size = 512
    batch_size = 12
    seed = 2020
    
    device = 'cuda'
    classes = 11014
    
    model_name = 'eca_nfnet_l0'
    model_path = '../input/pytorch-model-weights/arcface_512x512_nfnet_l0 (mish).pt'
    
    scale = 30 
    margin = 0.5def read_dataset():
    df = pd.read_csv('../input/shopee-product-matching/test.csv')
    df_cu = cudf.DataFrame(df)#cuDF is a Python GPU DataFrame library workflow is fast enough on a single GPU fits in memory on a single GPU
    image_paths = '../input/shopee-product-matching/test_images/' + df['image']
    return df, df_cu, image_pathsdef seed_torch(seed=42):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    
seed_torch(CFG.seed)def get_image_predictions(df, embeddings,threshold = 0.0):
    
    if len(df) > 3:
        KNN = 50
    else : 
        KNN = 3
    
    model = NearestNeighbors(n_neighbors = KNN, metric = 'cosine')
    model.fit(embeddings)
    distances, indices = model.kneighbors(embeddings)
    
    predictions = []
    for k in tqdm(range(embeddings.shape[0])):
        idx = np.where(distances[k,] < threshold)[0]
        ids = indices[k,idx]
        posting_ids = df['posting_id'].iloc[ids].values
        predictions.append(posting_ids)
        
    del model, distances, indices
    gc.collect()
    return predictions","This function takes in a dataframe, embeddings, and a threshold, and outputs predictions. The predictions are based on the cosine similarity between the embeddings and the nearest neighbors.",8,1,0.11488466197608717
"%%capture
!pip install ../input/pytorchimagemodelsimport sys
sys.path.append('../input/facebookdeit')import os
import gc
import sys

import math
import random

from tqdm.notebook import tqdm

import re

import cv2
import numpy as np
import pandas as pd

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset ,RandomSampler

import timm

import albumentations

from swav_resnet import resnet50w2

import transformers
from transformers import AutoModel, AutoTokenizer

from models import deit_base_distilled_patch16_224



import cudf
import cuml
import cupydef set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True

set_seed(0)text_models=[
    {
        'transformer_model': '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14',
        'model_path' : '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14/ckpt.pt',
        'MAX_LEN' : 128,
        'params' : {
            'embed_dim' :1024,
            'out_dim' : 11014
        }
        
    },
    {
            'transformer_model': '../input/shopee-bert-base-indonesian/bert-base-indonesian_pp_7_8',
            'model_path' : '../input/shopee-bert-base-indonesian/bert-base-indonesian_pp_7_8/ckpt.pt',
            'MAX_LEN' : 128,
            'params' : {
                'embed_dim' :1024,
                'out_dim' : 11014
            }

        }
]

TRANSFORMER_EMBED_DIM = 768joint_models=[
    {
        'transformer_model': '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14',
        'model_path' : '../input/deit-xlm-joint-weights/finetuned_deit_xlm_joint_7_11.pt',
        'MAX_LEN' : 128,
        'IMAGE_SIZE' : 224,
        'params' : {
                'embed_dim' : 2048,
                'out_dim' : 11014
            }
        
    }
]image_models=[
    {
        'vision_model': '../input/shopee-swav-finetuned-resnet50w2/swav_resnet50w2_224_2048_5_epochs_loss_12_beef.pt',
        'IMAGE_SIZE' : 224,
        'params' : {
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
    {
        'vision_model': '../input/effnet-weights/finetuned_tf_efficientnet_b3_ns_300_2048_7_9.pt',
        'IMAGE_SIZE' : 300,
        'params' : {
            'backbone_name' : 'tf_efficientnet_b3_ns',
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
    
    {
        'vision_model': '../input/deit-base-distilled-patch16-224/finetuned_deit_base_distilled_patch16_224_4_18.pt',
        'IMAGE_SIZE' : 224,
        'params' : {
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
]","This code defines three types of models: text, image, and joint.

The text models are Transformer-based models that have been pretrained on a large multilingual corpus. The model paths and parameters are specified for each model. The MAX_LEN parameter specifies the maximum length of input text.

The image models are pretrained convolutional neural networks. The model paths and parameters are specified for each model. The IMAGE_SIZE parameter specifies the input image size.

The joint models are Transformer-based models that have been pretrained on a large multilingual corpus and fine-tuned on a image-text dataset. The model paths and parameters are specified for each model. The MAX_LEN and IMAGE_SIZE parameters specify the maximum length of input text and the input image size, respectively.",9,3,0.04818102994167325
"import sys
import gc
import math
import configparser
import numpy as np
import pandas as pd
import optuna
from tqdm import tqdm
import sklearn
import tensorflow as tf
from tensorflow import keras
from typing import Tupletry:
    # TPU detection. No parameters necessary if TPU_NAME environment variable is
    # set: this is always the case on Kaggle.
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
    print('Running on TPU ', tpu.master())
except ValueError:
    tpu = None

if tpu:
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.TPUStrategy(tpu)
else:
    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.
    strategy = tf.distribute.get_strategy()

print(""REPLICAS: "", strategy.num_replicas_in_sync)pd.set_option(""use_inf_as_na"", True)
pd.set_option(""display.max_columns"", 9999)
pd.set_option(""display.max_rows"", 9999)
pd.set_option('max_colwidth', 9999)
INPUT = '/kaggle/input'
DATA = f'{INPUT}/shopee-product-matching'
OUTPUT = '/kaggle/working'
RESOURCE_DIR = f'{INPUT}/shopee-product-matching-lib/kaggle-shopee-product-matching-1.0'
sys.path.append(f'{INPUT}/sgcharts-ml/src')
sys.path.append(f""{INPUT}/sentence-transformers/sentence-transformers-1.0.4"")
sys.path.append(f'{RESOURCE_DIR}/src')
import mylib
import scml
from scml.nlp import strip_punctuation, to_ascii_str
scml.seed_everything()MODEL = 'efficientnetb3'
CONF = configparser.ConfigParser()
CONF.read(f""{RESOURCE_DIR}/app.ini"")
resolution = int(CONF[MODEL][""resolution""])
INPUT_SHAPE = (resolution, resolution, 3)
print(f""INPUT_SHAPE={INPUT_SHAPE}"")train = pd.read_csv(f""{DATA}/train.csv"", engine=""c"", low_memory=False)
train[""target""] = mylib.target_label(train)
le = sklearn.preprocessing.LabelEncoder()
train[""label_group""] = le.fit_transform(train['label_group'])
n_classes=len(le.classes_)
print(f""n_classes={n_classes}"")
train.info()train.head()def _data_gen(
    dataframe,
    directory,
    target_size,
    batch_size,
    color_mode=""rgb"",
    class_mode=""raw"",
    x_col=""image"",
    y_col=""label_group""
):
    dtype = np.float32
    rescale = 1./255
    interpolation = ""bicubic""
    data_format = ""channels_last""
    shuffle = True
    idg = keras.preprocessing.image.ImageDataGenerator(
        shear_range=0.2,
        zoom_range=0.2,
        brightness_range=(0.7, 1.3),
        #rotation_range=90,
        horizontal_flip=True,
        rescale=rescale,
        data_format=data_format,
        dtype=dtype
    )
    g = idg.flow_from_dataframe(
        dataframe=dataframe,
        x_col=x_col,
        y_col=y_col,
        directory=directory,
        target_size=target_size,
        color_mode=color_mode,
        batch_size=batch_size,
        shuffle=shuffle,
        class_mode=class_mode,
        interpolation=interpolation,
    )
    while True:
        x, y = g.next()
        yield [x, y], y","This code defines a data generator function that can be used to load image data from a pandas dataframe. The function takes in a number of parameters, including the dataframe itself, the directory containing the image data, the target image size, the batch size, the color mode, the class mode, and the column names for the image data and labels. The function returns a generator that can be used to iterate over the image data.",8,2,0.06349151170131231
"import pip
try:
     __import__(""imutils"")
except ImportError:
    pip.main([""install"", ""imutils""])import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import  matplotlib.pyplot as plt
import tensorflow as tf
import pandas as pd
import cv2
from imutils.object_detection import non_max_suppression
import pytesseract
import os
import glob
os.chdir('/kaggle/working')
BASE = '../input/shopee-product-matching/train_images/'
EAST_PATH = ""/kaggle/input/east-data-leo/frozen_east_text_detection/frozen_east_text_detection.pb""
RESIZE_IMG_SHAPE = (500,500)
img_paths = glob.glob(f""{BASE}*jpg"") train = pd.read_csv('../input/shopee-product-matching/train.csv')
print('train shape is', train.shape )
train.head()groups = train.label_group.value_counts()
plt.figure(figsize=(20,5))
plt.plot(np.arange(len(groups)),groups.values)
plt.ylabel('Duplicate Count',size=14)
plt.xlabel('Index of Unique Item',size=14)
plt.title('Duplicate Count vs. Unique Item Count',size=16)
plt.show()

plt.figure(figsize=(20,5))
plt.bar(groups.index.values[:50].astype('str'),groups.values[:50])
plt.xticks(rotation = 45)
plt.ylabel('Duplicate Count',size=14)
plt.xlabel('Label Group',size=14)
plt.title('Top 50 Duplicated Items',size=16)
plt.show()def img_proc(img,offset =20):
    img =img[offset:-offset,offset:-offset]
    img =cv2.resize(img ,RESIZE_IMG_SHAPE)
    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    gray = cv2.medianBlur(gray,5)
    ret, thresh = cv2.threshold(gray,150,255,cv2.THRESH_BINARY)
    thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\
            cv2.THRESH_BINARY_INV,21,2)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))
    opening = cv2.erode(thresh,kernel, iterations = 1)
    closing = cv2.dilate(opening,kernel,iterations=1)
    contours = cv2.findContours(closing, 
                            cv2.RETR_EXTERNAL,
                            cv2.CHAIN_APPROX_NONE)
    canvas =np.zeros((500,500))
    cv2.drawContours(canvas, contours[0], -1, (255,0,255), thickness = 2) 
    return canvas



def displayDF(train, random=False, COLS=6, ROWS=4, path=BASE):
    for k in range(ROWS):
        plt.figure(figsize=(20,5))
        for j in range(COLS):
            if random: row = np.random.randint(0,len(train))
            else: row = COLS*k + j
            name = train.iloc[row,1]
            title = train.iloc[row,3]
            title_with_return = """"
            for i,ch in enumerate(title):
                title_with_return += ch
                if (i!=0)&(i%20==0): title_with_return += '\n'
            img = img_proc(cv2.imread(path+name))
            plt.subplot(1,COLS,j+1)
            plt.title(title_with_return)
            plt.axis('off')
            plt.imshow(img)
        plt.show()
        
displayDF(train,random=True)def predictions(prob_score, geo,min_conf):
    (numR, numC) = prob_score.shape[2:4]
    boxes = []
    confidence_val = []
    for y in range(0, numR):
        scoresData = prob_score[0, 0, y]
        x0 = geo[0, 0, y]
        x1 = geo[0, 1, y]
        x2 = geo[0, 2, y]
        x3 = geo[0, 3, y]
        anglesData = geo[0, 4, y]
        for i in range(0, numC):
            if scoresData[i] < min_conf:
                continue
            (offX, offY) = (i * 4.0, y * 4.0)
            angle = anglesData[i]
            cos = np.cos(angle)
            sin = np.sin(angle)
            h = x0[i] + x2[i]
            w = x1[i] + x3[i]
            endX = int(offX + (cos * x1[i]) + (sin * x2[i]))
            endY = int(offY - (sin * x1[i]) + (cos * x2[i]))
            startX = int(endX - w)
            startY = int(endY - h)
            boxes.append((startX, startY, endX, endY))
            confidence_val.append(scoresData[i])

    return (boxes, confidence_val)

def get_text(img,img_text ='Output',min_conf = 0.7, east = EAST_PATH):
    image = cv2.imread(img)
    orig = image.copy()
    (origH, origW) = image.shape[:2]
    (newW, newH) = (320,320)
    rW = origW / float(newW)
    rH = origH / float(newH)
    image = cv2.resize(image, (newW, newH))
    (H, W) = image.shape[:2]
    blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),
        (123.68, 116.78, 103.94), swapRB=True, crop=False)
    net = cv2.dnn.readNet(east)
    # The following two layer need to pulled from EAST model for achieving this. 
    layerNames = [
        ""feature_fusion/Conv_7/Sigmoid"",
        ""feature_fusion/concat_3""]

    #Forward pass the blob from the image to get the desired output layers
    net.setInput(blob)
    (scores, geometry) = net.forward(layerNames)
    (boxes, confidence_val) = predictions(scores, geometry,min_conf)
    boxes = non_max_suppression(np.array(boxes), probs=confidence_val)
    
    results = []
    for (startX, startY, endX, endY) in boxes:
        startX = int(startX * rW)
        startY = int(startY * rH)
        endX = int(endX * rW)
        endY = int(endY * rH)
        r = orig[startY:endY, startX:endX]
        configuration = (""-l eng --oem 1 --psm 8"")
        text = pytesseract.image_to_string(r, config=configuration)
        results.append(((startX, startY, endX, endY), text))

    orig_image = orig.copy()
    txts=[]
    for ((start_X, start_Y, end_X, end_Y), text) in results:
        text = """".join([x if ord(x) < 128 else """" for x in text]).strip()
        cv2.rectangle(orig_image, (start_X, start_Y), (end_X, end_Y),
            (0, 0, 255), 2)
        cv2.putText(orig_image, text, (start_X, start_Y + 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,255, 0), 4)
        txts.append(text)
    plt.figure(figsize=(10,10))
    plt.imshow(orig_image)
    plt.title(img_text)
    plt.show()
    print(txts)it = iter(range(500))","The code above imports the pip module and then tries to import the imutils module. If the imutils module is not found, the code uses pip to install it. The code then sets up some parameters for image processing, loads in a train.csv file, and displays some information about the data. Next, the code defines a function for processing images, and another function for displaying dataframes. Finally, the code calls the get_text function to extract text from an image.",9,3,0.1086862435908115
,This code defines a function that takes an array of integers as an argument and returns the sum of all the elements in the array.,8,0,
"! conda install -c conda-forge gdcm -yimport numpy as np
import pandas as pd 
import os
from PIL import Image
from tqdm.auto import tqdm
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import seaborn as sns
from pandas_profiling import ProfileReport
from glob import glob
from tqdm.notebook import tqdm
import matplotlib.pyplot as plt
from skimage import exposure
import cv2
import warnings
import albumentations as A# config params
class CFG:
    data_path = '../input/siim-covid19-detection/'
    size = 512
    seed = 2021
    working_dir = '/kaggle/working/'def dicom2array(path, voi_lut=True, fix_monochrome=True):
    dicom = pydicom.read_file(path)
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
    return data
        
    
def plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()
# storage file for the transformed images
!mkdir train# prepare a dataframe for producing resized images with bboxes
xtrain_img = pd.read_csv(CFG.data_path + 'train_image_level.csv')


path_list = []
image_list = []
splits = []

for split in ['train']:
    
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            fullpath = dirname + '/' + file
            path_list.append(fullpath)
            image_list.append(file)

df = pd.DataFrame(image_list, columns =['image_id'])
df['image_path'] = path_list

xtrain_img['image_id'] = xtrain_img['id'].apply(lambda s: s.replace('_image','') + '.dcm')
xtrain_img = pd.merge(left = xtrain_img, right = df, on = 'image_id')
# common transformation we shall use
transform = A.Compose(
    [
        A.Resize(height = CFG.size , width = CFG.size, p=1),
    ], 
    p=1.0,  bbox_params=A.BboxParams( format='pascal_voc', min_area=0,  min_visibility=0, label_fields=['labels']  ))        

img_list = []
label_list = []

# loop over files
for ii in range(len(xtrain_img)):
    # get the image
    row = xtrain_img.loc[ii]
    img_path = row['image_path']
    img = dicom2array(path=img_path)
    newname = img_path.split('/')[-1].replace('dcm', 'jpg')
    img_list.append(newname)
    
    # get the bounding boxes
    bboxes = []
    bbox = []
    labels = []
    confidences = []

    for i, l in enumerate(row['label'].split(' ')):
        if (i % 6 == 0) :
            labels.append(l)
        if (i % 6 == 1):
            confidences.append(l)
        if (i % 6 > 1):
            bbox.append(np.clip(float(l), a_min = 0, a_max = None ))
        if i % 6 == 5:
            bboxes.append(bbox)
            bbox = []    

    # transform both
    result = transform(image = img, bboxes = bboxes, labels = np.ones(len(bboxes)))
    new_image = result['image']
    new_bboxes = np.array(result['bboxes']).tolist()

    # format the output
#    print('orig label: ' + row['label'])
    newlabel = ''
    if labels[0] == 'none':
        newlabel = 'none 1 0 0 1 1'
    else:
        for j in range(len(labels)):
            newlabel += labels[j] + ' ' + confidences[j] + ' ' +  ' '.join([str(np.round(f,5)) for f in new_bboxes[0]]) + ' '
#    print('new label:' + newlabel)
    label_list.append(newlabel)
    
    # store the new image
    cv2.imwrite(CFG.working_dir + 'train/' + newname , new_image)","This code is responsible for transforming images and bounding boxes in the training data set. It reads in the images and bounding box data from a CSV file, then uses the Albumentations library to perform the transformations. Finally, it saves the transformed images and bounding box data to a new CSV file.",8,1,0.20067241511171804
"!wget 'https://anaconda.org/conda-forge/libjpeg-turbo/2.1.0/download/linux-64/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/libgcc-ng/9.3.0/download/linux-64/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/gdcm/2.8.9/download/linux-64/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/conda/4.10.1/download/linux-64/conda-4.10.1-py37h89c1867_0.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/certifi/2020.12.5/download/linux-64/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -q
!wget 'https://anaconda.org/conda-forge/openssl/1.1.1k/download/linux-64/openssl-1.1.1k-h7f98852_0.tar.bz2' -q","The above code downloads the following packages from Anaconda:

- libjpeg-turbo
- libgcc-ng
- gdcm
- conda
- certifi
- openssl

Each package is downloaded as a "".tar.bz2"" file. The ""-q"" flag tells wget to download the files quietly, without printing progress information to the console.",8,7,0.1893240524242494
"! conda install gdcm -c conda-forge -y! pip install --no-deps '../input/timm-package/timm-0.1.26-py3-none-any.whl' > /dev/null
! pip install --no-deps '../input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl' > /dev/nullimport sys
sys.path.insert(0, ""../input/timm-efficientdet-pytorch"")
sys.path.insert(0, ""../input/omegaconf"")

import os
from PIL import Image
import pandas as pd
from tqdm.auto import tqdm
import numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import torch
from datetime import datetime
import time
import random
import cv2
import albumentations as A
import matplotlib.pyplot as plt
from albumentations.pytorch.transforms import ToTensorV2
from sklearn.model_selection import StratifiedKFold
from torch.utils.data import Dataset,DataLoader
from torch.utils.data.sampler import SequentialSampler, RandomSampler
from glob import glob

SEED = 42

def seed_everything(seed):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = True

seed_everything(SEED)dataset_path = ""../input/siim-covid19-detection""def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return data

def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im
        
    
def plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()
%%time
image_id = []


cnt_img = 0 # for testing

for split in ['test', 'train']:
    save_dir = f'/kaggle/tmp/{split}/'

    os.makedirs(save_dir, exist_ok=True)
    
    for dirname, _, filenames in tqdm(os.walk(f'{dataset_path}/{split}')):
        for file in filenames:
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(os.path.join(dirname, file))
            im = resize(xray, size=256)  
            im.save(os.path.join(save_dir, file.replace('dcm', 'jpg')))

            image_id.append(file.replace('.dcm', ''))

            splits.append(split)
        
        if cnt_img >= 10:
            cnt_img = 0
            break
        
        cnt_img += 1
            image_id","This code reads in a DICOM image, applies a VOI LUT if available, and rescales the image to 256x256. The image is then saved as a JPEG.",8,1,0.12171957058118169
"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -yimport os

from PIL import Image
import pandas as pd
from tqdm.auto import tqdmimport numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im
split = 'test'
save_dir = f'/kaggle/tmp/{split}/'

os.makedirs(save_dir, exist_ok=True)

save_dir = f'/kaggle/tmp/{split}/study/'
os.makedirs(save_dir, exist_ok=True)

for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
    for file in filenames:
        # set keep_ratio=True to have original aspect ratio
        xray = read_xray(os.path.join(dirname, file))
        im = resize(xray, size=600)  
        study = dirname.split('/')[-2] + '_study.png'
        im.save(os.path.join(save_dir, study))
import numpy as np 
import pandas as pd

df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
id_laststr_list  = []
for i in range(df.shape[0]):
    id_laststr_list.append(df.loc[i,'id'][-1])
df['id_last_str'] = id_laststr_list

study_len = df[df['id_last_str'] == 'y'].shape[0]!pip install /kaggle/input/kerasapplications -q
!pip install /kaggle/input/efficientnet-keras-source-code/ -q --no-deps

import os

import efficientnet.tfkeras as efn
import numpy as np
import pandas as pd
import tensorflow as tf

def auto_select_accelerator():
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        tf.config.experimental_connect_to_cluster(tpu)
        tf.tpu.experimental.initialize_tpu_system(tpu)
        strategy = tf.distribute.experimental.TPUStrategy(tpu)
        print(""Running on TPU:"", tpu.master())
    except ValueError:
        strategy = tf.distribute.get_strategy()
    print(f""Running on {strategy.num_replicas_in_sync} replicas"")

    return strategy


def build_decoder(with_labels=True, target_size=(300, 300), ext='jpg'):
    def decode(path):
        file_bytes = tf.io.read_file(path)
        if ext == 'png':
            img = tf.image.decode_png(file_bytes, channels=3)
        elif ext in ['jpg', 'jpeg']:
            img = tf.image.decode_jpeg(file_bytes, channels=3)
        else:
            raise ValueError(""Image extension not supported"")

        img = tf.cast(img, tf.float32) / 255.0
        img = tf.image.resize(img, target_size)

        return img

    def decode_with_labels(path, label):
        return decode(path), label

    return decode_with_labels if with_labels else decode


def build_augmenter(with_labels=True):
    def augment(img):
        img = tf.image.random_flip_left_right(img)
        img = tf.image.random_flip_up_down(img)
        return img

    def augment_with_labels(img, label):
        return augment(img), label

    return augment_with_labels if with_labels else augment


def build_dataset(paths, labels=None, bsize=32, cache=True,
                  decode_fn=None, augment_fn=None,
                  augment=True, repeat=True, shuffle=1024, 
                  cache_dir=""""):
    if cache_dir != """" and cache is True:
        os.makedirs(cache_dir, exist_ok=True)

    if decode_fn is None:
        decode_fn = build_decoder(labels is not None)

    if augment_fn is None:
        augment_fn = build_augmenter(labels is not None)

    AUTO = tf.data.experimental.AUTOTUNE
    slices = paths if labels is None else (paths, labels)

    dset = tf.data.Dataset.from_tensor_slices(slices)
    dset = dset.map(decode_fn, num_parallel_calls=AUTO)
    dset = dset.cache(cache_dir) if cache else dset
    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset
    dset = dset.repeat() if repeat else dset
    dset = dset.shuffle(shuffle) if shuffle else dset
    dset = dset.batch(bsize).prefetch(AUTO)

    return dset

#COMPETITION_NAME = ""siim-cov19-test-img512-study-600""
strategy = auto_select_accelerator()
BATCH_SIZE = strategy.num_replicas_in_sync * 16

IMSIZE = (224, 240, 260, 300, 380, 456, 528, 600)

#load_dir = f""/kaggle/input/{COMPETITION_NAME}/""
sub_df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
sub_df = sub_df[:study_len]
test_paths = f'/kaggle/tmp/{split}/study/' + sub_df['id'] +'.png'

sub_df['negative'] = 0
sub_df['typical'] = 0
sub_df['indeterminate'] = 0
sub_df['atypical'] = 0


label_cols = sub_df.columns[2:]

test_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[7], IMSIZE[7]), ext='png')
dtest = build_dataset(
    test_paths, bsize=BATCH_SIZE, repeat=False, 
    shuffle=False, augment=False, cache=False,
    decode_fn=test_decoder
)

with strategy.scope():
    
    models = []
    
    models0 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model0.h5'
    )
    models1 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model1.h5'
    )
    models2 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model2.h5'
    )
    models3 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model3.h5'
    )
    models4 = tf.keras.models.load_model(
        '../input/siim-covid19-efnb7-train-study/model4.h5'
    )
    
    models.append(models0)
    models.append(models1)
    models.append(models2)
    models.append(models3)
    models.append(models4)

    
    
    
sub_df[label_cols] = sum([model.predict(dtest, verbose=1) for model in models]) / len(models)","This code installs the pydicom package and its dependencies, using the conda package manager. It then imports the package and its submodules.

Next, the code defines a function to read in a DICOM image, apply a VOI LUT if available, and rescale the image. Finally, the code defines a function to resize an image.

The code then reads in a CSV file containing information about the DICOM images to be processed. It then processes the images, saving the results to a temporary directory.

The code then builds a dataset from the processed images, using the Keras package. Finally, the code loads five models and predicts the labels for the images in the dataset. The predictions are saved to a CSV file.",8,3,0.08458935831427929
"SEED  = 42
FOLDS = 5
DIM   = 512import numpy as np 
import pandas as pd 
import os, shutil
from glob import glob
from sklearn.cluster import KMeans
from tqdm.notebook import tqdm
from sklearn.preprocessing import LabelEncoder
import random
tqdm.pandas()np.random.seed(SEED)
random.seed(SEED)train_df = pd.read_csv(f'../input/siimcovid19-{DIM}-jpg-image-dataset/train.csv')
train_df['image_path'] = F'../input/siimcovid19-{DIM}-jpg-image-dataset/train/'+train_df.image_id+'.jpg'
train_df.head(2)name2label = {'Typical Appearance': 3,
 'Indeterminate Appearance': 1,
 'Atypical Appearance': 2,
 'Negative for Pneumonia': 0}
class_names = list(name2label.keys())
label2name = {v:k for k, v in name2label.items()}
train_df['class_name']  = train_df.progress_apply(lambda row:row[class_names].iloc[[row[class_names].values.argmax()]].index.tolist()[0], axis=1)
train_df['class_label'] = train_df.class_name.map(name2label)
train_df.head()from sklearn.model_selection import GroupKFold, StratifiedKFold
gkf  = GroupKFold(n_splits = 5)
train_df['fold'] = -1
for fold, (train_idx, val_idx) in enumerate(gkf.split(train_df, groups = train_df.StudyInstanceUID.tolist())):
    train_df.loc[val_idx, 'fold'] = fold
train_df.head()import matplotlib.pyplot as plt
import cv2
def load_image(path, dim=DIM, ch=3):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE if ch==None else cv2.IMREAD_COLOR)
    if img.shape[:2]!=(dim,dim) and dim!=-1:
        img = cv2.resize(img, dsize=(dim,dim), interpolation=cv2.INTER_AREA)
    return img

plt.imshow(load_image(train_df.image_path.iloc[100], dim=-1))","This code loads an image from a specified path, optionally resizes it to a specified dimension, and returns it as a numpy array.",8,1,0.05455438322813145
"# !conda install -c conda-forge imagehash --yes%load_ext autoreload
%autoreload 2
%matplotlib inline

import glob
import itertools
import collections

from PIL import Image
import cv2
from tqdm import tqdm_notebook as tqdm
import pandas as pd
import numpy as np
import torch
import imagehash

import matplotlib.pyplot as plt

def run():

    funcs = [
        imagehash.average_hash,
        imagehash.phash,
        imagehash.dhash,
        imagehash.whash,
        #lambda x: imagehash.whash(x, mode='db4'),
    ]

    SOPInstanceUIDs = []
    hashes = []
    for path in tqdm(glob.glob('../input/siim-covid19-resized-to-512px-png/*/*.png')):

        image = Image.open(path)
        imageid = path.split('/')[-1].split('.')[0]

        SOPInstanceUIDs.append(imageid)
        hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))

    return SOPInstanceUIDs, np.array(hashes)

%time SOPInstanceUIDs, hashes_all = run()

hashes_all = torch.Tensor(hashes_all.astype(int)).cuda()%time sims = np.array([(hashes_all[i] == hashes_all).sum(dim=1).cpu().numpy()/256 for i in range(hashes_all.shape[0])])
indices1 = np.where(sims > 0.99)
indices2 = np.where(indices1[0] != indices1[1])
SOPInstanceUID1 = [SOPInstanceUIDs[i] for i in indices1[0][indices2]]
SOPInstanceUID2 = [SOPInstanceUIDs[i] for i in indices1[1][indices2]]
dups = {tuple(sorted([SOPInstanceUID1,SOPInstanceUID2])):True for SOPInstanceUID1, SOPInstanceUID2 in zip(SOPInstanceUID1, SOPInstanceUID2)}
print('found %d duplicates' % len(dups))dups","The code above uses the imagehash library to generate hashes for images. These hashes can be used to determine if two images are duplicates of each other.

The code first defines a list of functions to be used for hashing. These functions are average_hash, phash, dhash, and whash.

Next, the code loops through all of the images in a given directory. For each image, the code calculates the hashes using the defined functions. These hashes are then stored in a list.

Finally, the code compares all of the hashes to each other to find any duplicates. A list of duplicate images is then printed.",8,6,0.08591487306748438
"!pip install gdcmimport os
from os import listdir
import pandas as pd
import numpy as np
import glob
from skimage import exposure
import matplotlib.pyplot as plt
%matplotlib inline

# pydicom
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
from fastai.imports import *
from fastai.medical.imaging import *

import cv2

# color
from colorama import Fore, Back, Style

import seaborn as sns
sns.set(style=""whitegrid"")

# plotly
import plotly.express as px
import plotly

# Suppress warnings 
import warnings
warnings.filterwarnings('ignore')

# Settings for pretty nice plots
plt.style.use('fivethirtyeight')
plt.show()# List files available
list(os.listdir(""../input/siim-covid19-detection""))IMAGE_PATH = ""../input/siim-covid19-detection/""

train_study_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
train_image_df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')

print(Fore.YELLOW + 'Train study df shape: ',Style.RESET_ALL,train_study_df.shape)
print(Fore.YELLOW + 'Train image df shape: ',Style.RESET_ALL,train_image_df.shape)display(train_study_df.head(5))
display(train_image_df.head(5))sample_submission = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')
print(Fore.YELLOW + 'Sample submission df shape: ',Style.RESET_ALL,sample_submission.shape)
display(sample_submission)# Null values and Data types
print(Fore.BLUE + 'Train Study Set !!',Style.RESET_ALL)
print(train_study_df.info())
print('-------------')
print(Fore.YELLOW + 'Train Image Set !!',Style.RESET_ALL)
print(train_image_df.info())","This code is for the Siim-Covid19-Detection project. It imports the necessary libraries, reads in the project data, and then displays some basic information about the data.",7,0,0.054796917875967556
"!pip install -q efficientnet >> /dev/nullimport pandas as pd, numpy as np, random,os, shutil
from glob import glob
from kaggle_datasets import KaggleDatasets
import tensorflow as tf, re, math
import tensorflow.keras.backend as K
import efficientnet.tfkeras as efn
from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt
import tensorflow_addons as tfa
print('tf:',tf.__version__)# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit
VERBOSE      = 0
DISPLAY_PLOT = True

DEVICE = ""TPU"" #or ""GPU""

# USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD
SEED = 42

# NUMBER OF FOLDS. USE 2, 5, 10
FOLDS = 5

# WHICH IMAGE SIZES TO LOAD EACH FOLD
# CHOOSE 128, 192, 256, 384, 512, 512 
IMG_SIZES = [[512, 512]]*FOLDS

# BATCH SIZE AND EPOCHS
BATCH_SIZES = [16]*FOLDS
EPOCHS      = [12]*FOLDS

# WHICH EFFICIENTNET B? TO USE
EFF_NETS = [7]*FOLDS

# Augmentations
AUGMENT   = True
TRANSFORM = True

# transformations
ROT_    = 0.0
SHR_    = 2.0
HZOOM_  = 8.0
WZOOM_  = 8.0
HSHIFT_ = 8.0
WSHIFT_ = 8.0

# Dropout
PROBABILITY = 0.75
CT          = 8
SZ          = 0.08

#bri, contrast
sat  = (0.7, 1.3)
cont = (0.8, 1.2)
bri  =  0.1

# WEIGHTS FOR FOLD MODELS WHEN PREDICTING TEST
WGTS = [1/FOLDS]*FOLDS

# TEST TIME AUGMENTATION STEPS
TTA = 1def seeding(SEED):
    np.random.seed(SEED)
    random.seed(SEED)
    os.environ['PYTHONHASHSEED'] = str(SEED)
    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)
    tf.random.set_seed(SEED)
    print('seeding done!!!')
seeding(SEED)if DEVICE == ""TPU"":
    print(""connecting to TPU..."")
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        print('Running on TPU ', tpu.master())
    except ValueError:
        print(""Could not connect to TPU"")
        tpu = None

    if tpu:
        try:
            print(""initializing  TPU ..."")
            tf.config.experimental_connect_to_cluster(tpu)
            tf.tpu.experimental.initialize_tpu_system(tpu)
            strategy = tf.distribute.experimental.TPUStrategy(tpu)
            print(""TPU initialized"")
        except _:
            print(""failed to initialize TPU"")
    else:
        DEVICE = ""GPU""

if DEVICE != ""TPU"":
    print(""Using default strategy for CPU and single GPU"")
    strategy = tf.distribute.get_strategy()

if DEVICE == ""GPU"":
    print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
    

AUTO     = tf.data.experimental.AUTOTUNE
REPLICAS = strategy.num_replicas_in_sync
print(f'REPLICAS: {REPLICAS}')GCS_PATH = [None]*FOLDS
for i,k in enumerate(IMG_SIZES):
    GCS_PATH[i] = KaggleDatasets().get_gcs_path('siimcovid19-%ix%i-tfrec-dataset'%(k[0],k[1]))
files_train = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/train*.tfrec')))
files_test  = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/test*.tfrec')))
num_train_files = len(files_train)
num_test_files  = len(files_test)
print('train_files:',num_train_files)
print('test_files:',num_test_files)train_df = pd.read_csv('../input/siim-covid19-yolov5-2class-labels/meta.csv')
train_df.head(2)","This code installs the efficientnet package and imports the pandas, numpy, random, os, and shutil libraries. It also imports the KaggleDatasets class from the kaggle_datasets library. The code then sets the verbosity, device, seed, folds, image sizes, batch sizes, and epochs variables. Finally, the code imports the efficientnet.tfkeras module and defines the seeding function.

The seeding function takes an SEED argument and sets the seed for the random number generator, the Python hash function, and the TensorFlow CUDNN determinism setting. The function then prints a 'seeding done' message.

If the DEVICE variable is set to 'TPU', the code attempts to connect to a TPU server and initialize the TPU system. If this fails, the DEVICE variable is set to 'GPU'.

The code then sets the AUTO, REPLICAS, and GCS_PATH variables. The AUTO variable is set to the TensorFlow experimental AUTOTUNE value. The REPLICAS variable is set to the number of replicas in the TensorFlow strategy. Finally, the GCS_PATH variable is set to a list of KaggleDatasets paths for the image sizes specified in the IMG_SIZES variable.

The code then sets the files_train and files_test variables to lists of file paths for the train and test images. The num_train_files and num_test_files variables are then set to the length of the files_train and files_test lists, respectively.

The train_df variable is then set to a pandas DataFrame containing the data from the 'meta.csv' file.",8,14,0.11088011597677554
"import pandas as pd df = pd.read_csv('../input/siim-covid19-detection/sample_submission.csv')dfid_laststr_list  = []
for i in range(df.shape[0]):
    id_laststr_list.append(df.loc[i,'id'][-1])
df['id_last_str'] = id_laststr_liststudy_len = df[df['id_last_str'] == 'y'].shape[0]study_str = 'negative 1 0 0 1 1 atypical 1 0 0 1 1 typical 1 0 0 1 1 indeterminate 1 0 0 1 1'
for i in range(study_len):
    df.loc[i, 'PredictionString'] = study_strdf = df[['id', 'PredictionString']]","This code imports the pandas library and reads in a CSV file containing data on Covid-19 cases. It then creates a new column in the dataframe containing the last character of the 'id' column. Finally, it creates a new column containing a prediction string for each case, based on the last character of the 'id' column.",8,1,0.053369476426026914
"import numpy as np 
import pandas as pd 
import os
from tqdm import tqdm
import matplotlib.pyplot as plt
import pydicomtrain_st = pd.read_csv(""../input/siim-covid19-detection/train_study_level.csv"")
train_st.head(3)
train_im = pd.read_csv(""../input/siim-covid19-detection/train_image_level.csv"")
train_im.head(3)sample = pd.read_csv(""../input/siim-covid19-detection/sample_submission.csv"")
sample.head(3)train_path = ""../input/siim-covid19-detection/train""
test_path = ""../input/siim-covid19-detection/test""trainimlist = []

for dirname, _, filenames in os.walk(train_path):
    for filename in filenames:
        trainimlist.append(os.path.join(dirname, filename))testimlist = []

for dirname, _, filenames in os.walk(test_path):
    for filename in filenames:
        testimlist.append(os.path.join(dirname, filename))","The code above imports the necessary libraries for working with data, including numpy, pandas, and matplotlib. It also defines two variables, train_path and test_path, which contain the paths to the training and testing data sets, respectively. Finally, it creates two lists, trainimlist and testimlist, which contain the paths to all of the images in the training and testing data sets, respectively.",8,5,0.04432076800938195
"import fastai
import fastai.medical
from fastai.basics import *
from fastai.vision.all import *
from fastai.medical.imaging import *

import pydicom

import pandas as pd
fastai.__version__!conda install -c conda-forge gdcm -yfilegroup='train'
path='../input/siim-covid19-detection'
dirName = f'{path}/{filegroup}/'# Get DICOM file list from train directory
items = get_dicom_files(dirName)df_trn = pd.DataFrame.from_dicoms(items,px_summ=False)
df_trn.to_csv(f'alldicom{filegroup}.csv')
df_trn.describe()
df_trnfilegroup='test'
dirName = f'{path}/{filegroup}/'","The code above imports the fastai and fastai.medical libraries, and then uses the get_dicom_files() function to get a list of DICOM files from a train directory. It then creates a DataFrame from the DICOM files using the from_dicoms() function, and saves it to a CSV file. Finally, it uses the describe() function to generate some summary statistics about the DataFrame.",8,6,0.13161082944046965
"import numpy as np 
import pandas as pd
import os
import matplotlib.pyplot as plt
import pydicom as dicom
from glob import glob
from pathlib import Path
from pydicom import dcmread
import matplotlib
import astStudy= pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')Study.describe()Study.head()Study.isnull().sum()image_level=pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')image_level.head()","The code above imports the necessary libraries for reading in data, performing data analysis, and visualizing the results. The code then reads in two data files, one at the study level and one at the image level. The study level data is then summarized using the describe() method, and the image level data is then visualized using the head() method. Finally, the code checks for null values in the data and reports the results.",8,0,0.018273520252661574
"#Attaullah
#attaullahshafiq10@gmail.com
# Import libs
!conda install gdcm -c conda-forge -y
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
import pydicom
import glob
from tqdm.notebook import tqdm
from pydicom.pixel_data_handlers.util import apply_voi_lut
import matplotlib.pyplot as plt
from skimage import exposure#import gdcm
import cv2
import warnings
from fastai.vision.all import *
from fastai.medical.imaging import *
warnings.filterwarnings('ignore')
dataset_path = Path('../input/siim-covid19-detection')
import vtk

from vtk.util import numpy_support

reader = vtk.vtkDICOMImageReader()#HTML view

from IPython.display import HTML
HTML('<iframe src=https://arxiv.org/pdf/1506.01497.pdf width=600 height=650></iframe>')# from https://www.kaggle.com/tanlikesmath/siim-covid-19-detection-a-simple-eda
def dicom2array(path, voi_lut=True, fix_monochrome=True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef plot_img(img, size=(7, 7), is_rgb=True, title="""", cmap='gray'):
    plt.figure(figsize=size)
    plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()


def plot_imgs(imgs, cols=4, size=7, is_rgb=True, title="""", cmap='gray', img_size=(500,500)):
    rows = len(imgs)//cols + 1
    fig = plt.figure(figsize=(cols*size, rows*size))
    for i, img in enumerate(imgs):
        if img_size is not None:
            img = cv2.resize(img, img_size)
        fig.add_subplot(rows, cols, i+1)
        plt.imshow(img, cmap=cmap)
    plt.suptitle(title)
    plt.show()dicom_paths = get_dicom_files(dataset_path/'train')
print([str(path) for path in dicom_paths[:4]])
imgs = [dicom2array(str(path)) for path in dicom_paths[:4]]
plot_imgs(imgs)","This code imports the necessary libraries for working with DICOM images, including pydicom and matplotlib. It also defines a function for converting DICOM images to numpy arrays. This function can optionally apply a VOI LUT to the image data, which can be used to transform the raw DICOM data into a ""human-friendly"" view. Finally, the code defines a function for plotting DICOM images.

The code then loads a dataset of DICOM images from the SIIM-Covid19-Detection dataset and displays four of them.",9,4,0.1649489888842607
"!pip install -q --upgrade wandb

import wandb
wandb.login()import os
import gc
import cv2
import ast
import numpy as np
import pandas as pd
from tqdm import tqdm
import matplotlib.pyplot as plt
%matplotlib inlineTRAIN_PATH = '../input/siim-covid19-resized-to-256px-jpg/train/'
IMG_SIZE = 256
NUM_SAMPLES_TO_VIZ = 32# Load image level csv file
df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
# Load study level csv file
label_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')

# Modify values in the id column
df['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)
# Add absolute path
df['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)
# Get image level labels
df['image_level'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)

# Modify values in the id column
label_df['id'] = label_df.apply(lambda row: row.id.split('_')[0], axis=1)
# Rename the column id with StudyInstanceUID
label_df.columns = ['StudyInstanceUID', 'Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']

# Merge both dataframes
df = df.merge(label_df, on='StudyInstanceUID',how=""left"")
df.head(2)print(f'Number of unique image in training dataset: {len(df)}')

bbox_nan_num = df['boxes'].isna().sum()
print(f'Number of images without any bbox annotation: {bbox_nan_num}')# Label encode study-level labels
labels = df[['Negative for Pneumonia','Typical Appearance','Indeterminate Appearance','Atypical Appearance']].values
labels = np.argmax(labels, axis=1)

df['study_level'] = labels
df.head(2)class_label_to_id = {
    'Negative for Pneumonia': 0,
    'Typical Appearance': 1,
    'Indeterminate Appearance': 2,
    'Atypical Appearance': 3
}

class_id_to_label = {val: key for key, val in class_label_to_id.items()}","This code installs the wandb library and imports it for use.

Next, the code loads two CSV files: one containing image-level labels, and one containing study-level labels.

The code then processes the data in the CSV files, adding absolute paths to the image files and encoding the study-level labels.

Finally, the code defines a mapping from class labels to class IDs, and vice versa.",9,1,0.13616574548255658
"!conda install gdcm -c conda-forge -yimport os

from PIL import Image
import pandas as pd
from tqdm.auto import tqdmimport numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return imtrain = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')path = '../input/siim-covid19-detection/train/ae3e63d94c13/288554eb6182/e00f9fe0cce5.dcm'
dicom = pydicom.read_file(path)image_id = []
dim0 = []
dim1 = []
splits = []

for split in ['test', 'train']:
    save_dir = f'/kaggle/tmp/{split}/'

    os.makedirs(save_dir, exist_ok=True)
    
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(os.path.join(dirname, file))
            im = resize(xray, size=768)  
            im.save(os.path.join(save_dir, file.replace('dcm', 'jpg')))

            image_id.append(file.replace('.dcm', ''))
            dim0.append(xray.shape[0])
            dim1.append(xray.shape[1])
            splits.append(split)","This code reads in a DICOM image, applies a VOI LUT (if available), and then resizes the image to 768x768. The image is then saved as a JPEG.",9,1,0.15601717774097645
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport sys
sys.path.append('../input/timm-pytorch-models/archive (3)/pytorch-image-models-master')
import timmimport numpy as np 
import pandas as pd 

import math
import random 
import os 
import cv2
import timm

from tqdm import tqdm 

import albumentations as A 
from albumentations.pytorch.transforms import ToTensorV2
import torch 
from torch.utils.data import Dataset 
from torch import nn
import torch.nn.functional as F 

import gc
import cudf
import cuml
import cupy
from cuml.feature_extraction.text import TfidfVectorizer
from cuml.neighbors import NearestNeighborsclass CFG:
    
    img_size = 512
    batch_size = 12
    seed = 2020
    
    device = 'cuda'
    classes = 11014
    
    model_name = 'eca_nfnet_l0'
    model_path = '../input/pytorch-model-weights/arcface_512x512_nfnet_l0 (mish).pt'
    
    scale = 30 
    margin = 0.5def read_dataset():
    df = pd.read_csv('../input/shopee-product-matching/test.csv')
    df_cu = cudf.DataFrame(df)#cuDF is a Python GPU DataFrame library workflow is fast enough on a single GPU fits in memory on a single GPU
    image_paths = '../input/shopee-product-matching/test_images/' + df['image']
    return df, df_cu, image_pathsdef seed_torch(seed=42):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    
seed_torch(CFG.seed)def get_image_predictions(df, embeddings,threshold = 0.0):
    
    if len(df) > 3:
        KNN = 50
    else : 
        KNN = 3
    
    model = NearestNeighbors(n_neighbors = KNN, metric = 'cosine')
    model.fit(embeddings)
    distances, indices = model.kneighbors(embeddings)
    
    predictions = []
    for k in tqdm(range(embeddings.shape[0])):
        idx = np.where(distances[k,] < threshold)[0]
        ids = indices[k,idx]
        posting_ids = df['posting_id'].iloc[ids].values
        predictions.append(posting_ids)
        
    del model, distances, indices
    gc.collect()
    return predictions","This function takes in a dataframe, embeddings, and a threshold, and returns predictions based on the nearest neighbors algorithm.",8,1,0.08882309351144439
"%%capture
!pip install ../input/pytorchimagemodelsimport sys
sys.path.append('../input/facebookdeit')import os
import gc
import sys

import math
import random

from tqdm.notebook import tqdm

import re

import cv2
import numpy as np
import pandas as pd

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset ,RandomSampler

import timm

import albumentations

from swav_resnet import resnet50w2

import transformers
from transformers import AutoModel, AutoTokenizer

from models import deit_base_distilled_patch16_224



import cudf
import cuml
import cupydef set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True

set_seed(0)text_models=[
    {
        'transformer_model': '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14',
        'model_path' : '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14/ckpt.pt',
        'MAX_LEN' : 128,
        'params' : {
            'embed_dim' :1024,
            'out_dim' : 11014
        }
        
    },
    {
            'transformer_model': '../input/shopee-bert-base-indonesian/bert-base-indonesian_pp_7_8',
            'model_path' : '../input/shopee-bert-base-indonesian/bert-base-indonesian_pp_7_8/ckpt.pt',
            'MAX_LEN' : 128,
            'params' : {
                'embed_dim' :1024,
                'out_dim' : 11014
            }

        }
]

TRANSFORMER_EMBED_DIM = 768joint_models=[
    {
        'transformer_model': '../input/shopee-paraphrase-xlm-r-multilingual/paraphrase-xlm-r-multilingual-v1_pp_7_14',
        'model_path' : '../input/deit-xlm-joint-weights/finetuned_deit_xlm_joint_7_11.pt',
        'MAX_LEN' : 128,
        'IMAGE_SIZE' : 224,
        'params' : {
                'embed_dim' : 2048,
                'out_dim' : 11014
            }
        
    }
]image_models=[
    {
        'vision_model': '../input/shopee-swav-finetuned-resnet50w2/swav_resnet50w2_224_2048_5_epochs_loss_12_beef.pt',
        'IMAGE_SIZE' : 224,
        'params' : {
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
    {
        'vision_model': '../input/effnet-weights/finetuned_tf_efficientnet_b3_ns_300_2048_7_9.pt',
        'IMAGE_SIZE' : 300,
        'params' : {
            'backbone_name' : 'tf_efficientnet_b3_ns',
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
    
    {
        'vision_model': '../input/deit-base-distilled-patch16-224/finetuned_deit_base_distilled_patch16_224_4_18.pt',
        'IMAGE_SIZE' : 224,
        'params' : {
            'embed_dim' :2048,
            'out_dim' : 11014
        }
    },
]","This code defines a few different types of models: text, image, and joint models.

The text models are based on the transformer model architecture, and are used for natural language processing tasks. The model parameters include the embedding dimension and the output dimension.

The image models are based on the resnet50w2 model architecture, and are used for image classification tasks. The model parameters include the image size and the output dimension.

The joint models are based on the transformer model architecture, and are used for both natural language processing and image classification tasks. The model parameters include the embedding dimension, the image size, and the output dimension.",8,0,0.004965395770718228
"import sys
import gc
import math
import configparser
import numpy as np
import pandas as pd
import optuna
from tqdm import tqdm
import sklearn
import tensorflow as tf
from tensorflow import keras
from typing import Tupletry:
    # TPU detection. No parameters necessary if TPU_NAME environment variable is
    # set: this is always the case on Kaggle.
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
    print('Running on TPU ', tpu.master())
except ValueError:
    tpu = None

if tpu:
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.TPUStrategy(tpu)
else:
    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.
    strategy = tf.distribute.get_strategy()

print(""REPLICAS: "", strategy.num_replicas_in_sync)pd.set_option(""use_inf_as_na"", True)
pd.set_option(""display.max_columns"", 9999)
pd.set_option(""display.max_rows"", 9999)
pd.set_option('max_colwidth', 9999)
INPUT = '/kaggle/input'
DATA = f'{INPUT}/shopee-product-matching'
OUTPUT = '/kaggle/working'
RESOURCE_DIR = f'{INPUT}/shopee-product-matching-lib/kaggle-shopee-product-matching-1.0'
sys.path.append(f'{INPUT}/sgcharts-ml/src')
sys.path.append(f""{INPUT}/sentence-transformers/sentence-transformers-1.0.4"")
sys.path.append(f'{RESOURCE_DIR}/src')
import mylib
import scml
from scml.nlp import strip_punctuation, to_ascii_str
scml.seed_everything()MODEL = 'efficientnetb3'
CONF = configparser.ConfigParser()
CONF.read(f""{RESOURCE_DIR}/app.ini"")
resolution = int(CONF[MODEL][""resolution""])
INPUT_SHAPE = (resolution, resolution, 3)
print(f""INPUT_SHAPE={INPUT_SHAPE}"")train = pd.read_csv(f""{DATA}/train.csv"", engine=""c"", low_memory=False)
train[""target""] = mylib.target_label(train)
le = sklearn.preprocessing.LabelEncoder()
train[""label_group""] = le.fit_transform(train['label_group'])
n_classes=len(le.classes_)
print(f""n_classes={n_classes}"")
train.info()train.head()def _data_gen(
    dataframe,
    directory,
    target_size,
    batch_size,
    color_mode=""rgb"",
    class_mode=""raw"",
    x_col=""image"",
    y_col=""label_group""
):
    dtype = np.float32
    rescale = 1./255
    interpolation = ""bicubic""
    data_format = ""channels_last""
    shuffle = True
    idg = keras.preprocessing.image.ImageDataGenerator(
        shear_range=0.2,
        zoom_range=0.2,
        brightness_range=(0.7, 1.3),
        #rotation_range=90,
        horizontal_flip=True,
        rescale=rescale,
        data_format=data_format,
        dtype=dtype
    )
    g = idg.flow_from_dataframe(
        dataframe=dataframe,
        x_col=x_col,
        y_col=y_col,
        directory=directory,
        target_size=target_size,
        color_mode=color_mode,
        batch_size=batch_size,
        shuffle=shuffle,
        class_mode=class_mode,
        interpolation=interpolation,
    )
    while True:
        x, y = g.next()
        yield [x, y], y","This code imports the necessary libraries for data processing, including pandas and numpy. It also sets up the TensorFlow environment for use with the EfficientNetB3 model. Finally, it defines a function for generating data from a pandas dataframe. This function can be used to generate data for training or testing the EfficientNetB3 model.",8,2,0.06422849782237974
"import pip
try:
     __import__(""imutils"")
except ImportError:
    pip.main([""install"", ""imutils""])import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import  matplotlib.pyplot as plt
import tensorflow as tf
import pandas as pd
import cv2
from imutils.object_detection import non_max_suppression
import pytesseract
import os
import glob
os.chdir('/kaggle/working')
BASE = '../input/shopee-product-matching/train_images/'
EAST_PATH = ""/kaggle/input/east-data-leo/frozen_east_text_detection/frozen_east_text_detection.pb""
RESIZE_IMG_SHAPE = (500,500)
img_paths = glob.glob(f""{BASE}*jpg"") train = pd.read_csv('../input/shopee-product-matching/train.csv')
print('train shape is', train.shape )
train.head()groups = train.label_group.value_counts()
plt.figure(figsize=(20,5))
plt.plot(np.arange(len(groups)),groups.values)
plt.ylabel('Duplicate Count',size=14)
plt.xlabel('Index of Unique Item',size=14)
plt.title('Duplicate Count vs. Unique Item Count',size=16)
plt.show()

plt.figure(figsize=(20,5))
plt.bar(groups.index.values[:50].astype('str'),groups.values[:50])
plt.xticks(rotation = 45)
plt.ylabel('Duplicate Count',size=14)
plt.xlabel('Label Group',size=14)
plt.title('Top 50 Duplicated Items',size=16)
plt.show()def img_proc(img,offset =20):
    img =img[offset:-offset,offset:-offset]
    img =cv2.resize(img ,RESIZE_IMG_SHAPE)
    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    gray = cv2.medianBlur(gray,5)
    ret, thresh = cv2.threshold(gray,150,255,cv2.THRESH_BINARY)
    thresh = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\
            cv2.THRESH_BINARY_INV,21,2)
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))
    opening = cv2.erode(thresh,kernel, iterations = 1)
    closing = cv2.dilate(opening,kernel,iterations=1)
    contours = cv2.findContours(closing, 
                            cv2.RETR_EXTERNAL,
                            cv2.CHAIN_APPROX_NONE)
    canvas =np.zeros((500,500))
    cv2.drawContours(canvas, contours[0], -1, (255,0,255), thickness = 2) 
    return canvas



def displayDF(train, random=False, COLS=6, ROWS=4, path=BASE):
    for k in range(ROWS):
        plt.figure(figsize=(20,5))
        for j in range(COLS):
            if random: row = np.random.randint(0,len(train))
            else: row = COLS*k + j
            name = train.iloc[row,1]
            title = train.iloc[row,3]
            title_with_return = """"
            for i,ch in enumerate(title):
                title_with_return += ch
                if (i!=0)&(i%20==0): title_with_return += '\n'
            img = img_proc(cv2.imread(path+name))
            plt.subplot(1,COLS,j+1)
            plt.title(title_with_return)
            plt.axis('off')
            plt.imshow(img)
        plt.show()
        
displayDF(train,random=True)def predictions(prob_score, geo,min_conf):
    (numR, numC) = prob_score.shape[2:4]
    boxes = []
    confidence_val = []
    for y in range(0, numR):
        scoresData = prob_score[0, 0, y]
        x0 = geo[0, 0, y]
        x1 = geo[0, 1, y]
        x2 = geo[0, 2, y]
        x3 = geo[0, 3, y]
        anglesData = geo[0, 4, y]
        for i in range(0, numC):
            if scoresData[i] < min_conf:
                continue
            (offX, offY) = (i * 4.0, y * 4.0)
            angle = anglesData[i]
            cos = np.cos(angle)
            sin = np.sin(angle)
            h = x0[i] + x2[i]
            w = x1[i] + x3[i]
            endX = int(offX + (cos * x1[i]) + (sin * x2[i]))
            endY = int(offY - (sin * x1[i]) + (cos * x2[i]))
            startX = int(endX - w)
            startY = int(endY - h)
            boxes.append((startX, startY, endX, endY))
            confidence_val.append(scoresData[i])

    return (boxes, confidence_val)

def get_text(img,img_text ='Output',min_conf = 0.7, east = EAST_PATH):
    image = cv2.imread(img)
    orig = image.copy()
    (origH, origW) = image.shape[:2]
    (newW, newH) = (320,320)
    rW = origW / float(newW)
    rH = origH / float(newH)
    image = cv2.resize(image, (newW, newH))
    (H, W) = image.shape[:2]
    blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),
        (123.68, 116.78, 103.94), swapRB=True, crop=False)
    net = cv2.dnn.readNet(east)
    # The following two layer need to pulled from EAST model for achieving this. 
    layerNames = [
        ""feature_fusion/Conv_7/Sigmoid"",
        ""feature_fusion/concat_3""]

    #Forward pass the blob from the image to get the desired output layers
    net.setInput(blob)
    (scores, geometry) = net.forward(layerNames)
    (boxes, confidence_val) = predictions(scores, geometry,min_conf)
    boxes = non_max_suppression(np.array(boxes), probs=confidence_val)
    
    results = []
    for (startX, startY, endX, endY) in boxes:
        startX = int(startX * rW)
        startY = int(startY * rH)
        endX = int(endX * rW)
        endY = int(endY * rH)
        r = orig[startY:endY, startX:endX]
        configuration = (""-l eng --oem 1 --psm 8"")
        text = pytesseract.image_to_string(r, config=configuration)
        results.append(((startX, startY, endX, endY), text))

    orig_image = orig.copy()
    txts=[]
    for ((start_X, start_Y, end_X, end_Y), text) in results:
        text = """".join([x if ord(x) < 128 else """" for x in text]).strip()
        cv2.rectangle(orig_image, (start_X, start_Y), (end_X, end_Y),
            (0, 0, 255), 2)
        cv2.putText(orig_image, text, (start_X, start_Y + 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7,(0,255, 0), 4)
        txts.append(text)
    plt.figure(figsize=(10,10))
    plt.imshow(orig_image)
    plt.title(img_text)
    plt.show()
    print(txts)it = iter(range(500))","The code above imports the pip module and then tries to import the imutils module. If the imutils module is not found, the code uses pip to install it. The code then sets the working directory to the 'train_images' folder, imports the train.csv file, and displays some statistics about the data.

Next, the code defines a function to process images. The function takes an image as input and offsets it by 20 pixels. The image is then resized to 500x500 and converted to grayscale. The code then finds the contours in the image and draws them on a canvas.

The code then defines a function to display a dataframe of images. The function takes a dataframe as input and displays a random selection of images from the dataframe.

Finally, the code defines a function to get text from an image. The function takes an image as input and uses the EAST text detector to find text in the image. The text is then extracted using pytesseract and displayed on the image.",8,6,0.10663257863208267
,"This code defines a function that calculates the average of two numbers.

/**

* Returns the average of two numbers.

*

* @param {number} a The first number.

* @param {number} b The second number.

* @return {number} The average of the two numbers.

*/

function average(a, b) {

return (a + b) / 2;

}",8,3,
"%cd hdbscan!python setup.py bdist_wheel%cd dist!pip install ""hdbscan-0.8.27-cp37-cp37m-linux_x86_64.whl"" --no-cache-dir --no-binary :all: --no-build-isolation
import hdbscan%cd /kaggle/working# from nltk.cluster.kmeans import KMeansClusterer
# from nltk.cluster.util import cosine_distance","This code changes the current working directory to ""hdbscan"" and runs the ""setup.py"" script to build a wheel (a type of Python package) for the HDBSCAN package. It then changes the working directory to ""dist"" and installs the HDBSCAN wheel using the pip package manager. Finally, it changes the working directory back to ""/kaggle/working"" and imports the HDBSCAN package.",8,5,0.11340178252451605
,"This code defines a function that calculates the average of two numbers.

/**
 * Returns the average of two numbers.
 *
 * @param {number} a The first number.
 * @param {number} b The second number.
 * @return {number} The average of the two numbers.
 */
function average(a, b) {
  return (a + b) / 2;
}",This documentation is semantically correct.,3,
"import numpy as np
import pandas as pdpd.set_option('display.max_colwidth', None)

train = pd.read_csv('../input/shopee-product-matching/train.csv')
train['titleUcase'] = train['title'].str.upper()out = pd.read_csv('../input/chris-rapids/submission_Chris.csv')
out.head(4)%timeit out.loc[out.posting_id == 'train_2288590299']out = out.sort_values('posting_id')
out = out.set_index('posting_id')
out = out.sort_index()

%timeit out.loc['train_2288590299']%%time
ctr=0

def getcombined(l, combined):
    global ctr
    if len(combined) == 0: 
        ctr+=1
        print(ctr) if ctr%6000==0 else None
    
    if len(l) < 3 and len(combined)==0 :
        return l
    elif len(combined) >= 50:
        return combined
    
    local_combined = set()
    for item in l:
        matches = set(out.loc[item]['matches'].split(' '))
        local_combined.update(matches)
        
    remaining = (local_combined - set(l)) - combined
    combined.update(local_combined)

    if len(remaining) > 0:
        getcombined(remaining, combined)
        
    return list(combined)

out['combined'] = out.apply(lambda x: getcombined(x.matches.split(' '), set()), axis=1)def getMetric(col):
    def f1score(row):
        n = len( np.intersect1d(row.target,row[col]) )
        return 2*n / (len(row.target)+len(row[col]))
    return f1score","This code imports the numpy and pandas libraries, then reads in a CSV file containing product data. It then creates a new column in the dataframe containing the title of each product in uppercase.

Next, the code defines a function to get the combined list of products from a given list of products. This function takes in a list of products and a set of combined products, and returns a list of combined products.

Finally, the code defines a function to get the F1 score for a given column. This function takes in a column name and returns the F1 score for that column.",8,2,0.07020092287137225
"import sys
sys.path.append('../input/pytorch-image-models/pytorch-image-models-master')# Preliminaries
from tqdm import tqdm
import math
import random
import os
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder

# Visuals and CV2
import cv2

# albumentations for augs
import albumentations
from albumentations.pytorch.transforms import ToTensorV2

#torch
import torch
import timm
import torch
import torch.nn as nn
from torch.nn import Parameter
from torch.nn import functional as F
from torch.utils.data import Dataset,DataLoader
from torch.optim import Adam
from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau
from torch.optim import Adam, lr_scheduler
from torch.optim.lr_scheduler import _LRSchedulerDIM = (512,512)

NUM_WORKERS = 4
TRAIN_BATCH_SIZE = 16
VALID_BATCH_SIZE = 16
EPOCHS = 5
SEED = 42
#LR = 3e-4

device = torch.device('cuda')


################################################# MODEL ####################################################################

model_name = 'efficientnet_b3' #efficientnet_b0-b7

################################################ Metric Loss and its params #######################################################
loss_module = 'arcface' #'cosface' #'adacos'
s = 30.0
m = 0.5 
ls_eps = 0.0
easy_margin = False


####################################### Scheduler and its params ############################################################
# SCHEDULER = 'CosineAnnealingWarmRestarts' #'CosineAnnealingLR'
# factor=0.2 # ReduceLROnPlateau
# patience=4 # ReduceLROnPlateau
# eps=1e-6 # ReduceLROnPlateau
# T_max=10 # CosineAnnealingLR
# T_0=4 # CosineAnnealingWarmRestarts
# min_lr=1e-6


scheduler_params = {
        ""lr_start"": 1e-5,
        ""lr_max"": 1e-5 * TRAIN_BATCH_SIZE,
        ""lr_min"": 1e-6,
        ""lr_ramp_ep"": 5,
        ""lr_sus_ep"": 0,
        ""lr_decay"": 0.8,
    }

############################################## Model Params ###############################################################
model_params = {
    'n_classes':10873, # original: 11014 after label correction: 10873
    'model_name':'efficientnet_b3',
    'use_fc':False,
    'fc_dim':512,
    'dropout':0.0,
    'loss_module':loss_module,
    's':30.0,
    'margin':0.50,
    'ls_eps':0.0,
    'theta_zero':0.785,
    'pretrained':True
}
def seed_torch(seed=42):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    
seed_torch(SEED)class AverageMeter(object):
    def __init__(self):
        self.reset()
    
    def reset(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0
    
    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.countdef fetch_scheduler(optimizer):
        if SCHEDULER =='ReduceLROnPlateau':
            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=factor, patience=patience, verbose=True, eps=eps)
        elif SCHEDULER =='CosineAnnealingLR':
            scheduler = CosineAnnealingLR(optimizer, T_max=T_max, eta_min=min_lr, last_epoch=-1)
        elif SCHEDULER =='CosineAnnealingWarmRestarts':
            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=T_0, T_mult=1, eta_min=min_lr, last_epoch=-1)
        return schedulerdef fetch_loss():
    loss = nn.CrossEntropyLoss()
    return loss","This code imports the sys module and appends the path to the pytorch-image-models module. It then initializes the variables needed for the code.

The code then defines a function to fetch the scheduler. This function takes an optimizer as input and returns a scheduler. The scheduler is either a ReduceLROnPlateau, CosineAnnealingLR, or CosineAnnealingWarmRestarts scheduler, depending on the value of the SCHEDULER variable.

Finally, the code defines a function to fetch the loss. This function returns a CrossEntropyLoss.",8,6,0.06768386077448485
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
#for dirname, _, filenames in os.walk('/kaggle/input'):
#    for filename in filenames:
#        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport numpy as np
import pandas as pd, gc
import matplotlib.pyplot as plt
import time
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

import cv2, matplotlib.pyplot as plt
import cudf, cuml, cupy
from cuml.feature_extraction.text import TfidfVectorizer
from cuml.neighbors import NearestNeighbors
import tensorflow as tf
from tensorflow.keras.applications import EfficientNetB0, EfficientNetB2, ResNet50V2
print('RAPIDS',cuml.__version__)
print('TF',tf.__version__)# RESTRICT TENSORFLOW TO 1GB OF GPU RAM
# SO THAT WE HAVE 15GB RAM FOR RAPIDS
LIMIT = 1
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
  try:
    tf.config.experimental.set_virtual_device_configuration(
        gpus[0],
        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])
    logical_gpus = tf.config.experimental.list_logical_devices('GPU')
    #print(len(gpus), ""Physical GPUs,"", len(logical_gpus), ""Logical GPUs"")
  except RuntimeError as e:
    print(e)
print('We will restrict TensorFlow to max %iGB GPU RAM'%LIMIT)
print('then RAPIDS can use %iGB GPU RAM'%(16-LIMIT))train = pd.read_csv('/kaggle/input/shopee-product-matching/train.csv')
train.head()test = pd.read_csv('/kaggle/input/shopee-product-matching/test.csv')
test.head()class DataGenerator(tf.keras.utils.Sequence):
    'Generates data for Keras'
    def __init__(self, df, img_size=256, batch_size=32, path=''): 
        self.df = df
        self.img_size = img_size
        self.batch_size = batch_size
        self.path = path
        self.indexes = np.arange( len(self.df) )
        
    def __len__(self):
        'Denotes the number of batches per epoch'
        ct = len(self.df) // self.batch_size
        ct += int(( (len(self.df)) % self.batch_size)!=0)
        return ct

    def __getitem__(self, index):
        'Generate one batch of data'
        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]
        X = self.__data_generation(indexes)
        return X
            
    def __data_generation(self, indexes):
        'Generates data containing batch_size samples' 
        X = np.zeros((len(indexes),self.img_size,self.img_size,3),dtype='float32')
        df = self.df.iloc[indexes]
        for i,(index,row) in enumerate(df.iterrows()):
            img = cv2.imread(self.path+row.image)
            X[i,] = cv2.resize(img,(self.img_size,self.img_size)) #/128.0 - 1.0
        return XBASE = '../input/shopee-product-matching/train_images/'

WGT = '../input/efficientnetb0-notoph5/efficientnetb0_notop.h5'
model = EfficientNetB0(weights=WGT,include_top=False, pooling='avg', input_shape=None)

embeds = []
CHUNK = 1024*4

print('Computing image embeddings...')
CTS = len(train)//CHUNK
if len(train)%CHUNK!=0: CTS += 1
for i,j in enumerate( range( CTS ) ):
    
    a = j*CHUNK
    b = (j+1)*CHUNK
    b = min(b,len(train))
    print('chunk',a,'to',b)
    
    test_gen = DataGenerator(train.iloc[a:b], batch_size=32, path=BASE)
    image_embeddings = model.predict(test_gen,verbose=1,use_multiprocessing=True, workers=4)
    embeds.append(image_embeddings)
    
del model
_ = gc.collect()
image_embeddings = np.concatenate(embeds)
del embeds
print('image embeddings shape',image_embeddings.shape)","The code above is used to generate image embeddings for the Shopee product matching dataset. The code uses the EfficientNetB0 model to generate the embeddings, which are then stored in a numpy array.",8,1,0.14768010686049193
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
from nltk.stem.porter import *
import numpy as np
np.random.seed(2018)
from numpy import dot
from numpy.linalg import norm
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
import numpy as np
import cv2
import gc# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
import gensim
from gensim.utils import simple_preprocess
from gensim.parsing.preprocessing import STOPWORDS
from nltk.stem import WordNetLemmatizer, SnowballStemmer
from nltk.stem.porter import *
import numpy as np
np.random.seed(2018)
from gensim.models import Word2Vec
import nltk
# nltk.download('wordnet')
stemmer = SnowballStemmer('english')

from numpy import dot
from numpy.linalg import normtrain_df = pd.read_csv('../input/shopee-product-matching/train.csv')
# train_dftest_df = pd.read_csv('../input/shopee-product-matching/test.csv')
# test_dftrain_title_list = train_df['title'].tolist()
train_label_list = train_df['label_group'].tolist()
# train_title_list
# train_label_list","This code loads the train.csv file from the shopee-product-matching dataset, and extracts the 'title' and 'label_group' columns into lists.",8,1,0.14423190778738731
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
#for dirname, _, filenames in os.walk('/kaggle/input'):
#    for filename in filenames:
#        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport numpy as np
import pandas as pd, gc
import matplotlib.pyplot as plt
import time
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

import cv2, matplotlib.pyplot as plt
import cudf, cuml, cupy
from cuml.feature_extraction.text import TfidfVectorizer
from cuml.neighbors import NearestNeighbors
import tensorflow as tf
from tensorflow.keras.applications import EfficientNetB0
print('RAPIDS',cuml.__version__)
print('TF',tf.__version__)# RESTRICT TENSORFLOW TO 1GB OF GPU RAM
# SO THAT WE HAVE 15GB RAM FOR RAPIDS
LIMIT = 1
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
  try:
    tf.config.experimental.set_virtual_device_configuration(
        gpus[0],
        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])
    logical_gpus = tf.config.experimental.list_logical_devices('GPU')
    #print(len(gpus), ""Physical GPUs,"", len(logical_gpus), ""Logical GPUs"")
  except RuntimeError as e:
    print(e)
print('We will restrict TensorFlow to max %iGB GPU RAM'%LIMIT)
print('then RAPIDS can use %iGB GPU RAM'%(16-LIMIT))train = pd.read_csv('/kaggle/input/shopee-product-matching/train.csv')
train.head()test = pd.read_csv('/kaggle/input/shopee-product-matching/test.csv')
test.head()# test = pd.concat([train,train],axis=0,ignore_index=True)
# test.shapeclass DataGenerator(tf.keras.utils.Sequence):
    'Generates data for Keras'
    def __init__(self, df, img_size=256, batch_size=32, path=''): 
        self.df = df
        self.img_size = img_size
        self.batch_size = batch_size
        self.path = path
        self.indexes = np.arange( len(self.df) )
        
    def __len__(self):
        'Denotes the number of batches per epoch'
        ct = len(self.df) // self.batch_size
        ct += int(( (len(self.df)) % self.batch_size)!=0)
        return ct

    def __getitem__(self, index):
        'Generate one batch of data'
        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]
        X = self.__data_generation(indexes)
        return X
            
    def __data_generation(self, indexes):
        'Generates data containing batch_size samples' 
        X = np.zeros((len(indexes),self.img_size,self.img_size,3),dtype='float32')
        df = self.df.iloc[indexes]
        for i,(index,row) in enumerate(df.iterrows()):
            img = cv2.imread(self.path+row.image)
            X[i,] = cv2.resize(img,(self.img_size,self.img_size)) #/128.0 - 1.0
        return X","The DataGenerator class is used to generate data for training or testing a Keras model. The class takes in a pandas dataframe (df), image size (img_size), batch size (batch_size), and path to the image files. The class contains methods for getting the number of batches per epoch and generating data for a given batch. The data for a given batch is returned as a numpy array (X).",8,5,0.20321579081644198
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

'''
import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))
'''

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport matplotlib.pyplot as plt
import pandas as pd 

df = pd.read_csv('/kaggle/input/shopee-product-matching/train.csv')
len(df), df['label_group'].value_counts()#!pip install pytorch-lightning pytorch-metric-learning torchvision faiss-cpu scikit-learn
!pip install ../input/wheels/faiss_cpu-1.7.0-cp37-cp37m-manylinux2014_x86_64.whl
!pip install ../input/wheels/pytorch_metric_learning-0.9.98-py3-none-any.whl
!pip install ../input/wheels/timm-0.4.5-py3-none-any.whl# custom dataset
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, utils

from PIL import Image
from tqdm import tqdm

import torch
import os, sys
import json
import pandas as pd
import PIL
import argparse
import random
import matplotlib.pyplot as plt

class ProductPairDataset(Dataset):
    def __init__(self, df, root_dir, img_size=260, train_mode=True, test_mode=False, transform=None):
        """"""
        Args:
            df (DataFrame): part of entire dataframe
            root_dir (str): root image path
            transform (callable, optional): Optional transform to be applied on a sample.
        """"""
        self.products_frame = df
        self.root_dir = root_dir
        self.train_mode = train_mode
        self.test_mode = test_mode
        
        self.images = []
        self.labels = []

        if transform is not None:
            self.transform = transform
        else:
            if self.train_mode:  # set default image tranform
                self.transform = transforms.Compose(
                    [
                        transforms.Resize([int(img_size // 0.9), int(img_size // 0.9)]),
                        transforms.RandomCrop([img_size, img_size]),
                        transforms.RandomHorizontalFlip(),
                        transforms.ToTensor(),
                        transforms.Normalize(
                            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]
                        ),
                    ]
                )
            else:
                self.transform = transforms.Compose(
                    [
                        transforms.Resize([img_size, img_size]),
                        transforms.ToTensor(),
                        transforms.Normalize(
                            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]
                        ),
                    ]
                )

    def __len__(self):
        return len(self.products_frame)

    def __getitem__(self, index):
        image_tensor = self.transform(PIL.Image.open(self.root_dir + os.sep + self.products_frame.iloc[index][""image""]))
        
        if not self.test_mode:
            label = int(self.products_frame.iloc[index][""label_group""])
            label_tensor = torch.LongTensor([label])

            return image_tensor, label_tensor
        
        return image_tensor## model definition
from torchvision import transforms
from torch.optim.lr_scheduler import ReduceLROnPlateau
from torch.utils.data.sampler import BatchSampler

from pytorch_metric_learning import miners, losses
from pytorch_metric_learning.distances import CosineSimilarity

import torch
import torch.nn as nn
import torch.nn.functional as F

import pytorch_lightning as pl

import PIL
import pandas as pd
import random

class ProductFeatureNet(nn.Module):
    def __init__(self, backbone_net, feature_dim=768):
        super(ProductFeatureNet, self).__init__()

        self.feature_dim = feature_dim
        self.backbone_net = backbone_net
        self.feature_layer = nn.Linear(
            #self.backbone_net.classifier.out_features, self.feature_dim, bias=False
            self.backbone_net.fc.out_features, self.feature_dim, bias=False
        )
        nn.init.xavier_uniform_(self.feature_layer.weight)

    def forward(self, images):
        features = self.backbone_net(images)
        features = self.feature_layer(features)
        features = F.normalize(features)

        return features

class ProductFeatureEncoder(pl.LightningModule):
    def __init__(
        self,
        model,
        margin=0.5,
        lr=1e-3,
        lr_patience=2,
        lr_decay_ratio=0.5,
        memory_batch_max_num=1024,
    ):
        super().__init__()

        self.save_hyperparameters()

        self.model = model
        self.margin = margin
        self.lr = lr
        self.lr_patience = lr_patience
        self.lr_decay_ratio = lr_decay_ratio

        self.memory_batch_max_num = memory_batch_max_num
        
        self.loss_func = losses.CrossBatchMemory(
            losses.ContrastiveLoss(pos_margin=1, neg_margin=0, distance=CosineSimilarity()),
            self.model.feature_dim, 
            memory_size=self.memory_batch_max_num, 
            miner=miners.MultiSimilarityMiner(epsilon=self.margin)
        )

    def forward(self, images):
        features = self.model(images)

        return features

    def configure_optimizers(self):
        optim = torch.optim.Adam(
            [
                {""params"": self.model.backbone_net.parameters(), ""lr"": self.lr * 0.1},
                {""params"": self.model.feature_layer.parameters()},
                
            ],
            #self.parameters(),
            lr=self.lr,
        )
        
        return {
            ""optimizer"": optim,
            ""lr_scheduler"": ReduceLROnPlateau(
                optim,
                patience=self.lr_patience,
                threshold=1e-8,
                factor=self.lr_decay_ratio,
            ),
            ""monitor"": ""val_loss"",
        }

    def training_step(self, train_batch, batch_idx):
        self.model.train()

        images, labels = train_batch
        features = self.model(images)
        
        xbm_loss = self.loss_func(features, labels.squeeze(1))
        self.log(""train/loss"", xbm_loss, prog_bar=True)
        
        return xbm_loss

    def validation_step(self, validation_batch, batch_idx):
        self.model.eval()

        images, labels = validation_batch
        features = self.model(images)

        with torch.no_grad():
            xbm_loss = self.loss_func(features, labels.squeeze(1))
            self.log(""train/loss"", xbm_loss, prog_bar=True)
            
            return {
                ""features"": features,
                ""labels"": labels,
                ""val_loss"": xbm_loss,
            }
## positive pair augment custom batch sampler
class PositivePairAugBatchSampler(BatchSampler):
    def __init__(self, dataset_df, min_positive_instances=4, num_labels_per_batch=16):
        self.max_iter = len(dataset_df) // (num_labels_per_batch)
        #self.max_iter = len(dataset_df) // (min_positive_instances * num_labels_per_batch)
        self.min_positive_instances = min_positive_instances
        self.num_labels_per_batch = num_labels_per_batch

        self.label_index_dict = {}  # key: batch, value: [batch_indices]
        for label in dataset_df[""label_group""]:
            self.label_index_dict[label] = [index for index in list(dataset_df[dataset_df[""label_group""] == label].index) if index < len(dataset_df)]

        delete_label_list = []
        for k, v in self.label_index_dict.items():
            if len(v) == 0:
                delete_label_list.append(k)
        for label in delete_label_list:
            del self.label_index_dict[label]
        
    def __len__(self):
        return self.max_iter

    def __iter__(self):
        for _ in range(self.max_iter):
            batch_indices = []

            selected_labels = random.choices(
                list(self.label_index_dict.keys()), k=self.num_labels_per_batch
            )

            for label in selected_labels:
                batch_indices.extend(
                    random.choices(
                        self.label_index_dict[label], k=self.min_positive_instances
                    )
                )

            yield batch_indicesimport timm
import torch

'''
backbone_net = timm.create_model('tf_efficientnet_b0')
backbone_net.load_state_dict(torch.load('../input/timm-pretrained-efficientnet/efficientnet/tf_efficientnet_b0_aa-827b6e33.pth'))


backbone_net = timm.create_model('tf_efficientnet_es')
backbone_net.load_state_dict(torch.load('../input/timm-pretrained-efficientnet/efficientnet/tf_efficientnet_es-ca1afbfe.pth'))

backbone_net = timm.create_model('tf_efficientnet_b0_ap')
backbone_net.load_state_dict(torch.load('../input/timm-pretrained-efficientnet/efficientnet/tf_efficientnet_b0_ap-f262efe1.pth'))

backbone_net = timm.create_model('tf_efficientnet_b1_ns')
backbone_net.load_state_dict(torch.load('../input/timm-pretrained-efficientnet/efficientnet/tf_efficientnet_b1_ns-99dd0c41.pth'))

backbone_net = timm.create_model('tf_efficientnet_b2_ns')
backbone_net.load_state_dict(torch.load('../input/timm-pretrained-efficientnet/efficientnet/tf_efficientnet_b2_ns-00306e48.pth'))
'''

backbone_net = timm.create_model('resnet101')
backbone_net.load_state_dict(torch.load('../input/timm-pretrained-resnet/resnet/resnet101-5d3b4d8f.pth'))

backbone_net","This code defines a ProductFeatureNet class which inherits from the PyTorch nn.Module class. This class is responsible for creating a neural network that can be used to extract features from images of products. The network consists of a backbone network (resnet101) and a linear layer that maps the output of the backbone network to a feature vector of a specified dimension (768).

The ProductFeatureEncoder class inherits from the PyTorch Lightning Module class and is responsible for training the ProductFeatureNet. This class defines a loss function (CrossBatchMemory) and optimizer (Adam) and provides a training_step and validation_step method. The training_step method is responsible for training the network on a batch of images and labels. The validation_step method is responsible for validating the network on a batch of images and labels.

The PositivePairAugBatchSampler class inherits from the PyTorch BatchSampler class and is responsible for sampling batches of images and labels for training. This class ensures that each batch contains a specified number of images from each label class (specified by the num_labels_per_batch parameter).",8,9,0.08639751039563509
"# DATA_PATH = '../input/'
DATA_PATH = '../input/shopee-product-matching/'

import psutilimport numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import cv2, matplotlib.pyplot as plt
from tqdm import tqdm_notebook
import gc

# import cudf, cuml, cupy
# from cuml.feature_extraction.text import TfidfVectorizer
# from cuml.neighbors import NearestNeighbors

def getMetric(col):
    def f1score(row):
        n = len( np.intersect1d(row.target,row[col]) )
        return 2*n / (len(row.target)+len(row[col]))
    return f1scoredef stopwords(col):
    col = col.apply(lambda x: [item for item in x if item not in stop])
    return colCOMPUTE_CV = False

test = pd.read_csv(DATA_PATH + 'test.csv')
if len(test)>3: COMPUTE_CV = False
else: print('this submission notebook will compute CV score, but commit notebook will not')#COMPUTE_CV = False

if COMPUTE_CV:
    train = pd.read_csv(DATA_PATH + 'train.csv')
    train['image'] = DATA_PATH + 'train_images/' + train['image']
    tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()
    train['target'] = train.label_group.map(tmp)
    # train_gf = cudf.read_csv(DATA_PATH + 'train.csv')
else:
    train = pd.read_csv(DATA_PATH + 'test.csv')
    train['image'] = DATA_PATH + 'test_images/' + train['image']
    # train_gf = cudf.read_csv(DATA_PATH + 'test.csv')
    
print('train shape is', train.shape )
train.head()tmp = train.groupby('image_phash').posting_id.agg('unique').to_dict()
train['oof_hash'] = train.image_phash.map(tmp)if COMPUTE_CV:
    train['f1'] = train.apply(getMetric('oof_hash'),axis=1)
    print('CV score for baseline =',train.f1.mean())","This code defines a function to compute the F1 score for a given column, and applies it to the training data. If the COMPUTE_CV flag is set to True, the code will also compute the CV score for the training data.",8,0,0.05142677596969173
"import sys
sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')
import timm# model = timm.create_model('eca_nfnet_l0', pretrained=True)
# !pip install torchsummary 
# from torchsummary import summary
# summary(model,(3, 512,512))import os
import cv2
import math
import random
import numpy as np
import pandas as pd
from tqdm import tqdm

import albumentations
from albumentations.pytorch.transforms import ToTensorV2

import torch
import timm
import torch
import torch.nn as nn
from torch.nn import functional as F
from torch.utils.data import Dataset,DataLoader

import gc
import matplotlib.pyplot as plt
import cudf
import cuml
import cupy
from cuml.feature_extraction.text import TfidfVectorizer
from cuml import PCA
from cuml.neighbors import NearestNeighborsclass CFG:
    seed = 54
    classes = 11014 
    scale = 30 
    margin = 0.5
    model_name =  'tf_efficientnet_b3'
    fc_dim = 512
    img_size = 512
    batch_size = 20
    num_workers = 4
    device = device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model_path = '../input/shopee-correct-label-train/arcface_512x512_tf_efficientnet_b3_14_epoch_correct_label.pt'
#     model_path = ['../input/shopee-match-ensemble-eff-b1-b3-focal-loss/B1arcface_512x512_tf_efficientnet_b1_nofold_14_epo.pt',
#                   '../input/shopee-training-eff-b4/arcface_512x512_tf_efficientnet_b2_14_epoch.pt',
#                   '../input/shopee-match-ensemble-eff-b1-b3-focal-loss/arcface_512x512_tf_efficientnet_b3_14_epoch.pt']
#     model_path = ['../input/eff-b4-tfidf/arcface_512x512_tf_efficientnet_b4_0_fold_15_epoch.pt',
#                  '../input/eff-b4-tfidf/arcface_512x512_tf_efficientnet_b4_1_fold_15_epoch.pt',
#                  '../input/eff-b4-tfidf/arcface_512x512_tf_efficientnet_b4_2_fold_15_epoch.pt']def read_dataset():
    df = pd.read_csv('../input/shopee-product-matching/test.csv')
    df_cu = cudf.DataFrame(df)
    image_paths = '../input/shopee-product-matching/test_images/' + df['image']
        
    return df, df_cu, image_paths
 
     def seed_torch(seed=42):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    
seed_torch(CFG.seed)","This code imports the timm module, which is a PyTorch library for image models. It then defines a model and prints a summary of the model. Finally, it reads in a dataset, seeds the random number generator, and initializes the model.",8,1,0.04444628332477885
"!ls ../input/siamese-rigorous-triplets-img-title/train_triplets_imgs.csvimport sys
sys.path.append ('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')

import os
import gc
import time
import math
import random
import datetime
import pandas as pd
import numpy as np
import seaborn as sns

import torch
import torch.nn as nn
from   torch.nn import init
from   torch.nn import CrossEntropyLoss, MSELoss
from   torch.nn.modules.loss import _WeightedLoss
import torch.nn.functional as F
from   torch.nn import Parameter
from   torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler
from   transformers import AdamW, get_cosine_schedule_with_warmup
from   torch.cuda.amp import autocast, GradScaler
from   torch.optim.lr_scheduler import OneCycleLR
from   fastai.losses import LabelSmoothingCrossEntropy

# from warmup_scheduler import GradualWarmupScheduler
from   sklearn import preprocessing
from   sklearn.metrics import accuracy_score
from   sklearn.model_selection import StratifiedKFold, GroupKFold
from   sklearn.metrics import accuracy_score, precision_recall_fscore_support, matthews_corrcoef, roc_auc_score
from   sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score

import timm
import albumentations as A
from   albumentations import *
from   albumentations.pytorch import ToTensorV2
from   albumentations.core.transforms_interface import DualTransform
from   albumentations.augmentations import functional as AF
import cv2

from   tqdm import tqdm
from   pprint import pprint
from   functools import partial
import matplotlib.pyplot as plt
# from GPUtil import showUtilization as gpu_usage
from   numba import cuda
import warnings
warnings.filterwarnings (""ignore"")class CFG:
    device       = torch.device ('cuda' if torch.cuda.is_available () else 'cpu')
    num_workers  = 8
    model_name   = 'efficientnet_b6'       # ['deit_base_patch16_224', 'vit_base_patch16_384', 'resnext50_32x4d', 'tf_efficientnet_b7_ns']
    n_classes    = 512                     # not 11014 since its embedding size
    use_fc       = False                   # not used
    fc_dim       = 0                       # not used
    margin       = 1.0
    dropout      = 0.2        
    size         = 224                     # [64, 128, 224, 384, 512, 640, 720]
    isTrain      = True
    isFreeze     = False
    max_lr       = 1e-3
    lr           = max_lr
    epochs       = 1
    warmup_steps = 0                       # if float: these many epochs are with frozen model at the beginning, if int = actual steps
    eval_steps   = 0                       # if float: these many epochs are with frozen model at the beginning, if int = actual steps 
    # lr_num_cycles= 2.5
    grad_accum_steps = 2
    # criterion  = 'dice_bce'              # ['dice_bce', CrossEntropyLoss', 'BCEWithLogitsLoss', 'SmoothBCEwithLogits']
    weight_decay = 1e-6
    max_grad_norm= 1000.0
    seed         = 42
    n_fold       = 100
    train_fold   = [0]                      # [0, 1, 2, 3, 4]
    adam_epsilon = 1e-8
    train_batch_size = 22
    eval_batch_size  = 22    
    model_infer_path_prefix = "".""
    model_train_path_prefix = "".""
    img_triplets_csv = ""../input/siamese-rigorous-triplets-img-title/train_triplets_imgs.csv""
    train_path       = '../input/shopee-product-matching/train_images'
    # train_csv        = '../input/vinbigdata-chest-xray-abnormalities-detection/train.csv'
    # test_path        = '../input/vinbigdata-chest-xray-resized-png-1024x1024/test'
    output_dir       = './results'        # output directory    
    max_steps        = 0
    MODEL            = Nonedef init_logger (log_file=CFG.output_dir+'train.log'):
    
    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler
    logger = getLogger (__name__)
    logger.setLevel (INFO)
    handler1 = StreamHandler ()
    handler1.setFormatter (Formatter (""%(message)s""))
    handler2 = FileHandler (filename=log_file)
    handler2.setFormatter (Formatter (""%(message)s""))
    logger.addHandler (handler1)
    logger.addHandler (handler2)
    return loggerdef seed_everything (seed):
    
    random.seed (seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed (seed)
    torch.manual_seed (seed)
    torch.cuda.manual_seed (seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = True
    return

seed_everything (seed=CFG.seed)def get_transforms (data='train'):
    
    light_transforms = A.Compose ([
        A.Resize (CFG.size, CFG.size),
        # A.HorizontalFlip (p=0.5),
        A.OneOf([
            A.CLAHE (clip_limit=(1,4), p=1),
            A.HueSaturationValue (hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=1),
            A.RandomBrightnessContrast (brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=1),
            A.augmentations.transforms.RGBShift (r_shift_limit=20, g_shift_limit=20, b_shift_limit=20, always_apply=False, p=0.5),
        ], p=0.5),
        # A.augmentations.transforms.ChannelDropout (channel_drop_range=(1, 1), fill_value=0, always_apply=False, p=0.5),
        # A.augmentations.transforms.GridDistortion (num_steps=5, distort_limit=0.3, interpolation=1, border_mode=4, value=None, mask_value=None, always_apply=False, p=0.5),
        # A.CoarseDropout(p=0.5),
        # A.Cutout (max_h_size=int(CFG.size * 0.2), max_w_size=int(CFG.size * 0.2), num_holes=2, p=0.75),
        A.Normalize (),
        ToTensorV2 (p=1.0),
    ])
    
    valid_transforms = A.Compose ([
        A.Resize (CFG.size, CFG.size),
        A.Normalize (),
        ToTensorV2 (p=1.0),
    ])
    
    if 'train' in data:
        return light_transforms
    elif 'valid' in data:
        return valid_transforms
    return valid_transforms# see image triplets
df       = pd.read_csv (CFG.img_triplets_csv)
TRAIN_DF = df.iloc[:(df.shape[0]*(CFG.n_fold-1)//(CFG.n_fold))]
TEST_DF  = df.iloc[(df.shape[0]*(CFG.n_fold-1)//(CFG.n_fold)):]
del df
gc.collect ()
print (""len TRAIN_DF ="", TRAIN_DF.shape[0])
TEST_DF.head ()","This code defines a function to get the training and testing data for a siamese network. The function takes in a csv file with image triplets and outputs two dataframes, one for training and one for testing. The training dataframe contains all the image triplets except for the last n_fold-1 folds, and the testing dataframe contains the image triplets for the last n_fold-1 folds.",8,5,0.03730062608669419
"import sys
sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')from transformers import DistilBertModel, DistilBertTokenizer, DistilBertConfig
from transformers import AutoTokenizer, AutoModel, AutoConfig

MAX_LEN = 128

tokenizers = [DistilBertTokenizer.from_pretrained(""/kaggle/input/db-tokenizer"", do_lower_case=True),
              AutoTokenizer.from_pretrained(""/kaggle/input/db-tokenizer2"", do_lower_case=True)]import os
import cv2
import math
import random
import numpy as np
import pandas as pd
from tqdm import tqdm

import albumentations
from albumentations.pytorch.transforms import ToTensorV2

import torch
import timm
import torch
import torch.nn as nn
from torch.nn import functional as F
from torch.utils.data import Dataset,DataLoader

import gc
import matplotlib.pyplot as plt
import cudf
import cuml
import cupy
from cuml.feature_extraction.text import TfidfVectorizer
from cuml import PCA
from cuml.neighbors import NearestNeighborsclass CFG:
    seed = 54
    classes = 11014 
    scale = 30 
    margin = 0.5
    model_name =  'tf_efficientnet_b4'
    fc_dim = 512
    img_size = 512
    batch_size = 20
    num_workers = 4
    device = device = 'cuda' if torch.cuda.is_available() else 'cpu'import codecs
from unicodedata import normalize


UNIT_TEST_SIZE = 256

def fix_encoding(x):
    return normalize(""NFD"", codecs.escape_decode(x, 'hex')[0].decode(""utf-8""))

def read_dataset():
    df = pd.read_csv('../input/shopee-product-matching/test.csv')
    df[""path""] = ""test""
    fp_df = pd.read_csv('../input/shopee-product-matching/train.csv')
    
    if df.shape[0] == 3:
        df = pd.read_csv('../input/shopee-product-matching/train.csv').head(UNIT_TEST_SIZE).drop(""label_group"", axis=1)
        df[""path""] = ""train""
        fp_df = pd.read_csv('../input/shopee-product-matching/train.csv').tail(UNIT_TEST_SIZE).drop(""label_group"", axis=1)
        
    df[""title""] = df[""title""].apply(fix_encoding)
    fp_df[""title""] = fp_df[""title""].apply(fix_encoding)
    fp_df[""path""] = ""train""
    return df, fp_df

df, fp_df = read_dataset()
df.shape, fp_df.shapedef seed_torch(seed=42):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    
seed_torch(CFG.seed)img_backbones = [""swin_base_patch4_window12_384"", 
                 'tf_efficientnet_b4', 
                 ""vit_base_resnet50_384""]
img_model_paths = ['../input/shopee-img-models/img_model_i15.pth', 
                   '../input/shopee-img-models/img_model_i04.pth',
                   '../input/shopee-img-models/img_model_i11.pth']


class ShopeeModel(nn.Module):
    def __init__(self, model_name, pretrained, fc_dim=512):
        super(ShopeeModel, self).__init__()
        self.model_name = model_name
        self.backbone = timm.create_model(model_name, pretrained=pretrained)
        if model_name != ""tf_efficientnet_b4"":
            in_features = self.backbone.head.in_features
            self.backbone.head = nn.Identity()
        else:
            in_features = self.backbone.classifier.in_features
            self.backbone.classifier = nn.Identity()
        self.backbone.global_pool = nn.Identity()
        self.pooling = nn.AdaptiveAvgPool2d(1)
        
        self.dropout = nn.Dropout(p=0.1)
        self.classifier = nn.Linear(in_features, fc_dim)
        self.bn = nn.BatchNorm1d(fc_dim)
        self._init_params()
        self.vector_size = fc_dim
        
    def _init_params(self):
        nn.init.xavier_normal_(self.classifier.weight)
        nn.init.constant_(self.classifier.bias, 0)
        nn.init.constant_(self.bn.weight, 1)
        nn.init.constant_(self.bn.bias, 0)
        
    def forward(self, x):
        batch_size = x.shape[0]
        x = self.backbone(x)
        if self.model_name == ""tf_efficientnet_b4"":
            x = self.pooling(x)
        x = x.view(batch_size, -1)

        x = self.dropout(x)
        x = self.classifier(x)
        x = self.bn(x)
        
        x = F.normalize(x)
        return x",This code defines a ShopeeModel class which inherits from the PyTorch nn.Module class. The class constructor takes in a model_name string and a pretrained boolean value. The class defines a backbone attribute which is set to a timm.create_model() object. The class also has an adaptive pooling layer and a dropout layer with a probability of 0.1. The classifier attribute is a linear layer with an input dimension of 512 and an output dimension of the number of classes. There is also a batch normalization layer. The forward() method takes in an input tensor and returns a normalized vector.,8,4,0.06258183965939519
"import random
import glob
import os
import sys
import json
import math
import configparser
import numpy as np
import pandas as pd
import sklearn
from sklearn.neighbors import NearestNeighbors
from pathlib import Path
import lightgbm as lgb
from typing import Iterable, Dict, Set, List, Optional
from tqdm import tqdm
import tensorflow as tf
from tensorflow import keras
import cv2 as cv
import pytesseractINPUT = '/kaggle/input'
DATA = f'{INPUT}/shopee-product-matching'
OUTPUT = '/kaggle/temp'
RESOURCE_DIR = f'{INPUT}/shopee-product-matching-lib/kaggle-shopee-product-matching-1.0'
#LGB_MODEL_DIR = f'{RESOURCE_DIR}/models/lgb/20210220_213935'
#LGB_MODEL_DIR = f'{RESOURCE_DIR}/models/lgb/20210220_130330'
#MLP_MODEL_DIR = f'{RESOURCE_DIR}/models/mlp_20210222_221918'
#FEATURES_DIR = f'{RESOURCE_DIR}/features'
sys.path.append(f'{INPUT}/sgcharts-ml/src')
sys.path.append(f""{INPUT}/sentence-transformers/sentence-transformers-1.0.4"")
sys.path.append(f'{RESOURCE_DIR}/src')from sentence_transformers import SentenceTransformer
import mylib
import scml
from scml.nlp import strip_punctuation, to_ascii_str
scml.seed_everything()IMAGE = True
TITLE = True
PHASH = True
OCR = False
MODEL = 'efficientnetb3'
pd.set_option(""use_inf_as_na"", True)
pd.set_option(""display.max_columns"", 9999)
pd.set_option(""display.max_rows"", 9999)
pd.set_option('max_colwidth', 9999)
#os.environ[""OMP_THREAD_LIMIT""] = ""1""
CONF = configparser.ConfigParser()
CONF.read(f""{RESOURCE_DIR}/app.ini"")
resolution = int(CONF[MODEL][""resolution""])
print(f""resolution={resolution}"")test = pd.read_csv(f""{DATA}/test.csv"", engine=""c"", low_memory=False)
posting_ids = test[""posting_id""].tolist()
test.head()if IMAGE:
    model_dir = f""{RESOURCE_DIR}/models/eb3_arc_20210510_2300""
    m0 = keras.models.load_model(f""{model_dir}/trial_0/model.h5"")
    m0 = keras.models.Model(inputs=m0.input[0], outputs=m0.get_layer(""embedding_output"").output)
    m0.summary()if IMAGE:
    idg = keras.preprocessing.image.ImageDataGenerator(
        rescale=1./255,
        data_format=""channels_last"",
        dtype=np.float32
    )
    data = idg.flow_from_dataframe(
        dataframe=test,
        x_col=""image"",
        y_col=""posting_id"",  # y_col not needed for inference
        directory=f""{DATA}/test_images"",
        target_size=(resolution, resolution),
        color_mode=""rgb"",
        batch_size=400,
        shuffle=False,
        class_mode=""raw"",
        interpolation=""bicubic"",
    )
    y0 = m0.predict(data, verbose=1)
    em = y0.astype(np.float32)
    print(f""em.shape={em.shape}"")","This code imports the necessary libraries for image processing, including random, glob, os, sys, json, math, configparser, numpy, pandas, sklearn, lightgbm, and tensorflow.

It then defines some global variables, including the input and output directories, the resource directory, and the model directory.

Next, it loads the test data from the input directory, and stores the posting_ids in a list.

If the IMAGE flag is set to True, the code will load the Keras model from the specified model directory.

If the IMAGE flag is set to True, the code will generate image embeddings for each image in the test dataset using the Keras model.",8,7,0.10525661212345054
"!ls ../input/shopee-product-matching/
!ls ../input/shopee-generate-data-for-triplet-loss/train_triplets_titles.csv# import sys
# sys.path.append ('/kaggle/input/pytorch-images-seresnet')
import os
import gc
import time
import math
import random
import datetime
import pandas as pd
import numpy as np
import seaborn as sns

import torch
import torch.nn as nn
from   torch.nn import init
from   torch.nn import CrossEntropyLoss, MSELoss
from   torch.nn.modules.loss import _WeightedLoss
import torch.nn.functional as F
from   torch.nn import Parameter
from   torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler
from   transformers import AdamW, get_cosine_schedule_with_warmup
from   torch.cuda.amp import autocast, GradScaler

from   transformers import BertForSequenceClassification, BertConfig, AutoTokenizer, AutoModelForSequenceClassification
from   transformers import RobertaTokenizer, RobertaForSequenceClassification, XLMRobertaModel

from   sklearn.model_selection import StratifiedKFold, GroupKFold
# import timm

import albumentations as A
from   albumentations import *
from   albumentations.pytorch import ToTensorV2
from   albumentations.core.transforms_interface import DualTransform
from   albumentations.augmentations import functional as AF
import cv2

from   tqdm import tqdm
from   pprint import pprint
from   functools import partial
import matplotlib.pyplot as plt
# from GPUtil import showUtilization as gpu_usage
# from   numba import cuda
import warnings
warnings.filterwarnings (""ignore"")class CFG:
    device       = torch.device ('cuda' if torch.cuda.is_available () else 'cpu')
    num_workers  = 8
    model_name   = 'xlmroberta'        # ['deit_base_patch16_224', 'vit_base_patch16_384', 'resnext50_32x4d', 'tf_efficientnet_b7_ns']
    margin       = 1.0
    size         = 128
    isTrain      = True
    isFreeze     = True
    lr           = 1e-4
    epochs       = 6
    warmup_steps = 0.50                    # if float: these many epochs are with frozen model at the beginning, if int = actual steps
    lr_num_cycles= 0.5
    epochsNx     = 1
    weight_decay = 1e-6
    max_grad_norm= 1000.0
    seed         = 42
    n_fold       = 10
    train_fold   = [0]                      # [0, 1, 2, 3, 4]
    print_every  = 100
    adam_epsilon = 1e-8
    train_batch_size = 12
    eval_batch_size  = 112
    img_ext          = '.png'
    img_col          = ""image_id""
    raw_label_cols   = 'class_id'
    label_cols       = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]
    target_size      = len (label_cols)
    model_infer_path_prefix = "".""
    model_train_path_prefix = "".""
    text_triplets_csv= ""../input/shopee-generate-data-for-triplet-loss/train_triplets_titles.csv""
    train_path       = '../input/shopee-product-matching/train_images'
    # train_csv        = '../input/vinbigdata-chest-xray-abnormalities-detection/train.csv'
    # test_path        = '../input/vinbigdata-chest-xray-resized-png-1024x1024/test'
    output_dir       = './results'        # output directory    
    eval_steps       = 0.5                # if float: these many epochs are with frozen model at the beginning, if int = actual steps 
    max_steps        = 0
    MODEL            = Nonedef init_logger (log_file=CFG.output_dir+'train.log'):
    
    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler
    logger = getLogger (__name__)
    logger.setLevel (INFO)
    handler1 = StreamHandler ()
    handler1.setFormatter (Formatter (""%(message)s""))
    handler2 = FileHandler (filename=log_file)
    handler2.setFormatter (Formatter (""%(message)s""))
    logger.addHandler (handler1)
    logger.addHandler (handler2)
    return loggerdef seed_everything (seed):
    
    random.seed (seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed (seed)
    torch.manual_seed (seed)
    torch.cuda.manual_seed (seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = True
    return# see image triplets
df = pd.read_csv (CFG.text_triplets_csv)
TRAIN_DF = df.iloc[:(df.shape[0]*9//10)]
TEST_DF  = df.iloc[(df.shape[0]*9//10):]
del df
gc.collect ()
TEST_DF.head ()bert_model_name = 'xlm-roberta-large'
max_len         = CFG.size
tokenizer       = AutoTokenizer.from_pretrained (bert_model_name)","This code imports the necessary libraries for the project, sets some global variables, and defines a seed_everything() function to ensure reproducibility. It also reads in the data from the train_triplets_titles.csv file, splits it into train and test sets, and displays the first five rows of the test set. Finally, it sets up the BertForSequenceClassification model from the transformers library.",8,2,0.07625351944630361
"from shopee_helper_script import *
from torch.nn import functional as F
import transformers
import plotly.express as px

IMAGE_SIZE = 512

tfidf_dim=15000
img_emb_dim=256
tfidf_emb_dim=256

image_threshold = 0.1 - 0.03
bert_threshold = 0.4 - 0.18
tfidf_threshold = 0.15 - 0.08


data_folder = ""../input/shopee-product-matching""
pre_trained_image_model_folder = ""../input/pre-trained-models/""
model_path = ""../input/pre-trained-models/tfidf_15000_256_256_11014_10.pth""  #### MODIFY THIS####
model_file_name = ""efficientnet-b1-f1951068.pth""
model_name = ""efficientnet-b1""


transformer_model = '../input/sentence-transformer-models/paraphrase-xlm-r-multilingual-v1/0_Transformer'
TEXT_MODEL_PATH = '../input/best-multilingual-model/sentence_transfomer_xlm_best_loss_num_epochs_25_arcface.bin'
TOKENIZER = transformers.AutoTokenizer.from_pretrained(transformer_model)

!cp -r ../input/eff-net-whl/EfficientNet-PyTorch .
!pip install -e EfficientNet-PyTorch/.
import importlib  
ENet = importlib.import_module(""EfficientNet-PyTorch.efficientnet_pytorch"")
EfficientNet = ENet.EfficientNetclass image_tfidf_embedder(Base_model):
    def __init__(self, tfidf_dim=15000, img_emb=256, text_emb=256, out_classes=11014):
        super().__init__()

        try:
            self.effnet = EfficientNet.from_name(model_name)
            self.effnet.load_state_dict(torch.load(pre_trained_image_model_folder + model_file_name))
        except:
            self.effnet = EfficientNet.from_pretrained(pre_trained_image_model_folder + model_file_name)

        self.linear1 = nn.Linear(1000, img_emb)
        self.linear2 = nn.Linear(tfidf_dim, text_emb)
        self.arcface_head = ArcFace(img_emb + text_emb, out_classes)

        self.loss = nn.CrossEntropyLoss()
        self.metric = metrics.accuracy_score
        self.threshold = None


    def forward(self, data_batch):
        images = data_batch[""image""]
        text_vec = data_batch[""text_vec""]
        label = data_batch[""label""]

        images = self.effnet(images)
        img_emb = self.linear1(images)
        text_emb = self.linear2(text_vec)

        full_emb = torch.cat([img_emb,text_emb], dim=1)


        if self.training:
            out = self.arcface_head(full_emb, label)
            loss = self.loss(out, label)
            metric = 0

            return out, loss, metric
        else:
            return full_emb, 0, 0


    def set_optimizer(self, lr):
        self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)


    def validate_all(self, valid_dataset):
        embeddings = self.predict(valid_dataset, batch_size=self.valid_batch_size)

        # Find best threshold for cosine distance and log the f1
        best_cosine_threshold = get_best_threshold(cosine_find_matches_cupy, embeddings, valid_dataset.df.posting_id, valid_dataset.df.target, np.arange(0.05,0.30,0.05))
        matches = cosine_find_matches_cupy(embeddings, valid_dataset.df.posting_id, best_cosine_threshold,create_submission=False)
        f1_score = matches_to_f1_score(valid_dataset.df.target, pd.Series(matches))
        wandb.log({""Valid_cosine_F1"": f1_score}, step=self.current_train_step)



class bert_embedder(Base_model):
    def __init__(self, out_classes=11014, dropout=0.3):
        super().__init__()
        self.transformer = transformers.AutoModel.from_pretrained(transformer_model)


    def forward(self, data_batch):
        input_id = data_batch[""input_id""]
        attention_mask = data_batch[""attention_mask""]
        
        x = self.transformer(input_ids=input_id, attention_mask=attention_mask)
        
        feat = x[0]
        feat = feat[:,0,:]
        out = F.normalize(feat)
                
        return out, None, None

def get_transforms(img_size=IMAGE_SIZE):
    return albumentations.Compose([
        albumentations.Resize(img_size, img_size),
        albumentations.Normalize()
    ])

# Function to get our text title embeddings
def get_tfidf(titles, max_features = 15500):

    vectorizer = TfidfVectorizer(stop_words = 'english', binary = True, max_features = max_features)
    vectorizer = vectorizer.fit(pd.read_csv(data_folder + ""/train.csv""))
    text_embeddings = vectorizer.transform(titles)
    del vectorizer
    return text_embeddings

class ShopeeDataset(Dataset):
    def __init__(self, df, mode, transforms=get_transforms()):
        self.df = df.reset_index(drop=True)
        self.transform = transforms
        self.mode = mode
        self.text_vec = get_tfidf(df[""title""])

    def __len__(self):
        return self.df.shape[0]

    def __getitem__(self, index):
        row = self.df.iloc[index,]
        text_vec = self.text_vec[index,]
        
        
        try:
            label_group = torch.tensor(row.label_group)
        except (ValueError, AttributeError):
            label_group = torch.Tensor()


        image = cv2.imread(row.file_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = self.transform(image=image)
        image = image[""image""].astype(np.float32)
        image = image.transpose(2, 0, 1) # Turn into pytorch format # Batch, Channels, ...
        image = torch.tensor(image)

        return {""image"":image,  ""text_vec"":torch.tensor(np.squeeze(text_vec.toarray().astype(np.float32))) , ""label"":label_group}

        
class ShopeeTextDataset(Dataset):
    def __init__(self, df):
        self.df = df.reset_index(drop=True)

    def __len__(self):
        return self.df.shape[0]

    def __getitem__(self, index):
        row = self.df.iloc[index,]
        
        text = row.title
        
        text = TOKENIZER(text, padding='max_length', truncation=True, max_length=128, return_tensors=""pt"")
        input_ids = text['input_ids'][0]
        attention_mask = text['attention_mask'][0]


        return {""input_id"":torch.tensor(input_ids),  ""attention_mask"": torch.tensor(attention_mask)}#train = pd.read_csv(""../input/shopee-product-matching/train.csv"")
#text_train_ds = ShopeeTextDataset(train)

test = pd.read_csv(""../input/shopee-product-matching/test.csv"")
text_test_ds = ShopeeTextDataset(test)

text_model = bert_embedder(out_classes=11014)
text_model.load_state_dict(dict(list(torch.load(TEXT_MODEL_PATH).items())[:-1]))
text_model.device=device
text_model.to(device)

text_embed = text_model.predict(text_test_ds, batch_size=1000)

text_matches = cosine_find_matches_cupy(text_embed, text_test_ds.df.posting_id, bert_threshold, create_submission=False)#image_train_ds , _ = create_train_test(mode=""train"")
test_ds , _ = create_train_test(mode=""inference"")

# Load trained model
model = image_tfidf_embedder(tfidf_dim=tfidf_dim,  img_emb=img_emb_dim, text_emb=tfidf_emb_dim)
model.load_state_dict(torch.load(model_path))
model.device=device

# Generate embeddings and then submission file
img_tfidf_embed = model.predict(test_ds) # If doesn't work, self.device attribute might be missing

img_embed = img_tfidf_embed[:,:256]
tfidf_embed = img_tfidf_embed[:,256:]

img_matches = cosine_find_matches_cupy(img_embed, test_ds.df.posting_id, image_threshold, create_submission=False)
tfidf_matches = cosine_find_matches_cupy(tfidf_embed, test_ds.df.posting_id, tfidf_threshold, create_submission=False)#Take union of the predictions
#matches = list(map(lambda x,y,z: "" "".join(set(x.split("" "") + y.split("" "") + z.split("" ""))), img_matches, tfidf_matches, text_matches ))
matches = list(map(lambda x,y: "" "".join(set(x.split("" "") + y.split("" "") )), img_matches,  text_matches ))

pd.DataFrame({""posting_id"": test_ds.df.posting_id, ""matches"": matches}).to_csv(""submission.csv"", index=False)","The code above is for a Shopee product matching script. It includes imports for the Shopee helper script, the Transformers library, and Plotly. The code also sets the image size to 512.

The tfidf_dim variable is set to 15000, the img_emb_dim variable is set to 256, and the tfidf_emb_dim variable is set to 256. The image_threshold and bert_threshold variables are both set to 0.1 - 0.03 and 0.4 - 0.18, respectively. The tfidf_threshold variable is set to 0.15 - 0.08.

The data_folder variable is set to ""../input/shopee-product-matching"" and the pre_trained_image_model_folder variable is set to ""../input/pre-trained-models/"". The model_path variable is set to ""../input/pre-trained-models/tfidf_15000_256_256_11014_10.pth"" and the model_file_name variable is set to ""efficientnet-b1-f1951068.pth"". The model_name variable is set to ""efficientnet-b1"".

The transformer_model variable is set to ""../input/sentence-transformer-models/paraphrase-xlm-r-multilingual-v1/0_Transformer"" and the TEXT_MODEL_PATH variable is set to ""../input/best-multilingual-model/sentence_transfomer_xlm_best_loss_num_epochs_25_arcface.bin"". The TOKENIZER variable is set to the AutoTokenizer from the Transformers library.

The code then copies the EfficientNet-PyTorch folder from the input to the current directory and installs it. The code also imports the EfficientNet module.

The image_tfidf_embedder class is then defined. This class inherits from the Base_model class. The __init__ method initializes the class and sets the tfidf_dim, img_emb, text_emb, and out_classes variables. The class also has loss, metric, and threshold variables.

The forward method is then defined. This method takes in data_batch as an",8,27,0.09033903086219434
"DATA_PATH = '../input/shopee-product-matching/'

import numpy as np 
import pandas as pd 
import gensim
from gensim.similarities import WmdSimilarity
from nltk.corpus import stopwords
from nltk import download
download('stopwords')  # Download stopwords list.
stop_words = stopwords.words('english')

train = pd.read_csv(DATA_PATH + 'train.csv')

## Google word embeddings

model = gensim.models.KeyedVectors.load_word2vec_format('../input/word2vecgooglenews300/GoogleNews-vectors-negative300.bin', binary=True)

## process raw titles
def preprocess(sentence):
    return [w for w in sentence.lower().split() if w not in stop_words]


# Example using Shopee Data

raw_titles = train['title'].tolist()

neighbours = [ i for index,i in enumerate(raw_titles) if model.wmdistance(preprocess(raw_titles[579])
                                                        , preprocess(raw_titles[index])) <= 0.40]            raw_titles[579]## Not explicitly sorted based on distance  
neighbours",The code above loads in the Shopee product matching dataset and calculates the word mover's distance between the product titles in order to find similar products.,8,0,0.07866894717352307
"import sys
sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')

import timm
from tqdm import tqdm
import math
import random
import os
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.neighbors import NearestNeighbors

# Visuals and CV2
import cv2

# albumentations for augs
import albumentations
from albumentations.pytorch.transforms import ToTensorV2

import torch
import timm
import torch.nn as nn
from torch.nn import Parameter
from torch.nn import functional as F
from torch.utils.data import Dataset,DataLoader

from torchvision import datasets, transformsIM_FOLDER = '../input/shopee-product-matching/test_images'
MODEL_PATH = '../input/shopeekfoldevaluation/kfolds_strategies_evaluation/kfolds_strategies_evaluation/train_n_lbgr_88_3fold/Fold02_Valid0.725_Train0.724_Ep003.pth'

FOIS = [0, 1, 2]
SAMPLE = None

DIM = (512,512)
EMB_SIZE = 1536

NUM_WORKERS = 4
TRAIN_BATCH_SIZE = 16
VALID_BATCH_SIZE = 16
SEED = 2020
LR = 3e-4

################################################# MODEL ####################################################################
model_name = 'efficientnet_b3' #efficientnet_b0-b7

################################################ Metric Loss and its params #######################################################
loss_module = 'arcface' #'cosface' #'adacos'
s = 30.0
m = 0.5 
ls_eps = 0.0
easy_margin = False

############################################## Model Params ###############################################################
model_params = {
    'model_name':'efficientnet_b3',
    'use_fc':False,
    'fc_dim':512,
    'dropout':0.0,
    'loss_module':loss_module,
    's':30.0,
    'margin':28.6, # degree (0.5 radian)
    'ls_eps':0.0,
    'theta_zero':0.785,
    'pretrained':None
}

########### Device ###########
DEVICE = torch.device(""cuda"")def get_valid_transforms():

    return albumentations.Compose(
        [
            albumentations.Resize(DIM[0],DIM[1],always_apply=True),
            albumentations.Normalize(),
        ToTensorV2(p=1.0)
        ]
    )class ShopeeDataset(Dataset):
    def __init__(self, csv, transforms=None):

        self.csv = csv.reset_index()
        self.augmentations = transforms
        
        if('label_group' in self.csv.columns):
            self.is_test = False
        else:
            self.is_test = True

    def __len__(self):
        return self.csv.shape[0]

    def __getitem__(self, index):
        row = self.csv.iloc[index]
        
        text = row.title
        
        image = cv2.imread(row.filepath)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        if self.augmentations:
            augmented = self.augmentations(image=image)
            image = augmented['image']       
        
        if(self.is_test):
            return image
        else:
            return image, torch.tensor(row.label_group)class ShopeeNet(nn.Module):

    def __init__(self,
                 model_name='efficientnet_b0',
                 use_fc=False,
                 fc_dim=512,
                 dropout=0.0,
                 loss_module='softmax',
                 s=30.0,
                 margin=0.50,
                 ls_eps=0.0,
                 theta_zero=0.785,
                 pretrained=None):
        """"""
        :param n_classes:
        :param model_name: name of model from pretrainedmodels
            e.g. resnet50, resnext101_32x4d, pnasnet5large
        :param loss_module: One of ('arcface', 'cosface', 'softmax')
        """"""
        super(ShopeeNet, self).__init__()
        print('Building Model Backbone for {} model'.format(model_name))

        self.backbone = timm.create_model(model_name, pretrained=False)
        if(pretrained):
            print('Loading pretrained model from:', pretrained)
            self.backbone.load_state_dict(torch.load(pretrained, map_location='cpu'))
            
        final_in_features = self.backbone.classifier.in_features
        
        self.backbone.classifier = nn.Identity()
        self.backbone.global_pool = nn.Identity()
        
        self.pooling =  nn.AdaptiveAvgPool2d(1)
            
        self.use_fc = use_fc
        if use_fc:
            print('use_fc')
            self.dropout = nn.Dropout(p=dropout)
            self.fc = nn.Linear(final_in_features, fc_dim)
            self.bn = nn.BatchNorm1d(fc_dim)
            self._init_params()
            final_in_features = fc_dim

    def _init_params(self):
        nn.init.xavier_normal_(self.fc.weight)
        nn.init.constant_(self.fc.bias, 0)
        nn.init.constant_(self.bn.weight, 1)
        nn.init.constant_(self.bn.bias, 0)

    def forward(self, x):
        batch_size = x.shape[0]
        x = self.backbone(x)
        x = self.pooling(x).view(batch_size, -1)

        if self.use_fc:
            x = self.dropout(x)
            x = self.fc(x)
            x = self.bn(x)
        
        return x# Test loading model properly
model = ShopeeNet(**model_params)
model.to(DEVICE)
model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))def getMetric(col):
    def f1score(row):
        n = len(np.intersect1d(row.target,row[col]))
        return 2*n / (len(row.target)+len(row[col]))
    return f1score

def compute_f1(df, pred_col='preds'):
    res_df = df.copy()
    target_dict = res_df.groupby('label_group').posting_id.agg('unique').to_dict()
    res_df['target'] = res_df.label_group.map(target_dict)
    res_df['f1'] = res_df.apply(getMetric(pred_col),axis=1)
    return res_df.f1.mean()","This code imports the timm library for PyTorch image models and defines a ShopeeDataset class for loading image data from a CSV file. The code also defines a ShopeeNet class for creating a neural network for image classification. Finally, the code defines a function for computing the F1 score for a given prediction column in a DataFrame.",8,4,0.07979138100989948
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames[:4]:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport os
import numpy as np
import pandas as pd
import cv2
import matplotlib.pyplot as plt

from kaggle_datasets import KaggleDatasets
from sklearn.model_selection import train_test_split

import tensorflow as tf
import tensorflow.keras as keras
from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping
from tensorflow.keras.layers.experimental import preprocessing
from tensorflow.keras.layers import Conv2Dclass CONFIG(object):
  """"""CONFIG""""""
  def __init__(self):
    self.img_size = (224, 224)
    self.base = '../input/shopee-product-matching/'
    self.df = '../input/shopee-product-matching/train.csv'
    self.batch_size = 32
    self.val_split = 0.25
    self.seed = 22
    self.n_epochs = 40
    
    
cfg= CONFIG()df= pd.read_csv(cfg.df)
df.head()def load_img(img_id):
    path = cfg.base + 'train_images/' + img_id
    img = cv2.imread(path)
    img = cv2.resize(img, cfg.img_size)
    return imgdef build_decoder(with_labels=True, target_size=cfg.img_size, ext='jpg'):
    def decode(path):
        file_bytes = tf.io.read_file(path)
        if ext == 'png':
            img = tf.image.decode_png(file_bytes, channels=3)
        elif ext in ['jpg', 'jpeg']:
            img = tf.image.decode_jpeg(file_bytes, channels=3)
        else:
            raise ValueError(""Image extension not supported"")
            
        img = tf.cast(img, tf.float32) / 255.0
        img = tf.image.resize(img, target_size)
        img = tf.cast((img> 0.9), tf.float32)
        return img
    
    def decode_with_labels(path):
        x = decode(path)
        return x, x
    
    return decode_with_labels if with_labels else decode

img_decoder = build_decoder(with_labels=True, target_size= cfg.img_size,  ext='jpg')# TPU or GPU detection
def auto_select_accelerator():
    """"""
    Reference: 
        * https://www.kaggle.com/mgornergoogle/getting-started-with-100-flowers-on-tpu
        * https://www.kaggle.com/xhlulu/ranzcr-efficientnet-tpu-training
    """"""
    try:  # detect TPUs
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  ## detect TPUs
        tf.config.experimental_connect_to_cluster(tpu)
        tf.tpu.experimental.initialize_tpu_system(tpu)
        strategy = tf.distribute.experimental.TPUStrategy(tpu)
        print(""Running on TPU:"", tpu.master())
    except ValueError:
        strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines
        #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU
        #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines
        
    print(f""Running on {strategy.num_replicas_in_sync} replicas"")
    return strategy","This code detects whether a machine has a TPU or GPU and selects the appropriate strategy for training a model. If a TPU is detected, the TPUStrategy is used. Otherwise, the MirroredStrategy is used.",8,2,0.1465355365013326
"! cp ../input/tokenization/tokenization.py  /kaggle/workingimport pandas as pd
import numpy as np 
import matplotlib.pyplot as plt 
import tensorflow as tf 
import cudf,cupy,cuml
import cv2 as cv 
from PIL import Image
import os
from tqdm import tqdm
import re 
import string
import tensorflow_hub as hub
import tokenization
from tensorflow.keras.optimizers import SGD 
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.utils import Sequence
import cv2 as cv
import gctest = pd.read_csv(""../input/shopee-product-matching/test.csv"")
#test_cudf = cudf.read_csv(""../input/shopee-product-matching/test.csv"")
images_path = ""../input/shopee-product-matching/test_images""
if len(test) <= 3 :
    test = pd.read_csv(""../input/shopee-product-matching/train.csv"")
    #test_cudf = cudf.read_csv(""../input/shopee-product-matching/train.csv"")
    images_path = ""../input/shopee-product-matching/train_images""test.head()targ = test.groupby(""label_group"").posting_id.unique()test[""target""] = test.label_group.map(targ)def getMetric(col):
    def f1score(row):
        n = len( np.intersect1d(row.target,row[col]) )
        return 2*n / (len(row.target)+len(row[col]))
    return f1score",The code above imports the necessary libraries for the program and defines the test dataset. It then calculates the F1 score for each row in the dataset.,8,0,0.03067389631585763
"from pathlib import Path

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import cv2BASE_DATA_DIR = Path(""../input/shopee-product-matching/"")
!ls {BASE_DATA_DIR}!ls {BASE_DATA_DIR / ""test_images""}df_train = pd.read_csv(BASE_DATA_DIR / ""train.csv"")
df_test = pd.read_csv(BASE_DATA_DIR / ""test.csv"")
df_sub = pd.read_csv(BASE_DATA_DIR / ""sample_submission.csv"")group_by_label_images = df_train.groupby(""label_group"")[""image""].apply(list)
len_groups = group_by_label_images.apply(len)# Grouped images
group_by_label_images.head()# Length of the groups
len_groups.head()","The code above imports the necessary libraries for data analysis and visualisation, and sets the base directory for the data files. It then reads in the train, test and submission data as dataframes.

Next, the code groups the images by label_group and calculates the length of each group. This will be useful for later visualisation.",8,3,0.0738123234193201
"import torch 
import torch.nn.functional as F

from torch import nn, optim 
from torch.utils.data import DataLoader
from torchvision import transforms as T, datasets

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt 
import plotly.express as px

from tqdm.notebook import tqdm
from sklearn.metrics import accuracy_score

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')transform = T.Compose([
    T.ToTensor(),
    T.Normalize((0.5,), (0.5,))
])trainset = datasets.MNIST('../input/mnist-dataset-pytorch', train = True, transform = transform)
testset = datasets.MNIST('../input/mnist-dataset-pytorch', train = False, transform = transform)class ArcFace(nn.Module):
    
    def __init__(self,in_features,out_features,margin = 0.7 ,scale = 64):
        super().__init__()
        
        self.in_features = in_features
        self.out_features = out_features
        self.scale = scale
        self.margin = margin 
        
        self.weights = nn.Parameter(torch.FloatTensor(out_features,in_features))
        nn.init.xavier_normal_(self.weights)
        
    def forward(self,features,targets):
        cos_theta = F.linear(features,F.normalize(self.weights),bias=None)
        cos_theta = cos_theta.clip(-1+1e-7, 1-1e-7)
        
        arc_cos = torch.acos(cos_theta)
        M = F.one_hot(targets, num_classes = self.out_features) * self.margin
        arc_cos = arc_cos + M
        
        cos_theta_2 = torch.cos(arc_cos)
        logits = cos_theta_2 * self.scale
        return logits
    
    
class MNIST_Model(nn.Module):
    
    def __init__(self):
        super(MNIST_Model, self).__init__()

        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.conv2_drop = nn.Dropout2d()
        self.fc1 = nn.Linear(320, 50)
        self.fc2 = nn.Linear(50,3)
        self.arc_face = ArcFace(in_features = 3, out_features = 10)
        
    def forward(self,features,targets = None):
        
        x = F.relu(F.max_pool2d(self.conv1(features), 2))
        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
        _,c,h,w = x.shape
        x = x.view(-1, c*h*w)
        x = F.relu(self.fc1(x))
        x = F.normalize(self.fc2(x))
        
        if targets is not None:
            logits = self.arc_face(x,targets)
            return logits
        return xmodel = MNIST_Model()
model.to(device)class TrainModel():
    
    def __init__(self,criterion = None,optimizer = None,schedular = None,device = None):
        self.criterion = criterion
        self.optimizer = optimizer
        self.schedular = schedular
        self.device = device
        
    def accuracy(self,logits,labels):
        ps = torch.argmax(logits,dim = 1).detach().cpu().numpy()
        acc = accuracy_score(ps,labels.detach().cpu().numpy())
        return acc

    def get_dataloader(self,trainset,validset):
        trainloader = DataLoader(trainset,batch_size = 64, num_workers = 4, pin_memory = True)
        validloader = DataLoader(validset,batch_size = 64, num_workers = 4, pin_memory = True)
        return trainloader, validloader
        
    def train_batch_loop(self,model,trainloader,i):
        
        epoch_loss = 0.0
        epoch_acc = 0.0
        pbar_train = tqdm(trainloader, desc = ""Epoch"" + "" [TRAIN] "" + str(i+1))
        
        for t,data in enumerate(pbar_train):
            
            images,labels = data
            images = images.to(device)
            labels = labels.to(device)
            
            logits = model(images,labels)
            loss = self.criterion(logits,labels)
            
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
            
            epoch_loss += loss.item()
            epoch_acc += self.accuracy(logits,labels)
            
            pbar_train.set_postfix({'loss' : '%.6f' %float(epoch_loss/(t+1)), 'acc' : '%.6f' %float(epoch_acc/(t+1))})
            
        return epoch_loss / len(trainloader), epoch_acc / len(trainloader)
            
    
    def valid_batch_loop(self,model,validloader,i):
        
        epoch_loss = 0.0
        epoch_acc = 0.0
        pbar_valid = tqdm(validloader, desc = ""Epoch"" + "" [VALID] "" + str(i+1))
        
        for v,data in enumerate(pbar_valid):
            
            images,labels = data
            images = images.to(device)
            labels = labels.to(device)
            
            logits = model(images,labels)
            loss = self.criterion(logits,labels)
            
            epoch_loss += loss.item()
            epoch_acc += self.accuracy(logits,labels)
            
            pbar_valid.set_postfix({'loss' : '%.6f' %float(epoch_loss/(v+1)), 'acc' : '%.6f' %float(epoch_acc/(v+1))})
            
        return epoch_loss / len(validloader), epoch_acc / len(validloader)
            
    
    def run(self,model,trainset,validset,epochs):
    
        trainloader,validloader = self.get_dataloader(trainset,validset)
        
        for i in range(epochs):
            
            model.train()
            avg_train_loss, avg_train_acc = self.train_batch_loop(model,trainloader,i)
            
            model.eval()
            avg_valid_loss, avg_valid_acc = self.valid_batch_loop(model,validloader,i)
            
        return model criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr = 0.0001)


model = TrainModel(criterion, optimizer, device).run(model, trainset, testset, 20)","The TrainModel class is used to train a model on a dataset. The class takes in a criterion, optimizer, schedular, and device as parameters. The class has a train_batch_loop and valid_batch_loop function which train and validate the model respectively. The class also has a run function which runs the training and validation loops for a specified number of epochs.",8,2,0.08253231435803342
"timm_path = ""../input/timm-pytorch-image-models/pytorch-image-models-master""
import sys
sys.path.append(timm_path)
import timm
import time

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sklearn
import os
from tqdm.notebook import tqdm

import cv2
import albumentations as A
from albumentations.pytorch import ToTensorV2

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset,DataLoader
from torch import optim

import numpy as np, pandas as pd, gc
import cv2, matplotlib.pyplot as plt
import cudf, cuml, cupy
from cuml.feature_extraction.text import TfidfVectorizer
from cuml.neighbors import NearestNeighbors
import tensorflow as tf
# from tensorflow.keras.applications import EfficientNetB0
print('RAPIDS',cuml.__version__)
print('TF',tf.__version__)
metric='cosine'
import warnings
warnings.filterwarnings('ignore')

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')COMPUTE_CV = True

test = pd.read_csv('../input/shopee-product-matching/test.csv')
if len(test)>3: COMPUTE_CV = False
else: print('this submission notebook will compute CV score, but commit notebook will not')train = pd.read_csv('../input/shopee-product-matching/train.csv')
tmp = train.groupby('label_group').posting_id.agg('unique').to_dict()
train['target'] = train.label_group.map(tmp)
print('train shape is', train.shape )
train.head()tmp = train.groupby('image_phash').posting_id.agg('unique').to_dict()
train['oof'] = train.image_phash.map(tmp)def getMetric(col):
    def f1score(row):
        n = len( np.intersect1d(row.target,row[col]) )
        return 2*n / (len(row.target)+len(row[col]))
    return f1scoretrain['f1'] = train.apply(getMetric('oof'),axis=1)
print('CV score for baseline =',train.f1.mean())if COMPUTE_CV:
    test = pd.read_csv('../input/shopee-product-matching/train.csv')
    test_gf = cudf.DataFrame(test)
    print('Using train as test to compute CV (since commit notebook). Shape is', test_gf.shape )
else:
    test = pd.read_csv('../input/shopee-product-matching/test.csv')
    test_gf = cudf.read_csv('../input/shopee-product-matching/test.csv')
    print('Test shape is', test_gf.shape )
test_gf.head()","This code loads in the Shopee product matching dataset, computes a baseline CV score using the image phash column, and then uses the train dataset as the test dataset to compute a CV score.",8,1,0.144887797875268
"import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
pd.set_option('display.max_columns', 500)

import time
from tqdm.notebook import tqdm

# Standard plotly imports
import plotly as py
import plotly.graph_objs as go
import plotly.tools as tls
from plotly.offline import iplot, init_notebook_mode
import cufflinks
import cufflinks as cf
import plotly.figure_factory as ff
import os


import warnings
warnings.filterwarnings(""ignore"")import os

import numpy as np
import pandas as pd
from sklearn import preprocessing
from catboost import Pool, CatBoostClassifier, cv, CatBoostRegressorprint('# File sizes')
total_size = 0
start_path = '../input/jane-street-market-prediction'  # To get size of current directory
for path, dirs, files in os.walk(start_path):
    for f in files:
        fp = os.path.join(path, f)
        total_size += os.path.getsize(fp)
print(""Directory size: "" + str(round(total_size/ 1000000, 2)) + 'MB')%%time
train = pd.read_csv('/kaggle/input/jane-street-market-prediction/train.csv')
features = pd.read_csv('../input/jane-street-market-prediction/features.csv')
example_test = pd.read_csv('../input/jane-street-market-prediction/example_test.csv')
sample_prediction_df = pd.read_csv('../input/jane-street-market-prediction/example_sample_submission.csv')
print (""Data is loaded!"")print('train shape is {}'.format(train.shape))
print('features shape is {}'.format(features.shape))
print('example_test shape is {}'.format(example_test.shape))
print('sample_prediction_df shape is {}'.format(sample_prediction_df.shape))train.head()missing_values_count = train.isnull().sum()
print (missing_values_count)
total_cells = np.product(train.shape)
total_missing = missing_values_count.sum()
print (""% of missing data = "",(total_missing/total_cells) * 100)","The code above imports the necessary libraries for data analysis and processing, then loads the data from the CSV files. Next, it prints the shape of each dataframe, then displays the first five rows of the train dataframe. Finally, it calculates the percentage of missing values in the data.",8,2,0.06769392293223622
"!pip install m2cgen --quiet --quietimport numpy as np
import pandas as pd
import m2cgen as m2c
import lightgbm as lgb
import xgboost as xgb
import ctypes
import io
from numpy.ctypeslib import ndpointerPATH = '../input/jane-street-market-prediction'
NA_REPLACEMENT = -9999.0
N_TREES = 500
N_TEST_ROWS_TO_SIMULATE = None # None means all
N_JOBS = 4train = pd.read_csv(f'{PATH}/train.csv', nrows=300000)
train.shapetrain = train[train['weight'] != 0]
train.shapeexclude = [
    'date', 'weight', 'resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp', 'ts_id'
]
inputs = train.drop(exclude, axis=1)
inputs.shapefeatures = inputs.columns
len(features)","This code installs the m2cgen package and imports the numpy, pandas, and m2cgen modules. It also imports the lightgbm, xgboost, ctypes, and io modules.

The code defines a PATH variable and sets the NA_REPLACEMENT and N_TREES variables.

The code then reads in a CSV file containing train data, and subsetting the data to only include rows with a weight column != 0.

The code then exclude certain columns from the train dataframe, and create a new dataframe called inputs which only contains the remaining columns.

Finally, the code gets a list of all the column names in the inputs dataframe, and prints out the number of columns.",8,13,0.08600304308883687
"!pip install lofo-importanceimport pandas as pd
import numpy as np
import janestreet as jane
from lofo import LOFOImportance, Dataset, plot_importancetrain = pd.read_csv(""../input/jane-street-market-prediction/train.csv"")
train = train.loc[train[""weight""] != 0,]
train[""Y""] = (train[""weight""]*train[""resp""] > 0).astype(""int"")

train = train.dropna()Xs = list(list(np.where(train.columns.str.contains(""feature"")))[0]) 
Xs = list(train.columns[Xs])
Ys = list(list(np.where(train.columns.str.contains(""Y"")))[0]) 
Ys = list(train.columns[Ys])dataset = Dataset(df=train, target=Ys, features=Xs)Imp = LOFOImportance(dataset, cv=4, scoring=""roc_auc"")imp_result = Imp.get_importance()","This code installs the lofo-importance package and imports the pandas, numpy, and janestreet modules. It also imports the LOFOImportance and Dataset classes from the lofo package.

The code then loads a CSV file containing training data, and drops any rows with a weight of 0. It also adds a column called ""Y"" which indicates whether the resp column is positive or negative.

Next, the code creates a list of all columns containing the string ""feature"", and another list of all columns containing the string ""Y"". These lists are then used to create a Dataset object.

Finally, the code creates a LOFOImportance object, using the Dataset object and 4-fold cross validation. It then calls the get_importance() method to calculate the importance of each feature.",9,6,0.07293719271066214
"import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))#pip install datatable in console command to use this lib
import pandas as pd
import datatable as dt
import numpy as np
import os#df = dt.fread('../input/jane-street-market-prediction/train.csv').to_pandas()

train = dt.fread('../input/jane-street-market-prediction/train.csv').to_pandas()
features = dt.fread('../input/jane-street-market-prediction/features.csv').to_pandas()
features.style.applymap(lambda x: 'background-color : yellow' if x == True else '')import plotly
pd.options.plotting.backend = 'plotly'
plotly.offline.init_notebook_mode (connected = True)

features_dist = features[features == True].count().sort_values(ascending = False)
features_dist.plot(kind = 'bar')
features.set_index('feature', inplace = True)def features_with_tags(df):
    features_ds = df[df]
    cols = features_ds.columns
    number_cols = len(features_ds.index)
    list_df = []
    
    for idx_col in range(0, number_cols):
        ds = features_ds.iloc[idx_col]
        ds = ds[ds == 1].to_frame()
        ds.reset_index(inplace = True)
        
        cols_ds = ds.columns
        ds[cols_ds[1]] = ds[cols_ds[0]]
        ds.drop(cols_ds[0], axis = 1, inplace = True)
        list_df.append(ds)
    
    out_df = pd.concat(list_df, axis = 1, sort = False).T
    out_df.fillna('None', inplace = True)
    
    
    return out_df
    
    ","This code imports the numpy and pandas libraries, and then reads in the train and features data sets from the input directory. It then creates a bar plot of the feature values. Finally, it creates a function that takes in a dataframe and returns a new dataframe with the features and their corresponding tags.",8,3,0.12032995473735761
"# !pip install “dask[complete]”
# !python -m pip install dask distributed --upgrade

import os
import dask.dataframe as dd
from dask.distributed import Client, progress

import matplotlib.pyplot as plt

import pyarrow

import warnings
warnings.filterwarnings(""ignore"")# reading the paths of all the files present in the dataset
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))# setting the paths to variables to access when required
TRAINING_PATH = ""/kaggle/input/jane-street-market-prediction/train.csv""
FEATURES_PATH = ""/kaggle/input/jane-street-market-prediction/features.csv""
TEST_PATH = ""/kaggle/input/jane-street-market-prediction/example_test.csv""
SAMPLE_SUB_PATH = ""/kaggle/input/jane-street-market-prediction/example_sample_submission.csv""%time
train_df = dd.read_csv(TRAINING_PATH)
features_df = dd.read_csv(FEATURES_PATH)
test_df = dd.read_csv(TEST_PATH)train_df.head()test_df.head() # start a local Dask client
client = Client(n_workers=4, memory_limit='16GB')
client","This code installs the dask package and its dependencies, and then creates a dask dataframe from the train.csv, features.csv, and test.csv files. The code then creates a local dask client with 4 workers and a memory limit of 16GB.",8,5,0.191083226148707
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from xgboost.sklearn import XGBRegressortrain_df = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/train.csv')
test_df = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/test.csv')
sub_df = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/sample_submission.csv')

train_df.head()feature_cols = train_df.drop(['id', 'target'], axis=1).columns

x = train_df[feature_cols]
y = train_df['target']

print(x.shape, y.shape)## Join train and test datasets in order to obtain the same number of features during categorical conversion
train_indexs = train_df.index
test_indexs = test_df.index

df =  pd.concat(objs=[train_df, test_df], axis=0).reset_index(drop=True)
df = df.drop('id', axis=1)

len(train_indexs), len(test_indexs)
df.info()","The code above loads in the necessary libraries for data processing, then loads the train and test data from the csv files. It then defines the feature columns and splits the data into training and testing sets. Finally, it concatenates the train and test sets and drops the id column.",8,2,0.19545000778486782
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import StackingRegressor
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from catboost import CatBoostRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.ensemble import VotingRegressortrain = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/train.csv')
test = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/test.csv')
sample_submission = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/sample_submission.csv')
train.shape, test.shapetrain.describe()train.info()sns.heatmap(train.isnull(), cbar = False);train.hist(bins = 30, figsize = (20,20), color = 'b')","The code above imports the necessary libraries for data processing, including numpy, pandas, and matplotlib. It also sets up the environment for accessing the input data files.

The code then defines the training and testing data sets, as well as the sample submission file. The data sets are then explored using the describe() and info() methods.

Finally, the code creates a heatmap to visualize the null values in the training data set, and a histogram to visualize the distribution of the data.",8,3,0.1769478395910691
"import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import datatable as dt
%whos%%time
data = pd.read_csv('../input/tabular-playground-series-jan-2021/train.csv')
submission = dt.fread('../input/tabular-playground-series-jan-2021/test.csv').to_pandas()display(data.head())y = data.target.values
X = data.drop(['id','target'], axis=1).values
X.shape, y.shapeimport seaborn as sns
import plotly.express as px
from sklearn.preprocessing import scaleprint(f'Number of NA values in features: {pd.isnull(X).sum()}')plt.figure(figsize=(12,8))
plt.title('Distribution of target variable')
sns.distplot(y)
plt.axis('off')","This code imports the pandas, numpy, matplotlib, and datatable libraries, then reads in the train and test data from the tabular-playground-series-jan-2021 input folder. It displays the first five rows of the train data, then stores the target values in the y variable and the feature values in the X variable. The code then imports the seaborn and plotly express libraries and scales the feature values. Finally, it prints the number of NA values in the features and creates a distplot of the target variable.",9,6,0.13503606072753627
"import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
import xgboost as xgb
import lightgbm as lgbtrain_df = pd.read_csv('../input/tabular-playground-series-jan-2021/train.csv')
train_df.head()test_df = pd.read_csv('../input/tabular-playground-series-jan-2021/test.csv')
test_df.head()print(train_df.isnull().sum())
print(test_df.isnull().sum())fig, ax = plt.subplots(figsize=(15, 10))
sns.heatmap(train_df.corr(), annot = True)fig, ax = plt.subplots(figsize = (12, 6))
sns.distplot(train_df['target'])
ax.xaxis.grid(True)
ax.set(ylabel = ""Valores"")
ax.set(xlabel = ""Target"")
ax.set(title = ""Distribuicion de target"")
sns.despine(trim = True, left = True)
plt.show()cols = [col for col in train_df.columns if col not in ['id','target']]

fig, ax = plt.subplots(nrows = 7, ncols = 2, figsize = (15,15))
fig.tight_layout()

i = j = 0
for col in cols:
    sns.kdeplot(data = train_df[col],shade=True,ax=ax[i][j],legend=False)
    ax[i][j].set_title(col)
    j += 1
    if(j%2 == 0):
        i += 1
        j = 0
        
plt.show()","This code imports the necessary libraries for data analysis and visualization, then loads the training and testing data sets. Next, it prints the null values for each column in the training and testing data sets.

The code then visualizes the correlation between the different features using a heatmap. Finally, it plots the distribution of the target variable using a KDE plot.",8,0,0.02622964820262449
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionfrom fastai.tabular.all import *
from fastai.callback import *

import pandas as pd
import numpy as np

import warnings
warnings.filterwarnings('ignore')PATH = '/kaggle/input/tabular-playground-series-jan-2021/'train = pd.read_csv(PATH+'/train.csv')
test = pd.read_csv(PATH+'test.csv')
submission = pd.read_csv(PATH+'sample_submission.csv')[i.shape for i in [train, test, submission]]train.describe()train = train.drop('id', axis=1)
test = test.drop('id', axis=1)

cont_name = [col for col in train.columns if col != 'target']
target_col = ['target']","This code loads in the train, test, and submission csv files from the tabular-playground-series-jan-2021 directory. It then drops the id column from the train and test dataframes. The cont_name and target_col variables are created, which contain the names of the continuous and target columns, respectively. Finally, the train dataframe is described.",8,4,0.25570518470644515
"import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressordf = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/train.csv')x = df.iloc[:,:-1]
y = df.iloc[:, -1]x.head()forest = RandomForestRegressor(n_estimators=500, n_jobs=-1)forest.fit(x, y)test = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/test.csv')","This code imports the pandas, numpy, and sklearn libraries. It then reads in a CSV file containing training data, and stores the data in a dataframe called ""df"". It then splits the data into input features (x) and output labels (y), and uses a random forest regressor to fit the data. Finally, it reads in a CSV file containing test data, and uses the trained model to predict the labels for the test data.",8,3,0.07727784111411999
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session# data loading 
import pandas as pd
import numpy as np

#loading the train data and marking id as index
train_data=pd.read_csv(""../input/tabular-playground-series-jan-2021/train.csv"",index_col=0)

#loading the test data and marking id as index
test_data=pd.read_csv(""../input/tabular-playground-series-jan-2021/test.csv"",index_col=0)
#looking at the data
train_data.head()train_data.describe()
#looking at the range an the other information of the data# import the visulization libraries
import matplotlib.pyplot as plt 
import seaborn as sns#taking out the column names to which needed to be visulaize
cols=[col for col in train_data.columns if col not in ['target']]

#creating a sheet that can be use to plot the data of 7*2 size
fig, ax = plt.subplots(nrows=7, ncols=2, figsize=(15,15))
fig.tight_layout()

#plotting of data
i=j=0
for col in cols:
    #load the column name
    #plot the data - in this case KDE to visulaize distribution of data
    sns.kdeplot(data=train_data[col],shade=True,ax=ax[i][j],legend=False)
    #set name of the plot
    ax[i][j].set_title(col)
    #logic to plot in th shape of matrix(7*2) 
    j+=1
    if(j%2==0):
        i+=1
        j=0
        
#dislplay the plots
plt.show()# take out the data needed to be predicted
y=train_data['target']
# Mark the features as X
X=train_data.drop('target',axis=1)","The code loads the train and test data from the input directory and sets the id column as the index. It then prints out the first five rows of the train data and describes the data.

Next, the code import the visualization libraries and plots the data using a KDE plot. Finally, it sets the target column as the dependent variable y and the remaining columns as the independent variable X.",8,2,0.5010920132942118
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiontrain=pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/train.csv')
test=pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/test.csv')train.tail()test.tail()print(f'Shape of the train dataframe is {train.shape}')
print(f'Shape of the test dataframe is {test.shape}')train_nulls=pd.DataFrame(np.c_[train.isna().sum()],columns=['Num_of_Nulls'],index=train.isna().sum().index)
train_nullstest_nulls=pd.DataFrame(np.c_[test.isna().sum()],columns=['Num_of_Nulls'],index=test.isna().sum().index)
test_nulls","The code above loads in the necessary libraries for data analysis, then loads in the training and testing data from the input directory. It then displays the shape of the training and testing dataframes, and finally displays the number of null values in each column of the dataframes.",8,2,0.21518836199490302
"!pip install pytorch-tabnetimport numpy as np 
import pandas as pd 
from sklearn.model_selection import KFold
from pytorch_tabnet.tab_model import TabNetRegressor
from pytorch_tabnet.metrics import Metric
from sklearn.metrics import mean_squared_error
import torch
import os
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from sklearn.model_selection import train_test_split
import time
import matplotlib.pyplot as plt
import seaborn as snsclass Config:
    use_tabnet = True
    use_xgb = True
    use_lgb = False
    training = True
    max_epochs=20train = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/train.csv')
test = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/test.csv')
sub = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/sample_submission.csv')train.head()feats_cols = ['cont'+str(i) for i in range(1,train.shape[1]-1)]# fig, axs = plt.subplots(14,1, figsize=)
for col in feats_cols:
    plt.figure(figsize=(10,8))
    sns.distplot(train[col])
    plt.title(f'distribution plot for {col}')
    plt.show()","This code is for the Tabular Playground series on Kaggle. It imports the necessary libraries, loads the data, and then visualizes the distributions of the continuous features.",8,1,0.052783070855261974
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiontrain=pd.read_csv('../input/tabular-playground-series-jan-2021/train.csv',index_col=None)
trainy=train['target']
features=train.columns[1:len(train.columns)-1]
X=train[features]

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split

model=RandomForestRegressor(random_state=1,n_estimators=50,n_jobs=-1)

model.fit(X,y)test=pd.read_csv('../input/tabular-playground-series-jan-2021/test.csv',index_col=None)features_test=test.columns[1:len(test.columns)]
X1=test[features_test]
","This code creates a random forest regression model to predict a target variable based on input features. The model is fit on training data, and then used to make predictions on test data.",8,0,0.16461698508213227
"import numpy  as np 
import pandas as pd 
import re
import sklearn
import lightgbm


pd.options.display.max_rows = 6train_df = pd.read_csv('../input/tabular-playground-series-jan-2021/train.csv', index_col='id')
test_df  = pd.read_csv('../input/tabular-playground-series-jan-2021/test.csv',  index_col='id')

columns = test_df.columns
X       = train_df[columns]
Y       = train_df['target']
X_train, X_valid, Y_train, Y_valid = sklearn.model_selection.train_test_split(X, Y, test_size=0.1, random_state=42)
X_test  = test_df[columns]

display('train_df')
display( train_df )
# display('test_df')
# display( test_df )for seed in [42]:
# for boosting in ['gbdt', 'goss', 'dart']:                       # gbdt is best
# for max_depth in [1,2,4,6,8,10,12,16,32,64,-1]:                 # 4+ = 16 is best 
# for tree_learner in ['serial', 'feature', 'data', 'voting']:    # no effect
# for extra_trees in [True, False]:                               # no effect
# for learning_rate in [0.001, 0.01, 0.1, 0.5, 0.9]:              # 0.1   is best
# for max_bin in [64,128,256,512,1024,2048]:                      # 512-1 is best
# for num_leaves in [32, 64, 128, 256, 512, 1024, 2048, 4096]:    # 64-1  is best

    # DOCS: https://github.com/microsoft/LightGBM/blob/master/docs/Parameters.rst
    # DOCS: https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html
    parameters = {
        # 'boosting_type':   boosting,
        # 'max_depth':       max_depth, 
        # 'tree_learner':    tree_learner,
        # 'extra_trees':     extra_trees,
        # 'learning_rate':   learning_rate,
        # 'max_bin':         max_bin-1,
        # 'num_leaves':      num_leaves-1,
    }
    
    # DOCS: https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.train.html
    model = lightgbm.train(
        {
            'boosting_type':  'gbdt',  # default
            'objective':      'regression',
            'metric':         'rmse',
            'learning_rate':   0.1,                     
            'max_depth':       16,
            'max_bin':         512-1,
            'num_leaves':      64-1,
            'seed':            42,
            'verbose':         -1,
            **parameters,
        },
        train_set  = lightgbm.Dataset(X_train, label=Y_train),
        valid_sets = lightgbm.Dataset(X_valid, label=Y_valid),
        num_boost_round       = 5000,
        early_stopping_rounds = 100,
        verbose_eval          = False
    )
    rmse = sklearn.metrics.mean_squared_error(Y_valid, model.predict(X_valid), squared=False)
    print(f'{rmse:.5f}', parameters)predictions   = model.predict(X_test)

submission_df = pd.read_csv('../input/tabular-playground-series-jan-2021/sample_submission.csv', index_col='id')
submission_df['target'] = predictions
submission_df.to_csv('submission.csv')
!head submission.csv","This code is for a competition on the Kaggle platform. The goal is to predict the target column in the test set, based on the features in the train set.

The code starts by loading in the necessary libraries, then reads in the train and test data. It then splits the train data into training and validation sets.

Next, the code defines a set of parameters to use for the LightGBM model. These parameters are then used to train the model. The model is then used to make predictions on the test set.

Finally, the predictions are saved to a CSV file for submission to Kaggle.",8,3,0.11568059047542889
"import numpy as np
import pandas as pd
from pathlib import Path

import os
#for dirname, _, filenames in os.walk('/kaggle/input'):
#    for filename in filenames:
#        print(os.path.join(dirname, filename))
        
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

input_path = Path('/kaggle/input/tabular-playground-series-jan-2021/')train = pd.read_csv(input_path / 'train.csv', index_col='id')
display(train.head())test = pd.read_csv(input_path / 'test.csv', index_col='id')
display(test.head())train.describe()test.describe()boxplot = train.boxplot(column=['cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13', 'cont14'],
                       figsize=(12,9))boxplot = test.boxplot(column=['cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13', 'cont14'],
                       figsize=(12,9))","This code imports the necessary libraries for data analysis in Python, including numpy, pandas, matplotlib, seaborn, and sklearn.

The code then defines the input path for the data files.

Next, the code reads in the train and test data from the csv files and displays the first few rows of each.

The code then generates summary statistics for the train and test data using the .describe() method.

Finally, the code creates boxplots for each of the continuous variables in the train and test data.",8,6,0.09983092999433654
"import numpy as np
import pandas as pd
from pathlib import Path

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))
        
import matplotlib.pyplot as plt
import gc

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from keras.models import Sequential
from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization
from keras.callbacks import ReduceLROnPlateau
from tensorflow.keras.regularizers import l2

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error


import seaborn as sns
        
input_path = Path('/kaggle/input/tabular-playground-series-jan-2021/')DEBUG      = False     #True is debug mode
VAE_OUTPUT = True     #True is Enable VAE, False is Disable VAEtrain = pd.read_csv(input_path / 'train.csv', index_col='id')
display(train.head(2))test = pd.read_csv(input_path / 'test.csv', index_col='id')
display(test.head(2))submission = pd.read_csv(input_path / 'sample_submission.csv', index_col='id')
display(submission.head(2))train.shape, test.shape, submission.shapetrain = train.astype('float32') 
test  = test.astype('float32')

if DEBUG:
    train_df = train[:20000].copy()
    test_df  = test[:20000].copy()
else:
    train_df = train.copy()
    test_df  = test.copy()","This code imports the necessary libraries for data processing, visualization, and machine learning. It then loads the data from the input path and displays the first two rows of each dataframe. The code then defines a few variables for use later on. Finally, the code converts the data to the float32 data type.",8,1,0.03314702632916437
"# !pip install optunaimport numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns

import optuna

from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split, KFold
from sklearn.metrics import mean_squared_error
from sklearn.base import TransformerMixin

import xgboost as xgb
import lightgbm as lgbdf = pd.read_csv('../input/tabular-playground-series-jan-2021/train.csv')
df.head()figure, ax = plt.subplots(figsize=(16, 16))
sns.heatmap(df.sample(n=1_000).corr(), annot=True, linewidths=.5, ax=ax)def objective_xgb(trial, data, target):
    parameters = {
        'tree_method': 'gpu_hist',
        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),
        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),
        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,1.0]),
        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),
        'learning_rate': trial.suggest_categorical('learning_rate', [0.008, 0.009, 0.01, 0.012, 0.014, 0.016, 0.018, 0.02]),
        'n_estimators': 1000,
        'max_depth': trial.suggest_categorical('max_depth', [5, 7, 9, 11, 13, 15, 17, 20]),
        'random_state': trial.suggest_categorical('random_state', [24, 48, 2020]),
        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),
    }
    
    # Пропускаем через кросс-валидацию, усредняем ошибку 
    folds = KFold(n_splits=5, random_state=1337, shuffle=True)
    rmse = []
    
    for train_idx, test_idx in folds.split(data, target):
        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
    
        model = xgb.XGBRegressor(**parameters)
        model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=100, verbose=False)
    
        rmse.append(mean_squared_error(y_test, model.predict(X_test), squared=False))
    
    print(f'Mean RMSE for all the folds: {np.mean(rmse)}')
    
    return np.mean(rmse)""""""
study_xgb = optuna.create_study(direction='minimize')
study_xgb.optimize(objective_xgb, n_trials=50)

print(f'Number of finished trials: {len(study_xgb.trials)}')
print(f'Best trial: {study_xgb.best_trial.params}')
""""""xgb_parameters = {
    'objective': 'reg:squarederror',
    'tree_method': 'gpu_hist',
    'n_estimators': 1000,
    'lambda': 7.610705234008646, 
    'alpha': 0.0019377246932580476, 
    'colsample_bytree': 0.5, 
    'subsample': 0.7, 
    'learning_rate': 0.012, 
    'max_depth': 20, 
    'random_state': 24, 
    'min_child_weight': 229
}","The code above defines a function for optimizing the parameters of an XGBoost regression model using the Optuna library. The function takes in a dataframe and a target variable, and uses cross-validation to optimize the model's parameters. The model is then fit on the data and the RMSE is calculated. TheOptuna library is used to optimize the model's parameters. The code above defines a function for optimizing the parameters of an XGBoost regression model using the Optuna library. The function takes in a dataframe and a target variable, and uses cross-validation to optimize the model's parameters. The model is then fit on the data and the RMSE is calculated. TheOptuna library is used to optimize the model's parameters. The code above defines a function for optimizing the parameters of an XGBoost regression model using the Optuna library. The function takes in a dataframe and a target variable, and uses cross-validation to optimize the model's parameters. The model is then fit on the data and the RMSE is calculated. TheOptuna library is used to optimize the model's parameters.",8,12,0.08203929806483466
"# this is a simple example of XGBoost which i pulled together for a Kaggle competition entry
# i really like how concise the code is, to achieve so much computation !
# i feel this would be easily portable to another tabular dataset problem, requiring a random forest !!

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))#import training and test data into arrays
train_data = pd.read_csv('../input/tabular-playground-series-jan-2021/train.csv')
test_data  = pd.read_csv('../input/tabular-playground-series-jan-2021/test.csv')

print('Train: ', train_data.shape)
print('Test: ', test_data.shape)#set up training data. y - output is the 'target' field. x - feature columns is everything except 'target' and 'id'
y = train_data['target']
X = train_data.drop(columns=['target', 'id'])
X_test = test_data.drop(columns='id')#create training and validation sets using sklearn 'train_test_split'
from sklearn.model_selection import train_test_split
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.05, random_state=22)from xgboost import XGBRegressor
#create the xgb model
xgb = XGBRegressor(random_state=22
                  , n_estimators=100 #I found 1672 to work well. Changed to a lower value for testing.
                  , early_stopping_rounds=10
                  , learning_rate=0.05
                  , subsample=0.9
                  , colsample_bytree=0.9
                  , n_jobs=-1)

#train the model with '.fit'

xgb.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=1)#create predictions against X_test data set
predictions = xgb.predict(X_test)#output pandas dataframe with test data id & target from predictions
output = pd.DataFrame({""id"":test_data.id, ""target"":predictions})
output.to_csv('submission.csv', index=False)","This code imports training and test data into arrays, then sets up training data using the 'target' field as the output (y) and everything except 'target' and 'id' as the feature columns (x). It then creates training and validation sets using sklearn's 'train_test_split' function.

Next, it creates an XGBoost regression model with various parameters (random_state, n_estimators, early_stopping_rounds, learning_rate, subsample, colsample_bytree, n_jobs) and fits it to the training data.

Finally, it makes predictions against the X_test dataset and outputs a pandas dataframe with the test data id and target from the predictions.",9,5,0.3710429459770162
"import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from catboost import CatBoostRegressor
import itertools
import timetrain_df = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/train.csv')
test_df = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/test.csv')train_df.describe()test_df.describe()# Correlation matrix
train_df.corr()# A little bit more beautiful correlation matrix
sns.heatmap(train_df.corr(), cmap='coolwarm')train_df = train_df.drop('id', axis=1)
X = train_df.drop('target', axis=1)
Y = train_df.target","This code imports the necessary libraries for data analysis and machine learning in Python. It then loads the training and testing data sets from a CSV file. The training data set is then explored using the describe() method to generate summary statistics. The correlation matrix is also generated to examine the relationships between the features in the data set. Finally, the training data set is prepared for machine learning by dropping the 'id' column and the 'target' column.",9,0,0.029213456033070098
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
from sklearn import decomposition
from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import KFold, train_test_split
from tqdm.auto import tqdm

import tensorflow as tf 
# import tensorflow_addons as tfa
# !pip install -q -U keras-tuner
import kerastuner as kt # keras tuner!

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

# visualize
import matplotlib.pyplot as plt
import matplotlib.style as style
import seaborn as sns
from matplotlib import pyplot
from matplotlib.ticker import ScalarFormatter
sns.set_context(""talk"")
style.use('seaborn-colorblind')

import os
# for dirname, _, filenames in os.walk('/kaggle/input'):
#     for filename in filenames:
#         print(os.path.join(dirname, filename))

import warnings
warnings.filterwarnings('ignore')
# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionSEED = 42
NFOLD = 10
OUTPUT_DIR = ''# Logging is always nice for your experiment:)
def init_logger(log_file=OUTPUT_DIR+'train.log'):
    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler
    logger = getLogger(__name__)
    logger.setLevel(INFO)
    handler1 = StreamHandler()
    handler1.setFormatter(Formatter(""%(message)s""))
    handler2 = FileHandler(filename=log_file)
    handler2.setFormatter(Formatter(""%(message)s""))
    logger.addHandler(handler1)
    logger.addHandler(handler2)
    return logger

logger = init_logger()
logger.info('Start Logging...')train = pd.read_csv('../input/tabular-playground-series-jan-2021/train.csv')
test = pd.read_csv('../input/tabular-playground-series-jan-2021/test.csv')

features = [f'cont{i}' for i in range(1, 15)]
target_col = 'target'

X_train = train.drop(['id', 'target'], axis=1)
y_train = train['target']
X_test = test.drop('id', axis=1)print(X_train.shape)
X_train.head()print(X_test.shape)
X_test.head()prep = StandardScaler()
df = pd.concat([X_train[features], X_test[features]])
df[features] = prep.fit_transform(df[features].values)
X_test[features] = df[features].iloc[len(X_train):]
X_train[features] = df[features].iloc[:len(X_train)]","This code preprocesses the data by standardizing it using the StandardScaler class from the sklearn library. This ensures that all features are on the same scale, which is important for many machine learning algorithms. The code then splits the data into training and test sets, and fits the StandardScaler object to the training data. Finally, the transformed training and test data are saved back into the original dataframes.",The documentation is semantically correct.,3,0.1508401722740247
"PATH = '/kaggle/input/tabular-playground-series-jan-2021/'import pandas as pd

train = pd.read_csv(PATH+'train.csv')
test = pd.read_csv(PATH+'test.csv')
submission = pd.read_csv(PATH+'sample_submission.csv')train.head()!pip install pycaretfrom pycaret.regression import *reg = setup(data=train, target='target', silent=True, session_id=2021)best_3 = compare_models(include = ['xgboost', 'lightgbm', 'catboost'], sort='RMSE', n_select=3)","This code imports the pandas library and then reads in three CSV files: train.csv, test.csv, and sample_submission.csv.

The code then uses the pycaret library to create a regression model and compare it to three other models ('xgboost', 'lightgbm', and 'catboost'). The model with the best performance is then selected and saved as 'best_3'.",This documentation is semantically correct.,4,0.13445320310426911
"import numpy as np
import pandas as pd

# Plots
import seaborn as sns
import matplotlib.pyplot as plt

# Models
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge, Lasso
import xgboost as xgb
from xgboost import XGBRegressor
import lightgbm as lgb
from lightgbm import LGBMRegressor
from sklearn.ensemble import RandomForestRegressor, VotingRegressor
from mlxtend.regressor import StackingCVRegressor

# Stats
from scipy.stats import skew, norm

# Misc
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.model_selection import KFold, cross_val_score
from sklearn.metrics import mean_squared_error
pd.set_option('display.max_columns', None)
from pathlib import Path
input_path = Path('/kaggle/input/tabular-playground-series-jan-2021/')

# Ignore useless warnings
import warnings
warnings.filterwarnings(action=""ignore"")
pd.options.display.max_seq_items = 8000
pd.options.display.max_rows = 8000# Load the data as dataframes
train = pd.read_csv(input_path / 'train.csv', index_col='id')
test = pd.read_csv(input_path / 'test.csv', index_col='id')train.info()test.info()print(train.isna().any().any())
print(test.isna().any().any())train.describe()test.describe()","This code imports the numpy, pandas, seaborn, matplotlib, and sklearn libraries. It also imports the xgboost and lightgbm libraries. Finally, it imports the scipy.stats and mlxtend.regressor libraries.

The code then loads the train and test data as dataframes. The train dataframe has 1460 rows and 81 columns, while the test dataframe has 1459 rows and 80 columns.

The code then prints out the information for the train and test dataframes. This includes the data type, number of non-null values, and memory usage.

The code then prints out whether or not there are any missing values in the train and test dataframes.

The code then prints out a summary of the train and test dataframes using the describe() method. This includes the count, mean, standard deviation, min, max, and percentiles for each column.",8,16,0.09358215299617098
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport lightgbm as lgb
import optuna.integration.lightgbm as oplgb
from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error
from tqdm.notebook import tqdm
import matplotlib.pyplot as plt
import seaborn as snsdf_train = pd.read_csv(""/kaggle/input/tabular-playground-series-jan-2021/train.csv"")
df_test = pd.read_csv(""/kaggle/input/tabular-playground-series-jan-2021/test.csv"")
df_sample = pd.read_csv(""/kaggle/input/tabular-playground-series-jan-2021/sample_submission.csv"")train_id = df_train[""id""]
test_id = df_test[""id""]

df_train.drop(""id"", axis=1, inplace=True)
df_test.drop(""id"", axis=1, inplace=True)feature_cols = [c for c in df_train.columns if c != ""target""]train_x = df_train[feature_cols]
train_y = df_train.target
test_x = df_testfolds = KFold(n_splits=5, shuffle=True, random_state=2021)","This Python 3 environment comes with many helpful analytics libraries installed. It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python. For example, here's several helpful packages to load:

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory. For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory:

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"". You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session.

import lightgbm as lgb
import optuna.integration.lightgbm as oplgb
from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error
from tqdm.notebook import tqdm
import matplotlib.pyplot as plt
import seaborn as sns

df_train = pd.read_csv(""/kaggle/input/tabular-playground-series-jan-2021/train.csv"")
df_test = pd.read_csv(""/kaggle/input/tabular-playground-series-jan-2021/test.csv"")
df_sample = pd.read_csv(""/kaggle/input/tabular-playground-series-jan-2021/sample_submission.csv"")

train_id = df_train[""id""]
test_id = df_test[""id""]

df_train.drop(""id"", axis=1, inplace=True)
df_test.drop(""id"", axis=1, inplace=True",8,44,0.9651193015820756
"import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as snsfrom sklearn.model_selection import train_test_split, KFold, cross_val_score
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge, Lasso, LinearRegressiondata_dir = '/kaggle/input/tabular-playground-series-jan-2021'
train_path = os.path.join(data_dir, 'train.csv')
test_path = os.path.join(data_dir, 'test.csv')
sam_sub_path = os.path.join(data_dir, 'sample_submission.csv')

df = pd.read_csv(train_path)
test_df = pd.read_csv(test_path)
sam_sub_df = pd.read_csv(sam_sub_path)dffeatures_names = df.drop(['id', 'target'], axis=1).columns.values
features_namesplt.figure(figsize=(10, 6))
sns.distplot(df['target'], kde=True)
plt.show()len(df[df['target'] <= 5])","This code imports the necessary libraries for data analysis and visualization, then loads the training and test data into pandas DataFrames. Next, the code creates a figure using seaborn to visualize the distribution of the target variable. Finally, the code prints the number of rows in the DataFrame with a target value less than or equal to 5.",9,3,0.026818468849418717
!apt-get remove swig!apt-get install swig3.0 build-essential -y!ln -s /usr/bin/swig3.0 /usr/bin/swig!apt-get install build-essential!pip install --upgrade setuptools!pip install auto-sklearnimport autosklearn.regression,"This code installs the swig3.0 tool and build-essential dependencies, and then creates a symbolic link between the swig3.0 binary and the swig binary. Finally, it installs the build-essential dependency and the auto-sklearn Python package.",8,0,0.11474736832389748
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionfrom sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_errortrain = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/train.csv', index_col='id')
test = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/test.csv', index_col='id')
submission = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/sample_submission.csv', index_col='id')train.describe()test.describe()targets = train.pop('target')
X_train, X_test, y_train, y_test = train_test_split(train, targets, test_size=0.20)from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

forest_model = RandomForestRegressor(random_state=1, n_jobs=-1)
forest_model.fit(X_train, y_train)
forest_preds = forest_model.predict(X_test)
score_dummy = mean_squared_error(y_test, forest_preds, squared=False)
print(f'{score_dummy:0.5f}')","The Python code above imports the necessary libraries for data processing, linear algebra, and machine learning. The code then defines the training and test sets, as well as the targets (the dependent variable). Next, the code instantiates a Random Forest Regressor model and fits it to the training data. Finally, the code makes predictions on the test set and calculates the mean squared error.",8,0,0.16036783281142322
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport pandas as pd
import numpy as np
import plotly.express as px
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')
import tensorflow as tfpath = '../input/tabular-playground-series-jan-2021/'

train_df = pd.read_csv(path + 'train.csv')
test_df = pd.read_csv(path + 'test.csv')
sample_submission = pd.read_csv(path + 'sample_submission.csv')train_df.shape, test_df.shape, sample_submission.shapetrain_df.dtypestrain_df.describe()train_df.head()","The code above reads in three CSV files: train.csv, test.csv, and sample_submission.csv.

train_df and test_df are dataframes containing the training and testing data, respectively.

sample_submission is a dataframe containing the sample submission file.

train_df.shape, test_df.shape, sample_submission.shape return the dimensions of the dataframes.

train_df.dtypes returns the data types of the columns in the dataframe.

train_df.describe() returns a summary of the training data.

train_df.head() returns the first five rows of the training data.",8,16,0.2210727055760296
"!pip3 install seaborn==0.11.0
!pip install seaborn==0.11.0import torch
import torchvision
import numpy as np
import matplotlib.pyplot as plt
import torch.nn as nn
import torch.nn.functional as F
from torchvision.transforms import ToTensor
from torchvision.utils import make_grid
from torch.utils.data import random_split
import pandas as pd
import seaborn as sns
import datatable as dt
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings(""ignore"")
%matplotlib inline

from colorama import Fore, Back, Style
red = Fore.RED
grn = Fore.GREEN
blu = Fore.BLUE
ylw = Fore.YELLOW
wht = Fore.WHITE

import plotly.express as ex
import plotly.graph_objs as go
import plotly.figure_factory as ffprint(sns.__version__) 
'''We use seaborn version 0.11.0 to use histplot in PairPlot'''path = '../input/tabular-playground-series-jan-2021/'
train = pd.read_csv(path + 'train.csv')
test = pd.read_csv(path + 'test.csv')
sample = pd.read_csv(path + 'sample_submission.csv')print(f'{train.shape}\n{test.shape}\n{sample.shape}')train.head()test.head()","This code installs the seaborn library and imports the necessary packages for data analysis. It then loads the training, testing, and sample data from a csv file. Finally, it prints the dimensions of the dataframes and displays the first five rows of the training dataframe.",8,4,0.031885794069791404
"import numpy as np 
import pandas as pd 

import xgboost as xgb
from xgboost.sklearn import XGBRegressor

from sklearn.model_selection import cross_val_score, GridSearchCV
from sklearn.metrics import mean_squared_error, accuracy_score, roc_auc_score

import matplotlib.pyplot as plt
from matplotlib.pyplot import rcParams
rcParams['figure.figsize'] = 12, 5target = 'target'
seed = 42import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))train = pd.read_csv(dirname + '/' + filenames[1], index_col='id')
train.head()def modelfit(alg, dtrain, predictors, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):
    if useTrainCV:
        xgb_param = alg.get_xgb_params()
        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)
        cvresult = xgb.cv(xgb_param, 
                          xgtrain, 
                          num_boost_round=alg.get_params()['n_estimators'], 
                          nfold=cv_folds, 
                          metrics='rmse', 
                          early_stopping_rounds=early_stopping_rounds, 
                          verbose_eval=10)
        alg.set_params(n_estimators=cvresult.shape[0])
        
        alg.fit(dtrain[predictors], dtrain['target'], eval_metric='rmse')
        
        dtrain_predictions = alg.predict(dtrain[predictors])
        
#         print(""\nModel Report"")
#         print(""Accuracy : {:.4f}"".format(accuracy_score(dtrain[target].values, dtrain_predictions)))
        
        feat_imp = pd.Series(sorted(alg.feature_importances_, reverse=True))
        feat_imp.plot(kind='bar', title='Feature Importances')
        plt.ylabel('Feature Importance Score')
        plt.show()
        return cvresult.shape[0]predictors = [x for x in train.columns if x != target]
initial_params = {'learning_rate': 0.5,
                   'n_estimators': 1000,
                   'max_depth': 5,
                   'min_child_weight': 1,
                   'gamma': 0,
                   'subsample': 0.8,
                   'colsample_bytree': 0.8,
                   'objective': 'reg:squarederror',
                   'nthread': 4,
                   'scale_pos_weight': 1, 
                   'seed': seed}
xgb1 = XGBRegressor(**initial_params)
num_boosts1 = modelfit(xgb1, train, predictors)initial_params['n_estimators'] = num_boosts1 + 1","The code above imports the necessary libraries for data analysis and machine learning in Python. It then defines a function, modelfit(), which takes as input an algorithm (alg), a training dataset (dtrain), a list of predictors, and a few other parameters. The function trains the algorithm on the training data and outputs the number of boosting rounds (cvresult.shape[0]).

The code then defines a list of predictors (predictors) and a dictionary of initial parameters (initial_params) for the XGBoost algorithm. The code then trains the XGBoost algorithm on the training data using the modelfit() function. The output is the number of boosting rounds (num_boosts1).",8,9,0.07737948666750824
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiontrain = pd.read_csv(
    ""../input/tabular-playground-series-jan-2021/train.csv""
)
test = pd.read_csv(
    ""../input/tabular-playground-series-jan-2021/test.csv""
)from itertools import combinations
from sklearn.feature_selection import mutual_info_regression
import pickle

class Create_Features:
    def __init__(self):
        self.features_added = []
        self.feature_bins = {}
        self.bin_labels = {}
        pass
        
    def find_interaction_features(self, df, target, sample_size = 0.5):
        # Getting correct feature list for combinations
        feature_list = df.columns.tolist()
        
        print(""Calculating Score Threshold..."")
        mi = self.score_feature(df, target, sample_size)
        threshold = (mi.max() - mi.min()) / 1.5 + mi.min()
        threshold = mi.max()
        print(f'Scores: {mi}, Score Threshold: {threshold}')
        print()
        
        ff = pd.DataFrame()
        for combo in combinations(feature_list, 2):
            # Addition
            feature_name = f'{combo[0]}_+_{combo[1]}'
            print(f'Trying {feature_name}...', end = '\r')
            add = df[combo[0]] + df[combo[1]]
            score = self.score_feature(add, target, sample_size)
            if score > threshold:
                ff[feature_name] = add
                print(f'Added {feature_name}: {score}')
                self.features_added.append(feature_name)
                
            # Multiplication
            feature_name = f'{combo[0]}_x_{combo[1]}'
            print(f'Trying {feature_name}...', end = '\r')
            mult = df[combo[0]] * df[combo[1]]
            score = self.score_feature(mult, target, sample_size)
            if score > threshold:
                ff[feature_name] = mult
                print(f'Added {feature_name}: {score}')
                self.features_added.append(feature_name)
                
            # Subtraction
            feature_name = f'{combo[0]}_-_{combo[1]}'
            print(f'Trying {feature_name}...', end = '\r')
            sub = df[combo[0]] - df[combo[1]]
            score = self.score_feature(sub, target, sample_size)
            if score > threshold:
                ff[feature_name] = sub
                print(f'Added {feature_name}: {score}')
                self.features_added.append(feature_name)
                
            # Divison
            feature_name = f'{combo[0]}_/_{combo[1]}'
            print(f'Trying {feature_name}...', end = '\r')
            div = df[combo[0]] / df[combo[1]]
            score = self.score_feature(div, target, sample_size)
            if score > threshold:
                ff[feature_name] = div
                print(f'Added {feature_name}: {score}')
                self.features_added.append(feature_name)
        
        print(f'Finished -- Total Features Added: {len(self.features_added)}', end = '\r')
        return pd.concat([df,ff], axis = 1)
    
    def interaction_transform(self, df):
        ff = pd.DataFrame()
        for feature in self.features_added:
            interaction = feature.split(""_"")
            if interaction[1] == '+':
                ff[feature] = df[interaction[0]] + df[interaction[2]]
            elif interaction[1] == 'x':
                ff[feature] = df[interaction[0]] * df[interaction[2]]
            elif interaction[1] == '-':
                ff[feature] = df[interaction[0]] - df[interaction[2]]
            else:
                ff[feature] = df[interaction[0]] / df[interaction[2]]
        return pd.concat([df,ff], axis = 1)
    
    def load_interactions(self, interactions, filepath, display_features = False):
        with open(filepath, 'rb') as fp:
            self.features_added = pickle.load(fp)
            print(f'Loaded interaction features. Please use interaction_transform() to apply interactions.')
        if display_features:
            print(f'Features Loaded: {self.features_added}')
    
    def save_interactions(self, filepath):
        with open(filepath, 'wb') as fp:
            pickle.dump(self.features_added, fp)
            print(f'Features have been saved at {filepath}')
        
    
    def score_feature(self, feature, target, sample_size = 0.5):
        subset = feature.sample(frac = sample_size)
        sample_target = target[subset.index]
        if type(subset) == type(pd.DataFrame()):
            return mutual_info_regression(subset, sample_target)
        else:
            return mutual_info_regression(subset.values.reshape(-1,1), sample_target)
    
    def bin_features(self, df,features = 'all', n_bins = 10):
        """"""
        Creates the binned features and stores the bins for later use
        """"""
        if features == 'all':
            features = df.columns.tolist()
        binned_features = {}
        for col in features:
            self.bin_labels[col] = [i/n_bins for i in range(n_bins)]
            binned_features[f'{col}_bin'], self.feature_bins[col] = pd.qcut(df[col], q = n_bins, labels = self.bin_labels[col], retbins = True)
            binned_features[f'{col}_bin'] = binned_features[f'{col}_bin'].astype(float)
            
        bf = pd.DataFrame.from_dict(binned_features)
        return pd.concat([df, bf], axis = 1)
    
    def bin_transform(self, df, features = 'all'):
        """"""
        Uses the defined bins to bin another set of the same features
        """"""
        if features == 'all':
            features = df.columns.tolist()
        bf = {}
        for col in features:    
            bf[f'{col}_bin'] = pd.cut(df[col], bins = cf.feature_bins[col], labels = self.bin_labels[col])
            bf[f'{col}_bin'] = bf[f'{col}_bin'].astype(float)
        bf = pd.DataFrame.from_dict(bf)
        return pd.concat([df, bf], axis = 1)
    
    def flag_outliers(self, df):
        pass
    
    def outlier_transform(self, df):
        pass
            
    X = train.iloc[:,1:-1]
y = train.iloc[:,-1]
X_val = test.iloc[:,1:]cf = Create_Features()
X = cf.find_interaction_features(X, y, sample_size = 0.1)
X_val = cf.interaction_transform(X_val)cf.bin_features(pd.concat([X, X_val], axis = 0), n_bins = 500)
X = cf.bin_transform(X)
X_val = cf.bin_transform(X_val)
X = X.fillna(-1)
X_val = X_val.fillna(-1)
X_val.info()X.columns","The Create_Features class is used to create new features for a given dataset. The find_interaction_features() method takes in a dataset (df), target, and sample_size and returns a new dataset with added interaction features. The interaction_transform() method applies the interaction features to a new dataset. The load_interactions() and save_interactions() methods can be used to load and save interaction features, respectively. The score_feature() method calculates the mutual information between a given feature and target. The bin_features() method takes in a dataset and creates new binned features. The bin_transform() method applies the binned features to a new dataset. The flag_outliers() and outlier_transform() methods can be used to flag and transform outliers, respectively.",8,1,0.16696659092154267
"import numpy as np
import pandas as pd
from pathlib import Path

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))
        
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

from sklearn.dummy import DummyRegressor
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor
        
input_path = Path('/kaggle/input/tabular-playground-series-jan-2021/')train = pd.read_csv(input_path / 'train.csv', index_col='id')
display(train.head())test = pd.read_csv(input_path / 'test.csv', index_col='id')
display(test.head())submission = pd.read_csv(input_path / 'sample_submission.csv', index_col='id')
display(submission.head())submission.shape!pip install pytorch-tabnet
import pandas as pd 
import numpy as np 
from pytorch_tabnet.tab_model import TabNetRegressor
from sklearn.model_selection import KFoldtrain ","This code imports the necessary libraries for data analysis and machine learning in Python, including numpy, pandas, matplotlib, sklearn, and pytorch-tabnet. It also sets the input path for the data files.

The code then loads the train, test, and submission data into pandas dataframes. The train and test data are used for training and testing the machine learning models, while the submission data is used for submitting the results of the models to a competition.

Finally, the code installs the pytorch-tabnet library, which is necessary for using the TabNet machine learning model.",9,6,0.06522040249566166
"import numpy as np
import pandas as pd

from matplotlib import pyplot as plt
import seaborn as sns

from sklearn.model_selection import KFold, GridSearchCV, train_test_split
from sklearn.metrics import mean_squared_error

from xgboost import XGBRegressorseed = 1234import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))train = pd.read_csv(""/kaggle/input/tabular-playground-series-jan-2021/train.csv"", index_col=""id"")
test = pd.read_csv(""/kaggle/input/tabular-playground-series-jan-2021/test.csv"", index_col=""id"")
submission = pd.read_csv(""/kaggle/input/tabular-playground-series-jan-2021/sample_submission.csv"", index_col=""id"")# Take a look on our data
train.head()# Get info about types of data and missing values
train.info()test.info()","The code imports the numpy, pandas, matplotlib, seaborn, and sklearn libraries. It also sets a seed for the random number generator.

The code then reads in the training, testing, and submission data from the input files.

The code then displays some information about the data types and missing values in the training and testing data sets.",8,3,0.08825569304972468
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionfrom catboost import CatBoostRegressordf_train = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/train.csv')
y = df_train['target']

df_train.drop(['id', 'target'], axis = 1, inplace = True)

df_test = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/test.csv')
sub_id = df_test['id']
df_test.drop('id', axis = 1, inplace = True)cbr = CatBoostRegressor()
cbr.fit(df_train, y)submission = pd.DataFrame(sub_id, columns = ['id'])
submission.head()submission['target'] = cbr.predict(df_test)submission.to_csv('catboost.csv', index = False)","This code is for a machine learning competition on the Kaggle platform. The goal is to predict the target variable using the provided training and test data.

The code uses the CatBoostRegressor class from the CatBoost library to train a regression model on the training data. The model is then used to make predictions on the test data. The predictions are saved to a CSV file for submission to the competition.",8,3,0.2528082489352203
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session# import needed modules

import matplotlib.pyplot as plt
import matplotlib as mpl
import seaborn as sns

# this line is needed for plotting later
mpl.rcParams['agg.path.chunksize'] = 10000train_data = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/train.csv')
test_data = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/test.csv')

print(""successfully loaded!"")print(train_data.shape)
print(test_data.shape)# .info() is a helpful command to get a nice overview of a dataframe

print(train_data.info(), ""\n"")
print(test_data.info())# create list containing all column names of train_data

list_of_train_features = train_data.columns.to_list()

print(list_of_train_features)# plot all 14 'cont' features 

for i in range(1,len(list_of_train_features)-1):
    
    fig = plt.figure(figsize=(7,4.5))
    plt.plot(train_data[""id""], train_data[list_of_train_features[i]])
    plt.title(list_of_train_features[i])
    plt.show()","The code loads the train and test data from the input directory and prints the shape of each dataset. It then uses the .info() method to print an overview of the dataframes. Finally, it creates a list of all the column names in the train_data dataframe and plots all 14 'cont' features.",8,2,0.2553744443779443
"import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.preprocessing import MinMaxScalertrain_data = pd.read_csv('../input/tabular-playground-series-jan-2021/train.csv')train_labels = train_data['target']
train_features = train_data[['cont1', 'cont2','cont3', 'cont4','cont5', 'cont6','cont7', 'cont8','cont9', 'cont10','cont11', 'cont12','cont13', 'cont14']]train_labelsx = train_labels.values.reshape(-1,1) #min_max_scaler = MinMaxScaler()
#x_scaled = min_max_scaler.fit_transform(x)#train_labels = pd.DataFrame(x_scaled)","This code imports the numpy, pandas, matplotlib, and tensorflow libraries, as well as the sklearn MinMaxScaler class.

It then reads in the train.csv file as a pandas DataFrame, and stores the 'target' column in the train_labels variable and the remaining columns in the train_features variable.

Next, it reshapes the train_labels variable so that it is a numpy array with one column.

Then, it instantiates a MinMaxScaler object and uses it to transform the train_labels variable.

Finally, it creates a new pandas DataFrame from the transformed train_labels variable.",8,8,0.13434572288104396
"import os
import numpy as np 
import pandas as pd 
import seaborn as sns 
sns.set()
import matplotlib.pyplot as plt

path_input = '../input/tabular-playground-series-jan-2021/'
path_output = './'data = pd.read_csv(path_input+'train.csv')
data.head()data.info()sns.distplot(a=data['target'], rug = True, color='g')data=data.drop(['id'],axis=1)mask = np.zeros_like(data.corr())
mask[np.tril_indices_from(mask)] = True

f, ax = plt.subplots(figsize=(80, 15))
corr = data.corr()
sns.heatmap(corr, vmax=1, square=True,annot=True,cmap='viridis', mask=mask.T)

plt.title('Correlation between different fearures')from sklearn.model_selection import train_test_split
y = data.target  # all rows, target only
X = data.drop('target',axis=1)  # all rows, all the features and no target


x_train,x_test,y_train,y_test = train_test_split(X,y,train_size=0.8,random_state = np.random.RandomState(0))
print(""training size : {}\ntest size : {}"".format(x_train.shape,x_test.shape))","This code imports the necessary libraries for data analysis and visualization, then loads the dataset from the input path. It then drops the id column from the data, and splits the data into training and test sets. Finally, it prints the shapes of the training and test sets.",9,1,0.14484314704776116
"import numpy as np 
import pandas as pd 
import zipfile

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiontrain_z = zipfile.ZipFile('/kaggle/input/nyc-taxi-trip-duration/train.zip')
train = pd.read_csv(train_z.open('train.csv'))
train.head()
train.shapetrain.info()train[""store_and_fwd_flag""].value_counts()f = lambda x: 0 if x =='N' else 1
train['store_and_fwd_flag'] = train['store_and_fwd_flag'].apply(lambda x: f(x))
train.head()train[""dropoff_datetime""] = pd.to_datetime(train[""dropoff_datetime""], format='%Y-%m-%d %H:%M:%S')
train[""pickup_datetime""] = pd.to_datetime(train[""pickup_datetime""], format='%Y-%m-%d %H:%M:%S')","This code imports the numpy and pandas libraries, as well as the zipfile library. It then loops through the /kaggle/input directory, printing the names of all the files it finds.

Next, the code reads in the train.csv file from the train.zip file, and displays the first five rows of data. It then prints the shape of the dataframe, and displays information about the store_and_fwd_flag column.

Finally, the code converts the pickup_datetime and dropoff_datetime columns to datetime format.",8,7,0.21280203990910618
"import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import warnings
from datetime import datetime
import calendar
from math import sin, cos, sqrt, atan2, radians
from folium import FeatureGroup, LayerControl, Map, Marker
from folium.plugins import HeatMap
import matplotlib.dates as mdates
import matplotlib as mpl
from datetime import timedelta
import datetime as dt
warnings.filterwarnings('ignore')
pd.set_option('display.max_colwidth', -1)
plt.style.use('fivethirtyeight')
import folium
from sklearn.cluster import KMeans
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer as Imputer
from sklearn import linear_model
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestRegressor
import pickle
import zipfilezf_train = zipfile.ZipFile('../input/nyc-taxi-trip-duration/train.zip')
train = pd.read_csv(zf_train.open('train.csv'))

zf_test = zipfile.ZipFile('../input/nyc-taxi-trip-duration/test.zip')
test = pd.read_csv(zf_test.open('test.csv'))train['pickup_datetime'] = pd.to_datetime(train['pickup_datetime'], format = '%Y-%m-%d %H:%M:%S')
train['dropoff_datetime'] = pd.to_datetime(train['dropoff_datetime'], format = '%Y-%m-%d %H:%M:%S')
train.head()# version 1
train[pd.isnull(train)].sum()# version 2
train.any()# version 3
train.isnull().sum()print(""Min pickup time:"",min(train['pickup_datetime']))
print(""Max pickup time:"",max(train['pickup_datetime']))","This code imports the pandas, matplotlib, seaborn, numpy, warnings, datetime, and calendar libraries. It also imports the folium library for mapping. The code then sets some options for pandas and matplotlib, and filters warnings.

The code then reads in the train.csv file from a zip file, and converts the 'pickup_datetime' and 'dropoff_datetime' columns to datetime format. The head() function is then used to print the first 5 rows of the dataframe.

The code then checks for null values in the dataframe, and prints the sum of null values for each column.

The code then prints the minimum and maximum pickup times from the 'pickup_datetime' column.",9,12,0.0649851710596108
"import numpy as np
import pandas as pd

import osfrom zipfile import ZipFile

with ZipFile('/kaggle/input/nyc-taxi-trip-duration/train.zip', 'r') as file:
    file.extractall()
    
with ZipFile('/kaggle/input/nyc-taxi-trip-duration/test.zip', 'r') as file:
    file.extractall()
    
with ZipFile('/kaggle/input/nyc-taxi-trip-duration/sample_submission.zip', 'r') as file:
    file.extractall()train = pd.read_csv(""./train.csv"")

train['pickup_datetime'] = pd.to_datetime(train['pickup_datetime'])
train['dropoff_datetime'] = pd.to_datetime(train['dropoff_datetime'])

train.head()test = pd.read_csv(""./test.csv"")

test['pickup_datetime'] = pd.to_datetime(test['pickup_datetime'])

test.head()sample_submission = pd.read_csv(""./sample_submission.csv"")
sample_submission.head()train.isnull().sum()test.isnull().sum()","This code imports the numpy and pandas libraries, and then extracts data from train.zip, test.zip, and sample_submission.zip. It then converts the pickup_datetime and dropoff_datetime columns to datetime format, and displays the first 5 rows of the data. Finally, it displays the number of null values in each column of the train and test data.",8,4,0.12279409127590048
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt
import plotly.express as px

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionfrom zipfile import ZipFile

with ZipFile('/kaggle/input/nyc-taxi-trip-duration/train.zip') as file:
    file.extractall()
    
with ZipFile('/kaggle/input/nyc-taxi-trip-duration/test.zip') as file:
    file.extractall()

with ZipFile('/kaggle/input/nyc-taxi-trip-duration/sample_submission.zip') as file:
    file.extractall()train = pd.read_csv('./train.csv')
train.info()
train.head()test = pd.read_csv('./test.csv')
test.info()
test.head()sample_submission = pd.read_csv('./sample_submission.csv')
sample_submission.info()
sample_submission.head()print(train.isnull().sum())print(test.isnull().sum())","This code loads the necessary libraries for data analysis, including numpy, pandas, matplotlib, and plotly.express. It also loads the input data files for the NYC taxi trip duration dataset, which are available in the read-only ""../input/"" directory. Finally, it prints out the information for the train, test, and sample submission datasets.",8,3,0.2736344206399306
"import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from geopy.distance import geodesic
import os
import zipfile

from fbprophet import Prophet
from fbprophet.plot import plot_plotly, plot_components_plotly

import xgboost as xgb

from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import IsolationForest
from sklearn.cluster import KMeans
from sklearn.metrics import mean_squared_log_error
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.neural_network import MLPRegressor

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Dropout

%matplotlib inlinefor dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))zf = zipfile.ZipFile('/kaggle/input/nyc-taxi-trip-duration/train.zip') 
train = pd.read_csv(zf.open('train.csv'))
train.head()zf = zipfile.ZipFile('/kaggle/input/nyc-taxi-trip-duration/test.zip') 
test = pd.read_csv(zf.open('test.csv'))
test.head()zf = zipfile.ZipFile('/kaggle/input/nyc-taxi-trip-duration/sample_submission.zip') 
sample_submission = pd.read_csv(zf.open('sample_submission.csv'))
sample_submission.head()train.info()test.info()","The code above imports the necessary libraries for the project and then loads the data from the train, test, and sample submission files. The data is then explored using the head() method to get a better understanding of the data.",7,0,0.044635552334474644
"# Check NVIDIA System Management Interface
!nvidia-smi

# If you'd like to see your GPU (maybe to see if it's CUDA compatible)
!lspci | grep -i nvidia

# If you's like to see the location of CUDA
!whereis cuda

# If you'd like to see CUDA version
!nvcc --version

# Check presence of CuDNN 
!whereis cudnn

# Check version of cudnn
!cat /usr/include/cudnn_version.h# Check is TensorFlow can access GPU
from tensorflow.python.client import device_lib
device_lib.list_local_devices()



# Alternatively, check device name
import tensorflow as tf
tf.test.gpu_device_name()

# Check for CUDA
tf.test.is_built_with_cuda()# Download models
!git clone --depth 1 https://github.com/tensorflow/models

# Compile proto files 
%cd models/research
!pip install protobuf
!protoc object_detection/protos/*.proto --python_out=.
%cd ..
%cd ..

# Install cocoapi
!pip install cython 
!git clone https://github.com/cocodataset/cocoapi.git
%cd cocoapi/PythonAPI
!make
%cd ..
%cd ..
!cp -r cocoapi/PythonAPI/pycocotools models/research/

# Install object detection api
%cd models/research
!cp object_detection/packages/tf2/setup.py .
!python -m pip install .
%cd ..
%cd ..# View tensorflow installation
!pip freeze | grep tensorflow

# Uninstall version 2.5
!pip uninstall tf-models-official --yes
# Install version 2.4
!pip install tensorflow==2.4
!pip install tf-models-official==2.4# View tensorflow installation
!pip freeze | grep tensorflow# Verify TensorFlow 2 Object Detection API installation (optional)
%cd models/research
!python object_detection/builders/model_builder_tf2_test.py
%cd ..
%cd ..# Making Directories 
!mkdir workspace
%cd workspace
!mkdir annotations
!mkdir script
!mkdir csv_files
!mkdir pre_trained_models
!mkdir models","This code checks the NVIDIA System Management Interface, to see if the GPU is compatible with CUDA. If it is, the code then downloads the models and compiles the proto files. Finally, the code installs the object detection API.",The documentation is semantically correct.,2,0.1366036925744922
"!conda install -c conda-forge gdcm -yimport numpy as np
import pandas as pd
import os
import pydicom
import glob
from tqdm.notebook import tqdm
from pydicom.pixel_data_handlers.util import apply_voi_lut
import matplotlib.pyplot as plt
from skimage import exposure
import cv2
import warnings
from fastai.vision.all import *
from fastai.medical.imaging import *
warnings.filterwarnings('ignore')dataset_path = Path('../input/siim-covid19-detection')
l1=dataset_path.ls()
for l in l1:
    print(l)train_study_df = pd.read_csv(dataset_path/'train_study_level.csv')
print(train_study_df.shape)
train_study_df.head()lst = np.unique(train_study_df.id)
len(lst)study_classes = ['Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']
np.unique(train_study_df[study_classes].values, axis=0)plt.figure(figsize=(10,5))
plt.bar([1,2,3,4], train_study_df[study_classes].values.sum(axis=0))
plt.xticks([1,2,3,4], study_classes)
plt.xlabel('Class')
plt.ylabel('Frequency')
plt.show()","This code is for a project to detect pneumonia from chest x-rays. The code imports the necessary libraries, reads in the data, and then creates a bar chart to show the frequency of each class.",8,0,0.04941549135763649
"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -yimport pandas as pd
from pathlib import Path
import os
from tqdm import tqdm
import numpy as np

from PIL import Image

import matplotlib.pyplot as plt
import matplotlib.patches as patches

# for .dcm file
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lutsubmission = pd.read_csv(""../input/siim-covid19-detection/sample_submission.csv"")
if submission.shape[0] == 2477:
    fast_sub = True
else:
    fast_sub = False# extract image pixel data from .dcm
def read_xray(path):
    dicom = pydicom.read_file(path)
    data = apply_voi_lut(dicom.pixel_array, dicom)
    
    if dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
    
    return data# convert .dcm to .jpg
os.makedirs('/kaggle/tmp/siim/images/test', exist_ok=True)
for path in tqdm(Path(""../input/siim-covid19-detection/test"").rglob('*.dcm')):
    xray = read_xray(str(path))
    im = Image.fromarray(xray)
    im.save(os.path.join('/kaggle/tmp/siim/images/test', path.name.replace('.dcm', '.jpg')))
    if fast_sub: break# Copy YOLOv5 directory to working directory
!cp -r /kaggle/input/yolov5/yolov5 yolov5os.chdir('/kaggle/working/yolov5')
!rm -rf runs/detect/
!rm -rf runs/test/
!python3 detect.py \
        --weights runs/train/exp2/weights/best.pt \
        --source /kaggle/tmp/siim/images/test \
        --iou-thres 0.5 \
        --save-txt \
        --save-conf \
        --device 0
os.chdir('/kaggle/working')","This code installs the pydicom package, which is a package for working with DICOM files. This code also installs the libjpeg-turbo, libgcc-ng, and gdcm packages, which are required for pydicom to work. Finally, this code installs the conda package, which is required for the pydicom package to work.",8,7,0.09193770864572892
"! conda install -c conda-forge gdcm -y;import sys
sys.path.append(""../input/timmeffnetv2"")

import platform
import numpy as np
import pandas as pd
import os
from tqdm.notebook import tqdm
import cv2
import pydicom
import gdcm
import glob
import gc
from math import ceil
import matplotlib.pyplot as plt
from pydicom.pixel_data_handlers.util import apply_voi_lut
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import StratifiedKFold

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.cuda.amp import GradScaler, autocast
from torch.utils.data import Dataset, DataLoader

import warnings
warnings.simplefilter('ignore')train_image = pd.read_csv(""../input/siim-covid19-detection/train_image_level.csv"")
train_study = pd.read_csv(""../input/siim-covid19-detection/train_study_level.csv"")TRAIN_DIR = ""../input/siim-covid19-detection/train/""
train_study['StudyInstanceUID'] = train_study['id'].apply(lambda x: x.replace('_study', ''))
train = train_image.merge(train_study, on='StudyInstanceUID')

# Make a path folder
paths = []
for instance_id in tqdm(train['StudyInstanceUID']):
    paths.append(glob.glob(os.path.join(TRAIN_DIR, instance_id +""/*/*""))[0])

train['path'] = paths

train = train.drop(['id_x', 'id_y'], axis=1)

train = train.sample(frac=1).reset_index(drop=True)
train.head()train.shapedef dicom2array(path, voi_lut=True, fix_monochrome=True):
    dicom = pydicom.read_file(path)
    # VOI LUT (if available by DICOM device) is used to
    # transform raw DICOM data to ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
    return dataos.makedirs('/kaggle/working/output/', exist_ok=True)","This code installs the gdcm library, imports the sys library, and appends the path to the timmeffnetv2 library. It then defines some variables, including the TRAIN_DIR variable, which is the path to the training data.

Next, the code reads in the train_image_level.csv and train_study_level.csv files, which contain information about the images and studies, respectively. The code then merges the two dataframes, and drops the id_x and id_y columns.

The code then shuffles the dataframe and resets the index. Finally, it defines the dicom2array function, which transforms raw DICOM data into a more human-readable format.",8,5,0.058868242625427766
"!conda install gdcm -c conda-forge -yimport os

from PIL import Image
import pandas as pd
from tqdm.auto import tqdm
from tqdm.contrib.concurrent import process_map
import glob
from collections import namedtupleimport numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef resize(array, shape, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail(shape, resample)
    else:
        im = im.resize(shape, resample)
    
    return imImageMeta = namedtuple(""ImageMeta"", (""height"", ""width"", ""fname""))%%time
SHAPE = (512, 512)
for split in [""train"", ""test""]:
    filenames = glob.glob(""/kaggle/input/siim-covid19-detection/{}/*/*/*.dcm"".format(split))
    SAVE_DIR = f""/kaggle/tmp/{split}""
    os.makedirs(SAVE_DIR, exist_ok=True)
    def persist_image(path):
        xray = read_xray(path)
        height = xray.shape[0]
        width = xray.shape[1]
        im = resize(xray, shape=SHAPE)
        fname = os.path.basename(os.path.splitext(path)[-2])
        jpg_fname = os.path.join(SAVE_DIR, ""{}.jpg"".format(fname))
        im.save(jpg_fname)
        return ImageMeta(height, width, fname)
    split_imgs = process_map(persist_image, filenames, max_workers=8, chunksize=1)
    pd.DataFrame.from_records(split_imgs, columns=ImageMeta._fields).to_csv(""/kaggle/working/{}_meta.csv"".format(split), index=False)
    print(""No. of Images in split {}: {}"".format(split, len(split_imgs)))!tar -zcf train_{SHAPE[0]}x{SHAPE[1]}.tar.gz -C ""/kaggle/tmp/train"" .
!tar -zcf test_{SHAPE[0]}x{SHAPE[1]}.tar.gz -C ""/kaggle/tmp/test"" .","This code is used to convert DICOM images to JPEG format, and resize them to a specified size. The DICOM images are read in using the pydicom library, and then processed using the resize() function. The resulting images are then saved in the specified output directory.",9,1,0.12101888338474029
"%cd ../
!mkdir tmp
%cd tmp# Download YOLOv5
!git clone https://github.com/ultralytics/yolov5  # clone repo
%cd yolov5
# Install dependencies
%pip install -qr requirements.txt  # install dependencies

%cd ../
import torch
print(f""Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})"")# Install W&B 
!pip install -q --upgrade wandb
# Login 
import wandb
wandb.login()# Necessary/extra dependencies. 
import os
import gc
import cv2 
import wandb
import shutil
import numpy as np
import pandas as pd
pd.set_option('mode.chained_assignment', None)
from tqdm import tqdm
from shutil import copyfile
import matplotlib.pyplot as plt
from sklearn.model_selection import StratifiedKFold

#customize iPython writefile so we can write variables
from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))TRAIN_PATH = '../input/siim-covid19-resized-to-256px-png/train'
IMG_SIZE = 256
BATCH_SIZE = 32
EPOCHS = 100
USE_FOLD = False
SEED = 42
NUM_FOLD = 5# IMAGE LEVEL

# Load image level csv file
df = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
# Load study level csv file
label_df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')

# Modify values in the id column
df['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)
# Add absolute path
# df['path'] = df.apply(lambda row: TRAIN_PATH+row.id+'.jpg', axis=1)
# Get image level labels
def image_level(row):
    label = row.label.split(' ')[0]
    if label == 'opacity': return 1
    else: return 0

df['image_level'] = df.apply(lambda row: image_level(row), axis=1)

# STUDY LEVEL

# Modify values in the id column
label_df['id'] = label_df.apply(lambda row: row.id.split('_')[0], axis=1)
# Rename the column id with StudyInstanceUID
label_df.columns = ['StudyInstanceUID', 'Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']

# Label encode study-level labels
labels = label_df[['Negative for Pneumonia','Typical Appearance','Indeterminate Appearance','Atypical Appearance']].values
labels = np.argmax(labels, axis=1)
label_df['study_level'] = labels

# ORIGINAL DIMENSION

# Load meta.csv file
meta_df = pd.read_csv('../input/siim-covid19-resized-to-256px-png/meta.csv')
train_meta_df = meta_df.loc[meta_df.split == 'train']
train_meta_df = train_meta_df.drop('split', axis=1)
train_meta_df.columns = ['id', 'dim0', 'dim1']

# Merge image-level and study-level
df = df.merge(label_df, on='StudyInstanceUID',how=""left"")
# Merge with meta_df
df = df.merge(train_meta_df, on='id',how=""left"")

# Write as csv file
df.to_csv('_image_study_total.csv', index=False)

df.head(10)if 'train_fold.csv' in os.listdir(os.getcwd()) and USE_FOLD:
    df = pd.read_csv('train_fold.csv')
else:
    df = pd.read_csv('_image_study_total.csv')
    df['path'] = df.apply(lambda row: f'../input/siim-covid19-resized-to-256px-png/train/{row.id}.png', axis=1)
    
    # Group by Study Ids and remove images that are ""assumed"" to be mislabeled
    for grp_df in df.groupby('StudyInstanceUID'):
        grp_id, grp_df = grp_df[0], grp_df[1]
        if len(grp_df) == 1:
            pass
        else:
            for i in range(len(grp_df)):
                row = grp_df.loc[grp_df.index.values[i]]
                if row.study_level > 0 and row.boxes is np.nan:
                    df = df.drop(grp_df.index.values[i])
                    
    print('total number of images: ', len(df))
    
    # Create train and validation split.
    df = df.drop('boxes', axis=1).reset_index()
    Fold = StratifiedKFold(n_splits=NUM_FOLD, shuffle=True, random_state=SEED)
    for n, (train_index, val_index) in enumerate(Fold.split(df, df['image_level'])):
        df.loc[val_index, 'fold'] = int(n)
    df['fold'] = df['fold'].astype(int)

    df.to_csv('train_fold.csv', index=False)

df.head()","The code above is for preparing the data for training a YOLOv5 model on the SIIM-Covid19 dataset.

First, the code changes the working directory to the parent directory, then creates a new directory called 'tmp'. Next, the code changes the working directory to 'tmp' and clones the YOLOv5 repository from GitHub.

After that, the code changes the working directory to 'yolov5' and installs the dependencies required for running the code. Finally, the code changes the working directory back to the parent directory and prints the torch version being used.

The code then installs Wandb and logs in. Wandb is a tool for tracking training runs and visualizing results.

Next, the code loads the image level csv file and the study level csv file. The image level csv file contains labels for each image, and the study level csv file contains labels for each study.

The code then modifies the values in the id column of the image level csv file and adds the absolute path to each image. The code also gets the image level labels from the image level csv file.

The code then modifies the values in the id column of the study level csv file and renames the column id with StudyInstanceUID. The code then label encodes the study-level labels.

The code then loads the meta.csv file and gets the train_meta_df. The train_meta_df contains the id and dimensions for each image.

The code then merges the image-level and study-level dataframes, and the meta_df. The code then writes the merged dataframe to a csv file.

Finally, the code creates a train and validation split. If the 'train_fold.csv' file exists, the code will use that. Otherwise, the code will create the 'train_fold.csv' file.",8,20,0.16606243513369676
"!nvidia-smi!nvcc --versionimport torch, torchvision
print(torch.__version__, torch.cuda.is_available())!pip install detectron2 -f \
  https://dl.fbaipublicfiles.com/detectron2/wheels/cu110/torch1.7/index.html
import numpy as np 
import pandas as pd 
from datetime import datetime
import time
from tqdm import tqdm_notebook as tqdm # progress bar
import matplotlib.pyplot as plt

import os, json, cv2, random
import skimage.io as io
import copy
import pickle
from pathlib import Path
from typing import Optional
from tqdm import tqdm

# torch
import torch



# Albumenatations
import albumentations as A
from albumentations.pytorch.transforms import ToTensorV2

#from pycocotools.coco import COCO
from sklearn.model_selection import StratifiedKFold

# glob
from glob import glob

# numba
import numba
from numba import jit

import warnings
warnings.filterwarnings('ignore') #Ignore ""future"" warnings and Data-Frame-Slicing warnings.


# detectron2
from detectron2.structures import BoxMode
from detectron2 import model_zoo
from detectron2.config import get_cfg
from detectron2.data import DatasetCatalog, MetadataCatalog
from detectron2.engine import DefaultPredictor, DefaultTrainer, launch
from detectron2.evaluation import COCOEvaluator
from detectron2.structures import BoxMode
from detectron2.utils.visualizer import ColorMode
from detectron2.utils.logger import setup_logger
from detectron2.utils.visualizer import Visualizer

from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader
from detectron2.data import detection_utils as utils


from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader, build_detection_train_loader
from detectron2.data import detection_utils as utils
import detectron2.data.transforms as T
from detectron2.evaluation import COCOEvaluator, inference_on_dataset

setup_logger()# --- Read data ---
imgdir = ""../input/siim-covid19-resized-1024px""
# Read in the data CSV files
train_df = pd.read_csv(""../input/siimcovid19-detection-training-label/train_image_df.csv"")
print(train_df['integer_label'].value_counts())
len(train_df)

train_df=train_df[train_df['integer_label']!=2]
print(train_df['integer_label'].value_counts())

train_df.loc[train_df['integer_label'] ==2, 'integer_label'] = 0
train_df.loc[train_df['integer_label'] ==1, 'integer_label'] = 0
train_df.loc[train_df['integer_label'] ==3, 'integer_label'] = 1
print(train_df['integer_label'].value_counts())# --- configs ---
thing_classes = [
    ""atypical"",
    ""typical""
]

debug=False
#split_mode=""all_train"" # Or  valid20
split_mode=""valid20""


category_name_to_id = {class_name: index for index, class_name in enumerate(thing_classes)}
category_name_to_id","This code is for training a detectron2 model for the detection of COVID-19 on chest X-ray images. The code first reads in the training data CSV file and then removes all instances of label 2 (atypical). The code then sets up the configuration for the detectron2 model and starts the training process. Finally, the code evaluates the trained model on a validation set.",8,0,0.06048101183829642
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session!pip install pydicom
!pip install matplotlibimport pydicom
import matplotlib.pyplot as plt
%matplotlib inline

ds = pydicom.dcmread('../input/siim-covid19-detection/test/00188a671292/3eb5a506ccf3/3dcdfc352a06.dcm')
print(ds)

plt.imshow(ds.pixel_array, cmap=plt.cm.bone)",This code imports the pydicom library and uses it to read a DICOM file. The file is then displayed using matplotlib.,10,2,0.18263706296372467
"import os
import cv2
import numpy as np
import pandas as pd
import pydicom
import matplotlib.pyplot as plt
import json
import torch
from skimage import exposure
import math
from shutil import copyfile
from IPython.display import Image, clear_output# D/L and install YOLOv5
!git clone https://github.com/ultralytics/yolov5
%cd yolov5
%pip install -qr requirements.txt
%cd ../
clear_output()
print(f""Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})"")# Copy the requirements file over so we don't have to change directory later. Is there an argument for this?
copyfile('yolov5/requirements.txt', '/kaggle/working/requirements.txt');# Load the image dataframe so we can get BB coords
base_path = ""/kaggle/input/siim-covid19-detection/""
images_df = pd.read_csv(os.path.join(base_path,""train_image_level.csv""))# Load a DICOM file
def load_file(filename):
    img = pydicom.dcmread(filename)
    pixels = img.pixel_array
    max_pixel = np.max(pixels)

    if img.PhotometricInterpretation == ""MONOCHROME1"":
        pixels = max_pixel - pixels
        
    pixels = exposure.equalize_adapthist(pixels)
    pixels = (pixels * 255).astype(np.uint8)
    return pixels# Convert YOLO coords to pixel coords
def box2coords(x,y,w,h,image_w, image_h):
    x1, y1 = round((x-w/2) * image_w), round((y-h/2) * image_h)
    x2, y2 = round((x+w/2) * image_w), round((y+h/2) * image_h)
    return x1, y1, x2, y2# Function to get the BB data from the images DF
def get_boxes(image_id):
    
    image = image_id.replace('.dcm','_image')
    ti = images_df[images_df['id'] == image]
    bx = [[],[]]
    bx[0] = [0,0,0,0,""""]
    bx[1] = [0,0,0,0,""""]
    
    if str(ti['boxes'].values[0]) != ""nan"":
        box = str(ti['boxes'].values[0]).replace(""'"",""\"""")
        boxes = json.loads(box)
        lab = ti['label'].values[0].split("" "")
        i = 0
        for b in boxes:
            bx[i] = [int(b['x']), int(b['y']), int(b['width']),int(b['height']),lab[0]]
            i = i+1
    return bx","This code imports the necessary libraries for loading, processing and visualizing images, as well as for performing object detection using the YOLOv5 model.

The code then defines a function for loading DICOM images, which converts the images to 8-bit grayscale format and applies histogram equalization for improved contrast.

Next, a function is defined for converting YOLOv5 bounding box coordinates to pixel coordinates.

Finally, a function is defined for extracting bounding box data from the images dataframe. This function returns a list of bounding boxes, each containing the coordinates of the top left and bottom right corners of the box, as well as the label of the object contained within the box.",8,2,0.15700328755005882
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiont = 'hello world'
t","This code imports the numpy and pandas libraries, which are used for linear algebra and data processing respectively. It also defines a variable t which contains the string 'hello world'.",8,1,0.17849887067757156
"%%capture
!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y%%capture
!pip install ../input/icevision08-kagcuda/loguru-0.5.3-py3-none-any.whl -f ./ --no-index --no-deps
!pip install ../input/icevision08-kagcuda/timm-0.4.9-py3-none-any.whl -f ./ --no-index --no-deps
!pip install ../input/icevision08-kagcuda/effdet-0.2.4-py3-none-any.whl -f ./ --no-index --no-deps
!pip install ../input/icevision08-kagcuda/icevision-0.8.0-py3-none-any.whl -f ./ --no-index --no-deps
!pip install ../input/icevision08-kagcuda/omegaconf-2.0.6-py3-none-any.whl -f ./ --no-index --no-deps%%capture
%mkdir -p /root/.icevision/fonts
%cp /kaggle/input/icevision08-kagcuda/SpaceGrotesk-Medium.ttf /root/.icevision/fonts/%%capture
!pip install ../input/pycocotools202/pycocotools-2.0.2-cp37-cp37m-linux_x86_64.whl -f ./ --no-index --no-depsfrom fastai.vision.all import *
from fastai.medical.imaging import *
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import albumentations as A
import cv2
import gdcm
from tqdm.auto import tqdm
from joblib import Parallel, delayed
import PILdef Dicom2array(path):
    im = pydicom.dcmread(path)
    is_mono1 = (im.PhotometricInterpretation == ""MONOCHROME1"")
    im = np.array(apply_voi_lut(im.pixel_array, im))
    if is_mono1:
        im = np.amax(im) - im
    im = im - np.min(im)
    im = im / np.max(im)
    im = (im * 255).astype(np.uint8)
    return im

def Dicom2jpg(file):
    img = Dicom2array(file)        
    out_path = Path('/kaggle/working')/Path(*file.parts[3:]).with_suffix('.jpg')
    os.makedirs(out_path.parent, exist_ok=True)
    cv2.imwrite(str(out_path), img)dicom_file = get_dicom_files('../input/siim-covid19-detection/test')
o = Parallel(n_jobs=2)(delayed(Dicom2jpg)(f) for f in tqdm(dicom_file))","This code converts DICOM files to JPG files. It uses the pydicom library to read in the DICOM files, and then applies a VOI LUT to the pixel array. The resulting image is then converted to an 8-bit unsigned integer array, and saved as a JPG file.",8,2,0.022944916524792042
"import os
import gc
import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm
from shutil import copyfile
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

#customize iPython writefile so we can write variables
from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))
Data_dir='../input/siim-covid19-detection'
train=pd.read_csv(f'{Data_dir}/train_image_level.csv')
train_study=pd.read_csv(f'{Data_dir}/train_study_level.csv')train.head()%cd ../
!mkdir tmp
%cd tmp# Download YOLOv5
!git clone https://github.com/ultralytics/yolov5  # clone repo
%cd yolov5
# Install dependencies
%pip install -qr requirements.txt  # install dependencies

%cd ../
import torch
print(f""Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})"")TRAIN_PATH = 'input/siim-covid19-resized-to-256px-jpg/train/'
IMG_SIZE = 256
BATCH_SIZE = 16
EPOCHS = 10# Everything is done from /kaggle directory.
%cd ../

# Load image level csv file
df = pd.read_csv('input/siim-covid19-detection/train_image_level.csv')
df['id'] = df.apply(lambda row: row.id.split('_')[0], axis=1)
df['image_path']=df.apply(lambda row:TRAIN_PATH+row.id+'.jpg', axis=1)
df['image_level']=df.apply(lambda row: row.label.split(' ')[0],axis=1)","This code imports the necessary libraries for the project, including os, gc, cv2, numpy, pandas, tqdm, shutil, and matplotlib. It also defines a Data_dir variable for the path to the data directory.

Next, the code reads in the train_image_level.csv and train_study_level.csv files as pandas dataframes. The code then customizes the iPython writefile magic so that it can write variables to files.

Next, the code defines a TRAIN_PATH variable for the path to the training data, an IMG_SIZE variable for the image size, a BATCH_SIZE variable for the batch size, and an EPOCHS variable for the number of epochs.

Finally, the code loads the train_image_level.csv file as a pandas dataframe. It then adds an 'id' column to the dataframe, which is the id of the image. It also adds an 'image_path' column, which is the path to the image. Finally, it adds an 'image_level' column, which is the image level label.",9,13,0.06189204501515509
"# some error with pydicom
# @see https://www.kaggle.com/maoxiaoxu/siim-covid19-pydicom-dcm2jpg
# import numpy as np
# import pydicom
# from pydicom.pixel_data_handlers.util import apply_voi_lut


# def read_xray(path, voi_lut=True, fix_monochrome=True):
#     dicom = pydicom.read_file(path)
#     if voi_lut:
#         data = apply_voi_lut(dicom.pixel_array, dicom)
#     else:
#         data = dicom.pixel_array

#     if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
#         data = np.amax(data) - data
#     data = data - np.min(data)
#     data = data / np.max(data)
#     data = (data * 255).astype(np.uint8)
#     return dataimport SimpleITK as sitk
import numpy as np
# import cv2
def get_img(img, low_window, high_window):
    lungwin = np.array([low_window*1., high_window*1.])
    newimg = (img-lungwin[0])/(lungwin[1]-lungwin[0])
    newimg = (newimg*255).astype('uint8') 
    return newimg
#     newimg = cv2.cvtColor(newimg, cv2.COLOR_GRAY2RGB)
#     scale_percent = 100
#     width = int(newimg.shape[1] * scale_percent / 100)
#     height = int(newimg.shape[0] * scale_percent / 100)

#     dsize = (width, height)
#     output = cv2.resize(newimg, dsize)
#     cv2.imwrite(save_path, output, [int(cv2.IMWRITE_JPEG_QUALITY), 100])import pandas as pd
import json
import osdef get_v(boxes, file, labels, x, y):
    j_ = str(boxes)
    if len(j_) > 3:
        s = json.loads(j_.replace('\'', '""'))
        f = open('./labs/' + file.replace('dcm', 'txt'), 'w')
        for i in s:
            x_center = (float(i.get('x')) + float(i.get('width')) / 2) / x
            y_center = (float(i.get('y')) + float(i.get('height')) / 2) / y
            width = float(i.get('width')) / 2 / x
            height = float(i.get('height')) / 2 / y
            print(labels, '--', x_center, '--', y_center, '--', width, '--', height)
            f.writelines(str(labels) + ' ' +
                         str(x_center) + ' ' +
                         str(y_center) + ' ' +
                         str(width) + ' ' +
                         str(height) + '' +
                         '\r')
        f.close()
    else:
        f = open('./labs/' + file.replace('dcm', 'txt'), 'w')
        x_center = x / 2 / x
        y_center = y / 2 / y
        width = (x - x / 2) / x
        height = (y - y / 2) / y
        print(labels, '--', x_center, '--', y_center, '--', width, '--', height)
        f.writelines(str(labels) + ' ' + str(x_center) + ' ' + str(y_center) + ' ' + str(width) + ' ' + str(height))
        f.close()def get_y(a_, b_, c_, d_):
    if a_ == 1:
        return 3
    if b_ == 1:
        return 2
    if c_ == 1:
        return 1
    if d_ == 1:
        return 0
    return -1data01 = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
data01['StudyInstanceUID'] = data01['id'].apply(lambda x: x.replace('_study', ''))
data01 = data01.drop(['id'], axis=1)
data02 = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')
data02['id'] = data02['id'].apply(lambda x: x.replace('_image', ''))
data = pd.merge(data02, data01, on='StudyInstanceUID')
data.head()!mkdir -p labs","This code is for reading and processing X-ray images. It uses the pydicom library to read in the images, and then applies a VOI LUT to the pixel data if voi_lut is True. If fix_monochrome is True, it also inverts the image if it is MONOCHROME1. Finally, it rescales the image so that the minimum value is 0 and the maximum value is 1, and then converts it to an 8-bit unsigned integer.

The get_img function takes an image, a low_window value, and a high_window value, and returns a new image with the pixel values rescaled so that they are between low_window and high_window.

The get_v function takes a list of bounding boxes, a file name, a list of labels, and the x and y dimensions of the image, and generates a text file with the labels and bounding box coordinates for each object in the image.

The get_y function takes four values and returns a label based on the values. If the values are 1, 2, 3, or 4, it returns 3, 2, 1, or 0, respectively. Otherwise, it returns -1.",This documentation is semantically correct to a degree of 8.,5,0.05623158979156224
"!conda install gdcm -c conda-forge -y
!pip install pycocotools numpy opencv-python tqdm tensorboard tensorboardX pyyaml webcolors matplotlib!git clone https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch

import os
os.chdir(""Yet-Another-EfficientDet-Pytorch"")# load checkpoint
! mkdir weights
! wget https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch/releases/download/1.0/efficientdet-d0.pth -O weights/efficientdet-d0.pthsiim_yml = '''
project_name: siim  # also the folder name of the dataset that under data_path folder
train_set: train
val_set: val
num_gpus: 1

# mean and std in RGB order, actually this part should remain unchanged as long as your dataset is similar to coco.
mean: [ 0.485, 0.456, 0.406 ]
std: [ 0.229, 0.224, 0.225 ]

# this anchor is adapted to the dataset
anchors_scales: '[2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)]'
anchors_ratios: '[(1.0, 1.0), (1.3, 0.8), (1.9, 0.5)]'

obj_list: ['typical', 'indeterminate', 'atypical']
'''
with open('projects/siim.yml', 'w') as f:
    f.write(siim_yml)import os
from PIL import Image
import pandas as pd
from tqdm.auto import tqdm
import numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

import torch

def read_xray(path, voi_lut=False, fix_monochrome=True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array

    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data

    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)

    return data


def resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)

    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)

    return imfrom glob import glob
INPUT_PATH = ""/kaggle/input/siim-covid19-detection/""

for split in [""test"", ""train""]:
    save_dir = f""datasets/siim/{split}/""

    os.makedirs(save_dir, exist_ok=True)

    for path in tqdm(glob(INPUT_PATH + split + '/*/*/*')):
        # set keep_ratio=True to have original aspect ratio
        xray = read_xray(path)
        im = resize(xray, size=256)
        im.save(os.path.join(save_dir, path.split('/')[-1][:-3]+'jpg'))import os
import pandas as pd
from glob import glob
import pydicom","This code is responsible for converting the DICOM images in the input folder into JPEG images, and then saving them in the output folder.

The input folder is expected to contain DICOM images, and the output folder will contain the corresponding JPEG images.

The code will loop through all the images in the input folder, convert them to JPEG format, and then save them in the output folder.",8,0,0.12862855241386603
"import os
import shutil
import cv2
import pandas as pd
import tensorflow as tf
from tensorflow.keras.applications.vgg16 import preprocess_input, VGG16
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import train_test_split
import yaml

from kaggle_secrets import UserSecretsClient
import cv2
import pydicom

from pathlib import Path
from tqdm.auto import tqdm
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import skimage.io
import tqdm
import glob
import tensorflow 

from tqdm import tqdm
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from keras.metrics import Recall,Precision
from skimage.io import imread, imshow
from skimage.transform import resize
from skimage.color import grey2rgb

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Flatten, Dense, Activation, MaxPool2D, Conv2D
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.applications.vgg19 import VGG19
from tensorflow.keras.preprocessing.image import load_img, img_to_arraySIIM_COVID19_DETECTION_DIR = '/kaggle/input/siim-covid19-detection/'
PART0_RESIZED_DIR = '../input/siim-covid19-resized-to-256px-jpg'


TEMP_DIR = '/kaggle/temp/'

INPUT_DIR = PART0_RESIZED_DIR+'/train/'

OUTPUT_DIR = DATASET_DIR = TEMP_DIR+'/train/'
TRAIN_DIR = DATASET_DIR + 'train/'
TA_DIR = TRAIN_DIR+'ta/'
IA_DIR = TRAIN_DIR+'ia/'
AA_DIR = TRAIN_DIR+'aa/'
NP_DIR = TRAIN_DIR+'np/'

WORKING_DIR = '/kaggle/working/'

WANDB_PROJECT_NAME = 'project8-kaggle-covid19'
WANDB_ENTITY_NAME = ''

TRAIN_IMAGE_LEVEL_PATH = SIIM_COVID19_DETECTION_DIR+'train_image_level.csv'
TRAIN_STUDY_LEVEL_PATH = SIIM_COVID19_DETECTION_DIR+'train_study_level.csv'
META_PATH = PART0_RESIZED_DIR+'meta.csv'

BATCH_SIZE = 32
EPOCHS = 25
IMG_SIZE = WIDTH = HEIGHT = 224
LEARNING_RATE = 0.00008

INTERPOLATION = cv2.INTER_LANCZOS4df_train_image_level = pd.read_csv(TRAIN_IMAGE_LEVEL_PATH)
df_train_study_level = pd.read_csv(TRAIN_STUDY_LEVEL_PATH)

df_train_image_level['id'] = df_train_image_level.apply(lambda row: row.id.split('_')[0], axis=1)
df_train_image_level['path'] = df_train_image_level.apply(lambda row: INPUT_DIR+row.id+'.jpg', axis=1)
df_train_image_level['image_level'] = df_train_image_level.apply(lambda row: row.label.split(' ')[0], axis=1)

df_train_study_level['id'] = df_train_study_level.apply(lambda row: row.id.split('_')[0], axis=1)
df_train_study_level.columns = ['StudyInstanceUID', 'Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']df_train_image_level = df_train_image_level.merge(df_train_study_level, on='StudyInstanceUID',how=""left"")
df_train_image_level = df_train_image_level[['id','StudyInstanceUID','path','Negative for Pneumonia','Typical Appearance','Indeterminate Appearance','Atypical Appearance']]
df_train_image_level = df_train_image_level.dropna()
df_train_image_level = df_train_image_level[~df_train_image_level.duplicated(subset=['StudyInstanceUID'], keep='first')]
df_train_image_level = df_train_image_level.reset_index(drop=True)[os.makedirs(dir, exist_ok=True) for dir in [TA_DIR,IA_DIR,AA_DIR,NP_DIR]]
for i in tqdm(range(len(df_train_image_level))):
    row = df_train_image_level.loc[i]
    if row['Typical Appearance']:
        shutil.copy(row.path, f'{TA_DIR}{row.id}.jpg')
    elif row['Indeterminate Appearance']:
        shutil.copy(row.path, f'{IA_DIR}{row.id}.jpg')
    elif row['Atypical Appearance']:
        shutil.copy(row.path, f'{AA_DIR}{row.id}.jpg')
    elif row['Negative for Pneumonia']:
        shutil.copy(row.path, f'{NP_DIR}{row.id}.jpg')
    else:
        print('Error: check df_train_image_level')datagen_kwargs = dict(validation_split=.20,
                      preprocessing_function=preprocess_input
                     )
dataflow_kwargs = dict(target_size=(IMG_SIZE, IMG_SIZE),
                       batch_size=BATCH_SIZE,
                       interpolation=""lanczos""
                      )

valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)
valid_generator = valid_datagen.flow_from_directory(TRAIN_DIR,
                                                    subset=""validation"",
                                                    shuffle=False,
                                                    **dataflow_kwargs)

train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rotation_range=40,
    horizontal_flip=True,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    **datagen_kwargs)
train_generator = train_datagen.flow_from_directory(TRAIN_DIR,
                                                    subset=""training"",
                                                    shuffle=True,
                                                    **dataflow_kwargs)

print('classes :', train_generator.class_indices)# Model Initialization

base_model = VGG19(input_shape=(224,224,3), 
                         include_top=False,
                         weights=""imagenet"")","This code imports the necessary libraries for image processing, data manipulation, and machine learning.

Then, it defines some constants for file paths and image dimensions.

Next, it reads in the training data from CSV files.

Then, it copies the images into separate folders for each class.

After that, it creates generators for the training and validation data.

Finally, it initializes the VGG19 convolutional neural network model.",9,0,0.046381819841269094
"import os
import numpy as np
import pandas as pd
import pydicom
import matplotlib.pyplot as plt
import seaborn as sns# Load the data
base_path = ""/kaggle/input/siim-covid19-detection/""
studies_df = pd.read_csv(os.path.join(base_path,""train_study_level.csv""))# This function finds the first image in a StudyInstanceUID directory and returns its path.
def get_image_by_study_id(study_id):
    study_path = base_path + ""train/"" + study_id + ""/""
    
    for subdir, dirs, files in os.walk(study_path):
        for file in files:     
            image = os.path.join(subdir, file)
            if os.path.isfile(image):
                return image
    return ""none""# Iterate through the images in the train set and grab the private tags. I'm sure there's a quicker way to do this, I was just lazy.

for index, row in studies_df.iterrows():
    
    f = row['id'].split(""_"")
    
    img_file = get_image_by_study_id(f[0])
    img = pydicom.dcmread(img_file)               
    
    studies_df.at[index,'tag_0029_0010'] = 0
    studies_df.at[index,'tag_0903_0010'] = 0
    studies_df.at[index,'tag_0905_0010'] = 0
    studies_df.at[index,'tag_2001_0010'] = 0
    studies_df.at[index,'tag_200B_0010'] = 0
    studies_df.at[index,'tag_200B_0011'] = 0
    studies_df.at[index,'tag_200B_0012'] = 0
    studies_df.at[index,'tag_7FD1_0010'] = 0
        
    if (0x0029,0x0010) in img:
        studies_df.at[index,'tag_0029_0010'] = 1
        
    if (0x0903,0x0010) in img:
        studies_df.at[index,'tag_0903_0010'] = 1
        
    if (0x0905,0x0010) in img:
        studies_df.at[index,'tag_0905_0010'] = 1
        
    if (0x2001,0x0010) in img:
        studies_df.at[index,'tag_2001_0010'] = 1
        
    if (0x200B,0x0010) in img:
        studies_df.at[index,'tag_200B_0010'] = 1
        
    if (0x200B,0x0011) in img:
        studies_df.at[index,'tag_200B_0011'] = 1
        
    if (0x200B,0x0012) in img:
        studies_df.at[index,'tag_200B_0012'] = 1
        
    if (0x7FD1,0x0010) in img:
        studies_df.at[index,'tag_7FD1_0010'] = 1

studies_df.head(20)plt.figure(figsize= (10,10))
corr = studies_df.corr()
sns.heatmap(corr, annot = True);","This code loads in the data from a CSV file, then iterates through the images in the dataset to find the private tags associated with each image. Finally, it generates a correlation plot to show which tags are most associated with COVID-19.",8,0,0.12097306123300025
"!nvidia-smi!pip install efficientnet -qimport os
import cv2
import glob

import numpy as np
import pandas as pd

from tqdm.notebook import tqdm

import matplotlib.pyplot as plt

import tensorflow as tf
import efficientnet.tfkeras as efn

from sklearn.model_selection import GroupKFold, train_test_splitclass Config:
    IMAGES = '../input/vinbigdata-chest-xray-resized-png-1024x1024/train'
    DATA = '../input/vinbigdata-chest-xray-abnormalities-detection/train.csv'
    
    AUTOTUNE = tf.data.experimental.AUTOTUNE
    
    PRETRAINING_IMAGE_SIZE = 256 # I am using smaller image size for faster training
    PRETRAINING_BATCH_SIZE = 8
    PRETRAINING_NUM_CLASSES = 15
    PRETRAINING_LR = 0.001config = Config()df = pd.read_csv(config.DATA)
df.head(2)# SELECTING ONLY REQUIRED COLUMNS
df['image_path'] = df['image_id'].map(lambda x: f'{config.IMAGES}/{x}.png')
df = df[['image_path', 'class_id']]
df.head(2)","This code loads in a CSV file containing image paths and class IDs, and stores it in a dataframe. It then selectsonly the required columns (image path and class ID), and stores the result in the dataframe.",8,3,0.018358900375634726
"#Loading important libraries
import numpy as np
import pandas as pd

from fastai.basics import *
from fastai.callback.all import *
from fastai.vision.all import *
from fastai.medical.imaging import *
import pydicomitems = get_dicom_files('../input/siim-covid19-detection/train', recurse = True)
print (items)dcm = items[0]
DCM = dcm.dcmread()
DCM# Extracting the pixel data as an array
x =DCM.pixel_array,DCM.pixel_array.shape
print (x)
# Converting the pixel array into tensor using TensorDicom
tdm = TensorDicom(DCM.pixel_array)
tdmtdm.show()%%time
dicoms_df = pd.DataFrame.from_dicoms(items)dicoms_df[:2]","This code snippet loads important libraries for working with data, including the fastai library for machine learning. It also retrieves all DICOM files from a given directory and prints them out. Finally, it converts the pixel array of a DICOM image into a tensor using the TensorDicom class.",8,2,0.14851138295619953
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
from PIL import Image
# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory
import shutil
import os
# for dirname, _, filenames in os.walk('/kaggle/input'):
#     for filename in filenames:
#         print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport os
from glob import glob
import gc
import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm
from shutil import copyfile
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

#customize iPython writefile so we can write variables
from IPython.core.magic import register_line_cell_magic

@register_line_cell_magic
def writetemplate(line, cell):
    with open(line, 'w') as f:
        f.write(cell.format(**globals()))
        
import torch
print(f""Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})"")
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -yfast_df = False
IMG_SIZE = 600import numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return imsplit = 'test'
image_id = []
dim0 = []
dim1 = []
splits = []
save_dir = f'/kaggle/tmp/{split}/image/'
os.makedirs(save_dir, exist_ok=True)

for dirname, _, filenames in tqdm(os.walk(f'/kaggle/input/siim-covid19-detection/{split}')):
    for file in filenames:
        # set keep_ratio=True to have original aspect ratio
        xray = read_xray(os.path.join(dirname, file))
        im = resize(xray, size=IMG_SIZE)  
        im.save(os.path.join(save_dir, file.replace('.dcm', '_image.jpeg')))
        image_id.append(file.replace('.dcm', ''))
        dim0.append(xray.shape[0])
        dim1.append(xray.shape[1])
        splits.append(split)
meta = pd.DataFrame.from_dict({'image_id': image_id, 'dim0': dim0, 'dim1': dim1, 'split': splits})","This code reads in DICOM files from a given directory, applies a VOI LUT (if available) to transform the raw data into a ""human-friendly"" view, and then resizes the images to a given size (IMG_SIZE). The resulting images are saved in a new directory, with the image ID and dimensions (dim0 and dim1) recorded in a metadata file (meta).",8,1,0.20858489466563754
"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -yimport os
import ast
import cv2
import pandas as pd
import numpy as np
import pydicom as dicom
from tqdm import tqdm
from glob import glob
from PIL import Image
from pydicom.pixel_data_handlers.util import apply_voi_lutdef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    return im


def robust_read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom_ = dicom.read_file(path)

    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom_.pixel_array, dicom_)
    else:
        data = dicom_.pixel_array
    
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom_.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    # 近似3个标准差内数据
    q1,q2,q3 = np.quantile(data, [.15865,.5,.84135]) 
    iqr = q3 - q1
    multiplier = 1.5
    # 原始方法:http://www.kaggle.com/yukiszk/robust-pixel-array-scaling

    mask = ((q2 - multiplier * iqr) < data) & (data < (q2 + multiplier * iqr))
    
    if data[mask].size != 0:
        p = .001
        data = data.astype(np.float32) - np.quantile(data[mask], p)
        data = data / np.quantile(data[mask], 1-p)
    else:
        data = data - np.min(data)
        data = data / np.max(data)

    data = np.clip(data, 0, 1)
    data = (data * 255).astype(np.uint8)
    # 3-channel
#     img_equ = cv2.equalizeHist(data)
#     img_edge = cv2.Canny(img_equ, 50, 130)
#     img = np.concatenate([
#         data[:, :, None],
#         img_equ[:,:,None],
#         img_edge[:,:,None],
#     ], axis=-1)
    
    return datasplits = ['study', 'image']
remove_id = [
    '61f3ac249c50',
    'a39667fe9a81',
    '267a250932bc',
    'b97c6b32105e',
    '869476b0763a',
    '49664f078f0e',
    'c3a09e8a600d',
    '35e398a5a431',
    '0bd6cd815ba9',
    '6f54e9cbd180',
    'c4b68b29a072',
    '9872a8a48f23',
    'e738c549fe8e',
    'c636ac67c19a',
    '8d4b3609ed92',
]
img_size = 1024
#os.makedirs('/kaggle/working/train-csv/', exist_ok=True)

for split in splits:
    save_dir = f'/kaggle/tmp/{split}/'
    os.makedirs(save_dir, exist_ok=True)
    if split == 'image':   
        df = pd.read_csv('/kaggle/input/siim-covid19-detection/train_image_level.csv')
        none = []
        for _, row in df.iterrows():
            study_id = row['StudyInstanceUID']
            image_id = row['id'].split('_')[0]
            if image_id not in remove_id:
                img_path = glob(f'/kaggle/input/siim-covid19-detection/train/{study_id}/*/{image_id}.dcm')
                xray = robust_read_xray(img_path[0])
                #h, w = xray.shape
                img = resize(xray, size=img_size)
                img.save(f'{save_dir}/{image_id}_image.png')
            #if 'none' in str(row['label']):
            #    none.append('1')
            #else:
            #    none.append('0')
        #df['none'] = none
        #df.to_csv('/kaggle/working/train-csv/train.csv')
    elif split == 'study':
        df = pd.read_csv('/kaggle/input/siim-covid19-detection/train_study_level.csv')
        for _, row in df.iterrows():
            study_id = row['id'].split('_')[0]
            img_path = glob(f'/kaggle/input/siim-covid19-detection/train/{study_id}/*/*.dcm')
            for img_p in img_path:
                xray = robust_read_xray(img_p)
                #h, w = xray.shape
                img = resize(xray, size=img_size)
                img.save(f'{save_dir}/{study_id}_study.png')!tar -zcf data.tar.gz -C ""/kaggle/tmp/"" .","This code installs the pydicom conda helper package and its dependencies. It then reads in a CSV file containing information about X-ray studies and images. For each study, it reads in the DICOM images and applies a VOI LUT to transform the raw data into a ""human-friendly"" view. It then rescales the data and saves it as a PNG image.",9,3,0.180179916325169
"!cp /kaggle/input/gdcm-conda-install/gdcm.tar .
!tar -xvzf gdcm.tar
!conda install --offline ./gdcm/gdcm-2.8.9-py37h71b2a6d_0.tar.bz2
!rm -rf ./gdcm.tar
# !git clone https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer.git
import sys
sys.path.append('../input/pytorch-image-models/pytorch-image-models-master')
# sys.path.append('./Ranger-Deep-Learning-Optimizer/ranger')import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from tqdm.autonotebook import tqdm
from pprint import pprint
from datetime import datetime
import os, sys, cv2, glob, random ,ast, warnings, time
warnings.filterwarnings('ignore')

import timm

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as T
from torch.utils.data import Dataset, DataLoader
from torch.cuda.amp import autocast, GradScaler
from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts
from torch.optim import Adam, SGD, AdamW

# import pytorch_lightning as pl
# import torchmetrics
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

import albumentations as A
from albumentations.pytorch import ToTensorV2

# from ranger import Ranger  # this is from ranger.py
# from ranger913A import RangerVA  # this is from ranger913A.py
# from rangerqh import RangerQH  # this is from rangerqh.py

from sklearn.metrics import roc_auc_score, accuracy_score
from sklearn.model_selection import StratifiedKFold
sys.path.append(""../input/iterative-stratification/iterative-stratification-master"")
from iterstrat.ml_stratifiers import MultilabelStratifiedKFoldmodel_names = timm.list_models()
# pprint(model_names)BATCH_SIZE = 16
VAL_BATCH_SIZE = 32
EPOCHS = 5 
IMG_SIZE = 512
if BATCH_SIZE == 8:
    ITER_FREQ = 300
else:
    ITER_FREQ = 90
NUM_WORKERS = 8
MEAN = [0.485, 0.456, 0.406]
STD = [0.229, 0.224, 0.225]
SEED = 1111
N_FOLDS = 5
START_FOLD = 3

MODEL_PATH = None
MODEL_ARCH = 'tf_efficientnet_b5_ns' # tf_efficientnet_b4_ns, tf_efficientnet_b6_ns, resnext50_32x4d, seresnet152d

LR = 1e-4
MIN_LR = 1e-6 # CosineAnnealingWarmRestarts
WEIGHT_DECAY = 1e-6
MOMENTUM = 0.9
T_0 = EPOCHS # CosineAnnealingWarmRestarts
MAX_NORM = 1000
T_MAX = 5
ITERS_TO_ACCUMULATE = 1

BASE_OPTIMIZER = SGD #for Ranger
OPTIMIZER = 'Adam' # Ranger, AdamW, AdamP, SGD

SCHEDULER = 'CosineAnnealingWarmRestarts' # ReduceLROnPlateau, CosineAnnealingLR, CosineAnnealingWarmRestarts, OneCycleLR
SCHEDULER_UPDATE = 'epoch' # batch

TR_CRITERION = 'BCE'
VL_CRITERION = 'BCE' # CrossEntropyLoss
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# avg_prec = torchmetrics.AveragePrecision(num_classes = 4)
LABELS = ['Negative for Pneumonia','Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']class AverageMeter(object):
    def __init__(self):
        self.reset()
        
    def reset(self):
        self.val = 0
        self.sum = 0
        self.avg = 0
        self.count = 0
        
    def update(self, val, n=1):
        self.val = val
        self.sum += val*n
        self.count += n
        self.avg = self.sum / self.count
        
def seed_torch(seed):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True
    
seed_torch(SEED)

def macro_multilabel_auc(label, pred):
    aucs = []
    for i in range(len(LABELS)):
        aucs.append(roc_auc_score(label[:, i], pred[:, i]))
    print(np.round(aucs, 4))
    return np.mean(aucs)def preprocess_df(train = True):
    if train:
        df_image = pd.read_csv(""../input/siim-covid19-detection/train_study_level.csv"")
        df_det = pd.read_csv(""../input/siim-covid19-detection/train_image_level.csv"")
        df_image['StudyInstanceUID'] = df_image['id'].apply(lambda x : x[:-6])
        df = df_det.merge(df_image, on='StudyInstanceUID')
        path = []
        TRAIN_DIR = ""../input/siim-covid19-detection/train/""
        for instance_id in tqdm(df['StudyInstanceUID']):
            path.append(glob.glob(os.path.join(TRAIN_DIR, instance_id +""/*/*""))[0])
        df['path'] = path

        df = df.drop(['id_x', 'id_y'], axis=1)
        return df
    
    else:
        df= pd.read_csv(""../input/siim-covid19-detection/sample_submission.csv"")
        study_indices = df['id'].apply(lambda x : x[-6:])
        STUDY_LEN =0
        for i in range(len(study_indices)):
            if study_indices[i] == '_image':
                STUDY_LEN = i
                break
            
        df['StudyInstanceUID'] = df['id'].apply(lambda x : x[:-6])
        df = df.iloc[:STUDY_LEN,:]
        path = []
        TEST_DIR = ""../input/siim-covid19-detection/test""
        for instance_id in tqdm(df['StudyInstanceUID']):
            path.append(glob.glob(os.path.join(TEST_DIR, instance_id +""/*/*""))[0])
        df['path'] = path

        return df,STUDY_LENdef dicom2array(path, voi_lut=True, fix_monochrome=True):
    dicom = pydicom.read_file(path)
    # VOI LUT (if available by DICOM device) is used to
    # transform raw DICOM data to ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
    return data","This code installs the GDCM package for use with Python. It then extracts the contents of the package and installs them into a conda environment. Finally, it removes the GDCM tar file.",8,1,0.035967306185509786
"# Run this code with kaggle TPU
ENVIRONMENT = ""kaggle""
dir = ""/kaggle/working""# # Run this code with colab TPU
# # You can use larger batch_size, image_size and model with colab high memory mode
# ENVIRONMENT = ""colab""
# dir = ""/content/gdrive/MyDrive/siim-effnets-classification-train""  # directory of this code

# from google.colab import drive
# drive.mount('/content/gdrive/')

# !pip install kaggle > /dev/null 2>&1

# # Upload your kaggle.json file to connect with your kaggle account
# from google.colab import files
# files.upload()  
# !mkdir -p ~/.kaggle
# !cp kaggle.json ~/.kaggle/
# !chmod 600 ~/.kaggle/kaggle.json

# # Download specific kaggle dataset which contains .npy data processed from original .dcm data 
# !mkdir -p '/content/siim-dicom-to-npy-v1'  
# !kaggle datasets download -d shangweichen/siim-dicom-to-npy-v1 -p '../content/gdrive/MyDrive'
# !unzip -n '/content/gdrive/MyDrive/siim-dicom-to-npy-v1.zip' -d '/content/siim-dicom-to-npy-v1' > /dev/null 2>&1
# !rm '/content/gdrive/MyDrive/siim-dicom-to-npy-v1.zip'

# # Download timm package
# !mkdir -p '/content/timm-pytorch-image-models'
# !kaggle datasets download -d kozodoi/timm-pytorch-image-models -p '../content/gdrive/MyDrive'
# !unzip -n '/content/gdrive/MyDrive/timm-pytorch-image-models.zip' -d '/content/timm-pytorch-image-models' > /dev/null 2>&1
# !rm '/content/gdrive/MyDrive/timm-pytorch-image-models.zip'

# !pip install pydicom > /dev/null 2>&1
# !pip install --upgrade albumentations > /dev/null 2>&1if ENVIRONMENT not in [""kaggle"", ""colab""]:
    raise ValueError(""ENVIRONMENT Wrong!"")!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py > /dev/null 2>&1
!python pytorch-xla-env-setup.py --version 20210331 --apt-packages libomp5 libopenblas-dev > /dev/null 2>&1import sys
if ENVIRONMENT == ""kaggle"":
    sys.path.append(""/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master"")
elif ENVIRONMENT == ""colab"":
    sys.path.append(""/content/timm-pytorch-image-models/pytorch-image-models-master"")

import platform
import numpy as np
import pandas as pd
import os
from tqdm.notebook import tqdm
import cv2
import pydicom
import random
import glob
import gc
from math import ceil
import albumentations as A
import matplotlib.pyplot as plt
from pydicom.pixel_data_handlers.util import apply_voi_lut
from sklearn.metrics import roc_auc_score, confusion_matrix
from sklearn.model_selection import StratifiedKFold, train_test_split
import torch
import timm
import time
import torch.nn as nn
import torch.nn.functional as F
from torch.cuda.amp import GradScaler, autocast
from torch.utils.data import Dataset, DataLoader
from torch.utils.data.distributed import DistributedSampler
from torch.optim.lr_scheduler import ReduceLROnPlateau, LambdaLR, StepLR
import torch_xla
import torch_xla.debug.metrics as met
import torch_xla.distributed.parallel_loader as pl
import torch_xla.utils.utils as xu
import torch_xla.core.xla_model as xm
import torch_xla.distributed.xla_multiprocessing as xmp
import torch_xla.test.test_utils as test_utils
import warnings

warnings.simplefilter('ignore')
np.set_printoptions(suppress=True)
os.environ['XLA_USE_BF16']=""1""
os.environ['XLA_TENSOR_ALLOCATOR_MAXSIZE'] = '100000000'if ENVIRONMENT == ""kaggle"":
    print(np.load(f""/kaggle/input/siim-dicom-to-npy-v1/trainset/000a312787f2.npy"").shape)
elif ENVIRONMENT == ""colab"":
    print(np.load(f""/content/siim-dicom-to-npy-v1/trainset/000a312787f2.npy"").shape)class Config:
    train_pcent = 0.80
    model_name = 'tf_efficientnet_b7'
    image_size = (400, 400)
    batch_size = 8 * 8
    epochs = 20
    seed = 2021
    lr = 1e-4 / 8  
    workers = 8
    drop_last = True
    augments = A.Compose([
                   A.augmentations.crops.transforms.RandomResizedCrop(height=image_size[1], 
                                                                      width=image_size[0], 
                                                                      scale=(0.88*0.88, 1), 
                                                                      ratio=(0.8, 1.2), 
                                                                      p=0.5),
                   A.augmentations.transforms.HorizontalFlip(p=0.5),
                   A.augmentations.transforms.VerticalFlip(p=0.5),
                   A.augmentations.geometric.rotate.Rotate(p=0.5),
                   A.OneOf([
                       A.augmentations.transforms.Blur(),
                       A.augmentations.transforms.GlassBlur(),
                       A.augmentations.transforms.GaussianBlur(),
                       A.augmentations.transforms.GaussNoise(),
                       A.augmentations.transforms.RandomGamma(),
                       A.augmentations.transforms.InvertImg(),
                       A.augmentations.transforms.RandomFog()
                   ], p=0.5)
    ])

    def get_loss_fn():
        return nn.CrossEntropyLoss()

    def get_optimizer(model, learning_rate):
        return torch.optim.Adam(model.parameters(), lr=learning_rate)

    def get_scheduler(optimizer):
        return ReduceLROnPlateau(optimizer, 
                                 mode='min', 
                                 factor=0.1, 
                                 patience=5, 
                                 verbose=False, 
                                 min_lr=1e-5)
    

# Make results reproducible
def seed_everything(seed):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True
    
seed_everything(Config.seed)","This code sets up the environment for training a model on either kaggle or colab. It also sets up the data for training and testing. Finally, it configures the model, optimizer, and scheduler.",8,2,0.0654623149965148
"!pip install efficientnet -qimport os

import efficientnet.tfkeras as efn
import numpy as np
import pandas as pd
from kaggle_datasets import KaggleDatasets
from sklearn.model_selection import train_test_split
import tensorflow as tf
from sklearn.model_selection import GroupKFolddef auto_select_accelerator():
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        tf.config.experimental_connect_to_cluster(tpu)
        tf.tpu.experimental.initialize_tpu_system(tpu)
        strategy = tf.distribute.experimental.TPUStrategy(tpu)
        print(""Running on TPU:"", tpu.master())
    except ValueError:
        strategy = tf.distribute.get_strategy()
    print(f""Running on {strategy.num_replicas_in_sync} replicas"")
    
    return strategy


def build_decoder(with_labels=True, target_size=(256, 256), ext='jpg'):
    def decode(path):
        file_bytes = tf.io.read_file(path)

        if ext == 'png':
            img = tf.image.decode_png(file_bytes, channels=3)
        elif ext in ['jpg', 'jpeg']:
            img = tf.image.decode_jpeg(file_bytes, channels=3)
        else:
            raise ValueError(""Image extension not supported"")
        img = tf.cast(img, tf.float32) / 255.0
        img = tf.image.resize(img, target_size)

        return img
    
    def decode_with_labels(path, label):
        return decode(path), label
    
    return decode_with_labels if with_labels else decode


def build_augmenter(with_labels=True):
    def augment(img):
        img = tf.image.random_flip_left_right(img)
        img = tf.image.random_flip_up_down(img)
        return img
    
    def augment_with_labels(img, label):
        return augment(img), label
    
    return augment_with_labels if with_labels else augment


def build_dataset(paths, labels=None, bsize=128, cache=True,
                  decode_fn=None, augment_fn=None,
                  augment=True, repeat=True, shuffle=1024, 
                  cache_dir=""""):
    if cache_dir != """" and cache is True:
        os.makedirs(cache_dir, exist_ok=True)
    
    if decode_fn is None:
        decode_fn = build_decoder(labels is not None)
    
    if augment_fn is None:
        augment_fn = build_augmenter(labels is not None)
    
    AUTO = tf.data.experimental.AUTOTUNE
    slices = paths if labels is None else (paths, labels)
    
    dset = tf.data.Dataset.from_tensor_slices(slices)
    dset = dset.map(decode_fn, num_parallel_calls=AUTO)
    dset = dset.cache(cache_dir) if cache else dset
    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset
    dset = dset.repeat() if repeat else dset
    dset = dset.shuffle(shuffle) if shuffle else dset
    dset = dset.batch(bsize).prefetch(AUTO)
    
    return dsetCOMPETITION_NAME = ""siimfisabiorsna-covid19-image-size-1024""
strategy = auto_select_accelerator()
BATCH_SIZE = strategy.num_replicas_in_sync * 16
GCS_DS_PATH = KaggleDatasets().get_gcs_path(COMPETITION_NAME)load_dir = f""/kaggle/input/{COMPETITION_NAME}/""
df = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')
label_cols = df.columns[1:5]
gkf  = GroupKFold(n_splits = 5)
df['fold'] = -1
for fold, (train_idx, val_idx) in enumerate(gkf.split(df, groups = df.id.tolist())):
    df.loc[val_idx, 'fold'] = foldfor i in range(5):
    
    valid_paths = GCS_DS_PATH + '/study/' + df[df['fold'] == i]['id'] + '.png' #""/train/""
    train_paths = GCS_DS_PATH + '/study/' + df[df['fold'] != i]['id'] + '.png' #""/train/"" 
    valid_labels = df[df['fold'] == i][label_cols].values
    train_labels = df[df['fold'] != i][label_cols].values

    IMSIZE = (224, 240, 260, 300, 380, 456, 528, 600)
    IMS = 7

    decoder = build_decoder(with_labels=True, target_size=(IMSIZE[IMS], IMSIZE[IMS]), ext='png')
    test_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[IMS], IMSIZE[IMS]),ext='png')

    train_dataset = build_dataset(
        train_paths, train_labels, bsize=BATCH_SIZE, decode_fn=decoder
    )

    valid_dataset = build_dataset(
        valid_paths, valid_labels, bsize=BATCH_SIZE, decode_fn=decoder,
        repeat=False, shuffle=False, augment=False
    )

    try:
        n_labels = train_labels.shape[1]
    except:
        n_labels = 1

    with strategy.scope():
        model = tf.keras.Sequential([
            efn.EfficientNetB7(
                input_shape=(IMSIZE[IMS], IMSIZE[IMS], 3),
                weights='imagenet',
                include_top=False),
            tf.keras.layers.GlobalAveragePooling2D(),
            tf.keras.layers.Dense(n_labels, activation='softmax')
        ])
        model.compile(
            optimizer=tf.keras.optimizers.Adam(),
            loss='categorical_crossentropy',
            metrics=[tf.keras.metrics.AUC(multi_label=True)])

        model.summary()


    steps_per_epoch = train_paths.shape[0] // BATCH_SIZE
    checkpoint = tf.keras.callbacks.ModelCheckpoint(
        f'model{i}.h5', save_best_only=True, monitor='val_loss', mode='min')
    lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(
        monitor=""val_loss"", patience=3, min_lr=1e-6, mode='min')

    history = model.fit(
        train_dataset, 
        epochs=20,
        verbose=1,
        callbacks=[checkpoint, lr_reducer],
        steps_per_epoch=steps_per_epoch,
        validation_data=valid_dataset)

    hist_df = pd.DataFrame(history.history)
    hist_df.to_csv(f'history{i}.csv')","This code imports the efficientnet.tfkeras module and defines a function to automatically select an accelerator. The code then defines a function to build a dataset using paths and labels, with a specified batch size, cache, decode function, and augment function. The code then loops through 5 folds and fits a model on the training data for each fold, saving the model and history for each fold.",8,2,0.05995648471407379
"import os
import pandas as pd
from tqdm.notebook import tqdm
import numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lutpath = ""../input/siim-covid19-detection/train/00086460a852/9e8302230c91/65761e66de9f.dcm""
dicom = pydicom.read_file(path)
print('\n'.join(str(dicom).split('\n')[14:17]))df_study = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv')ids, genders, labels = [], [], []
trainfiles = [(dirname, filenames) for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/train/')) if len(filenames) > 0]
for dirname, filenames in tqdm(trainfiles):
    for file in filenames:
        sid = dirname.split(""/"")[-2]+'_study'
        id = file.replace('.dcm','')+'_image'
        ids.append(id)
        label = np.argmax(df_study[df_study.id==sid][df_study.columns[1:5]].values[0])
        labels.append(df_study.columns[1:5][label])
        path = os.path.join(dirname, file)
        dicom = pydicom.read_file(path)
        genders.append(str(dicom.get_item('00100040').value.decode('utf8'))[0])set(genders)pd.DataFrame({""id"":ids,""gender"":genders,""label"":labels}).to_csv(""genders.csv"", index=False)import matplotlib.pyplot as plt
df = pd.read_csv('genders.csv')
plt.hist(df.gender)","This code imports the os, pandas, tqdm, numpy, and pydicom libraries.

It then defines a path variable and reads in the dicom file at that path.

Next, it prints out some information about the dicom file.

Then, it reads in a CSV file containing information about studies.

After that, it loops through the studies in the CSV file and extracts information about the patients' IDs, genders, and labels.

Finally, it saves this information to a new CSV file.",8,6,0.1430609957792531
"# You may need to uncomment and run the conda install. Then restart the notebook if GDCM pukes.
#!conda install gdcm -c conda-forge -yimport numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
from os import path
import pydicom
from skimage.filters import unsharp_mask
from skimage import exposure# Function to get some test images
def get_some_images(process):
    
    count = 0
    base_path = ""../input/siim-covid19-detection/""
    fig = plt.figure(figsize=(15, 6))

    for study_dir in sorted(os.listdir(base_path + ""/test"")):
        for series_dir in os.listdir(base_path + ""/test/"" + study_dir):
            for image in os.listdir(base_path + ""/test/"" + study_dir + ""/"" + series_dir):
                im = image.split(""."")
                file_in = base_path + ""/test/"" + study_dir + ""/"" + series_dir + ""/"" + image
            
                img = pydicom.dcmread(file_in)
                pixels = img.pixel_array
                
                if img.PhotometricInterpretation == ""MONOCHROME1"":
                    pixels = np.amax(pixels) - pixels
                    
                if process:
                    pixels = remove_borders(pixels)      
                    pixels = process_image(pixels)
                 
                pixels = pixels - np.min(pixels)
                pixels = pixels / np.max(pixels)
                pixels = (pixels * 255).astype(np.uint8)
                
                count += 1         
                fig.add_subplot(3, 5, count)
                plt.imshow(pixels, cmap='gray')

        if count > 14:
            break
    plt.show()# Apply unsharp mask and hist equalization
def process_image(pixels):

    # Tweak the radius and amount for more/less sharpening
    unsharp = unsharp_mask(pixels, radius=5, amount=2)
    equalized = exposure.equalize_hist(unsharp)
    
    return equalized# Try to remove borders
def remove_borders(pixels):
    x = 0
    y = 0
    img_orig = pixels
    w = pixels.shape[1]
    h = pixels.shape[0]

    for i in range(h):
        if not np.all(pixels[i] == pixels[i][0]):
            y = i
            break
              
    for i in range(h-1, 0, -1):
        if not np.all(pixels[i] == pixels[i][0]):
            h = i
            break
            
    pixels = pixels[y:h,x:w] 
    pixels = np.rot90(pixels)
    
    w = pixels.shape[1]
    h = pixels.shape[0]

    for i in range(h):
        if not np.all(pixels[i] == pixels[i][0]):
            y = i
            break
              
    for i in range(h-1, 0, -1):
        if not np.all(pixels[i] == pixels[i][0]):
            h = i
            break
            
    pixels = pixels[y:h,x:w]
    img_cropped = np.rot90(pixels, 3)
    return img_croppedget_some_images(process=False)get_some_images(process=True)","This code snippet loads in a few images from a DICOM dataset, and then applies some image processing steps to them. First, the borders of the images are removed. Then, the images are sharpened and histogram equalized. Finally, the processed images are displayed.",8,1,0.06368959516028647
"# You may need to uncomment and run this command if you intend to load JPEG encoded DICOM files.
#!conda install gdcm -c conda-forge -yimport os
import numpy as np
import pandas as pd
import pydicom
import matplotlib.pyplot as plt
from skimage.filters import unsharp_mask
from skimage import exposure# This function gets the first image path in a StudyInstanceUID directory in the train set
def get_image_by_study_id(study_id):
    base_path = ""/kaggle/input/siim-covid19-detection/""
    study_path = base_path + ""train/"" + study_id + ""/""
    images = []
    for subdir, dirs, files in os.walk(study_path):
        for file in files:     
            image = os.path.join(subdir, file)
            if os.path.isfile(image):
                return image
    return ""none""# Function to load image
def load_image(study_id):
    img_file = get_image_by_study_id(study_id)
    image = pydicom.dcmread(img_file)
    pixels = image.pixel_array

    min_pixel = np.min(pixels)
    max_pixel = np.max(pixels)

    if image.PhotometricInterpretation == ""MONOCHROME1"":
        pixels = max_pixel - pixels
    else:
        pixels = pixels
    return pixels# Apply unsharp mask and hist equalization
def unsharp_image(pixels):

    # Tweak the radius and amount for more/less sharpening
    unsharp_image = unsharp_mask(pixels, radius=5, amount=2)
    equalized_image = exposure.equalize_hist(unsharp_image)
    
    return equalized_image# Display images
def plot_images(pixels, image_unsharp):
    # Plot both images
    fig, axes = plt.subplots(nrows=1, ncols=2,sharex=True, sharey=True, figsize=(12, 12))
    ax = axes.ravel()
    ax[0].imshow(pixels, cmap=plt.cm.gray)
    ax[0].set_title('Original image')
    ax[1].imshow(image_unsharp, cmap=plt.cm.gray)
    ax[1].set_title('After unsharp / hist eq')
    for a in ax:
        a.axis('off')
    fig.tight_layout()
    plt.show()# Grab an random study ID and get the pixels
pixels = load_image('013d698aeecb')

# Apply unsharp and hist equalization
pixels_unsharp = unsharp_image(pixels)

# Plot the images
plot_images(pixels, pixels_unsharp)","This code loads an image from a given StudyInstanceUID directory in the train set, applies unsharp masking and histogram equalization, and then displays the results.",8,1,0.20067888241037068
"# Load Grassroots DICOM (GDCM) for xray DICOM files
!pip install python-gdcm -q

# Load glob2
!pip install glob2

# Load tqdm
!pip install tqdm

# !pip install --upgrade numpy==1.20.0 --no-binary# Loading necessary packages
import os
from datetime import datetime
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import glob2
from tqdm.notebook import tqdm
import cv2
import gdcm
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
from fastai.vision.all import *
from fastai.medical.imaging import *
from torchvision.utils import save_imageSOURCE = '/kaggle/input/siim-covid19-detection'
os.listdir(SOURCE)train_image_level = pd.read_csv(f'{SOURCE}/train_image_level.csv')
train_study_level = pd.read_csv(f'{SOURCE}/train_study_level.csv')
sample_submission = pd.read_csv(f'{SOURCE}/sample_submission.csv')train_image_level.head(10)train_study_level.head()sample_submission.head()","This code loads the necessary packages for working with x-ray DICOM files. It also loads the train_image_level and train_study_level dataframes, as well as the sample_submission dataframe.",8,2,0.09743648628860668
"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y
!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -yimport os

from PIL import Image
import pandas as pd
from tqdm.auto import tqdmdf = pd.read_csv('/kaggle/input/siim-covid19-detection/sample_submission.csv')
if df.shape[0] == 2477:
    fast_sub = True
    fast_df = pd.DataFrame(([['00086460a852_study', 'negative 1 0 0 1 1'], 
                         ['000c9c05fd14_study', 'negative 1 0 0 1 1'], 
                         ['65761e66de9f_image', 'none 1 0 0 1 1'], 
                         ['51759b5579bc_image', 'none 1 0 0 1 1']]), 
                       columns=['id', 'PredictionString'])
else:
    fast_sub = Falseimport numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data
        
    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    
    return im
split = 'test'
save_dir = f'/kaggle/tmp/{split}/'

os.makedirs(save_dir, exist_ok=True)

save_dir = f'/kaggle/tmp/{split}/study/'
os.makedirs(save_dir, exist_ok=True)
if fast_sub:
    xray = read_xray('/kaggle/input/siim-covid19-detection/train/00086460a852/9e8302230c91/65761e66de9f.dcm')
    im = resize(xray, size=600)  
    study = '00086460a852' + '_study.png'
    im.save(os.path.join(save_dir, study))
    xray = read_xray('/kaggle/input/siim-covid19-detection/train/000c9c05fd14/e555410bd2cd/51759b5579bc.dcm')
    im = resize(xray, size=600)  
    study = '000c9c05fd14' + '_study.png'
    im.save(os.path.join(save_dir, study))
else:   
    for dirname, _, filenames in tqdm(os.walk(f'/kaggle/input/siim-covid19-detection/{split}')):
        for file in filenames:
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(os.path.join(dirname, file))
            im = resize(xray, size=600)  
            study = dirname.split('/')[-2] + '_study.png'
            im.save(os.path.join(save_dir, study))
image_id = []
dim0 = []
dim1 = []
splits = []
save_dir = f'/kaggle/tmp/{split}/image/'
os.makedirs(save_dir, exist_ok=True)
if fast_sub:
    xray = read_xray('/kaggle/input/siim-covid19-detection/train/00086460a852/9e8302230c91/65761e66de9f.dcm')
    im = resize(xray, size=512)  
    im.save(os.path.join(save_dir,'65761e66de9f_image.png'))
    image_id.append('65761e66de9f.dcm'.replace('.dcm', ''))
    dim0.append(xray.shape[0])
    dim1.append(xray.shape[1])
    splits.append(split)
    xray = read_xray('/kaggle/input/siim-covid19-detection/train/000c9c05fd14/e555410bd2cd/51759b5579bc.dcm')
    im = resize(xray, size=512)  
    im.save(os.path.join(save_dir, '51759b5579bc_image.png'))
    image_id.append('51759b5579bc.dcm'.replace('.dcm', ''))
    dim0.append(xray.shape[0])
    dim1.append(xray.shape[1])
    splits.append(split)
else:
    for dirname, _, filenames in tqdm(os.walk(f'/kaggle/input/siim-covid19-detection/{split}')):
        for file in filenames:
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(os.path.join(dirname, file))
            im = resize(xray, size=512)  
            im.save(os.path.join(save_dir, file.replace('.dcm', '_image.png')))
            image_id.append(file.replace('.dcm', ''))
            dim0.append(xray.shape[0])
            dim1.append(xray.shape[1])
            splits.append(split)
meta = pd.DataFrame.from_dict({'image_id': image_id, 'dim0': dim0, 'dim1': dim1, 'split': splits})","This code installs the pydicom package and its dependencies, and then uses the package to read in a DICOM image and resize it. Finally, it saves the image in a temporary directory.",8,1,0.07968215340205123
"!conda install gdcm -c conda-forge -yimport os

from PIL import Image
import pandas as pd
from tqdm.auto import tqdmimport numpy as np
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut

def read_xray(path, voi_lut = True, fix_monochrome = True):
    # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way
    dicom = pydicom.read_file(path)
    
    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to 
    # ""human-friendly"" view
    if voi_lut:
        data = apply_voi_lut(dicom.pixel_array, dicom)
    else:
        data = dicom.pixel_array
               
    # depending on this value, X-ray may look inverted - fix that:
    if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
        data = np.amax(data) - data

    data = data - np.min(data)
    data = data / np.max(data)
    data = (data * 255).astype(np.uint8)
        
    return datadef resize(array, size, keep_ratio=False, resample=Image.LANCZOS):
    # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image
    im = Image.fromarray(array)
    '''
    if keep_ratio:
        im.thumbnail((size, size), resample)
    else:
        im = im.resize((size, size), resample)
    '''
    return im'''image_id = []
dim0 = []
dim1 = []
splits = []

for split in ['test', 'train']:
    i = 0
    save_dir = f'/kaggle/tmp/{split}/'

    os.makedirs(save_dir, exist_ok=True)
    
    for dirname, _, filenames in tqdm(os.walk(f'../input/siim-covid19-detection/{split}')):
        for file in filenames:
            # set keep_ratio=True to have original aspect ratio
            xray = read_xray(os.path.join(dirname, file))
            c=Counter()
            c.update(xray.reshape(1,-1)[0])
            ee = np.array(sorted(list(zip(c.keys(),c.values()))))
            plt.bar(ee[:,0],ee[:,1])
            plt.title(split)
            plt.show()
            #im = resize(xray, size=256)  
            #im.save(os.path.join(save_dir, file.replace('dcm', 'jpg')))

            #image_id.append(file.replace('.dcm', ''))
            #dim0.append(xray.shape[0])
            #dim1.append(xray.shape[1])
            #splits.append(split)
            i+=1
        if i == 10:
            break'''train = pd.read_csv('../input/siim-covid19-detection/train_image_level.csv')#path = '../input/siim-covid19-detection/train/000c9c05fd14/e555410bd2cd/51759b5579bc.dcm'
#dicom = pydicom.read_file(path)","This code reads in a DICOM image, applies a VOI LUT (if available), and then transforms the raw data into a ""human-friendly"" view. If the image is monochrome, the code also fixes any inversion that may occur. Finally, the code resizes the image to a standard size (256x256).",9,1,0.18509216681373636
"# Script to search for the in dicom images (in the relevant folders) in the order of their appearance in the csv file

%cd /kaggle/input/siim-covid19-detection/
%matplotlib inline

import pydicom
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from pydicom.pixel_data_handlers.util import apply_voi_lut

# Can't get Andres' fun to work
# def read_xray(path, voi_lut = True, fix_monochrome = True):
  #  dicom = pydicom.read_file(path)
    
  #  # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to ""human-friendly"" view
  #  if voi_lut:
  #      data = apply_voi_lut(dicom.pixel_array, dicom)
  #  else:
  #      data = dicom.pixel_array
               
  #  # depending on this value, X-ray may look inverted - fix that:
  #  if fix_monochrome and dicom.PhotometricInterpretation == ""MONOCHROME1"":
  #      data = np.amax(data) - data
        
  #  data = data - np.min(data)
  #  data = data / np.max(data)
  #  data = (data * 255).astype(np.uint8)
        
  #   return data# Where are the .dcm files? What do the folders look like?

# We loop over all folders and if it ends with "".dcm"" we print it.
pathdf = pd.DataFrame(columns=('root', 'file'))
i = 0
import os
for root, dirs, files in os.walk("".""):
    for file in files:
        # print(root)   # ./test/2fb11712bc93/b056067b8455
        # print(file) # a29c5a68b07b.dcm
        # if file.endswith("".dcm""):                              # mixes train and test files
        if file.endswith("".dcm"") and root.startswith(""./train""): # We only need dcm files and train objects for now
            path_file = os.path.join(root,file)
            #  print(path_file)             # enable to see all the files
            # ./train/cd5dd5e6f3f5/b2ee36aa2df5/d8ba599611e5.dcm [...]
            # These are the paths that will be used to load in the dicom.
            # Don't only print the paths, save them so that we can use them later on. 
            pathdf.loc[i] = [root,file]
            i = i + 1
            
# We have ""test"" and ""train"" folders 
# Within we have 2 subfolders
# And then we have the dcm file.
# We probably just need the ""train"" flders for now

# path_file is the path of one picture, we overwrite the ""path_file"" each time
# print(len(path_file)) # 50
# type(path_file)       # str
# print(path_file)      # 1 [the last ]path: ./train/22353f3ff2d1/191c168c55c0/058d56025fa2.dcm# data.frame of paths
pathdf.head
print(pathdf.shape) # Great: we indeed have 6334 images
pathdf.file
# Aside from all the pictures, we have 2 csv's : train_image_level and train_study_level#1 train_study_level
trainstudy = pd.read_csv('train_study_level.csv')
trainstudy.head(5)
# trainstudy.shape 
# (6054, 5)
# cols: id (unique study identifier), negative, typical, indeterminate, atypical
# rows: 1 row for each study

# these are the study level detections. 
# These are the ouputs in the sample_submission# Separate study objects. These are the output ids for the submission file
trainstudy.iloc[:,0]
# _study should be removed later on when we prepare the submission file#2 train_image_level: AHA the one we're working with now.
trainimage = pd.read_csv('train_image_level.csv')

trainimage.shape
# (6334, 4)

trainimage.head(5)
# cols: id (6334 unique values), boxes, label, StudyInstanceUiD (6054 unique vals)
# rows: 1 row for each image
# The train data set comprises of 6,334 chest scans. 
# StudyInstance are the ppl? We hebben dus meerdere waarden per study object.
# In the folders we have 6054 directories

# These are the image level predictions. 

# type(trainimage) # dataframe

# BFMA wants to order them in this way

","The code above loops through all the folders in the input directory and prints out the path of any file that ends with "".dcm"". It then stores these paths in a dataframe for further processing.

Next, the code reads in the two CSV files that contain the labels for the images. The first file, ""train_study_level.csv"" contains labels at the study level, while the second file, ""train_image_level.csv"" contains labels at the image level.

Finally, the code orders the images in the dataframe according to the labels in the ""train_image_level.csv"" file. This ensures that the images are processed in the correct order for the submission file.",8,3,0.49129524004546943
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import osimport matplotlib.pyplot as plt
from matplotlib import patches, patheffects
import imageiodef read_image_locs(dirname='../input/siim-covid19-detection/train'):
    collect = []
    for dirname, _, filenames in os.walk(dirname):
        for filename in filenames:
            study, series = dirname.split(""/"")[-2:]
            image = filename.replace("".dcm"", """")
            collect.append((study, series, image))
    locs = pd.DataFrame(collect, columns=(""study"", ""series"", ""image""))
    return locs

train_image_locs = read_image_locs()image_level = pd.read_csv(""../input/siim-covid19-detection/train_image_level.csv"")
study_level = pd.read_csv(""../input/siim-covid19-detection/train_study_level.csv"")image_level.head()study_level.head()study_level_ = study_level.copy()
study_level_.id = study_level_.id.str.replace(""_study"", """")
merged = image_level.merge(study_level_, left_on=""StudyInstanceUID"", right_on=""id"", suffixes=(""_image"", ""_study""))
merged = merged.rename({'Negative for Pneumonia': 'Negative', 'Typical Appearance': 'Typical', 'Indeterminate Appearance': 'Indeterminate', 'Atypical Appearance': 'Atypical'}, 
              axis=""columns"")
merged.head()","The code above reads in data from two CSV files: image_level and study_level. These files contain information on individual images and studies, respectively. The code then merges the two files into a single dataframe (merged), and renames some of the columns for clarity. Finally, the code displays the first five rows of the merged dataframe.",8,2,0.10102947239083587
"input_dir=""/kaggle/input/siim-covid19-detection""%%file dicom_image_description.csv
Description,Code
SpecificCharacterSet,CS
SOPClassUID,UI
SOPInstanceUID,UI
StudyDate,DA
StudyTime,TM
AccessionNumber,SH
Modality,CS
PatientName,PN
PatientID,LO
PatientSex,CS
BodyPartExamined,CS
StudyInstanceUID,UI
SeriesInstanceUID,UI
StudyID,SH
SeriesNumber,IS
InstanceNumber,IS
SamplesperPixel,US
PhotometricInterpretation,CS
Rows,US
Columns,US
BitsAllocated,US
BitsStored,US
HighBit,US
PixelRepresentation,US
PixelData,OB!cp ../input/gdcm-conda-install/gdcm.tar .
!tar -xvzf gdcm.tar
!conda install --offline ./gdcm/gdcm-2.8.9-py37h71b2a6d_0.tar.bz2
print(""done"")import pydicom as dicom
import matplotlib.pyplot as plt
import os
import glob
import cv2
import pandas as pd
import csv

# Specify the .dcm folder path
images_path = glob.glob(input_dir+""/train/**/*.dcm"", recursive=True)[:5]
# Specify dest folder path
dest_folder_path = ""/kaggle/tmp""
# list of attributes available in dicom image
# download this file from the given link # https://github.com/vivek8981/DICOM-to-JPG
dicom_image_description = pd.read_csv(""dicom_image_description.csv"")

# make dirs
os.makedirs('/kaggle/tmp/', exist_ok=True)
os.makedirs('/kaggle/tmp/train_images/', exist_ok=True)

with open(dest_folder_path+'/train_dcom_details.csv', 'w', newline ='') as csvfile:
    fieldnames = list(dicom_image_description[""Description""])
    writer = csv.writer(csvfile, delimiter=',')
    # write header
    writer.writerow(fieldnames)
    for n, image_path in enumerate(images_path):
        ds = dicom.dcmread(image_path)
        rows = []
        pixel_array_numpy = ds.pixel_array
        
        image = os.path.basename(image_path).replace('.dcm', '.png')
        cv2.imwrite(os.path.join(dest_folder_path, 'train_images', image), pixel_array_numpy)
        if n % 100 == 0:
            print('{} image converted'.format(n))
        for field in fieldnames:
            if ds.data_element(field) is None:
                rows.append('')
            else:
                x = str(ds.data_element(field)).replace(""'"", """")
                y = x.find("":"")
                x = x[y+2:]
                rows.append(x)
        writer.writerow(rows)plt.imshow(cv2.imread('/kaggle/tmp/train_images/d54f6204b044.png',0), cmap='gray')pd.read_csv(dest_folder_path+'/train_dcom_details.csv').head()",This code converts DICOM images to PNG format and saves them in a folder. It also generates a CSV file with details about the DICOM images.,8,0,0.12754357763637164
"!pip install efficientnet -qimport os

import numpy as np
import pandas as pd
from kaggle_datasets import KaggleDatasets
from sklearn.model_selection import train_test_split
import tensorflow as tf
from sklearn.model_selection import KFoldSEED = 0        #随机数种子，用来KFold分数据集
FOLDS = 5        #交叉验证次数
BATCH_SIZES = 18
EPOCHS = 40
ls = 0.015       # 标签平滑，可以尝试0.015，不用请写0，可抗过拟合
IMAGE_SIZE = (224, 240, 260, 300, 380, 456, 528, 600, 512)

SIIM_para = {}
SIIM_para['SEED'] = SEED
SIIM_para['FOLDS'] = FOLDS
SIIM_para['BATCH_SIZES'] = BATCH_SIZES
SIIM_para['EPOCHS'] = EPOCHS
SIIM_para['IMAGE_SIZE'] = IMAGE_SIZE[8]
print('SIIM_parameters: {}'.format(SIIM_para))def get_lr_callback():
    lr_start   = 1e-4 # 初始学习率
    lr_max   =  2e-4# 最大学习率
    lr_min     = 1e-7 #最小学习率
    lr_ramp_ep =  3 # 用几个epoch达到最大学习率
    lr_sus_ep  =  3# 用最大的学习率跑几个epoch
    lr_decay   = .4 # 退火，常用方法
   
    def lrfn(epoch):
        if epoch < lr_ramp_ep:
            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start
            
        elif epoch < lr_ramp_ep + lr_sus_ep:
            lr = lr_max
            
        else:
            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min
            
        return lr

    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)
    return lr_callbackdef auto_select_strategy():
    try:
        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
        tf.config.experimental_connect_to_cluster(tpu)
        tf.tpu.experimental.initialize_tpu_system(tpu)
        strategy = tf.distribute.experimental.TPUStrategy(tpu)
        print(""Running on TPU:"", tpu.master())
    except ValueError:
        strategy = tf.distribute.get_strategy()
    print(f""Running on {strategy.num_replicas_in_sync} replicas"")
    
    return strategydef build_decoder(with_labels=True, target_size=(256, 256), ext='jpg'):
    def decode(path):
        file_bytes = tf.io.read_file(path)

        if ext == 'png':
            img = tf.image.decode_png(file_bytes, channels=3)
        elif ext in ['jpg', 'jpeg']:
            img = tf.image.decode_jpeg(file_bytes, channels=3)
        else:
            raise ValueError(""Image extension not supported"")
        img = tf.cast(img, tf.float32) / 255.0
        img = tf.image.resize(img, target_size)

        return img
    
    def decode_with_labels(path, label):
        return decode(path), label
    
    return decode_with_labels if with_labels else decode


def build_augmenter(with_labels=True):
    def augment(img):
        if tf.random.uniform(()) > 0.5:
            img = tf.image.flip_left_right(img)
    
        if tf.random.uniform(()) > 0.4:
            img = tf.image.flip_up_down(img)

        if tf.random.uniform(()) > 0.5:
            img = tf.image.rot90(img, k=1)

#        if tf.random.uniform(()) > 0.45:
#            img = tf.image.random_saturation(img, 0.7, 1.3)

#        if tf.random.uniform(()) > 0.45:
#            img = tf.image.random_contrast(img, 0.8, 1.2)
#            
#        if tf.random.uniform(()) > 0.45:
#            img = tf.image.random_brightness(img, 0.1)
        return img
    
    def augment_with_labels(img, label):
        return augment(img), label
    
    return augment_with_labels if with_labels else augment


def build_dataset(paths, labels=None, bsize=128, cache=True,
                  decode_fn=None, augment_fn=None,
                  augment=True, repeat=True, shuffle=1024, 
                  cache_dir=""""):
    if cache_dir != """" and cache is True:
        os.makedirs(cache_dir, exist_ok=True)
    
    if decode_fn is None:
        decode_fn = build_decoder(labels is not None)
    
    if augment_fn is None:
        augment_fn = build_augmenter(labels is not None)
    
    AUTO = tf.data.experimental.AUTOTUNE
    slices = paths if labels is None else (paths, labels)
    
    dset = tf.data.Dataset.from_tensor_slices(slices)
    dset = dset.map(decode_fn, num_parallel_calls=AUTO)
    dset = dset.cache(cache_dir) if cache else dset
    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset
    dset = dset.repeat() if repeat else dset
    dset = dset.shuffle(shuffle) if shuffle else dset
    dset = dset.batch(bsize).prefetch(AUTO)
    
    return dsetCOMPETITION_NAME = ""siimcovid19-512-img-png-600-study-png""
strategy = auto_select_strategy()
REPLICAS = strategy.num_replicas_in_sync * BATCH_SIZES
GCS_DS_PATH = KaggleDatasets().get_gcs_path(COMPETITION_NAME)","This code installs the efficientnet library and imports the os, numpy, pandas, and sklearn libraries. It defines some variables for use later in the code (SEED, FOLDS, BATCH_SIZES, EPOCHS, ls, and IMAGE_SIZE) and then defines a function to get the learning rate callback. The code then defines a function to automatically select the strategy to use (TPU or CPU) and a function to build the decoder. Finally, the code defines a function to build the dataset.",8,3,0.025942606322719008
"# !pip install numpy==1.21.0
# !pip install scikit-image==0.18.1
# !pip install pandas==1.2.5
# !pip install tensorflow-gpu==2.2.0
# !pip install ipython==7.24.1
# !pip install pydicom==2.1.2
# !pip install pylibjpeg==1.3.0 pylibjpeg-libjpeg==1.2.0
# !pip install gdcm

!pip3 install numpy
# !pip3 install pycocotools==2.0.0
!pip3 install scikit-image
!pip3 install pandas
!pip3 install tensorflow-gpu
!pip3 install ipython
!pip3 install pydicom
!pip3 install pylibjpeg pylibjpeg-libjpeg
!pip3 install gdcm
import sys  
sys.path.insert(0, '/kaggle/input/cnnmodel/montagem/codigo/')
from pred_MaskRCNN import *
## test with test set
#path_open_dicom = ""../input/siim-covid19-detection/test/""

## test with train set
#path_open_dicom = ""../input/siim-covid19-detection/train/""

## test with samples set
path_open_dicom = ""../input/cnnmodel/montagem/data_dicom/""

path_open_model = ""/kaggle/input/cnnmodel/montagem/pesos_mrcnn/""

execute(path_open_dicom, path_open_model)
","This code is for testing a Mask R-CNN model on a given dataset of DICOM images. The model is first loaded from the path specified in path_open_model. Then, the DICOM images are loaded from path_open_dicom. Finally, the model is applied to the DICOM images and the results are saved to a new folder.",8,1,0.017476933548501605
"import numpy as np 
import pandas as pd
import random
from sklearn.utils import shuffle
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten
from tensorflow.keras import layers
from xgboost import XGBRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
import xgboost as xgb
import lightgbm as lgb
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from catboost import CatBoostRegressor


import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import tensorflow as tf

import warnings
warnings.filterwarnings('ignore')IMG_SIZE = 224
CHANNELS = 3
BATCH_SIZE = 16
EPOCHS = 10
SEED = 2021

DATA_DIR = '../input/petfinder-pawpularity-score/'
TRAIN_DIR = DATA_DIR + 'train/'
TEST_DIR = DATA_DIR + 'test/'# Configure Strategy. Assume TPU...if not set default for GPU/CPU
tpu = None
try:
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.experimental.TPUStrategy(tpu)
except ValueError:
    # Enable XLA
    tf.config.optimizer.set_jit(enabled = ""autoclustering"")
    strategy = tf.distribute.get_strategy()# Load Train Data
sample_df = pd.read_csv(f'{DATA_DIR}train.csv')
sample_df['Id'] = sample_df['Id'].apply(lambda x: f'{TRAIN_DIR}{x}.jpg')

# Label value to be used for feature model 'classification' training.
sample_df['target_value'] = sample_df['Pawpularity'] / 100.sample_df = shuffle(sample_df, random_state=SEED)
train_size = int(len(sample_df)*0.8)
train_df = sample_df[:train_size]
validation_df = sample_df[train_size:]
train_df.head()training_data = tf.data.Dataset.from_tensor_slices((train_df['Id'].values, train_df['target_value'].values))
validation_data = tf.data.Dataset.from_tensor_slices((validation_df['Id'].values, validation_df['target_value'].values))def load_image_and_label_from_path(image_path, label):
    img = tf.io.read_file(image_path)
    img = tf.image.decode_jpeg(img, channels=CHANNELS)
    img = tf.image.resize_with_pad(img, IMG_SIZE, IMG_SIZE)
    img = tf.image.adjust_brightness(img, 0.5)
    img = tf.image.adjust_saturation(img, 3)
    return img, label

AUTOTUNE = tf.data.experimental.AUTOTUNE #메모리 동적 할당을 위한 AUTOTUNE
training_data = training_data.map(load_image_and_label_from_path, num_parallel_calls=AUTOTUNE) #train 데이터를 불러옴
validation_data = validation_data.map(load_image_and_label_from_path,num_parallel_calls=AUTOTUNE) #validation 데이터를 불러옴","This code imports the necessary libraries for image processing, data manipulation, and machine learning. It then defines some parameters for image processing and machine learning. Next, it loads the training data from a CSV file, shuffles it, and splits it into training and validation sets. Finally, it defines a function for loading images and labels from a path, and applies that function to the training and validation data.",8,0,0.06303115346670025
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiondf_train_metadata = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/train.csv')
df_test_metadata = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/test.csv')
df_train_metadata.head
import tensorflow as tf
import cv2
import missingno as msno
import matplotlib.pyplot as plt

train_image = df_train_metadata.copy()
test_image = df_test_metadata.copy()

train_image[""file_path""] = df_train_metadata[""Id""].apply(lambda x: ""../input/petfinder-pawpularity-score/train/"" + x + "".jpg"")
test_image[""file_path""] = df_test_metadata[""Id""].apply(lambda x: ""../input/petfinder-pawpularity-score/test/"" + x + "".jpg"")



plt.figure(figsize=(20, 20))
row, col = 5, 4
for i in range(row * col):
    plt.subplot(row, col, i+1)
    image = cv2.imread(train_image.loc[i, 'file_path'])
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    target = train_image.loc[i, 'Pawpularity']
    plt.imshow(image)
    plt.title(f""No: {i}"" f""   Pawpularity: {target}"")
plt.show()image_features_train = pd.read_csv('../input/image-features-train/image_features_train.csv')
image_features_test = pd.read_csv('../input/image-features-test/image_features_test.csv')
\

df_train = pd.concat([df_train_metadata['Pawpularity'], df_train_metadata.loc[:,'Subject Focus':'Blur'],image_features_train.loc[:,'centroid_pr_x':'kurtosis_pr_y']], axis=1)
df_test = pd.concat([df_test_metadata.loc[:,'Subject Focus':'Blur'],image_features_test.loc[:,'centroid_pr_x':'kurtosis_pr_y']], axis=1)

df_test.head(3)# from skfeature.function.similarity_based import fisher_score, reliefF, trace_ratio
# from skfeature.function.statistical_based import f_score, chi_square, gini_index
# from skfeature.function.information_theoretical_based import FCBF, JMI
from sklearn import preprocessing
from sklearn.preprocessing import MinMaxScaler

# #ambil kolom untuk label kontinu
label_kontinu = np.asarray(df_train['Pawpularity'])

# # ambil kolom untuk features
features_train = np.asarray(df_train.loc[:, 'Subject Focus':'kurtosis_pr_y'])
features_test = np.asarray(df_test.loc[:, 'Subject Focus':'kurtosis_pr_y'])
# #melakukan label encoding label diskrit
# # encoder = preprocessing.LabelEncoder().fit(label_diskrit)
# # transformed_label_diskrit = encoder.transform(label_diskrit)
# # print(transformed_label_diskrit)

# melakukan feature scaling
scaler = preprocessing.MinMaxScaler(feature_range=(0, 10)).fit(features_train)
scaled_feature_train = scaler.transform(features_train)
scaled_features_test = scaler.transform(features_test)
print(scaled_feature_train)

# # bentuk awal method dan parameter gini-index terdapat X dan y
# # dimana X adalah fitur dan y adalah label
# # MIM.mim(X, y)
# # ranked_index = fisher_score.fisher_score(scaled_feature, transformed_label_diskrit, mode='raw')
# # print(""\nfisher score raw"")
# # print(ranked_index)

# # ranked_index = fisher_score.fisher_score(scaled_feature, transformed_label_diskrit, mode='rank')
# # print(""\nfisher score rank"")
# # print(ranked_index)

# ranked_index = JMI.jmi(scaled_feature_train, label_kontinu, mode='index')
# print(""\nJMI"")
# print(ranked_index)


# # menampilkan fitur yang sudah diurutkan berdasarkan seleksi fitur
# result_train = scaled_feature_train[:, ranked_index[:]]
# print(result_train)
# result_test = scaled_features_test[:, ranked_index[:]]ranked_index = [19, 18, 17, 14, 12, 11, 6, 3, 13, 2, 15, 8, 16, 5, 7, 4, 0, 1, 10, 9]
print(""\nMIM"")
print(ranked_index)


# menampilkan fitur yang sudah diurutkan berdasarkan seleksi fitur
result_train = scaled_feature_train[:, ranked_index[:]]
print(result_train)
result_test = scaled_features_test[:, ranked_index[:]]def rmse(predict, actual):
    predict = np.array(predict)
    actual = np.array(actual)

    distance = predict - actual

    square_distance = distance ** 2

    mean_square_distance = square_distance.mean()

    score = np.sqrt(mean_square_distance)

    return score","# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside",8,23,0.43236581822672693
"!pip install --user /kaggle/input/fastaimaster/torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl# kaggle datasets download -d nasheqlbrm/fastaimasterimport fastai
from fastai.vision.all import *# import fastbook
# from fastbook import *
from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype
from fastai.tabular.all import *
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
#from dtreeviz.trees import *
from IPython.display import Image, display_svg, SVG

pd.options.display.max_rows = 20
pd.options.display.max_columns = 12

# plt.rcParams['figure.dpi'] = 100
# plt.rcParams['savefig.dpi'] = 100
%config InlineBackend.figure_format = 'retina'path = Path('/kaggle/input/petfinder-pawpularity-score')Path.BASE_PATH = path
path.ls()df = pd.read_csv(path/('train.csv'), low_memory=False)","1. The code imports the fastai library and defines a function to read in a dataset from a CSV file.

2. The code then defines a variable called ""df"" which stores the data from the CSV file.

3. Finally, the code prints out the contents of the ""df"" variable.",7,3,0.06794821008371091
"# Whether this notebook is inference mode or not
is_inference = False

# Whether to normalize target from [0,100] to [0,1]
is_normalize_target = Trueif not is_inference:
    !pip install -q torch-summary==1.4.5
    !pip install -q timm
    !pip install -q --upgrade wandb
    !pip install -q grad-cam==1.3.3
    !pip install -q torch-lr-finder==0.2.1
else:
    import sys
    sys.path.append(""../input/timm-pytorch-image-models/pytorch-image-models-master"")
    sys.path.append(""../input/reighns-gradcam/pytorch-grad-cam-master"")
    sys.path.append(""../input/reighns-ttach/ttach-master"")import collections
import gc
import os
import random
import warnings
from collections import defaultdict
from dataclasses import asdict, dataclass, field
from typing import *

import numpy as np
import pandas as pd
import timm
import torchfrom pathlib import Path
import pathlib

class config:
    warnings.filterwarnings(""ignore"", category=UserWarning)
    # Need to change in local path
    DATA_DIR = Path(""../input/petfinder-pawpularity-score"")
    OUTPUT_DIR = Path(""./"")
    LOGS_DIR = Path(OUTPUT_DIR, ""logs"")
    MODEL_DIR = Path(OUTPUT_DIR, ""model"")
    OOF_DIR = Path(OUTPUT_DIR, ""oof"")
    LOGS_DIR.mkdir(parents=True, exist_ok=True)
    MODEL_DIR.mkdir(parents=True, exist_ok=True)
    OOF_DIR.mkdir(parents=True, exist_ok=True)
    
configfrom logging import INFO, FileHandler, Formatter, StreamHandler, getLogger
import logging

def init_logger(log_file: str = Path(config.LOGS_DIR, ""info.log"")) -> logging.Logger:
    """"""Initialize logger and save to file.

    Consider having more log_file paths to save, eg: debug.log, error.log, etc.

    Args:
        log_file (str, optional): [description]. Defaults to Path(LOGS_DIR, ""info.log"").

    Returns:
        logging.Logger: [description]
    """"""
    logger = getLogger(__name__)
    logger.setLevel(INFO)
    stream_handler = StreamHandler()
    stream_handler.setFormatter(
        Formatter(""%(asctime)s: %(message)s"", ""%Y-%m-%d %H:%M:%S"")
    )
    file_handler = FileHandler(filename=log_file)
    file_handler.setFormatter(
        Formatter(""%(asctime)s: %(message)s"", ""%Y-%m-%d %H:%M:%S"")
    )
    logger.addHandler(stream_handler)
    logger.addHandler(file_handler)

    return loggerconfig.logger = init_logger()device = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")
config.logger.info(f""We are using {device}"")",This code initializes a logger to save log information to a file. The logger is set to output info level messages. A stream handler and file handler are added to the logger. The stream handler outputs messages to the console. The file handler outputs messages to the log file.,8,0,0.1283625708720564
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport numpy as np
def preprocessImagePrediction(imagePath,width,height):
    image = tf.keras.preprocessing.image.load_img(imagePath, target_size=(width,height))
    input_arr = tf.keras.preprocessing.image.img_to_array(image)
    input_arr = np.array([input_arr])  
    return input_arrimport tensorflow as tf


# load json and create model
json_file = open('../input/mobilenet-classification/mobNet_classification.json', 'r')
loaded_model_json = json_file.read()
json_file.close()
mobNet_v2_classification = tf.keras.models.model_from_json(loaded_model_json)
# load weights into new model
mobNet_v2_classification.load_weights(""../input/mobilenet-classification/mobNet_classification.h5"")
print(""Loaded model from disk"")result_mob = []
import os
# assign directory
directory = '../input/petfinder-pawpularity-score/test'
 
# iterate over files in
# that directory
for filename in os.listdir(directory):
    f = os.path.join(directory, filename)
    # checking if it is a file
    prediction = mobNet_v2_classification.predict(preprocessImagePrediction(f,160,160))
    result_mob.append(round(prediction[0][0],2)*100)df_train = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')
df_test = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')df_testresult_final = []
for result in result_mob:
    result_final.append(result)
    ","The code loads a MobileNet model that has been trained on pet images and makes predictions on a test set of pet images. The predictions are stored in a list, and the list is converted into a DataFrame. The DataFrame is then outputted.",8,3,0.11899177882665711
"load_model = False              # False    #True
KAGGLE = True                  #True   #False


print(""load_model = "", load_model)
print(""KAGGLE = "", KAGGLE)if KAGGLE:
    # This Python 3 environment comes with many helpful analytics libraries installed
    # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
    # For example, here's several helpful packages to load

    import numpy as np # linear algebra
    import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

    # Input data files are available in the read-only ""../input/"" directory
    # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

    import os
    
    
    
#     > ls /kaggle
#     input/  lib/  working/
#     > pwd
#     '/kaggle/working'
#     > ls ../working
#     __notebook_source__.ipynb



#     ../input/petfinder-pawpularity-score/sample_submission.csv
#     ../input/mypetmodels/mymodel_epoch8.pth
#     ../input/pythonbox/Box-master/.github
#     ../input/timmpackage/pytorch-image-models-master/
#     ../working



#     for dirname, _, filenames in os.walk('/kaggle/input'):
    for dirname, _, filenames in os.walk('/kaggle/working'):
        for filename in filenames:
            print(os.path.join(dirname, filename))

    # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
    # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session
if KAGGLE: 
    root_dir = '/kaggle/input/petfinder-pawpularity-score/'
#     model_dir = '/kaggle/input/trainedModels/'
    model_dir = '../input/mypetmodels'
else:
    root_dir = '../ori_data/petData/'
    model_dir = '.'

        
        
print(""root_dir = "", root_dir)
print(""model_dir = "", model_dir)# !pip install opencv-python
# !pip install python-box timm pytorch-lightning==1.4.0 grad-cam ttach# based on the post here: https://www.kaggle.com/c/petfinder-pawpularity-score/discussion/275094

import sys


if KAGGLE:
#     sys.path.append(""../input/Box-master/"")
#     sys.path.append(""../input/pytorch-image-models-master/"")
    sys.path.append(""../input/pythonbox/Box-master/"")
    sys.path.append(""../input/timmpackage/pytorch-image-models-master/"")
else:
    packge_dir = '/home1/yhl/jupyter/petfinder/packages_dir/'
    sys.path.append(packge_dir + ""Box-master/"")
    sys.path.append(packge_dir + ""pytorch-image-models-master/"")import os
import warnings
from pprint import pprint
from glob import glob
from tqdm import tqdm
import gc

import torch
import torchvision.transforms as T
from torchvision.io import read_image

import torch.optim as optim
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from box import Box
from timm import create_model
from sklearn.model_selection import StratifiedKFold
from torch.utils.data import DataLoader, Dataset
# from pytorch_grad_cam import GradCAMPlusPlus
# from pytorch_grad_cam.utils.image import show_cam_on_image


import pytorch_lightning as pl
from pytorch_lightning.utilities.seed import seed_everything
from pytorch_lightning import callbacks
from pytorch_lightning.callbacks.progress import ProgressBarBase
from pytorch_lightning.callbacks.early_stopping import EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from pytorch_lightning import LightningDataModule, LightningModule

from pathlib import Path
import time


warnings.filterwarnings(""ignore"")batch_size_train_val = 32   #32    #31
#32
#96   #64

print(""batch_size_train_val = "", batch_size_train_val)","This code defines two variables, load_model and KAGGLE. Load_model is set to False, and KAGGLE is set to True. If KAGGLE is set to True, the code will run in the Kaggle environment. Otherwise, it will run locally.",8,4,0.16176528364780554
"import sys
sys.path.append(""../input/cpythonlibrary/cpython-master/"")
sys.path.append(""../input/coatnet-module-for-img-classification/External-Attention-pytorch-master/model/attention/"")import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import torch
import albumentations
import torch.nn as nn
import torch.nn.functional as F
import gc
import cv2
import warnings

from torch.utils.data import DataLoader
from PIL import Image
from tqdm import tqdm
from Lib import copy 
from CoAtNet import CoAtNet

warnings.filterwarnings(""ignore"")class config:
    TRAINING_FILE = ""../input/petfinder-pawpularity-score/train.csv""
    TRAINING_IMAGE_PATH = ""../input/petfinder-pawpularity-score/train/""
    DEVICE = torch.device(""cuda"")
    TRAIN_BATCH_SIZE = 64
    VALID_BATCH_SIZE = 64
    EPOCHS = 5
    
class AverageMeter:
    """"""
    Computes and stores the average and current value
    """"""
    def __init__(self):
        self.reset()

    def reset(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0

    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.countnew_train = pd.read_csv(config.TRAINING_FILE)# create folds
from sklearn import model_selection

new_train[""kfold""] = -1    
new_train = new_train.sample(frac=1).reset_index(drop=True)
y = new_train.Pawpularity.values
kf = model_selection.StratifiedKFold(n_splits=5)

for f, (t_, v_) in enumerate(kf.split(X = new_train, y = y)):
    new_train.loc[v_, 'kfold'] = fclass petFinderDataset:
    def __init__(self, dataframe, is_valid = 0):
        self.dataframe = dataframe
        self.is_valid = is_valid
        if self.is_valid == 1: # transforms for validation images
            self.aug = albumentations.Compose([
            albumentations.RandomResizedCrop(224, 224),
            albumentations.Normalize(
                mean=[0.485, 0.456, 0.406], 
                std=[0.229, 0.224, 0.225], 
                max_pixel_value=255.0, 
                p=1.0
            )], p=1.)

        else:       # transfoms for training images 
            self.aug = albumentations.Compose([
            albumentations.RandomResizedCrop(224, 224),
            albumentations.Transpose(p=0.5),
            albumentations.HorizontalFlip(p=0.5),
            albumentations.VerticalFlip(p=0.5),
            albumentations.ShiftScaleRotate(p=0.5),
            albumentations.HueSaturationValue(
                hue_shift_limit=0.2, 
                sat_shift_limit=0.2, 
                val_shift_limit=0.2, 
                p=0.5
            ),
            albumentations.RandomBrightnessContrast(
                brightness_limit=(-0.1,0.1), 
                contrast_limit=(-0.1, 0.1), 
                p=0.5
            ),
            albumentations.Normalize(
                mean=[0.485, 0.456, 0.406], 
                std=[0.229, 0.224, 0.225], 
                max_pixel_value=255.0, 
                p=1.0
            ),
            albumentations.CoarseDropout(p=0.5),
            albumentations.Cutout(p=0.5)], p=1.)
    
    def __len__(self):
        return len(self.dataframe)

    def __getitem__(self, item):
        df = self.dataframe.iloc[item, :]

        # converting jpg format of images to numpy array
        img = np.array(Image.open(config.TRAINING_IMAGE_PATH + df[""Id""] + '.jpg')) 
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = self.aug(image = img)['image']
        img = np.transpose(img , (2,0,1)).astype(np.float32) # 2,0,1 because pytorch excepts image channel first then dimension of image
        
        return {
            'image': torch.tensor(img, dtype = torch.float),
            'tabular_data' : torch.tensor(df[1:-2], dtype = torch.float),
            'target' : torch.tensor(df['Pawpularity'], dtype = torch.float)
        }img = petFinderDataset(new_train)[71]['image']
plt.imshow(np.transpose(img.numpy(), (1,2,0)))
petFinderDataset(new_train)[71]['tabular_data']","The code imports the necessary libraries, defines a config class, and creates a custom dataset class called petFinderDataset. The petFinderDataset class can be used to load data from the petfinder-pawpularity-score dataset. The class provides methods for reading data from the dataset and for applying data augmentation transforms.",8,3,0.07960206835851563
"# Standard imports
import os
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objs as go
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import trange
from colorama import Fore
from glob import glob
import json
from pprint import pprint
import time
import cv2
from enum import Enum
from IPython.display import display
import random
import inspect

# For Data preparation
from sklearn.preprocessing import *
from sklearn.model_selection import *
from sklearn.metrics import *

# Tensorflow modules
import tensorflow as tf
from tensorflow.keras import layers as tf_l
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import MeanSquaredError
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint 
from tensorflow.keras.metrics import RootMeanSquaredError
from tensorflow.keras.utils import plot_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import load_model, save_model, Model
import tensorflow.keras.backend as K
from tensorflow.keras import Input


import warnings
warnings.filterwarnings(""ignore"")

# To ignore tensorflow warnings
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

print(f""GPU is available : {tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)}"")class Config(Enum):
    DATA_CSV = ""../input/petfinder-cv-dataset/data.csv""
    TEST_CSV = ""../input/petfinder-cv-dataset/test.csv""
    IMG_SHAPE = 224
    BATCH_SIZE = 64
    EPOCHS = 10

    META_FEATURES = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',
       'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']
    LABEL = ""Pawpularity""def setSeed(seed):
    """"""
    Setting the seed of all the random function to maintain reproducibility
    
    """"""
    np.random.seed(seed)
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    os.environ['TF_CUDNN_DETERMINISTIC'] = str(seed)
    tf.random.set_seed(seed)
    print('SEEDITIZATION DONE !')

setSeed(0)data_df = pd.read_csv(Config.DATA_CSV.value)
test_df = pd.read_csv(Config.TEST_CSV.value)data_df.head()test_df.head()class CustomModel:
    def __init__(self, filters : list, kernel_sizes : list, img_dim = 512, use_dropout = False):
        INPUT = tf_l.Input(shape = [img_dim, img_dim, 3])
        
        x = tf_l.Conv2D(
                filters = filters[0],
                kernel_size = kernel_sizes[0],
                padding = 'same',
                activation = ""relu"",
            )(INPUT)

        x = tf_l.BatchNormalization()(x)
        x = tf_l.MaxPooling2D(pool_size = (2, 2))(x)

        if use_dropout:
            x = tf_l.Dropout(rate = 0.2)(x)
        
        for i in range(1, len(filters)):
            x = tf_l.Conv2D(
                filters = filters[i],
                kernel_size = kernel_sizes[i],
                padding = 'same',
                activation = ""relu"",
            )(x)

            x = tf_l.BatchNormalization()(x)
            x = tf_l.MaxPooling2D(pool_size = (2, 2))(x)

            if use_dropout:
                x = tf_l.Dropout(rate = 0.2)(x)
                
        x = tf_l.GlobalMaxPooling2D()(x)
        
        x = tf_l.Dense(128, kernel_initializer = ""he_uniform"", activation = ""relu"")(x)
        x = tf_l.Dense(32, kernel_initializer = ""he_uniform"", activation = ""relu"")(x)
        OUTPUT = tf_l.Dense(1, kernel_initializer = ""he_uniform"", activation = ""relu"")(x)
        
        self.model = tf.keras.Model(inputs = INPUT, outputs = OUTPUT)
    
    def __call__(self):
        return self.model
    ","This class defines a custom model for a convolutional neural network. The model consists of a series of convolutional layers, pooling layers, and fully connected layers. The number of filters and kernel sizes for each layer are configurable. The model also includes batch normalization and dropout for regularization.",9,0,0.05128167199127416
"import sys
sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master') ## Importing Timm Libraryimport os


import fastai 
import os
import warnings
from pprint import pprint
from glob import glob
from tqdm import tqdm
from fastai.vision.all import *
import torch

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from timm import create_model

#Importing Dataloaders

from sklearn.model_selection import StratifiedKFold
from torchvision.io import read_image
from torch.utils.data import DataLoader, Dataset

#Augmentation & Preprocessing Modules  

import albumentations
from albumentations.pytorch import ToTensorV2 
from albumentations import ImageOnlyTransform
import random
import timm
import cv2

#For enabling fp16

from torch.cuda.amp import autocast, GradScaler  

import warnings 
warnings.filterwarnings('ignore')    ##ignore warning

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') ### Enabling use of cudaclass Config: 
    model_name='swin_base_patch4_window12_384'  # which model to use
    pretrained = False # enable pretrained weights
    train_dir = '../input/petfinder-pawpularity-score/train' # Train Image Directory
    train_csv = '../input/abhi-folds-petfinder/train_10folds.csv' # Train Csv Location
    
    test_dir = '../input/petfinder-pawpularity-score/test' # Test Image Directory
    test_csv = '../input/petfinder-pawpularity-score/test.csv' # Test Csv Location
    sample_csv = '../input/petfinder-pawpularity-score/sample_submission.csv' # Sample Submission
    
    image_size= 384   # Image Size for training / inference
    num_workers=4  #number of worker
    targets = 1  # number of targets
    batch_size=6 # Batch size
    weight_decay=1e-4  #Weight decay for optimizer 
    seed=42 # SEED
    n_fold=10  #No of folds
    trn_fold=[0, 1, 2, 3,4,5,6,7,8,9]  #Folds to be used in training / inference
    train=False  
    model_dir = '../input/petfinder-v0-models/exp0'  # Saved models directorydef seed_torch(seed=42):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.backends.cudnn.deterministic = True

seed_torch(seed=Config.seed)class PetDataset:
    def __init__(self, df,image_path, augmentations):
        self.image_path = image_path
        self.df = df
        self.augmentations = augmentations
        
    def __len__(self):
        return len(self.df)
    
    def __getitem__(self, item):
        id_ = self.df.Id.iloc[item] 
        path = f'{self.image_path}/{id_}.jpg' # Getting Image paths for samples

        targets = self.df.Pawpularity.iloc[item] # Target value for samples
        image = cv2.imread(path)  # Reading Image
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Converting BGR to RGB images
        
        if self.augmentations is not None:
            augmented = self.augmentations(image=image)  # Apply Augmentations
            image = augmented[""image""]
            
        image = np.transpose(image, (2, 0, 1)).astype(np.float32)    
        image = torch.tensor(image, dtype=torch.float) 
        
        targets = torch.tensor(targets, dtype=torch.float) / 100  # For classification
        return image, targets
            def get_transforms(*, data):

    if data == 'valid':
        return albumentations.Compose([
            albumentations.Resize(Config.image_size, Config.image_size),   # Resize all images to 384 image size.
            albumentations.Normalize(     
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225],
            max_pixel_value=255.0,
            p=1.0,
        ),           

        ])

class RMSELoss(nn.Module):
    def __init__(self, eps=1e-6):
        super().__init__()
        self.mse = nn.MSELoss()
        self.eps = eps

    def forward(self, yhat, y):
        loss = torch.sqrt(self.mse(yhat, y) + self.eps)
        return loss","This code defines a class for loading and preprocessing pet images for training or inference. The class inherits from the PyTorch Dataset class. The class takes in a DataFrame containing pet image information and paths, as well as a list of image augmentation transforms. The __len__ and __getitem__ methods are implemented to allow for indexing of images and targets.

The get_transforms function defines a set of image augmentation transforms to be applied to pet images. These include resizing, normalization, and random horizontal flips.

The RMSELoss class inherits from the PyTorch nn.Module class and implements a custom loss function for regression tasks. This loss function is the root mean squared error between predictions and targets.",7,7,0.13312006970815646
"import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import matplotlib.patches as patches
%matplotlib inline

import tensorflow as tf
from tensorflow import keras
import tensorflow.keras.layers as tfl
from tensorflow.keras import regularizers

from sklearn.model_selection import train_test_split, KFold
from sklearn.decomposition import PCA
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from sklearn.cluster import KMeans

import os
from multiprocessing import cpu_count
from tqdm.notebook import tqdm
from sklearn.model_selection import StratifiedKFold
from scipy.stats import pearsonr
from PIL import Image

import glob
import sys
import cv2
import imageio
import joblib
import math
import warnings
import torch
import imagehash
from sklearn.cluster import KMeans
from collections import Counter
from skimage.color import rgb2lab, deltaE_cie76

import warnings
warnings.filterwarnings(""ignore"")

tqdm.pandas()
np.random.seed(0)
tf.random.set_seed(0)# the original file
# train = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/train.csv')
# train['path'] = '../input/petfinder-pawpularity-score/train/' + train['Id'] + '.jpg'
# train.head(3)test = pd.read_csv('/kaggle/input/petfinder-pawpularity-score/test.csv')
test['path'] = '../input/petfinder-pawpularity-score/test/' + test['Id'] + '.jpg'# feature pre-extracted file - to save time. (R,G,B columns are not used in this notebook)
train = pd.read_csv('../input/train-final/train_final.csv')
train = train.drop('Unnamed: 0', axis=1)
train['path'] = '../input/petfinder-pawpularity-score/train/' + train['Id'] + '.jpg'
train# importing yolov5 without internet 
!mkdir /root/.config/Ultralytics/
!cp ../input/yolo-arial/Arial.ttf /root/.config/Ultralytics/Arial.ttf
yolov5x6_model = torch.hub.load('../input/d/nilavanakilan/yolov5/', 'custom', source='local', force_reload=True, path='../input/ultralyticsyolov5aweights/yolov5x6.pt')# Get Image Info
def get_image_info(file_path, plot=False):
    # Read Image
    image = imageio.imread(file_path)
    h, w, c = image.shape
    
    if plot: # Debug Plots
        fig, ax = plt.subplots(1, 2, figsize=(8,8))
        ax[0].set_title('Pets detected in Image', size=16)
        ax[0].imshow(image)
        
    # Get YOLOV5 results using Test Time Augmentation for better result
    results = yolov5x6_model(image, augment=True)
    
    # Mask for pixels containing pets, initially all set to zero
    pet_pixels = np.zeros(shape=[h, w], dtype=np.uint8)
    
    # Dictionary to Save Image Info
    h, w, _ = image.shape
    image_info = { 
        'n_pets': 0, # Number of pets in the image
        'labels': [], # Label assigned to found objects
        'thresholds': [], # confidence score
        'coords': [], # coordinates of bounding boxes
        'x_min': 0, # minimum x coordinate of pet bounding box
        'x_max': w - 1, # maximum x coordinate of pet bounding box
        'y_min': 0, # minimum y coordinate of pet bounding box
        'y_max': h - 1, # maximum x coordinate of pet bounding box
    }
    
    # Save found pets to draw bounding boxes
    pets_found = []
    
    # Save info for each pet
    for x1, y1, x2, y2, treshold, label in results.xyxy[0].cpu().detach().numpy():
        label = results.names[int(label)]
        if label in ['cat', 'dog']:
            image_info['n_pets'] += 1
            image_info['labels'].append(label)
            image_info['thresholds'].append(treshold)
            image_info['coords'].append(tuple([x1, y1, x2, y2]))
            image_info['x_min'] = max(x1, image_info['x_min'])
            image_info['x_max'] = min(x2, image_info['x_max'])
            image_info['y_min'] = max(y1, image_info['y_min'])
            image_info['y_max'] = min(y2, image_info['y_max'])
            
            # Set pixels containing pets to 1
            pet_pixels[int(y1):int(y2), int(x1):int(x2)] = 1
            
            # Add found pet
            pets_found.append([x1, x2, y1, y2, label])

    if plot:
        for x1, x2, y1, y2, label in pets_found:
            c = 'red' if label == 'dog' else 'blue'
            rect = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, edgecolor=c, facecolor='none')
            # Add the patch to the Axes
            ax[0].add_patch(rect)
            ax[0].text(max(25, (x2+x1)/2), max(25, y1-h*0.02), label, c=c, ha='center', size=14)
                
    # Add Pet Ratio in Image
    image_info['pet_ratio'] = pet_pixels.sum() / (h*w)

    if plot:
        # Show pet pixels
        ax[1].set_title('Pixels Containing Pets', size=16)
        ax[1].imshow(pet_pixels)
        plt.show()
        
    return image_info# # Image Info train
# IMAGES_INFO = {
#     'n_pets': [],
#     'label': [],
#     'coords': [],
#     'x_min': [],
#     'x_max': [],
#     'y_min': [],
#     'y_max': [],
#     'pet_ratio': [],
# }


# for idx, file_path in enumerate(tqdm(train['path'])):
#     image_info = get_image_info(file_path, plot=False)
    
#     IMAGES_INFO['n_pets'].append(image_info['n_pets'])
#     IMAGES_INFO['coords'].append(image_info['coords'])
#     IMAGES_INFO['x_min'].append(image_info['x_min'])
#     IMAGES_INFO['x_max'].append(image_info['x_max'])
#     IMAGES_INFO['y_min'].append(image_info['y_min'])
#     IMAGES_INFO['y_max'].append(image_info['y_max'])
#     IMAGES_INFO['pet_ratio'].append(image_info['pet_ratio'])
    
#     # Not Every Image can be Correctly Classified
#     labels = image_info['labels']
#     if len(set(labels)) == 1: # unanimous label
#         IMAGES_INFO['label'].append(labels[0])
#     elif len(set(labels)) > 1: # Get label with highest confidence
#         IMAGES_INFO['label'].append(labels[0])
#     else: # unknown label, yolo could not find pet
#         IMAGES_INFO['label'].append('unknown')","This code imports the necessary libraries for working with the data, including numpy, pandas, matplotlib, and tensorflow. It also sets up the environment for using Ultralytics YOLOv5.

The get_image_info function takes an image file path and returns a dictionary containing information about the pets found in the image. This includes the number of pets, their labels, bounding box coordinates, and the ratio of pet pixels to total pixels in the image.",9,4,0.15935152029330482
"import sys
sys.path.append(""../input/pytorch-tabnet-zip"")import os

import pandas as pd
import numpy as np
import datatable as dt
import warnings
import random
warnings.filterwarnings('ignore')
pd.set_option('max_columns',None)
from sklearn.metrics import mean_squared_error

from time import time
import pprint
import joblib
from functools import partial
from sklearn.model_selection import KFold, StratifiedKFold

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

from pytorch_tabnet.tab_model import TabNetRegressorFOLDER = ""/kaggle/input/petfinder-pawpularity-score/""
TRAIN_FNAME = os.path.join(FOLDER, ""train.csv"")
TEST_FNAME = os.path.join(FOLDER, ""test.csv"")
SUBMISSION_FNAME = os.path.join(FOLDER, ""sample_submission.csv"")

RANDOM_STATE = 42
TEST_SIZE = 0.1
MAX_EPOCHS_TABNET = 200def rmse_fn(y_pred, y_true):
    return np.sqrt(mean_squared_error(y_pred, y_true))train = pd.read_csv(TRAIN_FNAME)
test = pd.read_csv(TEST_FNAME)
submission = pd.read_csv(SUBMISSION_FNAME)train.shape, test.shape, submission.shapetrain.head()","This code imports the sys and os modules, as well as pandas, numpy, datatable, warnings, and random.

sys.path.append(""../input/pytorch-tabnet-zip"") allows the code to access the pytorch-tabnet-zip folder.

The code sets warnings.filterwarnings('ignore') to ignore warnings.

pd.set_option('max_columns',None) allows pandas to display all columns in a dataframe.

The code defines a rmse_fn function that calculates the root mean squared error.

The code then reads in the train, test, and submission csv files.

The code then splits the train data into train and test sets, with the test set being 10% of the total data.

The code then trains a TabNetRegressor on the train set and predicts on the test set.

The code then outputs the classification report.",8,14,0.08451490482691398
"import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn import metrics

import os
import pathimport math

def sigmoid(x):
  return 1 / (1 + math.exp(-x))oof_values = pd.read_csv('../input/swim-classify/oof_df.csv') 
#oof_valuesoof_values['preds'] = oof_values['preds'].apply(sigmoid)
oof_values['preds'] = oof_values['preds'] * 100cv_score = metrics.mean_squared_error(oof_values['Pawpularity'], oof_values['preds'], squared = False)
cv_scoreerr = []
for row in zip(oof_values['Pawpularity'], oof_values['preds']):
    err.append(metrics.mean_squared_error([row[0]], [row[1]], squared = False))
    
oof_values['error'] = err

display(oof_values.head())def make_ranges(value):
    if value <= 10:
        return 1
    elif value > 10 and value <= 20:
        return 2
    elif value > 20 and value <= 30:
        return 3
    elif value > 30 and value <= 40:
        return 4
    elif value > 40 and value <= 50:
        return 5
    elif value > 50 and value <= 60:
        return 6
    elif value > 60 and value <= 70:
        return 7
    elif value > 70 and value <= 80:
        return 8
    elif value > 80 and value <= 90:
        return 9
    elif value > 90:
        return 10

oof_values['range'] = oof_values['Pawpularity'].apply(make_ranges)","This code imports the pandas, numpy, matplotlib, seaborn, and sklearn libraries. It defines a sigmoid function, reads in a CSV file containing predictions and actual values, applies the sigmoid function to the predictions, and calculates the mean squared error between the predictions and actual values. It also creates a list of errors and adds it to the dataframe. Finally, it creates ranges for the actual values and adds them to the dataframe.",9,5,0.07708117546990034
"import numpy as np
import pandas as pd
from PIL import Image
import cv2, os

from tqdm.auto import tqdmdef resize_and_crop(image_path, new_size):
    image = Image.open(image_path)
    size = image.size
    aspect_ratio = size[0] / size[1]
    if aspect_ratio >= 1.0:
        new_width = int(new_size * aspect_ratio)
        new_height = new_size
    else:
        new_width = new_size
        new_height = int(new_size / aspect_ratio)
    image = image.resize((new_width, new_height), Image.ANTIALIAS)  
    width, height = image.size
    
    left = int((width - new_size) / 2)
    top = int((height - new_size) / 2)
    right = int((width + new_size) / 2)
    bottom = int((height + new_size) / 2)

    # Crop the center of the image
    image = image.crop((left, top, right, bottom))
    image = image.resize((new_size, new_size), Image.ANTIALIAS)# to just ensure
    
    return imagenew_size = 224
os.makedirs('./train', exist_ok=True)

for roots, dirs, files in os.walk('../input/petfinder-pawpularity-score/train'):
    for file in tqdm(files):
        image_path = os.path.join(roots, file)
        image = resize_and_crop(image_path, new_size)
        image.save(f'./train/{file}')# %%time
# !tar -zcf pawfinder_train_data.tar.gz -C ""./train/"" .","This code imports the numpy and pandas libraries, as well as the Image module from the PIL library. It also imports the cv2 and os modules.

The resize_and_crop() function takes an image path and a new size as input. It opens the image and gets its size. It then calculates the aspect ratio of the image. If the aspect ratio is greater than or equal to 1.0, the new width of the image is set to the new size times the aspect ratio, and the new height is set to the new size. If the aspect ratio is less than 1.0, the new width is set to the new size, and the new height is set to the new size divided by the aspect ratio. The image is then resized to the new width and height.

The code then crops the image to the desired new size. Finally, the image is resized to the new size again, just to ensure that it is the correct size.

The new_size variable is set to 224. The code then creates a train directory, if it doesn't already exist.

The code then loops through the roots, dirs, and files in the os.walk() function. For each file, the image path is joined with the file name, the image is resized and cropped, and the image is saved in the train directory.",9,6,0.24271996584226602
"import sys
sys.path.append(""../input/cleanfid20211014"")

import os
import glob
from pathlib import Path

from tqdm import tqdm

import torch

from cleanfid import resize
from cleanfid.resize import FolderResizer
from cleanfid.utils import EXTENSIONS


SIZES = [224, 384, 512] # resize all images to these sizes (size, size)
OUTPUT_EXTENSION = '.png'
BASE = '../input/petfinder-pawpularity-score/'
FOLDERS = ['test', 'train'] # resize all images in these folders
LIMIT = None # None=no limit. Set to 10 or 30 or whatever to test a few images

BATCH_SIZE = 64
NUM_WORKERS = 4 # set to number of cpu cores. kaggle currently allows 4
USE_CUDA = False

# Shouldn't need to change the following if running this on kaggle
OUTFOLDER = '/kaggle/working'use_cuda = False
if USE_CUDA:
    use_cuda = torch.cuda.is_available()
device = torch.device(""cuda:0"" if use_cuda else ""cpu"")

params = {'batch_size': BATCH_SIZE,
          'num_workers': NUM_WORKERS}

## Some code adapted from: https://github.com/GaParmar/clean-fid
def process_dir(files, size, new_folder):
    size_tuple = (size, size)
    fn_resize = resize.make_resizer(""PIL"", True, ""bicubic"", size_tuple)
    dataset = FolderResizer(files=files, outpath=new_folder,
            fn_resize=fn_resize, output_ext=OUTPUT_EXTENSION)
    img_gener = torch.utils.data.DataLoader(dataset, **params)
    for item in tqdm(img_gener):
        pass

for folder in FOLDERS:
    files = [file for ext in EXTENSIONS for file in glob.glob(os.path.join(
        BASE, folder, f""**/*.{ext}""), recursive=True)]
    files = sorted(files)

    if LIMIT is not None:
        files = files[:LIMIT]

    for size in SIZES:
        new_folder = os.path.join(OUTFOLDER, folder + str(size))
        Path(new_folder).mkdir(parents=True, exist_ok=True)
        
        print(f""Found {len(files)} images for folder {new_folder}"")
        process_dir(files, size, new_folder)","The code above imports the sys module and appends the cleanfid20211014 folder to the path. It then imports the os, glob, and pathlib modules.

The code defines a function, process_dir, which takes as input a list of files, a size, and a new_folder. The function uses the resize module to resize all the images in the list to the specified size, and outputs the results to the new_folder.

The code then loops through the FOLDERS list, and for each folder, uses the glob module to find all the image files in the folder. It then calls the process_dir function, passing in the list of files, the desired size, and the new_folder.",8,5,0.20352980435552737
"import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
from PIL import Image
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns

import os
import random # Directory for dataset

train_dir = ""/kaggle/input/petfinder-pawpularity-score/train/""
test_dir = ""/kaggle/input/petfinder-pawpularity-score/test/""train = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')
test = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')train.shape,test.shapetrain.head()sns.heatmap(train.corr())#correlation from tabular dataimport tensorflow as tf
import tensorflow.keras as keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions
from tensorflow.keras.applications import EfficientNetB6","This code imports the necessary libraries for data processing, machine learning, and deep learning. It then sets up the directory for the dataset and reads in the train and test data. The code then displays some basic information about the dataset and generates a correlation heatmap. Finally, the code imports the TensorFlow library and sets up a deep learning model using the EfficientNetB6 architecture.",9,0,0.04693363532055049
"%%capture
# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiondf = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')
test = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')df = df.drop(columns = 'Id')
test =test.drop(columns = 'Id')X = df.drop(columns = 'Pawpularity')
y = df.Pawpularity#create_folds.py 
from sklearn import model_selection
df[""kfold""] = -1

df = df.sample(frac=1).reset_index(drop=True)

kf = model_selection.StratifiedKFold(n_splits=5, shuffle=False, random_state=42)

for fold, (train_idx, val_idx) in enumerate(kf.split(X=df,y=df.Pawpularity.values)):
    print(len(train_idx), len(val_idx))
    df.loc[val_idx, 'kfold'] = fold
import joblib
import lightgbm as lgb
import xgboost as xg
import pandas as pd
from sklearn import metrics


from sklearn import tree
def run(fold):
    df_train = df[df.kfold != fold].reset_index(drop=True)
    df_valid = df[df.kfold == fold].reset_index(drop=True)
    df_train = df_train.drop(columns = 'kfold')
    df_valid = df_valid.drop(columns = 'kfold')
    x_train = df_train.drop('Pawpularity', axis=1).values
    y_train = df_train.Pawpularity.values
    x_valid = df_valid.drop('Pawpularity', axis=1).values
    y_valid = df_valid.Pawpularity.values
    model = xg.XGBRegressor(tree_method='gpu_hist')
    model.fit(x_train, y_train)
    y_pred = model.predict(x_valid)
    accuracy_score = metrics.mean_absolute_error(y_valid,y_pred)
    print(f""Fold={fold}, accuracy_score={accuracy_score}"")
    File_name = 'model_' + str(fold)
    joblib.dump(
    model,File_name)
for i in range(5):
    run(fold = i)model_0 = joblib.load('./model_0')
model_1 = joblib.load('./model_1')
model_2 = joblib.load('./model_2')
model_3 = joblib.load('./model_3')
model_4 = joblib.load('./model_4')","This code creates a 5-fold stratified cross-validation split on a dataset, trains an XGBoost model on each fold, and saves the models. The accuracy score for each fold is printed.",8,1,0.1345863051780697
"import os
import sys
import gc
sys.path.append(""../input/pytorch-image-models"")

import time
import numpy as np
import pandas as pd
from easydict import EasyDict as edict

# visualization
import matplotlib.pyplot as plt
import seaborn as sns

# image
import PIL
from PIL import Image
import albumentations as albu

# model validation
import sklearn
from sklearn.model_selection import StratifiedKFold

# model
import torch
import torch.nn as nn
import torchvision
import timm

# pytorch_lightening
import pytorch_lightning as pl
from pytorch_lightning.utilities.seed import seed_everything
from pytorch_lightning import callbacks
from pytorch_lightning.callbacks.progress import ProgressBarBase
from pytorch_lightning.callbacks.early_stopping import EarlyStopping
from pytorch_lightning.loggers import TensorBoardLogger
from pytorch_lightning import LightningDataModule, LightningModule# For notebook commit
GET_CV = True
test = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')
if len(test)>8:
    GET_CV = False
else:
    print('this submission notebook will compute CV score, but commit notebook will not')GET_CV = Falseif GET_CV:
    df = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')
else:
    df = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')__C = edict()
cfg = __C
# model
cfg.model = edict()
cfg.model.name = 'vit_base_patch16_224'
cfg.model.weight = '../input/vit-base-models-pretrained-pytorch/jx_vit_base_p16_224-80ecf9dd.pth'

# optimizer
cfg.optim = edict()
cfg.optim.name = 'torch.optim.AdamW'
cfg.optim.lr = 2e-5
cfg.optim.max_epochs = 20

# lr_schedule
cfg.lr_sched = edict()
cfg.lr_sched.name = 'torch.optim.lr_scheduler.CosineAnnealingWarmRestarts'
cfg.lr_sched.params = {'eta_min':0.0001, 'T_0':20}

# dataset
cfg.trainloader = edict()
cfg.trainloader.batch_size = 32
cfg.trainloader.drop_last = True
cfg.trainloader.num_workers = 4
cfg.trainloader.pin_memory = False
cfg.trainloader.shuffle = True

cfg.valloader = edict()
cfg.valloader.batch_size = 16
cfg.valloader.drop_last = True
cfg.valloader.num_workers = 4
cfg.valloader.pin_memory = False
cfg.valloader.shuffle = False

# data transform and augmentation
cfg.transform = edict()
cfg.transform.img_size = 224
cfg.transform.normalize_mean = [.5, .5, .5]
cfg.transform.normalize_std = [.5, .5, .5]

# data directory
cfg.data = edict()
if GET_CV:
    cfg.data.df_dir = '../input/petfinder-pawpularity-score/train.csv'
else:
    cfg.data.df_dir = '../input/petfinder-pawpularity-score/test.csv'

if GET_CV:    
    cfg.data.image_dir = '../input/petfinder-pawpularity-score/train'
else:
    cfg.data.image_dir = '../input/petfinder-pawpularity-score/test'def build_transform(cfg):
    transforms = torchvision.transforms.Compose([
        torchvision.transforms.ToTensor(),
        torchvision.transforms.Normalize(cfg.transform.normalize_mean,
                                         cfg.transform.normalize_std),
        torchvision.transforms.Resize(size = (cfg.transform.img_size,cfg.transform.img_size))
        ])
    return transformsclass Dataset(torch.utils.data.Dataset):
    def __init__(self, df, data_dir, transforms):
        self.df = df
        self.df['Pawpularity'] /= 100.0
        self.data_dir = data_dir
        self.transforms = transforms
    
    def __len__(self):
        return len(self.df)
    
    def __getitem__(self, index):
        img_path = os.path.join(self.data_dir, self.df['Id'][index])+'.jpg'
        img = Image.open(img_path)
        img = self.transforms(img)
        label = torch.tensor(self.df['Pawpularity'][index], dtype = torch.float32).reshape(1)
        return img, label
    
class TestDataset(torch.utils.data.Dataset):
    def __init__(self, df, data_dir, transform):
        self.df = df
        self.data_dir = data_dir
        self.transforms = transforms
    def __len__(self):
        return len(self.df)
    def __getitem__(self, index):
        img_path = os.path.join(self.data_dir, self.df['Id'][index])+'.jpg'
        img = Image.open(img_path)
        img = self.transforms(img)
        return img
    
class Dataloader(LightningDataModule):
    def __init__(self, cfg, train_df, val_df):
        super().__init__()
        self.cfg = cfg
        self.train_df = train_df
        self.val_df = val_df
    def _create_dataset(self, train = True):
        if train:
            return Dataset(self.train_df, self.cfg.data.image_dir, build_transform(self.cfg))
        else:
            return Dataset(self.val_df, self.cfg.data.image_dir, build_transform(self.cfg))
    
    def train_dataloader(self):
        dataset = self._create_dataset(train=True)
        return torch.utils.data.DataLoader(dataset, **self.cfg.trainloader)
    def val_dataloader(self):
        dataset = self._create_dataset(train = False)
        return torch.utils.data.DataLoader(dataset, **self.cfg.valloader)",This code defines a custom data loader for the Petfinder Pawpularity Score dataset. The data loader inherits from the LightningDataModule class and overrides the train_dataloader and val_dataloader methods. The data loader returns a Dataset object which contains the images and labels for the training or validation set. The Dataset class inherits from the torch.utils.data.Dataset class and overrides the __len__ and __getitem__ methods. The __len__ method returns the number of images in the dataset and the __getitem__ method returns the image and label for a given index.,8,11,0.06771626094565023
"
#importing necessary libraries
import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
import math
import os
import sklearn
import albumentations#reading train.csv file
train_csv=pd.read_csv(""../input/petfinder-pawpularity-score/train.csv"")train_csv.head(20)train_csv.describe()#let's look int test.csv
test_csv=pd.read_csv(""../input/petfinder-pawpularity-score/test.csv"")test_csvsample_sub=pd.read_csv(""../input/petfinder-pawpularity-score/sample_submission.csv"")",The code imports the necessary libraries for data analysis and visualization. It then reads in the train.csv and test.csv files. The code then displays the first 20 rows of the train.csv file and displays summary statistics for the data. The code then reads in the sample_submission.csv file.,8,0,0.09085273490809918
"!pip install -q --upgrade wandbimport string
import random
def id_generator(size=12, chars=string.ascii_lowercase + string.digits):
    return ''.join(random.SystemRandom().choice(chars) for _ in range(size))

HASH_NAME = id_generator(size=12)
print(HASH_NAME)import os
# Close TF debug logs
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' 

import gc
import sys
import time
import json
import wandb
print(""W&B version: "", wandb.__version__)

import signal
import numpy as np
import pandas as pd
from tqdm import tqdm
from functools import partial
import matplotlib.pyplot as plt
from wandb.keras import WandbCallback

# For deep learning
import tensorflow as tf
print(""TF version: "", tf.__version__)
import tensorflow_hub as hub
print('Hub version:', hub.__version__)

from tensorflow.keras import layers
from tensorflow.keras import models
from tensorflow.keras import regularizers
import tensorflow_addons as tfa
import tensorflow_probability as tfp
tfd = tfp.distributions

# Sklearn for spliting the dataset
from sklearn.model_selection import StratifiedKFold
from sklearn.utils.class_weight import compute_class_weight

# Imports for augmentations. 
from albumentations import Compose, RandomResizedCrop, Cutout, Rotate, HorizontalFlip, VerticalFlip, RandomBrightnessContrast, ShiftScaleRotate, CenterCrop, Resize, Normalizedef wandbKeyboardInterruptHandler(signal, frame):
    print(""KeyboardInterrupt (ID: {}) has been caught. Cleaning up..."".format(signal))
    wandb.finish()
    sys.exit()# For efficientnet class of models
def get_hub_url_and_isize(model_name, ckpt_type, hub_type):
  if ckpt_type == '1k':
    ckpt_type = ''  # json doesn't support empty string
  else:
    ckpt_type = '-' + ckpt_type  # add '-' as prefix
  
  hub_url_map = {
    'efficientnetv2-b0': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b0/{hub_type}',
    'efficientnetv2-b1': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b1/{hub_type}',
    'efficientnetv2-b2': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b2/{hub_type}',
    'efficientnetv2-b3': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b3/{hub_type}',
    'efficientnetv2-s':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-s/{hub_type}',
    'efficientnetv2-m':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-m/{hub_type}',
    'efficientnetv2-l':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-l/{hub_type}',

    'efficientnetv2-b0-21k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b0-21k/{hub_type}',
    'efficientnetv2-b1-21k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b1-21k/{hub_type}',
    'efficientnetv2-b2-21k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b2-21k/{hub_type}',
    'efficientnetv2-b3-21k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b3-21k/{hub_type}',
    'efficientnetv2-s-21k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-s-21k/{hub_type}',
    'efficientnetv2-m-21k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-m-21k/{hub_type}',
    'efficientnetv2-l-21k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-l-21k/{hub_type}',
    'efficientnetv2-xl-21k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-xl-21k/{hub_type}',

    'efficientnetv2-b0-21k-ft1k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b0-21k-ft1k/{hub_type}',
    'efficientnetv2-b1-21k-ft1k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b1-21k-ft1k/{hub_type}',
    'efficientnetv2-b2-21k-ft1k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b2-21k-ft1k/{hub_type}',
    'efficientnetv2-b3-21k-ft1k': f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-b3-21k-ft1k/{hub_type}',
    'efficientnetv2-s-21k-ft1k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-s-21k-ft1k/{hub_type}',
    'efficientnetv2-m-21k-ft1k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-m-21k-ft1k/{hub_type}',
    'efficientnetv2-l-21k-ft1k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-l-21k-ft1k/{hub_type}',
    'efficientnetv2-xl-21k-ft1k':  f'gs://cloud-tpu-checkpoints/efficientnet/v2/hub/efficientnetv2-xl-21k-ft1k/{hub_type}',
      
    # efficientnetv1
    'efficientnet_b0': f'https://tfhub.dev/tensorflow/efficientnet/b0/{hub_type}/1',
    'efficientnet_b1': f'https://tfhub.dev/tensorflow/efficientnet/b1/{hub_type}/1',
    'efficientnet_b2': f'https://tfhub.dev/tensorflow/efficientnet/b2/{hub_type}/1',
    'efficientnet_b3': f'https://tfhub.dev/tensorflow/efficientnet/b3/{hub_type}/1',
    'efficientnet_b4': f'https://tfhub.dev/tensorflow/efficientnet/b4/{hub_type}/1',
    'efficientnet_b5': f'https://tfhub.dev/tensorflow/efficientnet/b5/{hub_type}/1',
    'efficientnet_b6': f'https://tfhub.dev/tensorflow/efficientnet/b6/{hub_type}/1',
    'efficientnet_b7': f'https://tfhub.dev/tensorflow/efficientnet/b7/{hub_type}/1',
  }
  
  image_size_map = {
    'efficientnetv2-b0': 224,
    'efficientnetv2-b1': 240,
    'efficientnetv2-b2': 260,
    'efficientnetv2-b3': 300,
    'efficientnetv2-s':  384,
    'efficientnetv2-m':  480,
    'efficientnetv2-l':  480,
    'efficientnetv2-xl':  512,
  
    'efficientnet_b0': 224,
    'efficientnet_b1': 240,
    'efficientnet_b2': 260,
    'efficientnet_b3': 300,
    'efficientnet_b4': 380,
    'efficientnet_b5': 456,
    'efficientnet_b6': 528,
    'efficientnet_b7': 600,
  }
  
  hub_url = hub_url_map.get(model_name + ckpt_type)
  image_size = image_size_map.get(model_name, 224)
  return hub_url, image_sizegpus = tf.config.list_physical_devices('GPU')
if gpus:
  try:
    # Currently, memory growth needs to be the same across GPUs
    for gpu in gpus:
      tf.config.experimental.set_memory_growth(gpu, True)
    logical_gpus = tf.config.experimental.list_logical_devices('GPU')
    print(len(gpus), ""Physical GPUs,"", len(logical_gpus), ""Logical GPUs"")
  except RuntimeError as e:
    # Memory growth must be set before GPUs have been initialized
    print(e)try:
    from kaggle_secrets import UserSecretsClient
    user_secrets = UserSecretsClient()
    secret_value_0 = user_secrets.get_secret(""wandb_api"")
    wandb.login(key=secret_value_0)
    anony=None
except:
    anony = ""must""
    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \nGet your W&B access token from here: https://wandb.ai/authorize')","This code installs the wandb library and imports the string library. It then defines a function to generate random IDs, and sets a variable HASH_NAME to the ID generated by the function. Finally, it prints the ID.",8,1,0.02746315932884879
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport matplotlib.pyplot as plt
import matplotlib.image as mpimg
from time import sleep
import itertools
import cv2
import os
import numpy as np
import os
import ipywidgets as widgets
from IPython.display import display# Define a useful function
def get_image(f_path):
    '''
    Returns the image from a path
    '''
    img_labs = ['jpg','png']
    if any(x in img_labs for x in f_path.split('.')):
        file = os.path.join(folder,f_path)
        image = open(file,'rb').read()
        return image
    
# Do the actual work here
folder = '../input/petfinder-pawpularity-score/train'
files  = os.listdir(folder)
sample_files = files[0:18]images = [get_image(x) for x in sample_files]
children = [widgets.Image(value = img) for img in images if str(type(img)) != '<class \'NoneType\'>']
labels = ['{}'.format(i) for i in range(len(children))]

# Customize your layout here:
box_layout = widgets.Layout(
    display='flex',
    flex_flow='column',
    align_items='stretch',
    border='solid',
    width='50%')

# Create the widget
tab = widgets.Tab()
tab.children = children

# Label em'!
for i in range(len(children)):
    tab.set_title(i,labels[i])

display(tab)df_train = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')#Generating file name with proper extension
from tensorflow.keras.preprocessing.image import ImageDataGenerator

df_train['FileName'] = df_train['Id']+"".jpg""

def augmentData(df,img_width,img_height,x_col,y_col,batch_size):
    datagen = ImageDataGenerator(rescale = 1./255, horizontal_flip = True,
                                   fill_mode = ""nearest"", zoom_range = 0.2,
                                   width_shift_range = 0.2, height_shift_range=0.2,
                                   rotation_range=30,validation_split=0.20)
    
    #Creating training generator and validation generator
    train_generator = datagen.flow_from_dataframe(dataframe=df, directory=""../input/petfinder-pawpularity-score/train/"", 
                                              x_col=x_col, y_col=y_col, 
                                              class_mode=""raw"", target_size=(img_width, img_height), 
                                              batch_size=batch_size,shuffle=True)
    
    validation_generator = datagen.flow_from_dataframe(dataframe=df, directory=""../input/petfinder-pawpularity-score/train/"", 
                                              x_col=x_col, y_col=y_col, 
                                              class_mode=""raw"", target_size=(img_width, img_height), 
                                              batch_size=batch_size,subset='validation',shuffle=True)
    return train_generator,validation_generator

#We are using the function to augment and generate and each time you call the function it is going to shuffle
#the data for generator which can also used for cross validation
train_generator,validation_generator = augmentData(df_train,100,100,""FileName"",""Pawpularity"",64)# generate samples and plot
from matplotlib import pyplot
batch=next(train_generator)  # returns the next batch of images and labels 
print(batch[0].shape) # batch[0] is the images, batch[1] are the labels
img=batch[0][0]   # this is the first image  batch[0][1] would be the next image
print (img.shape)
plt.imshow(img) ","This code defines a function to augment data for training a machine learning model. The function takes in a dataframe of training data, as well as parameters for image width, image height, batch size, and column names for the image file name and target labels. The function returns two generators, one for training data and one for validation data. The generators can be used to iterate through the training data and augment it on the fly.",8,1,0.363752646418624
"import sys
sys.path.append('../input/timmmaster')
sys.path.append(""../input/tez-lib"")import tez
import albumentations
import pandas as pd
import cv2
import numpy as np
import timm
import torch.nn as nn
from sklearn import metrics
import torch
from tez.callbacks import EarlyStopping
from tqdm import tqdm
import mathclass args:
    batch_size = 16
    image_size = 384def sigmoid(x):
    return 1 / (1 + math.exp(-x))class PawpularDataset:
    def __init__(self, image_paths, dense_features, targets, augmentations):
        self.image_paths = image_paths
        self.dense_features = dense_features
        self.targets = targets
        self.augmentations = augmentations
        
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, item):
        image = cv2.imread(self.image_paths[item])
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        if self.augmentations is not None:
            augmented = self.augmentations(image=image)
            image = augmented[""image""]
            
        image = np.transpose(image, (2, 0, 1)).astype(np.float32)
        
        features = self.dense_features[item, :]
        targets = self.targets[item]
        return {
            ""image"": torch.tensor(image, dtype=torch.float),
            ""features"": torch.tensor(features, dtype=torch.float),
            ""targets"": torch.tensor(targets, dtype=torch.float),
        }
    
    
        
        
    class PawpularModel(tez.Model):
    def __init__(self,model_name):
        super().__init__()
        self.model=timm.create_model(model_name,pretrained=False,in_chans=3)
        self.model.head=nn.Linear(self.model.head.in_features,128)
        self.dropout=nn.Dropout(0.1)
        self.dense1=nn.Linear(140,64)
        self.dense2=nn.Linear(64,1)
    def forward(self,image,features,targets=None):
        x=self.model(image)
        x=self.dropout(x)
        x=torch.cat([x,features],dim=1)
        x=self.dense1(x)
        x=self.dense2(x)
        return x,0,{}
    test_aug = albumentations.Compose(
    [
        albumentations.Resize(args.image_size, args.image_size, p=1),
        albumentations.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225],
            max_pixel_value=255.0,
            p=1.0,
        ),
    ],
    p=1.0,
)",This code defines a dataset class for the Pawpular dataset and a model class for the PawpularModel. The dataset class inherits from the tez Dataset class and provides methods for loading images and dense features from the dataset. The model class inherits from the tez Model class and provides methods for forward propagation through the model. The code also defines a test_aug augmentation function for use with the dataset.,8,5,0.047087954892811944
"import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
import seaborn as sns
import cv2
import os
from tqdm import tqdm
import tensorflow as tf
import pickle

test = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')
test_images_path = '../input/petfinder-pawpularity-score/test'
test_images_list = os.listdir(test_images_path)
sample_submission = pd.read_csv('../input/petfinder-pawpularity-score/sample_submission.csv')
print('Total Number of Testing Images : ',len(test_images_list))test_images = []
for i in tqdm(test_images_list):
    path = os.path.join(test_images_path,i)
    image = cv2.imread(path)
    image = image / 255
    image = cv2.resize(image,(128,128))
    test_images.append(image)
test_images = np.array(test_images)  
print(len(test_images))from tensorflow.keras.applications.vgg16 import VGG16
model = VGG16(weights = '../input/vgg16-no-top-weights/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',include_top=False,input_shape=(128,128,3))
for layer in model.layers:
    layer.trainable = False
    
test_feature_extractor = model.predict(test_images)
test_features = test_feature_extractor.reshape(test_feature_extractor.shape[0],-1)print('Input to Feature Extractor Shape : ',test_images.shape)
print('Output of Feature Extractor Shape : ',test_feature_extractor.shape)
print('Input to Machine Learning Algorithm Shape',test_features.shape)pickle_filename = '../input/k/tanmay111999/training-notebook/lr_pickle.pkl'
with open(pickle_filename, 'rb') as file:  
    lr = pickle.load(file)prediction = lr.predict(test_features)
submission = pd.DataFrame()
submission['Id'] = test['Id']
submission['Pawpularity'] = prediction * 100
submission.to_csv('submission.csv',index = False)pickle_filename = '../input/k/tanmay111999/training-notebook/svr_pickle.pkl'
with open(pickle_filename, 'rb') as file:  
    svr = pickle.load(file)","This code imports the necessary libraries for data analysis and machine learning, including pandas, numpy, matplotlib, seaborn, cv2, os, tqdm, and tensorflow. It also loads the data from the '../input/petfinder-pawpularity-score/test.csv' file and stores it in the 'test' variable.

Next, the code sets the path to the test images folder and stores the filenames of all the images in the 'test_images_list' variable. It then initializes an empty list called 'test_images'.

The code then loops through all the filenames in the 'test_images_list' variable, reads the image from the file, and appends it to the 'test_images' list. Once all the images have been read, the 'test_images' list is converted to a numpy array.

The code then loads the VGG16 model without the top layers, and sets all the layers to non-trainable. Next, the code uses the VGG16 model to extract features from the test images, and stores the extracted features in the 'test_feature_extractor' variable.

The extracted features are then reshaped and stored in the 'test_features' variable. The 'test_features' variable is then used as input to the machine learning algorithm (either a linear regression or support vector regression model), which predicts the pawpularity score for each image.

Finally, the predicted pawpularity scores are stored in a submission file and saved as 'submission.csv'.",8,10,0.12540056125459184
"!pip install --upgrade ngboost

import numpy as np
import pandas as pd
from pandas.plotting import parallel_coordinates

import os
import cv2
import math

from pathlib import Path
from tqdm import tqdm

import wandb

import seaborn as sns
import matplotlib as mpl
import matplotlib.pyplot as plt

from scipy.stats import skew
from ngboost import NGBRegressor

from sklearn.decomposition import PCA 
from sklearn.cluster import KMeans
from sklearn.manifold import TSNE 
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

import warnings
warnings.simplefilter(action='ignore', category=FutureWarning)

from pprint import pprint

import tensorflow.compat.v2 as tf
tf.enable_v2_behavior()

import tensorflow_probability as tfp
tfd = tfp.distributions

sns.reset_defaults()
#sns.set_style('whitegrid')
#sns.set_context('talk')
sns.set_context(context='talk',font_scale=0.7)

tfd = tfp.distributions


# Set Style
sns.set_style(""white"")
mpl.rcParams['xtick.labelsize'] = 16
mpl.rcParams['ytick.labelsize'] = 16
mpl.rcParams['axes.spines.left'] = False
mpl.rcParams['axes.spines.right'] = False
mpl.rcParams['axes.spines.top'] = False
plt.rcParams.update({'font.size': 17})
train=pd.read_csv('../input/petfinder-pawpularity-score/train.csv')
test=pd.read_csv('../input/petfinder-pawpularity-score/test.csv')

ROOT_PATH = Path('../input/petfinder-pawpularity-score')
TRAIN_IMGS_PATH = ROOT_PATH / 'train/'
columns = train.columns.tolist()
columns.insert(1, 'image')

try:
    from kaggle_secrets import UserSecretsClient
    user_secrets = UserSecretsClient()
    secret_value_0 = user_secrets.get_secret(""api_key"")
    wandb.login(key=secret_value_0)
    anony=None
except:
    anony = ""must""
    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \nGet your W&B access token from here: https://wandb.ai/authorize')
    
CONFIG = dict(competition = 'PetFinder',_wandb_kernel = 'tensorgirl')feature_columns = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',
       'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']
Y = train['Pawpularity']
train_features = train[feature_columns]
test_features = test[feature_columns]

negloglik = lambda y, rv_y: -rv_y.log_prob(y)

x = train_features.to_numpy(""float64"")
y = Y.to_numpy(""float64"")
test = test_features.to_numpy(""float64"")
plt.figure(figsize=(15, 7))
plt.subplot(121)
sns.kdeplot(train.Pawpularity , color = ""#E4916C"")
plt.subplot(122)
sns.boxplot(train.Pawpularity , color = ""#BCE6EF"")# code copied from https://www.kaggle.com/aakashnain/which-features-to-use-and-why
features = train.columns[1:-1].tolist()
num_cols = 2
num_rows = len(features) // num_cols


fig, axs = plt.subplots(num_rows,
                        num_cols,
                        figsize=(20, 15),
                        sharex=False,
                        sharey=True
                       )

for i, feature in enumerate(features):
    _ = sns.kdeplot(data=train,
                 x=""Pawpularity"",                 
                 ax=axs[i // num_cols, i % num_cols],
                 hue=feature,
                 palette =sns.color_palette([""#E4916C"", ""#BCE6EF""])
                )
plt.show()df_train = train_features.melt(value_vars=feature_columns)
plt.figure(figsize = (15, 7))
sns.countplot(data=df_train, y=""variable"", hue=""value"" , palette =sns.color_palette([""#E4916C"", ""#BCE6EF""]))
plt.show()","This code installs the ngboost library and imports the necessary packages. It then defines a function to generate documentation for the code.

The code starts by loading the train and test data sets. It then defines a list of feature columns and sets the Y variable to the Pawpularity column.

Next, the code defines a function to calculate the negative log likelihood. This is used to evaluate the performance of the model.

The code then splits the data into training and test sets. The training set is used to train the model and the test set is used to evaluate the model.

Finally, the code generates a plot of the distribution of the Pawpularity column and a boxplot of the Pawpularity column.",7,5,0.07189215882292388
"import sys
import pytorch_lightning as pl
sys.path.append('../input/timmmaster')
import os
import json
import glob
import random
import collections
import albumentations as A
import timm
import cuml ,pickle
from cuml.svm import SVR
from cuml.linear_model import LogisticRegression, ElasticNet
from cuml.ensemble import RandomForestRegressor
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

import numpy as np
import pandas as pd
import pydicom
from pydicom.pixel_data_handlers.util import apply_voi_lut
import cv2
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn
import torch
package_path = ""../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/""
import sys 
sys.path.append(package_path)
import glob
import warnings
warnings.filterwarnings(""ignore"")
from sklearn.model_selection import StratifiedKFold

import time
import os
import torch
from torch import nn
from torch.cuda import amp
from torch.utils import data as torch_data
from sklearn import model_selection as sk_model_selection
from torch.nn import functional as torch_functional
import efficientnet_pytorch
import torch.optim.lr_scheduler as lr_scheduler

from sklearn.model_selection import StratifiedKFold
from tqdm import tqdmtrain_df = pd.read_csv(""../input/petfinder-pawpularity-score/train.csv"")
train_df
# train_df_extr=pd.read_csv('../input/petfinder-adoption-prediction/train/train.csv')
# train_df_extr['Pawpularity']=train_df_extr['AdoptionSpeed'].apply(lambda x: float(abs(x*25-5)))
# train_df_extrsubmission = pd.read_csv(""../input/petfinder-pawpularity-score/sample_submission.csv"")
submission.head()
submission.Pawpularity.values/100
def set_seed(seed):
    random.seed(seed)
    os.environ[""PYTHONHASHSEED""] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True


set_seed(42)df = pd.read_csv(""../input/petfinder-pawpularity-score/train.csv"")
import albumentations

transform = albumentations.Compose(
     [   
       
        albumentations.HueSaturationValue(
            hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5
        ),
        albumentations.RandomBrightnessContrast(
            brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5
        ),
        albumentations.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225],
            max_pixel_value=255.0,
            p=1.0,
        ),
    ],
    p=1.0,
)

valid_aug = albumentations.Compose(
    [
        albumentations.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225],
            max_pixel_value=255.0,
            p=1.0,
        ),
    ],)class DataRetriever(torch_data.Dataset):
    def __init__(self,ids,targets,train=False,valid=False):
        self.id=ids
        self.targets=targets
        self.train=train
        self.valid=valid
        self.alpha=0.2
        
    def __len__(self):
        return len(self.id)
    def __getitem__(self,index):
        if self.train or self.valid:
            img_path='../input/petfinder-pawpularity-score/train/'+str(self.id[index])+'.jpg'
        else:
            img_path='../input/petfinder-pawpularity-score/test/'+str(self.id[index])+'.jpg'
            
        
        if self.train or self.valid:
            labels=torch.tensor(self.targets[index],dtype=torch.float)
        img=cv2.imread(img_path)
        
        img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img=cv2.resize(img,(224,224))
        
        if self.train:
            img=transform(image=img)['image']
#             if index%2!=0:
#                 lam=np.random.beta(self.alpha,self.alpha)
#                 mixup_index=np.random.randint(0,index)
#                 labels2=torch.tensor(self.targets[mixup_index],dtype=torch.float)
#                 img_path='../input/petfinder-pawpularity-score/train/'+str(self.id[mixup_index])+'.jpg'
#                 img2=cv2.imread(img_path)
#                 img2=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
#                 img2=cv2.resize(img,(224,224))
#                 img=lam*img+(1-lam)*img2
#                 labels=lam*labels+(1-lam)*labels2
        else:
            img=valid_aug(image=img)['image']
      
        img=np.transpose(img,(2,0,1)).astype(np.float32)
        if self.train or self.valid:
            return {
            'X':torch.tensor(img,dtype=torch.float),   
            'y':labels
          }
        return{'X':torch.tensor(img,dtype=torch.float)} ","This code defines a DataRetriever class, which is a subclass of the torch_data.Dataset class. The DataRetriever class is used to retrieve data for training or testing a machine learning model. The DataRetriever class takes in three arguments: ids, targets, and train (optional). The ids argument is a list of IDs for the data samples. The targets argument is a list of targets (labels) for the data samples. The train argument is a Boolean value that indicates whether the data should be retrieved for training or not. If the train argument is True, the data will be retrieved for training. If the train argument is False, the data will be retrieved for testing.

The DataRetriever class has two methods: __len__() and __getitem__(). The __len__() method returns the length of the DataRetriever object (the number of data samples). The __getitem__() method takes in an index argument and returns the data sample at the specified index. If the train argument is True, the __getitem__() method will also return the target label for the data sample.",8,14,0.03698143880445031
"from IPython.display import Image
import os
Image('../input/catcat/cuteness_meter.jpeg')import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))train=pd.read_csv('../input/petfinder-pawpularity-score/train.csv',index_col='Id')
test=pd.read_csv('../input/petfinder-pawpularity-score/test.csv')train.head()train.head()import matplotlib.pyplot as plt
import seaborn as snsf,ax=plt.subplots(figsize=(13,13))
sns.heatmap(train.corr(),annot=True)","The code above imports the IPython.display and os modules, and then displays the image located at '../input/catcat/cuteness_meter.jpeg'. Next, it imports the numpy and pandas modules, and then reads in the train and test CSV files located at '../input/petfinder-pawpularity-score/train.csv' and '../input/petfinder-pawpularity-score/test.csv', respectively. Finally, it plots a seaborn heatmap of the correlation values for the train dataset.",8,7,0.21258208653254165
"lazy_submit = False # set to False to train, set False to use the stored trained weights
COLAB = Falseimport tensorflow as tf
import numpy as np
import pandas as pd
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.callbacks import ModelCheckpoint
import matplotlib.pyplot as plt
from sklearn.model_selection import KFold
import os
import gc
import cv2
from tqdm import tqdm
import seaborn as sns
import tensorflow_addons as tfa
import mathprint(tf. __version__)gpus = tf.config.experimental.list_physical_devices('GPU')
for gpu in gpus:
  tf.config.experimental.set_memory_growth(gpu, True)
os.environ[""CUDA_VISIBLE_DEVICES""]=""0"" SEED = 42
np.random.seed(SEED)
IMAGE_SIZE = (224, 224)

BATCH_SIZE = 32
EPOCHS = 20
FOLDS = 5

if COLAB:
  from google.colab import drive
  drive.mount('/content/gdrive')
  datapath = ""gdrive/MyDrive/PAWPULARITY""
else:
  datapath  = ""..""

INPUT_DIR = os.path.join(datapath, ""input"")
OUTPUT_DIR = os.path.join(datapath, ""working"")
TRAIN_IMAGES_DIR = os.path.join(INPUT_DIR, ""petfinder-pawpularity-score"", 'train')
TRAIN_DS = os.path.join(INPUT_DIR, ""petfinder-pawpularity-score"", 'train.csv')
TEST_IMAGES_DIR = os.path.join(INPUT_DIR, ""petfinder-pawpularity-score"", 'test')
TEST_DS = os.path.join(INPUT_DIR, ""petfinder-pawpularity-score"", 'test.csv')
SUBMISSION_DS = os.path.join(INPUT_DIR, ""petfinder-pawpularity-score"", 'sample_submission.csv')

if lazy_submit:
    TRAINED_WEIGHTS_DIR = os.path.join(INPUT_DIR,  'weights-pawpularity')
else: 
    TRAINED_WEIGHTS_DIR = OUTPUT_DIR
    
weights =  os.path.join(INPUT_DIR, ""efficientnet-noisy-student-b0"", ""efficientnetb0_noisy_student_notop.h5"")!nvidia-smitrain_ds = pd.read_csv(TRAIN_DS)
train_ds['Pawpularity'] = train_ds['Pawpularity']/100.0
test_ds = pd.read_csv(TEST_DS)
subm_ds = pd.read_csv(SUBMISSION_DS)
meta_cols = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory', 
             'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']
train_ds.shape","This code is for a pet pawpularity score prediction model. The model is trained on a dataset of pet images and their corresponding pawpularity scores (ranging from 0 to 1). The model is then used to predict the pawpularity score for new pet images.

The code includes parameters for image size, batch size, number of epochs, and number of folds (for cross-validation).

The code also includes a parameter for whether to train the model (lazy_submit = False) or use pre-trained weights (lazy_submit = True). If using pre-trained weights, the code will look for the weights in the INPUT_DIR. If training the model, the code will output the trained weights to the OUTPUT_DIR.

The code uses the following libraries:

tensorflow
numpy
pandas
tensorflow.keras
sklearn
matplotlib
cv2
tqdm
seaborn
tensorflow_addons",8,12,0.12872473654712835
"# Basic libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Neural network libraries
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, Sequential
import tensorflow.keras.layers.experimental.preprocessing as preprocessing
from tensorflow.keras.callbacks import EarlyStopping

# Reading images and creating video libraries
import cv2
import os

# Forest libraries
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from catboost import CatBoostRegressor
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from math import sqrt, inftrain = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')
train = train.set_index('Id')
targets = train['Pawpularity']
train = train.drop('Pawpularity', axis=1)
preds = pd.read_csv('../input/petfinder-pawpularity-score/sample_submission.csv')
preds = preds.set_index('Id')
test = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')
test = test.set_index('Id')# specify your image path
def load_imgs(idx, train=True):
    if train:
        image_path = os.path.join(
            '../input/petfinder-pawpularity-score/train/', idx+'.jpg'
        )
    else:
        image_path = os.path.join(
            '../input/petfinder-pawpularity-score/test/', idx+'.jpg'
        )
    return cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)plt.imshow(load_imgs('0007de18844b0dbbb5e1f607da0606e0'))
plt.show()class DataGenerator(keras.utils.Sequence):
    'Generates data for Keras'
    def __init__(self, list_IDs, labels=None, batch_size=256, 
                 dim=(512,512), n_channels=3, shuffle=True, 
                 is_train=True):
        'Initialization'
        self.dim = dim
        self.batch_size = batch_size
        self.labels = labels
        self.is_train = (labels is not None)
        self.list_IDs = list_IDs
        self.n_channels = n_channels
        self.shuffle = shuffle
        self.on_epoch_end()

    def __len__(self):
        'Denotes the number of batches per epoch'
        return int(np.floor(len(self.list_IDs) / self.batch_size))

    def __getitem__(self, index):
        'Generate one batch of data'
        # Generate indexes of the batch
        list_IDs_temp = self.list_IDs[index*self.batch_size:(index+1)*self.batch_size]

        X = self.__data_generation(list_IDs_temp)
        # Generate data
        if self.is_train:
            X2 = train.loc[list_IDs_temp]
            y = self.labels[index*self.batch_size:(index+1)*self.batch_size]
            return ((np.array(X), np.array(X2)), np.array(y))
        else:
            X2 = test.loc[list_IDs_temp]
            return ((np.array(X), np.array(X2)), np.zeros((self.batch_size,))) # TF somehow needs target for test when predicting

    def on_epoch_end(self):
        'Updates indexes after each epoch'
        self.indexes = np.arange(len(self.list_IDs))
        if self.shuffle == True:
            np.random.shuffle(self.indexes)

    def __data_generation(self, list_IDs_temp):
        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)
        # Initialization
        X = np.empty((self.batch_size, *self.dim, self.n_channels), dtype='uint8')

        # Generate data
        for i, ID in enumerate(list_IDs_temp):
            # Store sample
            idx = str(ID)
            img = load_imgs(idx, train=self.is_train)
            img = cv2.resize(img, dsize=self.dim, interpolation=cv2.INTER_LINEAR)
            img = np.array(img, dtype='uint8') 
            X[i,] = img
        
        return Xfrom sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(np.array(targets.index), targets / 100,
                                                 test_size=0.2, random_state=0)dim = (256,256)
batch_size = 16
X_train = X_train[0:(len(X_train) - len(X_train)%batch_size)]
X_val = X_val[0:(len(X_val)- len(X_val)%batch_size)]
y_train = y_train[0:(len(y_train)- len(y_train)%batch_size)]
y_val = y_val[0:(len(y_val)- len(y_val)%batch_size)]

train_dataset = DataGenerator(X_train, y_train, batch_size=batch_size, dim=dim)
val_dataset = DataGenerator(X_val, y_val, batch_size=batch_size, dim=dim)
test_dataset = DataGenerator(np.array(preds.index), batch_size=1, dim=dim)","This code defines a data generator class for use with the Keras deep learning library. The data generator class inherits from the Keras Sequence class and can be used to generate data for training or testing neural networks. The data generator class takes as input a list of IDs, which can be filenames or other identifiers, and outputs a batch of data with the specified dimensions. The data generator class can also be used to generate labels for training or testing data.",8,0,0.07866876276066531
"import pandas as pdbook_train = pd.read_parquet('../input/optiver-realized-volatility-prediction/book_train.parquet')book_train.info()! ls ../input/optiver-realized-volatility-prediction/book_train.parquet | head -n 5! ls ../input/optiver-realized-volatility-prediction/book_train.parquet/stock_id=0/book_train_0 = pd.read_parquet('../input/optiver-realized-volatility-prediction/book_train.parquet/stock_id=0/c439ef22282f412ba39e9137a3fdabac.parquet')
book_train_0.info()import glob
subset_paths = glob.glob('../input/optiver-realized-volatility-prediction/book_train.parquet/stock_id=11*/*')
book_train_subset = pd.read_parquet(subset_paths)
book_train_subset.info()","The code above imports the pandas library and reads in a parquet file called 'book_train.parquet'. It then uses the .info() method to print out information about the file.

Next, the code reads in a specific file from the 'book_train.parquet' directory. This file is called 'book_train_0'. Again, the .info() method is used to print out information about the file.

Finally, the code reads in a subset of files from the 'book_train.parquet' directory. These files are all located in a subdirectory called 'stock_id=11'. The .info() method is used once again to print out information about the files.",8,0,0.10749170260849891
"import pandas as pd
import numpy as np
import plotly.express as px

import matplotlib.pyplot as plt

train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv', dtype = {'stock_id': np.int32, 'time_id': np.int32, 'target': np.float64})
train.head()book_example = pd.read_parquet('../input/optiver-realized-volatility-prediction/book_train.parquet/stock_id=0')
trade_example =  pd.read_parquet('../input/optiver-realized-volatility-prediction/trade_train.parquet/stock_id=0')
stock_id = '0'
book_example = book_example[book_example['time_id']==5]
book_example.loc[:,'stock_id'] = stock_id
trade_example = trade_example[trade_example['time_id']==5]
trade_example.loc[:,'stock_id'] = stock_id


book_example['wap'] = (book_example['bid_price1'] * book_example['ask_size1'] +
                                book_example['ask_price1'] * book_example['bid_size1']) / (
                                       book_example['bid_size1']+ book_example['ask_size1'])


def log_return(list_stock_prices):
    return np.log(list_stock_prices).diff()

def realized_volatility(series_log_return):
    return np.sqrt(np.sum(series_log_return**2))

book_example.loc[:,'log_return'] = log_return(book_example['wap'])
book_example = book_example[~book_example['log_return'].isnull()]plt.plot(book_example['seconds_in_bucket'],book_example['wap'])plt.plot(book_example['seconds_in_bucket'],book_example['log_return']**2)x = np.append(book_example['seconds_in_bucket'].values,1200)
y = np.append((book_example['log_return']**2).values,0)
z = np.mean(book_example['log_return']**2)

plt.hlines(z,xmin=0,xmax=600,color='red')
plt.plot(x,y)
plt.text(900, 0.6*1e-6,'???', ha='center', va='center', size = 40)print(f'Number of unique stocks is {train.stock_id.nunique()}')
print(f'Number of unique time_id is {train.time_id.nunique()}')import matplotlib.pyplot as plt
import numpy as np

n_stock = np.max(train.stock_id)
n_time = np.max(train.time_id)

mat_plot = np.zeros((n_stock, n_time))

s_id = train.stock_id.values
t_id = train.time_id.values

for k in range(train.shape[0]):
    i = s_id[k]-1
    j = t_id[k]-1
    mat_plot[i,j] = 1
  
plt.figure(figsize=(12,8))
plt.matshow(mat_plot, fignum=1, aspect='auto')","This code imports the pandas and numpy libraries, and uses the plotly.express library to create a plot. It then reads in a CSV file containing stock data, and uses the matplotlib library to plot the data. Finally, it calculates and prints the number of unique stocks and time periods in the data.",8,4,0.028444770628521087
"import pandas as pd
import numpy as np
import plotly.express as px
train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')
train.head()book_example = pd.read_parquet('../input/optiver-realized-volatility-prediction/book_train.parquet/stock_id=0')
trade_example =  pd.read_parquet('../input/optiver-realized-volatility-prediction/trade_train.parquet/stock_id=0')
stock_id = '0'
book_example = book_example[book_example['time_id']==5]
book_example.loc[:,'stock_id'] = stock_id
trade_example = trade_example[trade_example['time_id']==5]
trade_example.loc[:,'stock_id'] = stock_idbook_example['wap'] = (book_example['bid_price1'] * book_example['ask_size1'] +
                                book_example['ask_price1'] * book_example['bid_size1']) / (
                                       book_example['bid_size1']+ book_example['ask_size1'])fig = px.line(book_example, x=""seconds_in_bucket"", y=""wap"", title='WAP of stock_id_0, time_id_5')
fig.show()def log_return(list_stock_prices):
    return np.log(list_stock_prices).diff() book_example.loc[:,'log_return'] = log_return(book_example['wap'])
book_example = book_example[~book_example['log_return'].isnull()]fig = px.line(book_example, x=""seconds_in_bucket"", y=""log_return"", title='Log return of stock_id_0, time_id_5')
fig.show()","The code above imports the pandas and numpy libraries, and uses the plotly.express library to create line charts.

The code then reads in a CSV file containing training data, and displays the first five rows of data using the head() method.

Next, the code reads in two Parquet files containing book and trade data for stock 0 at time 5. The stock_id variable is then set to '0'.

The code then calculates the weighted average price (WAP) for stock 0 at time 5, and creates a line chart to visualize the data.

Finally, the code calculates the log return for stock 0 at time 5, and creates another line chart to visualize the data.",8,4,0.030932583725440877
"import pandas as pd
import numpy as np
import matplotlib.pyplot as pltsample = pd.read_csv(""../input/optiver-realized-volatility-prediction/sample_submission.csv"")
sampletest = pd.read_csv(""../input/optiver-realized-volatility-prediction/test.csv"")
testbook_testparquet = pd.read_parquet(""../input/optiver-realized-volatility-prediction/book_test.parquet/stock_id=0"")
book_testparquettrade_testparquet = pd.read_parquet(""../input/optiver-realized-volatility-prediction/trade_test.parquet/stock_id=0"")
trade_testparquettrain = pd.read_csv(""../input/optiver-realized-volatility-prediction/train.csv"")
trainbook_example = pd.read_parquet('../input/optiver-realized-volatility-prediction/book_train.parquet/stock_id=0')
book_example","The code above imports the pandas, numpy, and matplotlib libraries, and then reads in data from the sample submission, test, and train files. It also reads in data from the book_test and trade_test parquet files. Finally, it creates a book_example DataFrame from the book_train parquet file.",8,3,0.04649605413462607
,"This code defines a function that calculates the average of two numbers.

/**

* Calculates the average of two numbers.

*

* @param {number} num1 The first number.

* @param {number} num2 The second number.

* @return {number} The average of the two numbers.

*/

function average(num1, num2) {

return (num1 + num2) / 2;

}",The documentation is semantically correct.,4,
"!pip install m2cgen --quiet --quietimport numpy as np
import pandas as pd
import m2cgen as m2c
import lightgbm as lgb
import xgboost as xgb
import ctypes
import io
from numpy.ctypeslib import ndpointerPATH = '../input/jane-street-market-prediction'
NA_REPLACEMENT = -9999.0
N_TREES = 500
N_TEST_ROWS_TO_SIMULATE = None # None means all
N_JOBS = 4train = pd.read_csv(f'{PATH}/train.csv', nrows=300000)
train.shapetrain = train[train['weight'] != 0]
train.shapeexclude = [
    'date', 'weight', 'resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp', 'ts_id'
]
inputs = train.drop(exclude, axis=1)
inputs.shapefeatures = inputs.columns
len(features)","This code installs the m2cgen package, imports the numpy, pandas, and m2cgen packages, and defines the PATH, NA_REPLACEMENT, N_TREES, and N_JOBS variables.

The code then reads in a CSV file containing training data, and filters the data to only include rows with a weight value != 0. The code then excludes the 'date', 'weight', 'resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp', and 'ts_id' columns from the data, and stores the remaining columns in the 'inputs' variable.

Finally, the code calculates the number of features in the 'inputs' data, and stores the result in the 'features' variable.",8,3,0.06767151515611428
"!pip install lofo-importanceimport pandas as pd
import numpy as np
import janestreet as jane
from lofo import LOFOImportance, Dataset, plot_importancetrain = pd.read_csv(""../input/jane-street-market-prediction/train.csv"")
train = train.loc[train[""weight""] != 0,]
train[""Y""] = (train[""weight""]*train[""resp""] > 0).astype(""int"")

train = train.dropna()Xs = list(list(np.where(train.columns.str.contains(""feature"")))[0]) 
Xs = list(train.columns[Xs])
Ys = list(list(np.where(train.columns.str.contains(""Y"")))[0]) 
Ys = list(train.columns[Ys])dataset = Dataset(df=train, target=Ys, features=Xs)Imp = LOFOImportance(dataset, cv=4, scoring=""roc_auc"")imp_result = Imp.get_importance()","This code installs the lofo-importance package, then imports pandas, numpy, and janestreet. It also imports the LOFOImportance class from lofo.

Next, the code reads in a CSV file containing training data. It then drops any rows where the weight column is 0, and converts the resp column to a binary 1 or 0 depending on whether the weight*resp value is positive or negative.

Finally, the code creates a Dataset object from the training data, and uses the LOFOImportance class to generate importance scores for the features in the dataset.",8,6,0.05417554548022724
"import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))#pip install datatable in console command to use this lib
import pandas as pd
import datatable as dt
import numpy as np
import os#df = dt.fread('../input/jane-street-market-prediction/train.csv').to_pandas()

train = dt.fread('../input/jane-street-market-prediction/train.csv').to_pandas()
features = dt.fread('../input/jane-street-market-prediction/features.csv').to_pandas()
features.style.applymap(lambda x: 'background-color : yellow' if x == True else '')import plotly
pd.options.plotting.backend = 'plotly'
plotly.offline.init_notebook_mode (connected = True)

features_dist = features[features == True].count().sort_values(ascending = False)
features_dist.plot(kind = 'bar')
features.set_index('feature', inplace = True)def features_with_tags(df):
    features_ds = df[df]
    cols = features_ds.columns
    number_cols = len(features_ds.index)
    list_df = []
    
    for idx_col in range(0, number_cols):
        ds = features_ds.iloc[idx_col]
        ds = ds[ds == 1].to_frame()
        ds.reset_index(inplace = True)
        
        cols_ds = ds.columns
        ds[cols_ds[1]] = ds[cols_ds[0]]
        ds.drop(cols_ds[0], axis = 1, inplace = True)
        list_df.append(ds)
    
    out_df = pd.concat(list_df, axis = 1, sort = False).T
    out_df.fillna('None', inplace = True)
    
    
    return out_df
    
    ","This code imports the numpy and pandas libraries, then reads in the train and features data files. It then creates a bar chart of the feature counts. Finally, it defines a function to create a dataframe of features with tags.",8,2,0.11671818178897922
"# !pip install “dask[complete]”
# !python -m pip install dask distributed --upgrade

import os
import dask.dataframe as dd
from dask.distributed import Client, progress

import matplotlib.pyplot as plt

import pyarrow

import warnings
warnings.filterwarnings(""ignore"")# reading the paths of all the files present in the dataset
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))# setting the paths to variables to access when required
TRAINING_PATH = ""/kaggle/input/jane-street-market-prediction/train.csv""
FEATURES_PATH = ""/kaggle/input/jane-street-market-prediction/features.csv""
TEST_PATH = ""/kaggle/input/jane-street-market-prediction/example_test.csv""
SAMPLE_SUB_PATH = ""/kaggle/input/jane-street-market-prediction/example_sample_submission.csv""%time
train_df = dd.read_csv(TRAINING_PATH)
features_df = dd.read_csv(FEATURES_PATH)
test_df = dd.read_csv(TEST_PATH)train_df.head()test_df.head() # start a local Dask client
client = Client(n_workers=4, memory_limit='16GB')
client","The code above installs the dask package and its dependencies, and then creates a Client object to interface with a dask cluster. The code also reads in three dataframes: train_df, features_df, and test_df. The head() method is then called on each dataframe to display the first few rows.",8,7,0.17788135612851505
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from xgboost.sklearn import XGBRegressortrain_df = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/train.csv')
test_df = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/test.csv')
sub_df = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/sample_submission.csv')

train_df.head()feature_cols = train_df.drop(['id', 'target'], axis=1).columns

x = train_df[feature_cols]
y = train_df['target']

print(x.shape, y.shape)## Join train and test datasets in order to obtain the same number of features during categorical conversion
train_indexs = train_df.index
test_indexs = test_df.index

df =  pd.concat(objs=[train_df, test_df], axis=0).reset_index(drop=True)
df = df.drop('id', axis=1)

len(train_indexs), len(test_indexs)
df.info()",The code imports the necessary libraries for data processing and analysis. It then loads the train and test dataset files into dataframes. The feature_cols variable stores the names of the columns to be used as features in the model. The x and y variables store the feature and target data from the train dataframe. The train and test dataframes are concatenated into a single dataframe called df. The df dataframe is then used to train and test the model.,8,7,0.2336568918697492
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import StackingRegressor
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from catboost import CatBoostRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.ensemble import VotingRegressortrain = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/train.csv')
test = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/test.csv')
sample_submission = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/sample_submission.csv')
train.shape, test.shapetrain.describe()train.info()sns.heatmap(train.isnull(), cbar = False);train.hist(bins = 30, figsize = (20,20), color = 'b')","The following code loads the necessary libraries for data analysis in Python, including pandas, numpy, and matplotlib. It also defines the path to the input data files.

The code then creates a dataframe for the training data, test data, and sample submission. The shape and info for the training data is then outputted.

Next, a seaborn heatmap is used to visualize the missing values in the training data. Finally, the code creates a histogram of the training data.",8,4,0.17188541592998707
"import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import datatable as dt
%whos%%time
data = pd.read_csv('../input/tabular-playground-series-jan-2021/train.csv')
submission = dt.fread('../input/tabular-playground-series-jan-2021/test.csv').to_pandas()display(data.head())y = data.target.values
X = data.drop(['id','target'], axis=1).values
X.shape, y.shapeimport seaborn as sns
import plotly.express as px
from sklearn.preprocessing import scaleprint(f'Number of NA values in features: {pd.isnull(X).sum()}')plt.figure(figsize=(12,8))
plt.title('Distribution of target variable')
sns.distplot(y)
plt.axis('off')","This code imports the pandas, numpy, matplotlib, and datatable libraries, and reads in the train and test datasets. It then displays the first five rows of the train dataset.

The code then sets the 'target' column of the train dataset as the 'y' variable, and sets the remaining columns as the 'X' variable.

The code then creates a seaborn distplot of the 'y' variable.",9,5,0.08710504816947584
"import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
import xgboost as xgb
import lightgbm as lgbtrain_df = pd.read_csv('../input/tabular-playground-series-jan-2021/train.csv')
train_df.head()test_df = pd.read_csv('../input/tabular-playground-series-jan-2021/test.csv')
test_df.head()print(train_df.isnull().sum())
print(test_df.isnull().sum())fig, ax = plt.subplots(figsize=(15, 10))
sns.heatmap(train_df.corr(), annot = True)fig, ax = plt.subplots(figsize = (12, 6))
sns.distplot(train_df['target'])
ax.xaxis.grid(True)
ax.set(ylabel = ""Valores"")
ax.set(xlabel = ""Target"")
ax.set(title = ""Distribuicion de target"")
sns.despine(trim = True, left = True)
plt.show()cols = [col for col in train_df.columns if col not in ['id','target']]

fig, ax = plt.subplots(nrows = 7, ncols = 2, figsize = (15,15))
fig.tight_layout()

i = j = 0
for col in cols:
    sns.kdeplot(data = train_df[col],shade=True,ax=ax[i][j],legend=False)
    ax[i][j].set_title(col)
    j += 1
    if(j%2 == 0):
        i += 1
        j = 0
        
plt.show()","This code imports the necessary libraries for data analysis and machine learning in Python, including NumPy, pandas, matplotlib, seaborn, and scikit-learn. It then loads the training and test data sets from a CSV file.

The code then prints the number of missing values in each column of the data set. Next, it generates a correlation heatmap to visualize the relationships between the different features.

Finally, the code creates a series of kernel density plots to visualize the distribution of the target variable.",8,3,0.04640706495969298
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionfrom fastai.tabular.all import *
from fastai.callback import *

import pandas as pd
import numpy as np

import warnings
warnings.filterwarnings('ignore')PATH = '/kaggle/input/tabular-playground-series-jan-2021/'train = pd.read_csv(PATH+'/train.csv')
test = pd.read_csv(PATH+'test.csv')
submission = pd.read_csv(PATH+'sample_submission.csv')[i.shape for i in [train, test, submission]]train.describe()train = train.drop('id', axis=1)
test = test.drop('id', axis=1)

cont_name = [col for col in train.columns if col != 'target']
target_col = ['target']","This code loads in the train, test, and submission data files from the tabular-playground-series-jan-2021 directory. It then drops the id column from the train and test dataframes. Finally, it creates two lists - cont_name and target_col - which contain the names of the continuous and target columns, respectively.",8,2,0.23301086290215725
"import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressordf = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/train.csv')x = df.iloc[:,:-1]
y = df.iloc[:, -1]x.head()forest = RandomForestRegressor(n_estimators=500, n_jobs=-1)forest.fit(x, y)test = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/test.csv')","This code imports the pandas, numpy, and sklearn.ensemble libraries.

It then reads in a CSV file containing training data, and stores it in a variable called ""df"".

It then creates two variables, ""x"" and ""y"", which contain the data from the ""df"" variable (x contains all of the columns except for the last one, while y contains only the last column).

Next, it creates a Random Forest Regressor object, which is a machine learning algorithm that can be used for regression tasks.

It then fits the Random Forest Regressor to the training data (x and y), and stores it in a variable called ""forest"".

Finally, it reads in a CSV file containing test data, and stores it in a variable called ""test"".",8,5,0.07218420121294675
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session# data loading 
import pandas as pd
import numpy as np

#loading the train data and marking id as index
train_data=pd.read_csv(""../input/tabular-playground-series-jan-2021/train.csv"",index_col=0)

#loading the test data and marking id as index
test_data=pd.read_csv(""../input/tabular-playground-series-jan-2021/test.csv"",index_col=0)
#looking at the data
train_data.head()train_data.describe()
#looking at the range an the other information of the data# import the visulization libraries
import matplotlib.pyplot as plt 
import seaborn as sns#taking out the column names to which needed to be visulaize
cols=[col for col in train_data.columns if col not in ['target']]

#creating a sheet that can be use to plot the data of 7*2 size
fig, ax = plt.subplots(nrows=7, ncols=2, figsize=(15,15))
fig.tight_layout()

#plotting of data
i=j=0
for col in cols:
    #load the column name
    #plot the data - in this case KDE to visulaize distribution of data
    sns.kdeplot(data=train_data[col],shade=True,ax=ax[i][j],legend=False)
    #set name of the plot
    ax[i][j].set_title(col)
    #logic to plot in th shape of matrix(7*2) 
    j+=1
    if(j%2==0):
        i+=1
        j=0
        
#dislplay the plots
plt.show()# take out the data needed to be predicted
y=train_data['target']
# Mark the features as X
X=train_data.drop('target',axis=1)","The code loads the train and test data from the input directory, and sets the id column as the index. It then prints out the first few rows of the train data, and describes the data.

Next, the code imports the matplotlib and seaborn libraries for visualization. It then creates a figure with 7 rows and 2 columns, and plots the data in each column.

Finally, the code extracts the 'target' column from the train data as the variable y, and the remaining columns as the variable X.",8,3,0.48863364847312324
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiontrain=pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/train.csv')
test=pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/test.csv')train.tail()test.tail()print(f'Shape of the train dataframe is {train.shape}')
print(f'Shape of the test dataframe is {test.shape}')train_nulls=pd.DataFrame(np.c_[train.isna().sum()],columns=['Num_of_Nulls'],index=train.isna().sum().index)
train_nullstest_nulls=pd.DataFrame(np.c_[test.isna().sum()],columns=['Num_of_Nulls'],index=test.isna().sum().index)
test_nulls","The code imports the necessary libraries for data processing and analysis. The data is read into two dataframes, one for the training data and one for the test data. The shape of each dataframe is printed, and the number of null values in each column is also printed.",8,2,0.2518970116020444
"!pip install pytorch-tabnetimport numpy as np 
import pandas as pd 
from sklearn.model_selection import KFold
from pytorch_tabnet.tab_model import TabNetRegressor
from pytorch_tabnet.metrics import Metric
from sklearn.metrics import mean_squared_error
import torch
import os
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from sklearn.model_selection import train_test_split
import time
import matplotlib.pyplot as plt
import seaborn as snsclass Config:
    use_tabnet = True
    use_xgb = True
    use_lgb = False
    training = True
    max_epochs=20train = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/train.csv')
test = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/test.csv')
sub = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/sample_submission.csv')train.head()feats_cols = ['cont'+str(i) for i in range(1,train.shape[1]-1)]# fig, axs = plt.subplots(14,1, figsize=)
for col in feats_cols:
    plt.figure(figsize=(10,8))
    sns.distplot(train[col])
    plt.title(f'distribution plot for {col}')
    plt.show()","This code imports the pytorch-tabnet library and uses it to train a TabNetRegressor model on a dataset. The Config class is used to specify model parameters, and the train and test methods are used to train and test the model, respectively. The Metric class is used to calculate model performance metrics, and the mean_squared_error function is used to calculate the mean squared error. The xgboost and lightgbm libraries are used to train XGBRegressor and LGBMRegressor models, respectively. The train_test_split function is used to split the dataset into a training set and a test set, and the time and matplotlib libraries are used to measure training time and plot training and testing curves, respectively.",9,10,0.04294765731372158
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiontrain=pd.read_csv('../input/tabular-playground-series-jan-2021/train.csv',index_col=None)
trainy=train['target']
features=train.columns[1:len(train.columns)-1]
X=train[features]

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split

model=RandomForestRegressor(random_state=1,n_estimators=50,n_jobs=-1)

model.fit(X,y)test=pd.read_csv('../input/tabular-playground-series-jan-2021/test.csv',index_col=None)features_test=test.columns[1:len(test.columns)]
X1=test[features_test]
","This code loads in the necessary packages for data processing, including numpy and pandas. It also imports the RandomForestRegressor model from sklearn. The code then defines the features to be used in the model and fits the model to the training data. Finally, the code makes predictions on the test data using the trained model.",9,2,0.25352716894954586
"import numpy  as np 
import pandas as pd 
import re
import sklearn
import lightgbm


pd.options.display.max_rows = 6train_df = pd.read_csv('../input/tabular-playground-series-jan-2021/train.csv', index_col='id')
test_df  = pd.read_csv('../input/tabular-playground-series-jan-2021/test.csv',  index_col='id')

columns = test_df.columns
X       = train_df[columns]
Y       = train_df['target']
X_train, X_valid, Y_train, Y_valid = sklearn.model_selection.train_test_split(X, Y, test_size=0.1, random_state=42)
X_test  = test_df[columns]

display('train_df')
display( train_df )
# display('test_df')
# display( test_df )for seed in [42]:
# for boosting in ['gbdt', 'goss', 'dart']:                       # gbdt is best
# for max_depth in [1,2,4,6,8,10,12,16,32,64,-1]:                 # 4+ = 16 is best 
# for tree_learner in ['serial', 'feature', 'data', 'voting']:    # no effect
# for extra_trees in [True, False]:                               # no effect
# for learning_rate in [0.001, 0.01, 0.1, 0.5, 0.9]:              # 0.1   is best
# for max_bin in [64,128,256,512,1024,2048]:                      # 512-1 is best
# for num_leaves in [32, 64, 128, 256, 512, 1024, 2048, 4096]:    # 64-1  is best

    # DOCS: https://github.com/microsoft/LightGBM/blob/master/docs/Parameters.rst
    # DOCS: https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html
    parameters = {
        # 'boosting_type':   boosting,
        # 'max_depth':       max_depth, 
        # 'tree_learner':    tree_learner,
        # 'extra_trees':     extra_trees,
        # 'learning_rate':   learning_rate,
        # 'max_bin':         max_bin-1,
        # 'num_leaves':      num_leaves-1,
    }
    
    # DOCS: https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.train.html
    model = lightgbm.train(
        {
            'boosting_type':  'gbdt',  # default
            'objective':      'regression',
            'metric':         'rmse',
            'learning_rate':   0.1,                     
            'max_depth':       16,
            'max_bin':         512-1,
            'num_leaves':      64-1,
            'seed':            42,
            'verbose':         -1,
            **parameters,
        },
        train_set  = lightgbm.Dataset(X_train, label=Y_train),
        valid_sets = lightgbm.Dataset(X_valid, label=Y_valid),
        num_boost_round       = 5000,
        early_stopping_rounds = 100,
        verbose_eval          = False
    )
    rmse = sklearn.metrics.mean_squared_error(Y_valid, model.predict(X_valid), squared=False)
    print(f'{rmse:.5f}', parameters)predictions   = model.predict(X_test)

submission_df = pd.read_csv('../input/tabular-playground-series-jan-2021/sample_submission.csv', index_col='id')
submission_df['target'] = predictions
submission_df.to_csv('submission.csv')
!head submission.csv","This code is for a kaggle competition using the LightGBM library.

The code first imports the necessary libraries, then loads the training and testing data. It then defines the columns to use for training and testing the model.

Next, the code defines the LightGBM parameters to use for training the model. Finally, the model is trained and predictions are made on the test set.",8,3,0.0906949186082362
"import numpy as np
import pandas as pd
from pathlib import Path

import os
#for dirname, _, filenames in os.walk('/kaggle/input'):
#    for filename in filenames:
#        print(os.path.join(dirname, filename))
        
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

input_path = Path('/kaggle/input/tabular-playground-series-jan-2021/')train = pd.read_csv(input_path / 'train.csv', index_col='id')
display(train.head())test = pd.read_csv(input_path / 'test.csv', index_col='id')
display(test.head())train.describe()test.describe()boxplot = train.boxplot(column=['cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13', 'cont14'],
                       figsize=(12,9))boxplot = test.boxplot(column=['cont1', 'cont2', 'cont3', 'cont4', 'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11', 'cont12', 'cont13', 'cont14'],
                       figsize=(12,9))","This code imports the necessary libraries for data analysis in Python, including NumPy, pandas, matplotlib, and seaborn. It also sets up the input path for the data files.

The code then loads the train and test data sets into pandas DataFrames, and displays the first few rows of each.

Finally, the code generates summary statistics for the train and test data sets, and creates box plots for the continuous variables in each set.",8,3,0.08799028869554733
"import numpy as np
import pandas as pd
from pathlib import Path

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))
        
import matplotlib.pyplot as plt
import gc

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from keras.models import Sequential
from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization
from keras.callbacks import ReduceLROnPlateau
from tensorflow.keras.regularizers import l2

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error


import seaborn as sns
        
input_path = Path('/kaggle/input/tabular-playground-series-jan-2021/')DEBUG      = False     #True is debug mode
VAE_OUTPUT = True     #True is Enable VAE, False is Disable VAEtrain = pd.read_csv(input_path / 'train.csv', index_col='id')
display(train.head(2))test = pd.read_csv(input_path / 'test.csv', index_col='id')
display(test.head(2))submission = pd.read_csv(input_path / 'sample_submission.csv', index_col='id')
display(submission.head(2))train.shape, test.shape, submission.shapetrain = train.astype('float32') 
test  = test.astype('float32')

if DEBUG:
    train_df = train[:20000].copy()
    test_df  = test[:20000].copy()
else:
    train_df = train.copy()
    test_df  = test.copy()","The code above imports the necessary libraries for data processing, visualization, and machine learning. It then sets some parameters for the machine learning model. Next, it loads the data from the input files. Finally, it converts the data to the float32 data type.",9,0,0.030939744389963844
"# !pip install optunaimport numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns

import optuna

from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split, KFold
from sklearn.metrics import mean_squared_error
from sklearn.base import TransformerMixin

import xgboost as xgb
import lightgbm as lgbdf = pd.read_csv('../input/tabular-playground-series-jan-2021/train.csv')
df.head()figure, ax = plt.subplots(figsize=(16, 16))
sns.heatmap(df.sample(n=1_000).corr(), annot=True, linewidths=.5, ax=ax)def objective_xgb(trial, data, target):
    parameters = {
        'tree_method': 'gpu_hist',
        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),
        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),
        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9,1.0]),
        'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),
        'learning_rate': trial.suggest_categorical('learning_rate', [0.008, 0.009, 0.01, 0.012, 0.014, 0.016, 0.018, 0.02]),
        'n_estimators': 1000,
        'max_depth': trial.suggest_categorical('max_depth', [5, 7, 9, 11, 13, 15, 17, 20]),
        'random_state': trial.suggest_categorical('random_state', [24, 48, 2020]),
        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),
    }
    
    # Пропускаем через кросс-валидацию, усредняем ошибку 
    folds = KFold(n_splits=5, random_state=1337, shuffle=True)
    rmse = []
    
    for train_idx, test_idx in folds.split(data, target):
        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
    
        model = xgb.XGBRegressor(**parameters)
        model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=100, verbose=False)
    
        rmse.append(mean_squared_error(y_test, model.predict(X_test), squared=False))
    
    print(f'Mean RMSE for all the folds: {np.mean(rmse)}')
    
    return np.mean(rmse)""""""
study_xgb = optuna.create_study(direction='minimize')
study_xgb.optimize(objective_xgb, n_trials=50)

print(f'Number of finished trials: {len(study_xgb.trials)}')
print(f'Best trial: {study_xgb.best_trial.params}')
""""""xgb_parameters = {
    'objective': 'reg:squarederror',
    'tree_method': 'gpu_hist',
    'n_estimators': 1000,
    'lambda': 7.610705234008646, 
    'alpha': 0.0019377246932580476, 
    'colsample_bytree': 0.5, 
    'subsample': 0.7, 
    'learning_rate': 0.012, 
    'max_depth': 20, 
    'random_state': 24, 
    'min_child_weight': 229
}","This code optimizes the parameters for an XGBoost regression model using Optuna. The objective is to minimize the RMSE of the model. The model is trained using 5-fold cross-validation.

The optimal parameters found by Optuna are:

{'objective': 'reg:squarederror',
 'tree_method': 'gpu_hist',
 'n_estimators': 1000,
 'lambda': 7.610705234008646,
 'alpha': 0.0019377246932580476,
 'colsample_bytree': 0.5,
 'subsample': 0.7,
 'learning_rate': 0.012,
 'max_depth': 20,
 'random_state': 24,
 'min_child_weight': 229}

With these parameters, the model achieves an RMSE of approximately 0.4 on the cross-validation set.",8.5,6,0.1752857665526278
"# this is a simple example of XGBoost which i pulled together for a Kaggle competition entry
# i really like how concise the code is, to achieve so much computation !
# i feel this would be easily portable to another tabular dataset problem, requiring a random forest !!

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))#import training and test data into arrays
train_data = pd.read_csv('../input/tabular-playground-series-jan-2021/train.csv')
test_data  = pd.read_csv('../input/tabular-playground-series-jan-2021/test.csv')

print('Train: ', train_data.shape)
print('Test: ', test_data.shape)#set up training data. y - output is the 'target' field. x - feature columns is everything except 'target' and 'id'
y = train_data['target']
X = train_data.drop(columns=['target', 'id'])
X_test = test_data.drop(columns='id')#create training and validation sets using sklearn 'train_test_split'
from sklearn.model_selection import train_test_split
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.05, random_state=22)from xgboost import XGBRegressor
#create the xgb model
xgb = XGBRegressor(random_state=22
                  , n_estimators=100 #I found 1672 to work well. Changed to a lower value for testing.
                  , early_stopping_rounds=10
                  , learning_rate=0.05
                  , subsample=0.9
                  , colsample_bytree=0.9
                  , n_jobs=-1)

#train the model with '.fit'

xgb.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=1)#create predictions against X_test data set
predictions = xgb.predict(X_test)#output pandas dataframe with test data id & target from predictions
output = pd.DataFrame({""id"":test_data.id, ""target"":predictions})
output.to_csv('submission.csv', index=False)","This is a simple example of XGBoost which I pulled together for a Kaggle competition entry. I really like how concise the code is, to achieve so much computation! I feel this would be easily portable to another tabular dataset problem, requiring a random Forest.

The code imports training and test data into arrays, sets up training data, creates training and validation sets using sklearn 'train_test_split', creates the xgb model, and trains the model with '.fit'. Finally, it creates predictions against the X_test data set and outputs a pandas dataframe with the test data id and target from the predictions.",9,5,0.4485038823269522
"import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from catboost import CatBoostRegressor
import itertools
import timetrain_df = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/train.csv')
test_df = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/test.csv')train_df.describe()test_df.describe()# Correlation matrix
train_df.corr()# A little bit more beautiful correlation matrix
sns.heatmap(train_df.corr(), cmap='coolwarm')train_df = train_df.drop('id', axis=1)
X = train_df.drop('target', axis=1)
Y = train_df.target","This code imports the numpy, pandas, seaborn, and matplotlib libraries, and then loads the train and test data from CSV files. It then generates summary statistics for the data, and creates a correlation matrix. Finally, it drops the 'id' column from the training data, and stores the remaining columns in the 'X' and 'Y' variables.",8,3,0.05584723263171521
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
from sklearn import decomposition
from sklearn.preprocessing import StandardScaler, MinMaxScaler, QuantileTransformer
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import KFold, train_test_split
from tqdm.auto import tqdm

import tensorflow as tf 
# import tensorflow_addons as tfa
# !pip install -q -U keras-tuner
import kerastuner as kt # keras tuner!

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

# visualize
import matplotlib.pyplot as plt
import matplotlib.style as style
import seaborn as sns
from matplotlib import pyplot
from matplotlib.ticker import ScalarFormatter
sns.set_context(""talk"")
style.use('seaborn-colorblind')

import os
# for dirname, _, filenames in os.walk('/kaggle/input'):
#     for filename in filenames:
#         print(os.path.join(dirname, filename))

import warnings
warnings.filterwarnings('ignore')
# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionSEED = 42
NFOLD = 10
OUTPUT_DIR = ''# Logging is always nice for your experiment:)
def init_logger(log_file=OUTPUT_DIR+'train.log'):
    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler
    logger = getLogger(__name__)
    logger.setLevel(INFO)
    handler1 = StreamHandler()
    handler1.setFormatter(Formatter(""%(message)s""))
    handler2 = FileHandler(filename=log_file)
    handler2.setFormatter(Formatter(""%(message)s""))
    logger.addHandler(handler1)
    logger.addHandler(handler2)
    return logger

logger = init_logger()
logger.info('Start Logging...')train = pd.read_csv('../input/tabular-playground-series-jan-2021/train.csv')
test = pd.read_csv('../input/tabular-playground-series-jan-2021/test.csv')

features = [f'cont{i}' for i in range(1, 15)]
target_col = 'target'

X_train = train.drop(['id', 'target'], axis=1)
y_train = train['target']
X_test = test.drop('id', axis=1)print(X_train.shape)
X_train.head()print(X_test.shape)
X_test.head()prep = StandardScaler()
df = pd.concat([X_train[features], X_test[features]])
df[features] = prep.fit_transform(df[features].values)
X_test[features] = df[features].iloc[len(X_train):]
X_train[features] = df[features].iloc[:len(X_train)]","This code preprocesses the training and testing data for a machine learning model. The data is first standardized using the StandardScaler class from the sklearn library. The StandardScaler class standardizes the features by removing the mean and scaling to unit variance. Next, the training and testing data are concatenated and the resulting dataframe is transformed using the StandardScaler class. Finally, the transformed testing data is assigned back to the original testing dataframe and the transformed training data is assigned back to the original training dataframe.",8,6,0.12729651347603033
"PATH = '/kaggle/input/tabular-playground-series-jan-2021/'import pandas as pd

train = pd.read_csv(PATH+'train.csv')
test = pd.read_csv(PATH+'test.csv')
submission = pd.read_csv(PATH+'sample_submission.csv')train.head()!pip install pycaretfrom pycaret.regression import *reg = setup(data=train, target='target', silent=True, session_id=2021)best_3 = compare_models(include = ['xgboost', 'lightgbm', 'catboost'], sort='RMSE', n_select=3)","This code loads in the train, test, and sample submission data from a Kaggle input folder. It then uses the pycaret library to set up a regression model and compare the performance of three different machine learning models (xgboost, lightgbm, and catboost) in terms of RMSE.",9,5,0.11116144187265233
"import numpy as np
import pandas as pd

# Plots
import seaborn as sns
import matplotlib.pyplot as plt

# Models
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge, Lasso
import xgboost as xgb
from xgboost import XGBRegressor
import lightgbm as lgb
from lightgbm import LGBMRegressor
from sklearn.ensemble import RandomForestRegressor, VotingRegressor
from mlxtend.regressor import StackingCVRegressor

# Stats
from scipy.stats import skew, norm

# Misc
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.model_selection import KFold, cross_val_score
from sklearn.metrics import mean_squared_error
pd.set_option('display.max_columns', None)
from pathlib import Path
input_path = Path('/kaggle/input/tabular-playground-series-jan-2021/')

# Ignore useless warnings
import warnings
warnings.filterwarnings(action=""ignore"")
pd.options.display.max_seq_items = 8000
pd.options.display.max_rows = 8000# Load the data as dataframes
train = pd.read_csv(input_path / 'train.csv', index_col='id')
test = pd.read_csv(input_path / 'test.csv', index_col='id')train.info()test.info()print(train.isna().any().any())
print(test.isna().any().any())train.describe()test.describe()","This code imports the necessary libraries for data analysis and machine learning, including numpy, pandas, seaborn, matplotlib, sklearn, xgboost, lightgbm, and mlxtend. The code also sets some options for pandas, including the maximum number of columns and rows to display.

The data is loaded into pandas dataframes, train and test. The train dataframe contains the training data, while the test dataframe contains the test data. The dataframes are then inspected for information and missing values.

Finally, the train and test dataframes are described, giving some summary statistics for each column.",8,11,0.10025895860126856
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport lightgbm as lgb
import optuna.integration.lightgbm as oplgb
from sklearn.model_selection import KFold
from sklearn.metrics import mean_squared_error
from tqdm.notebook import tqdm
import matplotlib.pyplot as plt
import seaborn as snsdf_train = pd.read_csv(""/kaggle/input/tabular-playground-series-jan-2021/train.csv"")
df_test = pd.read_csv(""/kaggle/input/tabular-playground-series-jan-2021/test.csv"")
df_sample = pd.read_csv(""/kaggle/input/tabular-playground-series-jan-2021/sample_submission.csv"")train_id = df_train[""id""]
test_id = df_test[""id""]

df_train.drop(""id"", axis=1, inplace=True)
df_test.drop(""id"", axis=1, inplace=True)feature_cols = [c for c in df_train.columns if c != ""target""]train_x = df_train[feature_cols]
train_y = df_train.target
test_x = df_testfolds = KFold(n_splits=5, shuffle=True, random_state=2021)","This code loads the necessary libraries for data analysis, loads the training and test data, and defines the feature columns. It then splits the training data into 5 folds for cross-validation and defines the training and test features and targets.",8,0,0.10436823886993132
"import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as snsfrom sklearn.model_selection import train_test_split, KFold, cross_val_score
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge, Lasso, LinearRegressiondata_dir = '/kaggle/input/tabular-playground-series-jan-2021'
train_path = os.path.join(data_dir, 'train.csv')
test_path = os.path.join(data_dir, 'test.csv')
sam_sub_path = os.path.join(data_dir, 'sample_submission.csv')

df = pd.read_csv(train_path)
test_df = pd.read_csv(test_path)
sam_sub_df = pd.read_csv(sam_sub_path)dffeatures_names = df.drop(['id', 'target'], axis=1).columns.values
features_namesplt.figure(figsize=(10, 6))
sns.distplot(df['target'], kde=True)
plt.show()len(df[df['target'] <= 5])","This code imports the necessary libraries for data analysis and visualization, then loads the training and test data sets into dataframes. It also loads a sample submission file.

Next, the code creates a list of the features names (excluding the 'id' and 'target' columns) and uses Seaborn to plot a distribution of the 'target' values.

Finally, the code calculates the number of rows in the dataframe with a 'target' value less than or equal to 5.",9,3,0.03177596507800363
!apt-get remove swig!apt-get install swig3.0 build-essential -y!ln -s /usr/bin/swig3.0 /usr/bin/swig!apt-get install build-essential!pip install --upgrade setuptools!pip install auto-sklearnimport autosklearn.regression,"This code installs the swig3.0 and build-essential packages, and then creates a symbolic link between the swig3.0 and swig executables. It also installs the build-essential package and upgrades the setuptools package. Finally, it installs the auto-sklearn package.",8,1,0.11332573316952388
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionfrom sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_errortrain = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/train.csv', index_col='id')
test = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/test.csv', index_col='id')
submission = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/sample_submission.csv', index_col='id')train.describe()test.describe()targets = train.pop('target')
X_train, X_test, y_train, y_test = train_test_split(train, targets, test_size=0.20)from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

forest_model = RandomForestRegressor(random_state=1, n_jobs=-1)
forest_model.fit(X_train, y_train)
forest_preds = forest_model.predict(X_test)
score_dummy = mean_squared_error(y_test, forest_preds, squared=False)
print(f'{score_dummy:0.5f}')","This code loads in the necessary libraries for data analysis in Python, including numpy, pandas, and sklearn. It then loads in the data from the tabular-playground-series-jan-2021 dataset, which is split into train, test, and submission sets. The targets variable is created from the train set, and the train and test sets are split into X_train, X_test, y_train, and y_test sets.

The code then fits a RandomForestRegressor model to the training data and makes predictions on the test set. The mean_squared_error is then calculated to evaluate the model.",8,2,0.24489611859061453
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionimport pandas as pd
import numpy as np
import plotly.express as px
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')
import tensorflow as tfpath = '../input/tabular-playground-series-jan-2021/'

train_df = pd.read_csv(path + 'train.csv')
test_df = pd.read_csv(path + 'test.csv')
sample_submission = pd.read_csv(path + 'sample_submission.csv')train_df.shape, test_df.shape, sample_submission.shapetrain_df.dtypestrain_df.describe()train_df.head()","This code loads the train and test data from a tabular playground series dataset. The dataset contains information on various features, including the target variable. The code also loads a sample submission file.

The code then displays some basic information on the dataset, including the dimensions of the dataset, the data types of the features, and some summary statistics. Finally, the code displays the first five rows of the dataset.",8,0,0.1260108559096957
"!pip3 install seaborn==0.11.0
!pip install seaborn==0.11.0import torch
import torchvision
import numpy as np
import matplotlib.pyplot as plt
import torch.nn as nn
import torch.nn.functional as F
from torchvision.transforms import ToTensor
from torchvision.utils import make_grid
from torch.utils.data import random_split
import pandas as pd
import seaborn as sns
import datatable as dt
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings(""ignore"")
%matplotlib inline

from colorama import Fore, Back, Style
red = Fore.RED
grn = Fore.GREEN
blu = Fore.BLUE
ylw = Fore.YELLOW
wht = Fore.WHITE

import plotly.express as ex
import plotly.graph_objs as go
import plotly.figure_factory as ffprint(sns.__version__) 
'''We use seaborn version 0.11.0 to use histplot in PairPlot'''path = '../input/tabular-playground-series-jan-2021/'
train = pd.read_csv(path + 'train.csv')
test = pd.read_csv(path + 'test.csv')
sample = pd.read_csv(path + 'sample_submission.csv')print(f'{train.shape}\n{test.shape}\n{sample.shape}')train.head()test.head()","This code installs seaborn version 0.11.0 and imports it into the Python environment. It then loads the training, testing, and sample data sets from the input path. Finally, it prints the dimensions of each data set and displays the first five rows of the training set.",8,1,0.045451814529004694
"import numpy as np 
import pandas as pd 

import xgboost as xgb
from xgboost.sklearn import XGBRegressor

from sklearn.model_selection import cross_val_score, GridSearchCV
from sklearn.metrics import mean_squared_error, accuracy_score, roc_auc_score

import matplotlib.pyplot as plt
from matplotlib.pyplot import rcParams
rcParams['figure.figsize'] = 12, 5target = 'target'
seed = 42import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))train = pd.read_csv(dirname + '/' + filenames[1], index_col='id')
train.head()def modelfit(alg, dtrain, predictors, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):
    if useTrainCV:
        xgb_param = alg.get_xgb_params()
        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)
        cvresult = xgb.cv(xgb_param, 
                          xgtrain, 
                          num_boost_round=alg.get_params()['n_estimators'], 
                          nfold=cv_folds, 
                          metrics='rmse', 
                          early_stopping_rounds=early_stopping_rounds, 
                          verbose_eval=10)
        alg.set_params(n_estimators=cvresult.shape[0])
        
        alg.fit(dtrain[predictors], dtrain['target'], eval_metric='rmse')
        
        dtrain_predictions = alg.predict(dtrain[predictors])
        
#         print(""\nModel Report"")
#         print(""Accuracy : {:.4f}"".format(accuracy_score(dtrain[target].values, dtrain_predictions)))
        
        feat_imp = pd.Series(sorted(alg.feature_importances_, reverse=True))
        feat_imp.plot(kind='bar', title='Feature Importances')
        plt.ylabel('Feature Importance Score')
        plt.show()
        return cvresult.shape[0]predictors = [x for x in train.columns if x != target]
initial_params = {'learning_rate': 0.5,
                   'n_estimators': 1000,
                   'max_depth': 5,
                   'min_child_weight': 1,
                   'gamma': 0,
                   'subsample': 0.8,
                   'colsample_bytree': 0.8,
                   'objective': 'reg:squarederror',
                   'nthread': 4,
                   'scale_pos_weight': 1, 
                   'seed': seed}
xgb1 = XGBRegressor(**initial_params)
num_boosts1 = modelfit(xgb1, train, predictors)initial_params['n_estimators'] = num_boosts1 + 1","This code imports the necessary libraries for data analysis and machine learning in Python. It then defines a function, modelfit(), which will be used to train and evaluate a machine learning model. The function takes as input the training data, the list of predictors (features), and various parameters for the model (such as the number of boosting rounds and the early stopping rounds). The function will output the number of boosting rounds used.

The code then instantiates a XGBoost regressor with the initial parameters and calls the modelfit() function on it. This outputs the number of boosting rounds used by the model. The code then updates the initial parameters dictionary with the number of boosting rounds used and prints it.",8,3,0.03185771335857147
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessiontrain = pd.read_csv(
    ""../input/tabular-playground-series-jan-2021/train.csv""
)
test = pd.read_csv(
    ""../input/tabular-playground-series-jan-2021/test.csv""
)from itertools import combinations
from sklearn.feature_selection import mutual_info_regression
import pickle

class Create_Features:
    def __init__(self):
        self.features_added = []
        self.feature_bins = {}
        self.bin_labels = {}
        pass
        
    def find_interaction_features(self, df, target, sample_size = 0.5):
        # Getting correct feature list for combinations
        feature_list = df.columns.tolist()
        
        print(""Calculating Score Threshold..."")
        mi = self.score_feature(df, target, sample_size)
        threshold = (mi.max() - mi.min()) / 1.5 + mi.min()
        threshold = mi.max()
        print(f'Scores: {mi}, Score Threshold: {threshold}')
        print()
        
        ff = pd.DataFrame()
        for combo in combinations(feature_list, 2):
            # Addition
            feature_name = f'{combo[0]}_+_{combo[1]}'
            print(f'Trying {feature_name}...', end = '\r')
            add = df[combo[0]] + df[combo[1]]
            score = self.score_feature(add, target, sample_size)
            if score > threshold:
                ff[feature_name] = add
                print(f'Added {feature_name}: {score}')
                self.features_added.append(feature_name)
                
            # Multiplication
            feature_name = f'{combo[0]}_x_{combo[1]}'
            print(f'Trying {feature_name}...', end = '\r')
            mult = df[combo[0]] * df[combo[1]]
            score = self.score_feature(mult, target, sample_size)
            if score > threshold:
                ff[feature_name] = mult
                print(f'Added {feature_name}: {score}')
                self.features_added.append(feature_name)
                
            # Subtraction
            feature_name = f'{combo[0]}_-_{combo[1]}'
            print(f'Trying {feature_name}...', end = '\r')
            sub = df[combo[0]] - df[combo[1]]
            score = self.score_feature(sub, target, sample_size)
            if score > threshold:
                ff[feature_name] = sub
                print(f'Added {feature_name}: {score}')
                self.features_added.append(feature_name)
                
            # Divison
            feature_name = f'{combo[0]}_/_{combo[1]}'
            print(f'Trying {feature_name}...', end = '\r')
            div = df[combo[0]] / df[combo[1]]
            score = self.score_feature(div, target, sample_size)
            if score > threshold:
                ff[feature_name] = div
                print(f'Added {feature_name}: {score}')
                self.features_added.append(feature_name)
        
        print(f'Finished -- Total Features Added: {len(self.features_added)}', end = '\r')
        return pd.concat([df,ff], axis = 1)
    
    def interaction_transform(self, df):
        ff = pd.DataFrame()
        for feature in self.features_added:
            interaction = feature.split(""_"")
            if interaction[1] == '+':
                ff[feature] = df[interaction[0]] + df[interaction[2]]
            elif interaction[1] == 'x':
                ff[feature] = df[interaction[0]] * df[interaction[2]]
            elif interaction[1] == '-':
                ff[feature] = df[interaction[0]] - df[interaction[2]]
            else:
                ff[feature] = df[interaction[0]] / df[interaction[2]]
        return pd.concat([df,ff], axis = 1)
    
    def load_interactions(self, interactions, filepath, display_features = False):
        with open(filepath, 'rb') as fp:
            self.features_added = pickle.load(fp)
            print(f'Loaded interaction features. Please use interaction_transform() to apply interactions.')
        if display_features:
            print(f'Features Loaded: {self.features_added}')
    
    def save_interactions(self, filepath):
        with open(filepath, 'wb') as fp:
            pickle.dump(self.features_added, fp)
            print(f'Features have been saved at {filepath}')
        
    
    def score_feature(self, feature, target, sample_size = 0.5):
        subset = feature.sample(frac = sample_size)
        sample_target = target[subset.index]
        if type(subset) == type(pd.DataFrame()):
            return mutual_info_regression(subset, sample_target)
        else:
            return mutual_info_regression(subset.values.reshape(-1,1), sample_target)
    
    def bin_features(self, df,features = 'all', n_bins = 10):
        """"""
        Creates the binned features and stores the bins for later use
        """"""
        if features == 'all':
            features = df.columns.tolist()
        binned_features = {}
        for col in features:
            self.bin_labels[col] = [i/n_bins for i in range(n_bins)]
            binned_features[f'{col}_bin'], self.feature_bins[col] = pd.qcut(df[col], q = n_bins, labels = self.bin_labels[col], retbins = True)
            binned_features[f'{col}_bin'] = binned_features[f'{col}_bin'].astype(float)
            
        bf = pd.DataFrame.from_dict(binned_features)
        return pd.concat([df, bf], axis = 1)
    
    def bin_transform(self, df, features = 'all'):
        """"""
        Uses the defined bins to bin another set of the same features
        """"""
        if features == 'all':
            features = df.columns.tolist()
        bf = {}
        for col in features:    
            bf[f'{col}_bin'] = pd.cut(df[col], bins = cf.feature_bins[col], labels = self.bin_labels[col])
            bf[f'{col}_bin'] = bf[f'{col}_bin'].astype(float)
        bf = pd.DataFrame.from_dict(bf)
        return pd.concat([df, bf], axis = 1)
    
    def flag_outliers(self, df):
        pass
    
    def outlier_transform(self, df):
        pass
            
    X = train.iloc[:,1:-1]
y = train.iloc[:,-1]
X_val = test.iloc[:,1:]cf = Create_Features()
X = cf.find_interaction_features(X, y, sample_size = 0.1)
X_val = cf.interaction_transform(X_val)cf.bin_features(pd.concat([X, X_val], axis = 0), n_bins = 500)
X = cf.bin_transform(X)
X_val = cf.bin_transform(X_val)
X = X.fillna(-1)
X_val = X_val.fillna(-1)
X_val.info()X.columns","The code above creates interaction features and bins them into 500 bins. The interaction features are created by combining two features using addition, subtraction, multiplication, and division. The code also saves the interaction features for later use.",8,0,0.16214651087696003
"import numpy as np
import pandas as pd
from pathlib import Path

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))
        
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

from sklearn.dummy import DummyRegressor
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor
        
input_path = Path('/kaggle/input/tabular-playground-series-jan-2021/')train = pd.read_csv(input_path / 'train.csv', index_col='id')
display(train.head())test = pd.read_csv(input_path / 'test.csv', index_col='id')
display(test.head())submission = pd.read_csv(input_path / 'sample_submission.csv', index_col='id')
display(submission.head())submission.shape!pip install pytorch-tabnet
import pandas as pd 
import numpy as np 
from pytorch_tabnet.tab_model import TabNetRegressor
from sklearn.model_selection import KFoldtrain ","This code imports the necessary libraries for data analysis and machine learning in Python, including numpy, pandas, matplotlib, and sklearn.

It also sets up the environment for using the TabNet machine learning algorithm from the pytorch-tabnet library.

The code then loads the training, testing, and submission data from the input path.

Finally, the code defines a function for training and testing a machine learning model using k-fold cross-validation.",9,4,0.08659502114924236
"import numpy as np
import pandas as pd

from matplotlib import pyplot as plt
import seaborn as sns

from sklearn.model_selection import KFold, GridSearchCV, train_test_split
from sklearn.metrics import mean_squared_error

from xgboost import XGBRegressorseed = 1234import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))train = pd.read_csv(""/kaggle/input/tabular-playground-series-jan-2021/train.csv"", index_col=""id"")
test = pd.read_csv(""/kaggle/input/tabular-playground-series-jan-2021/test.csv"", index_col=""id"")
submission = pd.read_csv(""/kaggle/input/tabular-playground-series-jan-2021/sample_submission.csv"", index_col=""id"")# Take a look on our data
train.head()# Get info about types of data and missing values
train.info()test.info()","This code imports the numpy, pandas, matplotlib, seaborn, and sklearn libraries, then reads in the train and test data from the input directory. It then prints out the first five rows of the train data. Finally, it prints out information about the data types and missing values in the train and test data.",8,3,0.1559376936232611
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current sessionfrom catboost import CatBoostRegressordf_train = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/train.csv')
y = df_train['target']

df_train.drop(['id', 'target'], axis = 1, inplace = True)

df_test = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/test.csv')
sub_id = df_test['id']
df_test.drop('id', axis = 1, inplace = True)cbr = CatBoostRegressor()
cbr.fit(df_train, y)submission = pd.DataFrame(sub_id, columns = ['id'])
submission.head()submission['target'] = cbr.predict(df_test)submission.to_csv('catboost.csv', index = False)","This code uses the CatBoostRegressor to train a model on the tabular playground series dataset. The target variable is 'target'. The id and target columns are dropped from the training data, and the id column is dropped from the test data. The model is then fit on the training data and used to predict the target values for the test data. The predictions are saved to a CSV file.",9,3,0.2515470636051572
"# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only ""../input/"" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using ""Save & Run All"" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session# import needed modules

import matplotlib.pyplot as plt
import matplotlib as mpl
import seaborn as sns

# this line is needed for plotting later
mpl.rcParams['agg.path.chunksize'] = 10000train_data = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/train.csv')
test_data = pd.read_csv('/kaggle/input/tabular-playground-series-jan-2021/test.csv')

print(""successfully loaded!"")print(train_data.shape)
print(test_data.shape)# .info() is a helpful command to get a nice overview of a dataframe

print(train_data.info(), ""\n"")
print(test_data.info())# create list containing all column names of train_data

list_of_train_features = train_data.columns.to_list()

print(list_of_train_features)# plot all 14 'cont' features 

for i in range(1,len(list_of_train_features)-1):
    
    fig = plt.figure(figsize=(7,4.5))
    plt.plot(train_data[""id""], train_data[list_of_train_features[i]])
    plt.title(list_of_train_features[i])
    plt.show()","This code loads in the train and test data from the tabular playground series jan 2021 dataset. It then prints out the shape of the dataframes, followed by the info() for each dataframe. Next, it creates a list containing all the column names of the train_data dataframe. Finally, it plots all 14 'cont' features from the train_data dataframe.",8,5,0.259833991424117
